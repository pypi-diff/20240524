# Comparing `tmp/gym_jiminy-1.8.5.post1-py3-none-any.whl.zip` & `tmp/gym_jiminy-1.8.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,41 @@
-Zip file size: 119155 bytes, number of entries: 35
--rw-r--r--  2.0 unx      230 b- defN 24-Apr-30 00:34 gym_jiminy/common/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-30 00:34 gym_jiminy/common/py.typed
--rw-r--r--  2.0 unx     1548 b- defN 24-Apr-30 00:34 gym_jiminy/common/bases/__init__.py
--rw-r--r--  2.0 unx    10466 b- defN 24-Apr-30 00:34 gym_jiminy/common/bases/blocks.py
--rw-r--r--  2.0 unx    14953 b- defN 24-Apr-30 00:34 gym_jiminy/common/bases/interfaces.py
--rw-r--r--  2.0 unx    40957 b- defN 24-Apr-30 00:34 gym_jiminy/common/bases/pipeline.py
--rw-r--r--  2.0 unx    18035 b- defN 24-Apr-30 00:34 gym_jiminy/common/bases/quantity.py
--rw-r--r--  2.0 unx      385 b- defN 24-Apr-30 00:34 gym_jiminy/common/blocks/__init__.py
--rw-r--r--  2.0 unx    37430 b- defN 24-Apr-30 00:34 gym_jiminy/common/blocks/deformation_estimator.py
--rw-r--r--  2.0 unx    17212 b- defN 24-Apr-30 00:34 gym_jiminy/common/blocks/mahony_filter.py
--rw-r--r--  2.0 unx    10089 b- defN 24-Apr-30 00:34 gym_jiminy/common/blocks/motor_safety_limit.py
--rw-r--r--  2.0 unx    26459 b- defN 24-Apr-30 00:34 gym_jiminy/common/blocks/proportional_derivative_controller.py
--rw-r--r--  2.0 unx      178 b- defN 24-Apr-30 00:34 gym_jiminy/common/envs/__init__.py
--rw-r--r--  2.0 unx    70853 b- defN 24-Apr-30 00:34 gym_jiminy/common/envs/generic.py
--rw-r--r--  2.0 unx    18748 b- defN 24-Apr-30 00:34 gym_jiminy/common/envs/locomotion.py
--rw-r--r--  2.0 unx      118 b- defN 24-Apr-30 00:34 gym_jiminy/common/envs/internal/__init__.py
--rw-r--r--  2.0 unx     9350 b- defN 24-Apr-30 00:34 gym_jiminy/common/envs/internal/play.py
--rw-r--r--  2.0 unx      367 b- defN 24-Apr-30 00:34 gym_jiminy/common/quantities/__init__.py
--rw-r--r--  2.0 unx    11998 b- defN 24-Apr-30 00:34 gym_jiminy/common/quantities/generic.py
--rw-r--r--  2.0 unx     4496 b- defN 24-Apr-30 00:34 gym_jiminy/common/quantities/locomotion.py
--rw-r--r--  2.0 unx     7024 b- defN 24-Apr-30 00:34 gym_jiminy/common/quantities/manager.py
--rw-r--r--  2.0 unx     2318 b- defN 24-Apr-30 00:34 gym_jiminy/common/utils/__init__.py
--rw-r--r--  2.0 unx    21000 b- defN 24-Apr-30 00:34 gym_jiminy/common/utils/math.py
--rw-r--r--  2.0 unx     8920 b- defN 24-Apr-30 00:34 gym_jiminy/common/utils/misc.py
--rw-r--r--  2.0 unx    10189 b- defN 24-Apr-30 00:34 gym_jiminy/common/utils/pipeline.py
--rw-r--r--  2.0 unx    54010 b- defN 24-Apr-30 00:34 gym_jiminy/common/utils/spaces.py
--rw-r--r--  2.0 unx      421 b- defN 24-Apr-30 00:34 gym_jiminy/common/wrappers/__init__.py
--rw-r--r--  2.0 unx     6153 b- defN 24-Apr-30 00:34 gym_jiminy/common/wrappers/flatten.py
--rw-r--r--  2.0 unx     4039 b- defN 24-Apr-30 00:34 gym_jiminy/common/wrappers/normalize.py
--rw-r--r--  2.0 unx     7770 b- defN 24-Apr-30 00:34 gym_jiminy/common/wrappers/observation_filter.py
--rw-r--r--  2.0 unx    10955 b- defN 24-Apr-30 00:34 gym_jiminy/common/wrappers/observation_stack.py
--rw-r--r--  2.0 unx     1659 b- defN 24-Apr-30 00:35 gym_jiminy-1.8.5.post1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-30 00:35 gym_jiminy-1.8.5.post1.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-30 00:35 gym_jiminy-1.8.5.post1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3290 b- defN 24-Apr-30 00:35 gym_jiminy-1.8.5.post1.dist-info/RECORD
-35 files, 431723 bytes uncompressed, 113779 bytes compressed:  73.6%
+Zip file size: 140754 bytes, number of entries: 39
+-rw-r--r--  2.0 unx      230 b- defN 24-May-24 13:32 gym_jiminy/common/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-24 13:32 gym_jiminy/common/py.typed
+-rw-r--r--  2.0 unx     2111 b- defN 24-May-24 13:32 gym_jiminy/common/bases/__init__.py
+-rw-r--r--  2.0 unx    10466 b- defN 24-May-24 13:32 gym_jiminy/common/bases/blocks.py
+-rw-r--r--  2.0 unx    15016 b- defN 24-May-24 13:32 gym_jiminy/common/bases/compositions.py
+-rw-r--r--  2.0 unx    15008 b- defN 24-May-24 13:32 gym_jiminy/common/bases/interfaces.py
+-rw-r--r--  2.0 unx    45685 b- defN 24-May-24 13:32 gym_jiminy/common/bases/pipeline.py
+-rw-r--r--  2.0 unx    40273 b- defN 24-May-24 13:32 gym_jiminy/common/bases/quantities.py
+-rw-r--r--  2.0 unx      385 b- defN 24-May-24 13:32 gym_jiminy/common/blocks/__init__.py
+-rw-r--r--  2.0 unx    38819 b- defN 24-May-24 13:32 gym_jiminy/common/blocks/deformation_estimator.py
+-rw-r--r--  2.0 unx    17162 b- defN 24-May-24 13:32 gym_jiminy/common/blocks/mahony_filter.py
+-rw-r--r--  2.0 unx    10420 b- defN 24-May-24 13:32 gym_jiminy/common/blocks/motor_safety_limit.py
+-rw-r--r--  2.0 unx    25999 b- defN 24-May-24 13:32 gym_jiminy/common/blocks/proportional_derivative_controller.py
+-rw-r--r--  2.0 unx      427 b- defN 24-May-24 13:32 gym_jiminy/common/compositions/__init__.py
+-rw-r--r--  2.0 unx     8443 b- defN 24-May-24 13:32 gym_jiminy/common/compositions/generic.py
+-rw-r--r--  2.0 unx     1695 b- defN 24-May-24 13:32 gym_jiminy/common/compositions/locomotion.py
+-rw-r--r--  2.0 unx      178 b- defN 24-May-24 13:32 gym_jiminy/common/envs/__init__.py
+-rw-r--r--  2.0 unx    67627 b- defN 24-May-24 13:32 gym_jiminy/common/envs/generic.py
+-rw-r--r--  2.0 unx    18319 b- defN 24-May-24 13:32 gym_jiminy/common/envs/locomotion.py
+-rw-r--r--  2.0 unx      118 b- defN 24-May-24 13:32 gym_jiminy/common/envs/internal/__init__.py
+-rw-r--r--  2.0 unx     9350 b- defN 24-May-24 13:32 gym_jiminy/common/envs/internal/play.py
+-rw-r--r--  2.0 unx      717 b- defN 24-May-24 13:32 gym_jiminy/common/quantities/__init__.py
+-rw-r--r--  2.0 unx    34327 b- defN 24-May-24 13:32 gym_jiminy/common/quantities/generic.py
+-rw-r--r--  2.0 unx     7415 b- defN 24-May-24 13:32 gym_jiminy/common/quantities/locomotion.py
+-rw-r--r--  2.0 unx    10684 b- defN 24-May-24 13:32 gym_jiminy/common/quantities/manager.py
+-rw-r--r--  2.0 unx     2580 b- defN 24-May-24 13:32 gym_jiminy/common/utils/__init__.py
+-rw-r--r--  2.0 unx    22567 b- defN 24-May-24 13:32 gym_jiminy/common/utils/math.py
+-rw-r--r--  2.0 unx     8920 b- defN 24-May-24 13:32 gym_jiminy/common/utils/misc.py
+-rw-r--r--  2.0 unx    22481 b- defN 24-May-24 13:32 gym_jiminy/common/utils/pipeline.py
+-rw-r--r--  2.0 unx    54061 b- defN 24-May-24 13:32 gym_jiminy/common/utils/spaces.py
+-rw-r--r--  2.0 unx      420 b- defN 24-May-24 13:32 gym_jiminy/common/wrappers/__init__.py
+-rw-r--r--  2.0 unx     6153 b- defN 24-May-24 13:32 gym_jiminy/common/wrappers/flatten.py
+-rw-r--r--  2.0 unx     4039 b- defN 24-May-24 13:32 gym_jiminy/common/wrappers/normalize.py
+-rw-r--r--  2.0 unx     7770 b- defN 24-May-24 13:32 gym_jiminy/common/wrappers/observation_filter.py
+-rw-r--r--  2.0 unx    11380 b- defN 24-May-24 13:32 gym_jiminy/common/wrappers/observation_stack.py
+-rw-r--r--  2.0 unx     1604 b- defN 24-May-24 13:33 gym_jiminy-1.8.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-24 13:33 gym_jiminy-1.8.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 24-May-24 13:33 gym_jiminy-1.8.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3663 b- defN 24-May-24 13:33 gym_jiminy-1.8.6.dist-info/RECORD
+39 files, 526615 bytes uncompressed, 134786 bytes compressed:  74.4%
```

## zipnote {}

```diff
@@ -6,21 +6,24 @@
 
 Filename: gym_jiminy/common/bases/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/bases/blocks.py
 Comment: 
 
+Filename: gym_jiminy/common/bases/compositions.py
+Comment: 
+
 Filename: gym_jiminy/common/bases/interfaces.py
 Comment: 
 
 Filename: gym_jiminy/common/bases/pipeline.py
 Comment: 
 
-Filename: gym_jiminy/common/bases/quantity.py
+Filename: gym_jiminy/common/bases/quantities.py
 Comment: 
 
 Filename: gym_jiminy/common/blocks/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/blocks/deformation_estimator.py
 Comment: 
@@ -30,14 +33,23 @@
 
 Filename: gym_jiminy/common/blocks/motor_safety_limit.py
 Comment: 
 
 Filename: gym_jiminy/common/blocks/proportional_derivative_controller.py
 Comment: 
 
+Filename: gym_jiminy/common/compositions/__init__.py
+Comment: 
+
+Filename: gym_jiminy/common/compositions/generic.py
+Comment: 
+
+Filename: gym_jiminy/common/compositions/locomotion.py
+Comment: 
+
 Filename: gym_jiminy/common/envs/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/envs/generic.py
 Comment: 
 
 Filename: gym_jiminy/common/envs/locomotion.py
@@ -87,20 +99,20 @@
 
 Filename: gym_jiminy/common/wrappers/observation_filter.py
 Comment: 
 
 Filename: gym_jiminy/common/wrappers/observation_stack.py
 Comment: 
 
-Filename: gym_jiminy-1.8.5.post1.dist-info/METADATA
+Filename: gym_jiminy-1.8.6.dist-info/METADATA
 Comment: 
 
-Filename: gym_jiminy-1.8.5.post1.dist-info/WHEEL
+Filename: gym_jiminy-1.8.6.dist-info/WHEEL
 Comment: 
 
-Filename: gym_jiminy-1.8.5.post1.dist-info/top_level.txt
+Filename: gym_jiminy-1.8.6.dist-info/top_level.txt
 Comment: 
 
-Filename: gym_jiminy-1.8.5.post1.dist-info/RECORD
+Filename: gym_jiminy-1.8.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gym_jiminy/common/bases/__init__.py

```diff
@@ -1,54 +1,70 @@
 # pylint: disable=missing-module-docstring
 
-from .quantity import (SharedCache,
-                       QuantityCreator,
-                       AbstractQuantity)
 from .interfaces import (DT_EPS,
                          ObsT,
                          ActT,
                          BaseObsT,
                          BaseActT,
                          InfoType,
                          SensorMeasurementStackMap,
                          EngineObsType,
                          InterfaceObserver,
                          InterfaceController,
                          InterfaceJiminyEnv)
+from .quantities import (QuantityCreator,
+                         QuantityEvalMode,
+                         SharedCache,
+                         InterfaceQuantity,
+                         AbstractQuantity,
+                         StateQuantity,
+                         DatasetTrajectoryQuantity)
+from .compositions import (AbstractReward,
+                           BaseQuantityReward,
+                           BaseMixtureReward)
 from .blocks import (BlockStateT,
                      InterfaceBlock,
                      BaseObserverBlock,
                      BaseControllerBlock)
 from .pipeline import (NestedObsT,
                        BasePipelineWrapper,
                        BaseTransformObservation,
                        BaseTransformAction,
+                       ComposedJiminyEnv,
                        ObservedJiminyEnv,
                        ControlledJiminyEnv)
 
 
 __all__ = [
-    'SharedCache',
-    'QuantityCreator',
-    'AbstractQuantity',
     'DT_EPS',
     'ObsT',
     'NestedObsT',
     'ActT',
     'BaseObsT',
     'BaseActT',
     'BlockStateT',
     'InfoType',
     'SensorMeasurementStackMap',
     'EngineObsType',
+    'SharedCache',
     'InterfaceObserver',
     'InterfaceController',
     'InterfaceJiminyEnv',
     'InterfaceBlock',
+    'InterfaceQuantity',
+    'AbstractQuantity',
+    'AbstractReward',
+    'BaseQuantityReward',
+    'BaseMixtureReward',
     'BaseObserverBlock',
     'BaseControllerBlock',
     'BasePipelineWrapper',
     'BaseTransformObservation',
     'BaseTransformAction',
+    'ComposedJiminyEnv',
     'ObservedJiminyEnv',
     'ControlledJiminyEnv',
+    'QuantityEvalMode',
+    'QuantityCreator',
+    'StateQuantity',
+    'DatasetTrajectoryQuantity'
 ]
```

## gym_jiminy/common/bases/interfaces.py

```diff
@@ -133,39 +133,32 @@
                         controller if any, the target motors efforts of the
                         environment to ultimately control otherwise. It must be
                         updated in-place.
         """
 
     def compute_reward(self,
                        terminated: bool,  # pylint: disable=unused-argument
-                       truncated: bool,  # pylint: disable=unused-argument
                        info: InfoType  # pylint: disable=unused-argument
                        ) -> float:
-        """Compute the reward related to a specific control block.
+        """Compute the reward related to a specific control block, plus extra
+        information that may be helpful for monitoring or debugging purposes.
 
         For the corresponding MDP to be stationary, the computation of the
         reward is supposed to involve only the transition from previous to
         current state of the simulation (possibly comprising multiple agents)
         under the ongoing action.
 
-        By default, it returns 0.0 no matter what. It is up to the user to
-        provide a dedicated reward function whenever appropriate.
-
-        .. warning::
-            Only returning an aggregated scalar reward is supported. Yet, it is
-            possible to update 'info' by reference if one wants for keeping
-            track of individual reward components or any kind of extra info
-            that may be helpful for monitoring or debugging purposes.
+        By default, it returns 0.0 without extra information no matter what.
+        The user is expected to provide an appropriate reward on its own,
+        either by overloading this method or by wrapping the environment with
+        `ComposedJiminyEnv` for modular environment pipeline design.
 
         :param terminated: Whether the episode has reached the terminal state
                            of the MDP at the current step. This flag can be
                            used to compute a specific terminal reward.
-        :param truncated: Whether a truncation condition outside the scope of
-                          the MDP has been satisfied at the current step. This
-                          flag can be used to adapt the reward.
         :param info: Dictionary of extra information for monitoring.
 
         :returns: Aggregated reward for the current step.
         """
         return 0.0
 
 
@@ -178,26 +171,37 @@
         InterfaceObserver[ObsT, EngineObsType],
         InterfaceController[ActT, np.ndarray],
         gym.Env[ObsT, ActT],
         Generic[ObsT, ActT]):
     """Observer plus controller interface for both generic pipeline blocks,
     including environments.
     """
+
     metadata: Dict[str, Any] = {
         "render_modes": (
             ['rgb_array'] + (['human'] if is_display_available() else []))
     }
 
     simulator: Simulator
     robot: jiminy.Robot
     stepper_state: jiminy.StepperState
     robot_state: jiminy.RobotState
     sensor_measurements: SensorMeasurementStackMap
     is_simulation_running: npt.NDArray[np.bool_]
 
+    num_steps: npt.NDArray[np.int64]
+    """Number of simulation steps that has been performed since last reset of
+    the base environment.
+
+    .. note::
+        The counter is incremented before updating the observation at the end
+        of the step, and consequently, before evaluating the reward and the
+        termination conditions.
+    """
+
     quantities: "QuantityManager"
 
     action: ActT
 
     def __init__(self, *args: Any, **kwargs: Any) -> None:
         # Track whether the observation has been refreshed manually since the
         # last called '_controller_handle'. It typically happens at the end of
@@ -246,21 +250,38 @@
             This method is not supposed to be called manually nor overloaded.
 
         :param t: Current simulation time.
         :param q: Current extended configuration vector of the robot.
         :param v: Current extended velocity vector of the robot.
         :param sensor_measurements: Current sensor data.
         """
+        # Early return if no simulation is running
+        if not self.is_simulation_running:
+            return
+
+        # Reset the quantity manager.
+        # In principle, the internal cache of quantities should be cleared each
+        # time the state of the robot and/or its derivative changes. This is
+        # hard to do because there is no way to detect this specifically at the
+        # time being. However, `_observer_handle` is never called twice in the
+        # exact same state by the engine, so resetting quantities at the
+        # beginning of the method should cover most cases. Yet, quantities
+        # cannot be used reliably in the definition of profile forces because
+        # they are always updated before the controller gets called, no matter
+        # if either one or the other is time-continuous. Hacking the internal
+        # dynamics to clear quantities does not address this issue either.
+        self.quantities.clear()
+
         # Refresh the observation if not already done but only if a simulation
         # is already running. It would be pointless to refresh the observation
         # at this point since the controller will be called multiple times at
         # start. Besides, it would defeat the purpose `_initialize_buffers`,
         # that is supposed to be executed before `refresh_observation` is being
         # called for the first time of an episode.
-        if not self.__is_observation_refreshed and self.is_simulation_running:
+        if not self.__is_observation_refreshed:
             measurement = self.__measurement
             measurement["t"][()] = t
             measurement["states"]["agent"]["q"] = q
             measurement["states"]["agent"]["v"] = v
             measurement_sensors = measurement["measurements"]
             sensor_measurements_it = iter(sensor_measurements.values())
             for sensor_type in self._sensors_types:
@@ -299,27 +320,14 @@
         :param sensor_measurements: Current sensor measurements.
         :param command: Output argument corresponding to motors torques to
                         apply on the robot. It must be updated by reference
                         using `[:]` or `np.copyto`.
 
         :returns: Motors torques to apply on the robot.
         """
-        # Reset the quantity manager.
-        # In principle, the internal cache of quantities should be cleared not
-        # each time the state of the robot and/or its derivative changes. This
-        # is hard to do because there is no way to detect this specifically at
-        # the time being. However, `_controller_handle` is never called twice
-        # in the exact same state by the engine, so resetting quantities at the
-        # beginning of the method should cover most cases. Yet, quantities
-        # cannot be used reliably in the definition of profile forces because
-        # they are always updated before the controller gets called, no matter
-        # if either one or the other is time-continuous. Hacking the internal
-        # dynamics to clear quantities does not address this issue either.
-        self.quantities.clear()
-
         # Refresh the observation
         self._observer_handle(t, q, v, sensor_measurements)
 
         # No need to check for breakpoints of the controller because it already
         # matches the update period by design.
         self.compute_command(self.action, command)
```

## gym_jiminy/common/bases/pipeline.py

```diff
@@ -15,26 +15,29 @@
 from abc import abstractmethod
 from collections import OrderedDict
 from typing import (
     Dict, Any, List, Optional, Tuple, Union, Generic, TypeVar, SupportsFloat,
     Callable, cast)
 
 import numpy as np
+
 import gymnasium as gym
 from gymnasium.core import RenderFrame
 from gymnasium.envs.registration import EnvSpec
+from jiminy_py.dynamics import Trajectory
 
 from .interfaces import (DT_EPS,
                          ObsT,
                          ActT,
                          BaseObsT,
                          BaseActT,
                          InfoType,
                          EngineObsType,
                          InterfaceJiminyEnv)
+from .compositions import AbstractReward
 from .blocks import BaseControllerBlock, BaseObserverBlock
 
 from ..utils import DataNested, is_breakpoint, zeros, build_copyto, copy
 
 
 OtherObsT = TypeVar('OtherObsT', bound=DataNested)
 OtherStateT = TypeVar('OtherStateT', bound=DataNested)
@@ -76,14 +79,15 @@
         # Initialize some proxies for fast lookup
         self.simulator = env.simulator
         self.stepper_state = env.stepper_state
         self.robot = env.robot
         self.robot_state = env.robot_state
         self.sensor_measurements = env.sensor_measurements
         self.is_simulation_running = env.is_simulation_running
+        self.num_steps = env.num_steps
 
         # Backup the parent environment
         self.env = env
 
         # Call base implementation
         super().__init__()  # Do not forward any argument
 
@@ -249,18 +253,15 @@
 
         # Compute block's reward and add it to base one as long as it is worth
         # doing so, namely it is not 'nan' already.
         # Note that the reward would be 'nan' if the episode is over and the
         # user keeps doing more steps nonetheless.
         reward = float(reward)
         if not math.isnan(reward):
-            try:
-                reward += self.compute_reward(terminated, truncated, info)
-            except NotImplementedError:
-                pass
+            reward += self.compute_reward(terminated, info)
 
         return obs, reward, terminated, truncated, info
 
     # methods to override:
     # ----------------------------
 
     def _setup(self) -> None:
@@ -296,14 +297,127 @@
 
         By default, it does nothing but forwarding the request to the base
         environment. This behavior can be overwritten by the user.
         """
         self.env.close()
 
 
+class ComposedJiminyEnv(
+        BasePipelineWrapper[ObsT, ActT, ObsT, ActT],
+        Generic[ObsT, ActT]):
+    """Extend an environment, eventually already wrapped, by plugging ad-hoc
+    reward components and termination conditions, including their accompanying
+    trajectory database if any.
+
+    This wrappers leaves unchanged the observation and action spaces of the
+    environment. This can be done by adding observation and/or control blocks
+    through `ObservedJiminyEnv` and `ControlledJiminyEnv` wrappers.
+
+    .. note::
+        This wrapper derives from `BasePipelineWrapper`, and such as, it is
+        considered as internal unlike `gym.Wrapper`. This means that it will be
+        taken into account when calling `evaluate` or `play_interactive` on the
+        wrapped environment.
+    """
+    def __init__(self,
+                 env: InterfaceJiminyEnv[ObsT, ActT],
+                 *,
+                 reward: Optional[AbstractReward] = None,
+                 trajectories: Optional[Dict[str, Trajectory]] = None) -> None:
+        """
+        :param env: Environment to extend, eventually already wrapped.
+        :param reward: Reward object deriving from `AbstractReward`. It will be
+                       evaluated at each step of the environment and summed up
+                       with one returned by the wrapped environment. This
+                       reward must be already instantiated and associated with
+                       the provided environment. `None` for not considering any
+                       reward.
+                       Optional: `None` by default.
+        :param trajectories: Set of named trajectories as a dictionary whose
+                             (key, value) pairs are respectively the name of
+                             each trajectory and the trajectory itself.  `None`
+                             for not considering any trajectory.
+                             Optional: `None` by default.
+        """
+        # Make sure that the unwrapped environment matches the reward one
+        assert reward is None or env.unwrapped is reward.env.unwrapped
+
+        # Backup user argument(s)
+        self.reward = reward
+
+        # Initialize base class
+        super().__init__(env)
+
+        # Add reference trajectories to all managed quantities if requested
+        if trajectories is not None:
+            for name, trajectory in trajectories.items():
+                self.env.quantities.add_trajectory(name, trajectory)
+
+        # Bind observation and action of the base environment
+        assert self.observation_space.contains(self.env.observation)
+        assert self.action_space.contains(self.env.action)
+        self.observation = self.env.observation
+        self.action = self.env.action
+
+    def _initialize_action_space(self) -> None:
+        """Configure the action space.
+
+        It simply copy the action space of the wrapped environment.
+        """
+        self.action_space = self.env.action_space
+
+    def _initialize_observation_space(self) -> None:
+        """Configure the observation space.
+
+        It simply copy the observation space of the wrapped environment.
+        """
+        self.observation_space = self.env.observation_space
+
+    def _setup(self) -> None:
+        """Configure the wrapper.
+
+        In addition to calling the base implementation, it sets the observe
+        and control update period.
+        """
+        # Call base implementation
+        super()._setup()
+
+        # Copy observe and control update periods from wrapped environment
+        self.observe_dt = self.env.observe_dt
+        self.control_dt = self.env.control_dt
+
+    def refresh_observation(self, measurement: EngineObsType) -> None:
+        """Compute high-level features based on the current wrapped
+        environment's observation.
+
+        It simply forwards the observation computed by the wrapped environment
+        without any processing.
+
+        :param measurement: Low-level measure from the environment to process
+                            to get higher-level observation.
+        """
+        self.env.refresh_observation(measurement)
+
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
+        """Compute the motors efforts to apply on the robot.
+
+        It simply forwards the command computed by the wrapped environment
+        without any processing.
+
+        :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to updated in-place.
+        """
+        self.env.compute_command(action, command)
+
+    def compute_reward(self, terminated: bool, info: InfoType) -> float:
+        if self.reward is None:
+            return 0.0
+        return self.reward(terminated, info)
+
+
 class ObservedJiminyEnv(
         BasePipelineWrapper[NestedObsT, ActT, BaseObsT, ActT],
         Generic[NestedObsT, ActT, BaseObsT]):
     """Wrap a `BaseJiminyEnv` Gym environment and a single observer.
 
     .. aafig::
         :proportional:
@@ -362,16 +476,16 @@
         assert observer.env.unwrapped is env.unwrapped
 
         # Backup user arguments
         self.observer = observer
 
         # Make sure that the environment is either some `ObservedJiminyEnv` or
         # `ControlledJiminyEnv` block, or the base environment directly.
-        if isinstance(env, BasePipelineWrapper) and not isinstance(
-                env, (ObservedJiminyEnv, ControlledJiminyEnv)):
+        if isinstance(env, BasePipelineWrapper) and not isinstance(env, (
+                ObservedJiminyEnv, ControlledJiminyEnv, ComposedJiminyEnv)):
             raise TypeError(
                 "Observers can only be added on top of another observer, "
                 "controller, or a base environment itself.")
 
         # Make sure that there is no other block with the exact same name
         block_name = observer.name
         env_unwrapped: InterfaceJiminyEnv = env
@@ -584,16 +698,16 @@
 
         # Backup user arguments
         self.controller = controller
         self.augment_observation = augment_observation
 
         # Make sure that the environment is either some `ObservedJiminyEnv` or
         # `ControlledJiminyEnv` block, or the base environment directly.
-        if isinstance(env, BasePipelineWrapper) and not isinstance(
-                env, (ObservedJiminyEnv, ControlledJiminyEnv)):
+        if isinstance(env, BasePipelineWrapper) and not isinstance(env, (
+                ObservedJiminyEnv, ControlledJiminyEnv, ComposedJiminyEnv)):
             raise TypeError(
                 "Controllers can only be added on top of another observer, "
                 "controller, or a base environment itself.")
 
         # Make sure that the pipeline does not have a block with the same name
         block_name = controller.name
         env_unwrapped: InterfaceJiminyEnv = env
@@ -732,19 +846,16 @@
         # Update the command to send to the actuators of the robot.
         # Note that the environment itself is responsible of making sure to
         # update the command at the right period. Ultimately, this is done
         # automatically by the engine, which is calling `_controller_handle` at
         # the right period.
         self.env.compute_command(self.env.action, command)
 
-    def compute_reward(self,
-                       terminated: bool,
-                       truncated: bool,
-                       info: InfoType) -> float:
-        return self.controller.compute_reward(terminated, truncated, info)
+    def compute_reward(self, terminated: bool, info: InfoType) -> float:
+        return self.controller.compute_reward(terminated, info)
 
 
 class BaseTransformObservation(
         BasePipelineWrapper[TransformedObsT, ActT, ObsT, ActT],
         Generic[TransformedObsT, ObsT, ActT]):
     """Apply some transform on the observation of the wrapped environment.
 
@@ -758,16 +869,16 @@
         The user is expected to define the observation transform and its
         corresponding space by overloading both `_initialize_action_space` and
         `transform_action`. The transform will be applied at the end of every
         environment step.
 
     .. note::
         This wrapper derives from `BasePipelineWrapper`, and such as, it is
-        considered as internal unlike `gym.Wrapper`. This means that it will be
-        taken into account calling `evaluate` or `play_interactive` on the
+        considered internal unlike `gym.Wrapper`. This means that it will be
+        taken into account when calling `evaluate` or `play_interactive` on the
         wrapped environment.
     """
     def __init__(self, env: InterfaceJiminyEnv[ObsT, ActT]) -> None:
         # Initialize base class
         super().__init__(env)
 
         # Initialize some proxies for fast lookup
@@ -865,16 +976,16 @@
         The user is expected to define the observation transform and its
         corresponding space by overloading both `_initialize_action_space` and
         `transform_action`. The transform will be applied at the beginning of
         every environment step.
 
     .. note::
         This wrapper derives from `BasePipelineWrapper`, and such as, it is
-        considered as internal unlike `gym.Wrapper`. This means that it will be
-        taken into account calling `evaluate` or `play_interactive` on the
+        considered internal unlike `gym.Wrapper`. This means that it will be
+        taken into account when calling `evaluate` or `play_interactive` on the
         wrapped environment.
     """
     def __init__(self, env: InterfaceJiminyEnv[ObsT, ActT]) -> None:
         # Initialize base class
         super().__init__(env)
 
         # Initialize some proxies for fast lookup
```

## gym_jiminy/common/blocks/deformation_estimator.py

```diff
@@ -6,15 +6,15 @@
 
 import numpy as np
 import numba as nb
 import gymnasium as gym
 
 import jiminy_py.core as jiminy
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    EncoderSensor as encoder, ImuSensor as imu, get_frame_indices)
+    EncoderSensor, ImuSensor, get_frame_indices)
 
 import pinocchio as pin
 
 from ..bases import BaseActT, BaseObsT, BaseObserverBlock, InterfaceJiminyEnv
 from ..utils import (DataNested,
                      matrices_to_quat,
                      quat_multiply,
@@ -256,16 +256,18 @@
     leaf_joint_indices = set(range(len(parents))) - set(parents)
 
     # Compute the support of each leaf joint, ie the sub-chain going from each
     # leaf to the root joint.
     supports = []
     for joint_index in leaf_joint_indices:
         support = []
-        while joint_index > 0:
+        while True:
             support.append(joint_index)
+            if joint_index == 0:
+                break
             joint_index = parents[joint_index]
         supports.append(support)
 
     # Deduce all the kinematic chains.
     # For each support, check if there is a match in any other chain.
     # The first match (in order) must be the only one to be considered.
     # It always exists, as a root joint is shared by all supports.
@@ -540,35 +542,40 @@
         # Sanitize user argument(s)
         imu_frame_names, flex_frame_names = map(
             list, (imu_frame_names, flex_frame_names))
 
         # Backup some of the user-argument(s)
         self.ignore_twist = ignore_twist
 
-        # Define proxies for fast access
-        self.pinocchio_model_th = env.robot.pinocchio_model_th.copy()
-        self.pinocchio_data_th = env.robot.pinocchio_data_th.copy()
-
         # Create flexible dynamic model.
         # Dummy physical parameters are specified as they have no effect on
         # kinematic computations.
         model = jiminy.Model()
-        model.initialize(env.robot.pinocchio_model_th)
+        pinocchio_model_th = env.robot.pinocchio_model_th
+        if env.robot.has_freeflyer:
+            pinocchio_model_th = pin.buildReducedModel(
+                pinocchio_model_th, [1], pin.neutral(pinocchio_model_th))
+        model.initialize(pinocchio_model_th)
         options = model.get_options()
+        options["dynamics"]["enableFlexibility"] = True
         for frame_name in flex_frame_names:
             options["dynamics"]["flexibilityConfig"].append(
                 {
                     "frameName": frame_name,
                     "stiffness": np.ones(3),
                     "damping": np.ones(3),
                     "inertia": np.ones(3),
                 }
             )
         model.set_options(options)
 
+        # Backup theoretical pinocchio model without floating base
+        self.pinocchio_model_th = model.pinocchio_model_th.copy()
+        self.pinocchio_data_th = model.pinocchio_data_th.copy()
+
         # Extract contiguous chains of flexibility and IMU frames for which
         # computations can be vectorized. It also stores the information of
         # whether or not the sign of the deformation must be reversed to be
         # consistent with standard convention.
         flexibility_joint_names = model.flexibility_joint_names
         flex_imu_frame_names_chains = get_flexibility_imu_frame_chains(
             model.pinocchio_model, flexibility_joint_names, imu_frame_names)
@@ -632,42 +639,45 @@
             assert isinstance(obs_imu_quats, Mapping)
             obs_imu_quats = obs_imu_quats[key]
         assert isinstance(obs_imu_quats, np.ndarray)
         self._obs_imu_quats = obs_imu_quats
 
         # Get mapping from IMU frame to index
         imu_frame_map: Dict[str, int] = {}
-        for sensor_name in env.robot.sensor_names[imu.type]:
-            sensor = env.robot.get_sensor(imu.type, sensor_name)
-            assert isinstance(sensor, imu)
+        for sensor in env.robot.sensors[ImuSensor.type]:
+            assert isinstance(sensor, ImuSensor)
             imu_frame_map[sensor.frame_name] = sensor.index
 
         # Make sure that the robot has one encoder per mechanical joint
-        encoder_sensor_names = env.robot.sensor_names[encoder.type]
-        if len(encoder_sensor_names) < len(model.mechanical_joint_indices):
+        encoder_sensors = env.robot.sensors[EncoderSensor.type]
+        if len(encoder_sensors) < len(model.mechanical_joint_indices):
             raise ValueError(
                 "The robot must have one encoder per mechanical joints.")
 
         # Extract mapping from encoders to theoretical configuration.
         # Note that revolute unbounded joints are not supported for now.
-        self.encoder_to_config = [-1 for _ in range(env.robot.nmotors)]
-        for i, sensor_name in enumerate(encoder_sensor_names):
-            sensor = env.robot.get_sensor(encoder.type, sensor_name)
-            assert isinstance(sensor, encoder)
-            if sensor.joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
+        self.encoder_to_position_map = [-1,] * env.robot.nmotors
+        for sensor in env.robot.sensors[EncoderSensor.type]:
+            assert isinstance(sensor, EncoderSensor)
+            joint_index = self.pinocchio_model_th.getJointId(sensor.joint_name)
+            joint = self.pinocchio_model_th.joints[joint_index]
+            joint_type = jiminy.get_joint_type(joint)
+            if joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
                 raise ValueError(
                     "Revolute unbounded joints are not supported for now.")
-            encoder_joint = self.pinocchio_model_th.joints[sensor.joint_index]
-            self.encoder_to_config[i] = encoder_joint.idx_q
+            self.encoder_to_position_map[sensor.index] = joint.idx_q
 
-        # Extract measured joint positions for fast access.
+        # Extract measured motor / joint positions for fast access.
         # Note that they will be initialized in `_setup` method.
         self.encoder_data = np.array([])
 
-        # Buffer storing the theoretical configuration.
+        # Ratio to translate encoder data to joint side
+        self.encoder_to_joint_ratio = np.array([])
+
+        # Buffer storing the theoretical configuration
         self._q_th = pin.neutral(self.pinocchio_model_th)
 
         # Whether the observer has been compiled already
         self._is_compiled = False
 
         # Initialize the observer
         super().__init__(name, env, update_ratio)
@@ -698,16 +708,20 @@
     def _setup(self) -> None:
         # Call base implementation
         super()._setup()
 
         # Refresh the theoretical model of the robot.
         # Even if the robot may change, the theoretical model of the robot is
         # not supposed to change in a way that would break this observer.
-        self.pinocchio_model_th = self.env.robot.pinocchio_model_th
-        self.pinocchio_data_th = self.env.robot.pinocchio_data_th
+        pinocchio_model_th = self.env.robot.pinocchio_model_th
+        if self.env.robot.has_freeflyer:
+            pinocchio_model_th = pin.buildReducedModel(
+                pinocchio_model_th, [1], pin.neutral(pinocchio_model_th))
+        self.pinocchio_model_th = pinocchio_model_th
+        self.pinocchio_data_th = self.pinocchio_model_th.createData()
 
         # Fix initialization of the observation to be valid quaternions
         self.observation[-1] = 1.0
 
         # Refresh flexibility and IMU frame orientation proxies
         self._kin_flex_rots.clear()
         self._kin_imu_rots.clear()
@@ -718,32 +732,48 @@
                 self.pinocchio_data_th.oMf[frame_index].rotation
                 for frame_index in get_frame_indices(
                     self.pinocchio_model_th, frame_names))
                 for frame_names in (flex_frame_names, imu_frame_names))
             self._kin_flex_rots.append(kin_flex_rots)
             self._kin_imu_rots.append(kin_imu_rots)
 
-        # Refresh measured motor positions and velocities proxies
-        self.encoder_data, _ = self.env.sensor_measurements[encoder.type]
+        # Refresh measured motor position proxy
+        self.encoder_data, _ = self.env.sensor_measurements[EncoderSensor.type]
+
+        # Refresh mechanical reduction ratio
+        encoder_to_joint_ratio = []
+        for sensor in self.env.robot.sensors[EncoderSensor.type]:
+            try:
+                motor = self.env.robot.motors[sensor.motor_index]
+                motor_options = motor.get_options()
+                mechanical_reduction = motor_options["mechanicalReduction"]
+                encoder_to_joint_ratio.append(1.0 / mechanical_reduction)
+            except IndexError:
+                encoder_to_joint_ratio.append(1.0)
+        self.encoder_to_joint_ratio = np.array(encoder_to_joint_ratio)
 
         # Call `refresh_observation` manually to pre-compile it if necessary
         if not self._is_compiled:
             self.refresh_observation(self.env.observation)
             self._is_compiled = True
 
     @property
     def fieldnames(self) -> List[List[str]]:
         return [[f"{name}.Quat{e}" for name in self.flexibility_frame_names]
                 for e in ("x", "y", "z", "w")]
 
     def refresh_observation(self, measurement: BaseObsT) -> None:
-        # Estimate the theoretical configuration of the robot from encoder data
-        self._q_th[self.encoder_to_config] = self.encoder_data
+        # Translate encoder data at joint level
+        joint_positions = self.encoder_to_joint_ratio * self.encoder_data
+
+        # Update the configuration of the theoretical model of the robot
+        self._q_th[self.encoder_to_position_map] = joint_positions
 
-        # Update kinematic quantities according to the estimated configuration
+        # Update kinematic quantities according to the estimated configuration.
+        # FIXME: Compute frame placement only for relevant IMUs.
         pin.framesForwardKinematics(
             self.pinocchio_model_th, self.pinocchio_data_th, self._q_th)
 
         # Estimate all the deformations in their local frame.
         # It loops over each flexibility-imu chain independently.
         for args in zip(
                 self._obs_imu_indices,
```

## gym_jiminy/common/blocks/mahony_filter.py

```diff
@@ -4,16 +4,15 @@
 import logging
 from typing import List, Union, Optional
 
 import numpy as np
 import numba as nb
 import gymnasium as gym
 
-from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    ImuSensor as imu)
+from jiminy_py.core import ImuSensor  # pylint: disable=no-name-in-module
 
 from ..bases import BaseObsT, BaseActT, BaseObserverBlock, InterfaceJiminyEnv
 from ..utils import (fill,
                      matrices_to_quat,
                      swing_from_vector,
                      compute_tilt_from_quat,
                      remove_twist_from_quat)
@@ -196,15 +195,15 @@
                           Optional: `0.1` by default.
         :param update_ratio: Ratio between the update period of the observer
                              and the one of the subsequent observer. -1 to
                              match the simulation timestep of the environment.
                              Optional: `1` by default.
         """
         # Handling of default argument(s)
-        num_imu_sensors = len(env.robot.sensor_names[imu.type])
+        num_imu_sensors = len(env.robot.sensors[ImuSensor.type])
         if isinstance(kp, float):
             kp = np.full((num_imu_sensors,), kp)
         if isinstance(ki, float):
             ki = np.full((num_imu_sensors,), ki)
 
         # Backup some of the user arguments
         self.exact_init = exact_init
@@ -264,28 +263,28 @@
         because it is uniquely determined from the orientation estimate.
         """
         # Strictly speaking, 'q_prev' is part of the internal state of the
         # observer since it is involved in its computations. Yet, it is not an
         # internal state of the (partially observable) MDP since the previous
         # observation must be provided anyway when integrating the observable
         # dynamics by definition.
-        num_imu_sensors = len(self.env.robot.sensor_names[imu.type])
+        num_imu_sensors = len(self.env.robot.sensors[ImuSensor.type])
         self.state_space = gym.spaces.Box(
             low=np.full((3, num_imu_sensors), -np.inf),
             high=np.full((3, num_imu_sensors), np.inf),
             dtype=np.float64)
 
     def _initialize_observation_space(self) -> None:
         """Configure the observation space of the observer.
 
         It corresponds to the current orientation estimate for all the IMUs of
         the robot at once, with special treatment for their twist part. See
         `__init__` documentation for details.
         """
-        num_imu_sensors = len(self.env.robot.sensor_names[imu.type])
+        num_imu_sensors = len(self.env.robot.sensors[ImuSensor.type])
         self.observation_space = gym.spaces.Box(
             low=np.full((4, num_imu_sensors), -1.0 - 1e-9),
             high=np.full((4, num_imu_sensors), 1.0 + 1e-9),
             dtype=np.float64)
 
     def _setup(self) -> None:
         # Call base implementation
@@ -297,15 +296,15 @@
         # Make sure observe update is discrete-time
         if self.env.observe_dt <= 0.0:
             raise ValueError(
                 "This block does not support time-continuous update.")
 
         # Refresh gyroscope and accelerometer proxies
         self.gyro, self.acc = np.split(
-            self.env.sensor_measurements[imu.type], 2)
+            self.env.sensor_measurements[ImuSensor.type], 2)
 
         # Reset the sensor bias
         fill(self._bias, 0)
 
         # Reset the twist estimate
         fill(self._twist, 0)
 
@@ -328,16 +327,16 @@
         self._is_initialized = False
 
     def get_state(self) -> np.ndarray:
         return self._bias
 
     @property
     def fieldnames(self) -> List[List[str]]:
-        sensor_names = self.env.robot.sensor_names[imu.type]
-        return [[f"{name}.Quat{e}" for name in sensor_names]
+        imu_sensors = self.env.robot.sensors[ImuSensor.type]
+        return [[f"{sensor.name}.Quat{e}" for sensor in imu_sensors]
                 for e in ("x", "y", "z", "w")]
 
     def refresh_observation(self, measurement: BaseObsT) -> None:
         # Re-initialize the quaternion estimate if no simulation running.
         # It corresponds to the rotation transforming 'acc' in 'e_z'.
         if not self._is_initialized:
             if not self.exact_init:
@@ -354,17 +353,16 @@
                     swing_from_vector(acc, self.observation)
 
                     self._is_initialized = True
             if not self._is_initialized:
                 # Get true orientation of IMU frames
                 imu_rots = []
                 robot = self.env.robot
-                for name in robot.sensor_names[imu.type]:
-                    sensor = robot.get_sensor(imu.type, name)
-                    assert isinstance(sensor, imu)
+                for sensor in robot.sensors[ImuSensor.type]:
+                    assert isinstance(sensor, ImuSensor)
                     rot = robot.pinocchio_data.oMf[sensor.frame_index].rotation
                     imu_rots.append(rot)
 
                 # Convert it to quaternions
                 matrices_to_quat(tuple(imu_rots), self.observation)
 
                 # Keep track of tilt if necessary
```

## gym_jiminy/common/blocks/motor_safety_limit.py

```diff
@@ -3,16 +3,15 @@
 """
 import warnings
 from typing import List
 
 import numpy as np
 import numba as nb
 
-from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    EncoderSensor as encoder)
+from jiminy_py.core import EncoderSensor  # pylint: disable=no-name-in-module
 
 from .proportional_derivative_controller import get_encoder_to_motor_map
 
 from ..bases import (BaseObsT,
                      InterfaceJiminyEnv,
                      BaseControllerBlock,
                      BasePipelineWrapper,
@@ -109,60 +108,67 @@
     """  # noqa: E501  # pylint: disable=line-too-long
     def __init__(self,
                  name: str,
                  env: InterfaceJiminyEnv[BaseObsT, np.ndarray],
                  *,
                  kp: float,
                  kd: float,
-                 soft_position_margin: float = 0.0,
-                 soft_velocity_max: float = float("inf")) -> None:
+                 soft_position_margin: float,
+                 soft_velocity_max: float) -> None:
         """
         :param name: Name of the block.
         :param env: Environment to connect with.
 
         :param kp: Scale of the velocity bound triggered by position limits.
         :param kd: Scale of the effort bound triggered by velocity limits.
-        :param soft_position_margin: Minimum distance of the current motor
+        :param soft_position_margin: Minimum distance of the current joint
                                      positions from their respective bounds
                                      before starting to break.
-        :param soft_velocity_max: Maximum velocity of the motor before
+        :param soft_velocity_max: Maximum velocity of the joint before
                                   starting to break.
         """
         # Make sure that no other controller has been added prior to this block
         env_unwrapped: InterfaceJiminyEnv = env
         while isinstance(env_unwrapped, BasePipelineWrapper):
             if isinstance(env_unwrapped, ControlledJiminyEnv):
                 raise TypeError(
                     "No other control block must be added prior to this one.")
             env_unwrapped = env_unwrapped.env
 
         # Backup some user argument(s)
         self.kp = kp
         self.kd = kd
 
+        # Refresh mechanical reduction ratio
+        encoder_to_joint_ratio = []
+        for motor in env.robot.motors:
+            motor_options = motor.get_options()
+            encoder_to_joint_ratio.append(motor_options["mechanicalReduction"])
+
         # Define buffers storing information about the motors for efficiency
-        motor_position_indices: List[int] = sum(
-            env.robot.motor_position_indices, [])
-        self.motors_position_lower = env.robot.position_limit_lower[
-            motor_position_indices] + soft_position_margin
-        self.motors_position_upper = env.robot.position_limit_upper[
-            motor_position_indices] - soft_position_margin
-        self.motors_velocity_limit = np.minimum(env.robot.velocity_limit[
-            env.robot.motor_velocity_indices], soft_velocity_max)
-        self.motors_effort_limit = env.robot.command_limit[
-            env.robot.motor_velocity_indices]
+        self.motors_position_lower = np.array([
+            motor.position_limit_lower + ratio * soft_position_margin
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
+        self.motors_position_upper = np.array([
+            motor.position_limit_upper - ratio * soft_position_margin
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
+        self.motors_velocity_limit = np.array([
+            min(motor.velocity_limit, ratio * soft_velocity_max)
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
+        self.motors_effort_limit = np.array([
+            motor.effort_limit for motor in env.robot.motors])
         self.motors_effort_limit[
             self.motors_position_lower > self.motors_position_upper] = 0.0
 
         # Mapping from motors to encoders
-        self.encoder_to_motor = get_encoder_to_motor_map(env.robot)
+        self.encoder_to_motor_map = get_encoder_to_motor_map(env.robot)
 
         # Whether stored reference to encoder measurements are already in the
         # same order as the motors, allowing skipping re-ordering entirely.
-        self._is_same_order = isinstance(self.encoder_to_motor, slice)
+        self._is_same_order = isinstance(self.encoder_to_motor_map, slice)
         if not self._is_same_order:
             warnings.warn(
                 "Consider using the same ordering for encoders and motors for "
                 "optimal performance.")
 
         # Extract measured motor positions and velocities for fast access.
         # Note that they will be initialized in `_setup` method.
@@ -180,36 +186,36 @@
 
     def _setup(self) -> None:
         # Call base implementation
         super()._setup()
 
         # Refresh measured motor positions and velocities proxies
         self.q_measured, self.v_measured = (
-            self.env.sensor_measurements[encoder.type])
+            self.env.sensor_measurements[EncoderSensor.type])
 
     @property
     def fieldnames(self) -> List[str]:
-        return [f"currentMotorTorque{name}"
-                for name in self.env.robot.motor_names]
+        return [f"currentMotorTorque{motor.name}"
+                for motor in self.env.robot.motors]
 
     def compute_command(self,
                         action: np.ndarray,
                         command: np.ndarray) -> None:
         """Apply safety limits to the desired motor torques right before
         sending it to the robot so as to avoid exceeded prescribed position
         and velocity limits.
 
         :param action: Desired motor torques to apply on the robot.
         :param command: Current motor torques that will be updated in-place.
         """
         # Extract motor positions and velocity from encoder data
         q_measured, v_measured = self.q_measured, self.v_measured
         if not self._is_same_order:
-            q_measured = q_measured[self.encoder_to_motor]
-            v_measured = v_measured[self.encoder_to_motor]
+            q_measured = q_measured[self.encoder_to_motor_map]
+            v_measured = v_measured[self.encoder_to_motor_map]
 
         # Clip command according to safe effort bounds
         apply_safety_limits(action,
                             q_measured,
                             v_measured,
                             self.kp,
                             self.kd,
```

## gym_jiminy/common/blocks/proportional_derivative_controller.py

```diff
@@ -6,16 +6,15 @@
 
 import numpy as np
 import numba as nb
 import gymnasium as gym
 
 import jiminy_py.core as jiminy
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    array_copyto,
-    EncoderSensor as encoder)
+    EncoderSensor, array_copyto)
 
 from ..bases import BaseObsT, InterfaceJiminyEnv, BaseControllerBlock
 from ..utils import fill
 
 
 # Name of the n-th position derivative
 N_ORDER_DERIVATIVE_NAMES = ("Position", "Velocity", "Acceleration")
@@ -231,35 +230,35 @@
         data instead of a reference. On the contrary, it reordering is not
         necessary, a slice is returned instead and no copy happens whatsoever.
 
     :param robot: Jiminy robot for which to compute mapping.
 
     :returns: A slice if possible, a list of indices otherwise.
     """
-    # Define the mapping from motors to encoders
-    encoder_to_motor = [-1 for _ in range(robot.nmotors)]
-    encoders = [robot.get_sensor(encoder.type, sensor_name)
-                for sensor_name in robot.sensor_names[encoder.type]]
-    for i, motor_name in enumerate(robot.motor_names):
-        motor = robot.get_motor(motor_name)
-        for j, sensor in enumerate(encoders):
-            assert isinstance(sensor, encoder)
-            if motor.joint_index == sensor.joint_index:
-                encoder_to_motor[sensor.index] = i
-                encoders.pop(j)
+    # Loop over all actuated joints and look for their encoder counterpart
+    encoder_to_motor_map = [-1,] * robot.nmotors
+    encoders = robot.sensors[EncoderSensor.type]
+    for motor in robot.motors:
+        for i, sensor in enumerate(encoders):
+            assert isinstance(sensor, EncoderSensor)
+            if motor.index == sensor.motor_index:
+                encoder_to_motor_map[sensor.index] = motor.index
+                del encoders[i]
                 break
         else:
             raise RuntimeError(
-                f"No encoder sensor associated with motor '{motor_name}'. "
-                "Every actuated joint must have encoder sensors attached.")
+                f"No encoder sensor associated with motor '{motor.name}'. "
+                "Every actuated joint must have a encoder sensor attached on "
+                "motor side.")
 
     # Try converting it to slice if possible
-    if (np.array(encoder_to_motor) == np.arange(robot.nmotors)).all():
+    if (np.array(encoder_to_motor_map) == np.arange(robot.nmotors)).all():
         return slice(None)
-    return encoder_to_motor
+
+    return encoder_to_motor_map
 
 
 class PDController(
         BaseControllerBlock[np.ndarray, np.ndarray, BaseObsT, np.ndarray]):
     """Low-level Proportional-Derivative controller.
 
     The action are the target motors accelerations. The latter are integrated
@@ -284,36 +283,34 @@
     def __init__(self,
                  name: str,
                  env: InterfaceJiminyEnv[BaseObsT, np.ndarray],
                  *,
                  update_ratio: int = 1,
                  kp: Union[float, List[float], np.ndarray],
                  kd: Union[float, List[float], np.ndarray],
-                 target_position_margin: float = 0.0,
-                 target_velocity_limit: float = float("inf"),
-                 target_acceleration_limit: float = float("inf")) -> None:
+                 joint_position_margin: float = 0.0,
+                 joint_velocity_limit: float = float("inf"),
+                 joint_acceleration_limit: float = float("inf")) -> None:
         """
         :param name: Name of the block.
         :param env: Environment to connect with.
         :param update_ratio: Ratio between the update period of the controller
                              and the one of the subsequent controller. -1 to
                              match the simulation timestep of the environment.
                              Optional: 1 by default.
         :param kp: PD controller position-proportional gains in motor order.
         :param kd: PD controller velocity-proportional gains in motor order.
-        :param target_position_margin: Minimum distance of the motor target
-                                       positions from their respective bounds.
-                                       Optional: 0.0 by default.
-        :param target_velocity_limit: Restrict maximum motor target velocities
-                                      wrt their hardware specifications.
-                                      Optional: "inf" by default.
-        :param target_acceleration_limit:
-            Restrict maximum motor target accelerations wrt their hardware
-            specifications.
-            Optional: "inf" by default.
+        :param joint_position_margin: Minimum distance of the joint target
+                                      positions from their respective bounds.
+                                      Optional: 0.0 by default.
+        :param joint_velocity_limit: Restrict maximum joint target velocities
+                                     wrt their hardware specifications.
+                                     Optional: "inf" by default.
+        :param joint_acceleration_limit: Maximum joint target acceleration.
+                                         Optional: "inf" by default.
         """
         # Make sure the action space of the environment has not been altered
         if env.action_space is not env.unwrapped.action_space:
             raise RuntimeError(
                 "Impossible to connect this block on an environment whose "
                 "action space has been altered.")
 
@@ -326,65 +323,66 @@
                 "PD gains inconsistent with number of motors.") from e
 
         # Backup some user argument(s)
         self.kp = kp
         self.kd = kd
 
         # Mapping from motors to encoders
-        self.encoder_to_motor = get_encoder_to_motor_map(env.robot)
+        self.encoder_to_motor_map = get_encoder_to_motor_map(env.robot)
 
         # Whether stored reference to encoder measurements are already in the
         # same order as the motors, allowing skipping re-ordering entirely.
-        self._is_same_order = isinstance(self.encoder_to_motor, slice)
+        self._is_same_order = isinstance(self.encoder_to_motor_map, slice)
         if not self._is_same_order:
             warnings.warn(
                 "Consider using the same ordering for encoders and motors for "
                 "optimal performance.")
 
         # Define buffers storing information about the motors for efficiency.
         # Note that even if the robot instance may change from one simulation
         # to another, the observation and action spaces are required to stay
         # the same the whole time. This induces that the motors effort limit
         # must not change unlike the mapping from full state to motors.
-        self.motors_effort_limit = env.robot.command_limit[
-            env.robot.motor_velocity_indices]
+        self.motors_effort_limit = np.array([
+            motor.effort_limit for motor in env.robot.motors])
 
-        # Extract the motors target position bounds from the model
-        motors_position_lower: List[float] = []
-        motors_position_upper: List[float] = []
-        for motor_name in env.robot.motor_names:
-            motor = env.robot.get_motor(motor_name)
-            joint_type = jiminy.get_joint_type(
-                env.robot.pinocchio_model, motor.joint_index)
-            if joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
-                lower, upper = float("-inf"), float("inf")
-            else:
-                motor_position_index = motor.joint_position_index
-                lower = env.robot.position_limit_lower[motor_position_index]
-                upper = env.robot.position_limit_upper[motor_position_index]
-            motors_position_lower.append(lower + target_position_margin)
-            motors_position_upper.append(upper - target_position_margin)
-
-        # Extract the motors target velocity bounds
-        motors_velocity_limit = np.minimum(
-            env.robot.velocity_limit[env.robot.motor_velocity_indices],
-            target_velocity_limit)
+        # Refresh mechanical reduction ratio
+        encoder_to_joint_ratio = []
+        for motor in env.robot.motors:
+            motor_options = motor.get_options()
+            encoder_to_joint_ratio.append(motor_options["mechanicalReduction"])
+
+        # Define the motors target position bounds
+        motors_position_lower = np.array([
+            motor.position_limit_lower + ratio * joint_position_margin
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
+        motors_position_upper = np.array([
+            motor.position_limit_upper - ratio * joint_position_margin
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
+
+        # Define the motors target velocity bounds
+        motors_velocity_limit = np.array([
+            min(motor.velocity_limit, ratio * joint_velocity_limit)
+            for motor, ratio in zip(env.robot.motors, encoder_to_joint_ratio)])
 
-        # Compute acceleration bounds allowing unrestricted bang-bang control
+        # Define acceleration bounds allowing unrestricted bang-bang control
         range_limit = 2 * motors_velocity_limit / env.step_dt
         effort_limit = self.motors_effort_limit / (
             self.kp * env.step_dt * np.maximum(env.step_dt / 2, self.kd))
+        target_acceleration_limit = np.array([
+            ratio * joint_acceleration_limit
+            for ratio in encoder_to_joint_ratio])
         acceleration_limit = np.minimum(
             np.minimum(range_limit, effort_limit), target_acceleration_limit)
 
         # Compute command state bounds
-        self._command_state_lower = np.stack([np.array(motors_position_lower),
+        self._command_state_lower = np.stack([motors_position_lower,
                                               -motors_velocity_limit,
                                               -acceleration_limit], axis=0)
-        self._command_state_upper = np.stack([np.array(motors_position_upper),
+        self._command_state_upper = np.stack([motors_position_upper,
                                               motors_velocity_limit,
                                               acceleration_limit], axis=0)
 
         # Extract measured motor positions and velocities for fast access.
         # Note that they will be initialized in `_setup` method.
         self.q_measured, self.v_measured = np.array([]), np.array([])
 
@@ -425,23 +423,23 @@
         # Make sure control update is discrete-time
         if self.env.control_dt <= 0.0:
             raise ValueError(
                 "This block does not support time-continuous update.")
 
         # Refresh measured motor positions and velocities proxies
         self.q_measured, self.v_measured = (
-            self.env.sensor_measurements[encoder.type])
+            self.env.sensor_measurements[EncoderSensor.type])
 
         # Reset the command state
         fill(self._command_state, 0)
 
     @property
     def fieldnames(self) -> List[str]:
-        return [f"currentTarget{N_ORDER_DERIVATIVE_NAMES[2]}{name}"
-                for name in self.env.robot.motor_names]
+        return [f"currentTarget{N_ORDER_DERIVATIVE_NAMES[2]}{motor.name}"
+                for motor in self.env.robot.motors]
 
     def get_state(self) -> np.ndarray:
         return self._command_state[:2]
 
     def compute_command(self, action: np.ndarray, command: np.ndarray) -> None:
         """Compute the target motor torques using a PD controller.
 
@@ -466,16 +464,16 @@
                         self._command_state_lower[i],
                         self._command_state_upper[i],
                         out=self._command_state[i])
 
         # Extract motor positions and velocity from encoder data
         q_measured, v_measured = self.q_measured, self.v_measured
         if not self._is_same_order:
-            q_measured = q_measured[self.encoder_to_motor]
-            v_measured = v_measured[self.encoder_to_motor]
+            q_measured = q_measured[self.encoder_to_motor_map]
+            v_measured = v_measured[self.encoder_to_motor_map]
 
         # Update target motor accelerations
         array_copyto(self._command_acceleration, action)
 
         # Compute the motor efforts using PD control.
         # The command state must not be updated if no simulation is running.
         pd_controller(
@@ -543,42 +541,32 @@
 
         # Backup some user argument(s)
         self.order = order
 
         # Define some proxies for convenience
         self._pd_controller = controller
 
-        # Allocate memory for the target motor accelerations
-        self._target_accelerations = np.zeros((env.robot.nmotors,))
-
         # Initialize the controller
         super().__init__(name, env, update_ratio)
 
     def _initialize_action_space(self) -> None:
         """Configure the action space of the controller.
 
         The action spaces corresponds to the N-th order derivative of the
         target motors positions.
         """
         self.action_space = gym.spaces.Box(
             low=self._pd_controller._command_state_lower[self.order],
             high=self._pd_controller._command_state_upper[self.order],
             dtype=np.float64)
 
-    def _setup(self) -> None:
-        # Call base implementation
-        super()._setup()
-
-        # Reset the target motor accelerations
-        fill(self._target_accelerations, 0)
-
     @property
     def fieldnames(self) -> List[str]:
-        return [f"nextTarget{N_ORDER_DERIVATIVE_NAMES[self.order]}{name}"
-                for name in self.env.robot.motor_names]
+        return [f"nextTarget{N_ORDER_DERIVATIVE_NAMES[self.order]}{motor.name}"
+                for motor in self.env.robot.motors]
 
     def compute_command(self, action: np.ndarray, command: np.ndarray) -> None:
         """Compute the target motor accelerations from the desired value of
         some derivative of the target motor positions.
 
         :param action: Desired target motor acceleration.
         :param command: Current motor torques that will be updated in-place.
```

## gym_jiminy/common/envs/generic.py

```diff
@@ -19,70 +19,53 @@
 import numpy as np
 from gymnasium import spaces
 from gymnasium.core import RenderFrame
 
 import jiminy_py.core as jiminy
 from jiminy_py import tree
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    array_copyto,
-    EncoderSensor as encoder,
-    EffortSensor as effort,
-    ContactSensor as contact,
-    ForceSensor as force,
-    ImuSensor as imu)
+    EncoderSensor, EffortSensor, array_copyto)
 from jiminy_py.dynamics import compute_freeflyer_state_from_fixed_body
 from jiminy_py.log import extract_variables_from_log
 from jiminy_py.simulator import Simulator, TabbedFigure
 from jiminy_py.viewer.viewer import (DEFAULT_CAMERA_XYZRPY_REL,
                                      interactive_mode,
                                      get_default_backend,
                                      Viewer)
-from jiminy_py.viewer.replay import viewer_lock  # type: ignore[attr-defined]
+from jiminy_py.viewer.replay import viewer_lock
 
 import pinocchio as pin
 
 from ..utils import (FieldNested,
                      DataNested,
                      zeros,
                      is_nan,
                      build_clip,
                      build_copyto,
                      build_contains,
                      get_fieldnames,
                      register_variables)
-from ..bases import (ObsT,
+from ..bases import (DT_EPS,
+                     ObsT,
                      ActT,
                      InfoType,
                      SensorMeasurementStackMap,
                      EngineObsType,
                      InterfaceJiminyEnv)
 from ..quantities import QuantityManager
 
 from .internal import loop_interactive
 
 
 # Maximum realtime slowdown of simulation steps before triggering timeout error
-TIMEOUT_RATIO = 10
+TIMEOUT_RATIO = 15
 
 # Absolute tolerance when checking that observations are valid
 OBS_CONTAINS_TOL = 0.01
 
-# Define universal bounds for the observation space
-FREEFLYER_POS_TRANS_MAX = 1000.0
-FREEFLYER_VEL_LIN_MAX = 1000.0
-FREEFLYER_VEL_ANG_MAX = 10000.0
-JOINT_POS_MAX = 10000.0
-JOINT_VEL_MAX = 100.0
-FLEX_VEL_ANG_MAX = 10000.0
-MOTOR_EFFORT_MAX = 1000.0
-SENSOR_FORCE_MAX = 100000.0
-SENSOR_MOMENT_MAX = 10000.0
-SENSOR_GYRO_MAX = 100.0
-SENSOR_ACCEL_MAX = 10000.0
-
 
 LOGGER = logging.getLogger(__name__)
 
 
 class _LazyDictItemFilter(Mapping):
     def __init__(self,
                  dict_packed: MappingT[str, SequenceT[Any]],
@@ -115,15 +98,14 @@
     There is no reward by default. It is up to the user to overload this class
     to implement one. It has been designed to be highly flexible and easy to
     customize by overloading it to fit the vast majority of users' needs.
     """
     def __init__(self,
                  simulator: Simulator,
                  step_dt: float,
-                 enforce_bounded_spaces: bool = False,
                  debug: bool = False,
                  render_mode: Optional[str] = None,
                  **kwargs: Any) -> None:
         r"""
         :param simulator: Jiminy Python simulator used for physics
                           computations. It must be fully initialized.
         :param step_dt: Simulation timestep for learning. Note that it is
@@ -131,19 +113,14 @@
                         periods. The latter are configured via
                         `engine.set_options`.
         :param mode: Rendering mode. It can be either 'human' to display the
                      current simulation state, or 'rgb_array' to return a
                      snapshot as an RGB array without showing it on the screen.
                      Optional: 'human' by default if available with the current
                      backend (or default if none), 'rgb_array' otherwise.
-        :param enforce_bounded_spaces:
-            Whether to enforce finite bounds for the observation and action
-            spaces. If so, then '\*_MAX' are used whenever it is necessary.
-            Note that whose bounds are very spread to make sure it is suitable
-            for the vast majority of systems.
         :param debug: Whether the debug mode must be enabled. Doing it enables
                       telemetry recording.
         :param render_mode: Desired rendering mode, ie "human" or "rgb_array".
                             If "human" is specified, calling `render` will open
                             a graphical window for visualization, otherwise a
                             rgb image is returned, as a 3D numpy array whose
                             first dimension are the 3 red, green, blue channels
@@ -189,15 +166,14 @@
         # Make sure that rendering mode is valid
         assert render_mode in self.metadata['render_modes']
 
         # Backup some user arguments
         self.simulator: Simulator = simulator
         self._step_dt = step_dt
         self.render_mode = render_mode
-        self.enforce_bounded_spaces = enforce_bounded_spaces
         self.debug = debug
 
         # Define some proxies for fast access.
         # Note that some of them will be initialized in `_setup` method.
         self.engine: jiminy.Engine = self.simulator.engine
         self.stepper_state = self.simulator.stepper_state
         self.is_simulation_running = self.simulator.is_simulation_running
@@ -231,16 +207,15 @@
         # Information about the learning process
         self._info: InfoType = {}
 
         # Keep track of cumulative reward
         self.total_reward = 0.0
 
         # Number of simulation steps performed
-        self.num_steps = -1
-        self.max_steps = 0
+        self.num_steps = np.array(-1, dtype=np.int64)
         self._num_steps_beyond_terminate: Optional[int] = None
 
         # Initialize the interfaces through multiple inheritance
         super().__init__()  # Do not forward extra arguments, if any
 
         # Initialize the seed of the environment
         self._initialize_seed()
@@ -294,15 +269,16 @@
 
         # Register the action to the telemetry automatically iif there is
         # exactly one scalar action per motor.
         if isinstance(self.action, np.ndarray):
             action_size = self.action.size
             if action_size > 0 and action_size == self.robot.nmotors:
                 action_fieldnames = [
-                    ".".join(('action', e)) for e in self.robot.motor_names]
+                    ".".join(('action', motor.name))
+                    for motor in self.robot.motors]
                 self.register_variable(
                     'action', self.action, action_fieldnames)
 
     def __getattr__(self, name: str) -> Any:
         """Fallback attribute getter.
 
         It enables to get access to the attribute and methods of the low-level
@@ -332,62 +308,57 @@
         """Get time space.
         """
         return spaces.Box(low=0.0,
                           high=self.simulation_duration_max,
                           shape=(),
                           dtype=np.float64)
 
-    def _get_agent_state_space(
-            self, use_theoretical_model: bool = False) -> spaces.Dict:
+    def _get_agent_state_space(self,
+                               use_theoretical_model: bool = False,
+                               ignore_velocity_limit: bool = True
+                               ) -> spaces.Dict:
         """Get state space.
 
         This method is not meant to be overloaded in general since the
         definition of the state space is mostly consensual. One must rather
         overload `_initialize_observation_space` to customize the observation
         space as a whole.
+
+        :param use_theoretical_model: Whether to compute the state space
+                                      associated with the theoretical model
+                                      instead of the extended simulation model.
+        :param ignore_velocity_limit: Whether to ignore the velocity bounds
+                                      specified in model.
         """
         # Define some proxies for convenience
-        model_options = self.robot.get_model_options()
-        joint_velocity_indices = self.robot.mechanical_joint_velocity_indices
-        position_limit_upper = self.robot.position_limit_upper
-        position_limit_lower = self.robot.position_limit_lower
-        velocity_limit = self.robot.velocity_limit
-
-        # Replace inf bounds of the state space if requested
-        if self.enforce_bounded_spaces:
-            if self.robot.has_freeflyer:
-                position_limit_lower[:3] = -FREEFLYER_POS_TRANS_MAX
-                position_limit_upper[:3] = +FREEFLYER_POS_TRANS_MAX
-                velocity_limit[:3] = FREEFLYER_VEL_LIN_MAX
-                velocity_limit[3:6] = FREEFLYER_VEL_ANG_MAX
-
-            for joint_index in self.robot.flexibility_joint_indices:
-                joint_velocity_index = (
-                    self.robot.pinocchio_model.joints[joint_index].idx_v)
-                velocity_limit[
-                    joint_velocity_index + np.arange(3)] = FLEX_VEL_ANG_MAX
-
-            if not model_options['joints']['enableVelocityLimit']:
-                velocity_limit[joint_velocity_indices] = JOINT_VEL_MAX
+        pinocchio_model = self.robot.pinocchio_model
+        position_limit_lower = pinocchio_model.lowerPositionLimit
+        position_limit_upper = pinocchio_model.upperPositionLimit
+        velocity_limit = pinocchio_model.velocityLimit
 
         # Deduce bounds associated the theoretical model from the extended one
         if use_theoretical_model:
             position_limit_lower, position_limit_upper = map(
                 self.robot.get_theoretical_position_from_extended,
                 (position_limit_lower, position_limit_upper))
             velocity_limit = self.robot.get_theoretical_velocity_from_extended(
                 velocity_limit)
 
+        # Ignore velocity bounds in requested
+        if ignore_velocity_limit:
+            velocity_limit = np.full_like(velocity_limit, float("inf"))
+
         # Aggregate position and velocity bounds to define state space
         return spaces.Dict(OrderedDict(
             q=spaces.Box(low=position_limit_lower,
                          high=position_limit_upper,
                          dtype=np.float64),
-            v=spaces.Box(low=-velocity_limit,
-                         high=velocity_limit,
+            v=spaces.Box(low=float("-inf"),
+                         high=float("inf"),
+                         shape=(self.robot.pinocchio_model.nv,),
                          dtype=np.float64)))
 
     def _get_measurements_space(self) -> spaces.Dict:
         """Get sensor space.
 
         It gathers the sensors data in a dictionary. It maps each available
         type of sensor to the associated data matrix. Rows correspond to the
@@ -402,112 +373,70 @@
                 field = getattr(jiminy_py.core, key).fieldnames[i]
 
             The mapping between column `j` of data matrix and associated sensor
             name and object are given by:
 
             .. code-block:: python
 
-                sensor_name = env.robot.sensor_names[key][j]
-                sensor = env.robot.get_sensor(key, sensor_name)
+                sensor = env.robot.sensors[key][j]
 
         .. warning:
             This method is not meant to be overloaded in general since the
             definition of the sensor space is mostly consensual. One must
             rather overload `_initialize_observation_space` to customize the
             observation space as a whole.
         """
         # Define some proxies for convenience
-        sensor_measurements = self.robot.sensor_measurements
-        command_limit = self.robot.command_limit
-        position_space, velocity_space = self._get_agent_state_space().values()
-        assert isinstance(position_space, spaces.Box)
-        assert isinstance(velocity_space, spaces.Box)
-
-        # Replace inf bounds of the action space
-        for motor_name in self.robot.motor_names:
-            motor = self.robot.get_motor(motor_name)
-            motor_options = motor.get_options()
-            if not motor_options["enableCommandLimit"]:
-                command_limit[motor.joint_velocity_index] = MOTOR_EFFORT_MAX
+        position_limit_lower = self.robot.pinocchio_model.lowerPositionLimit
+        position_limit_upper = self.robot.pinocchio_model.upperPositionLimit
 
         # Initialize the bounds of the sensor space
+        sensor_measurements = self.robot.sensor_measurements
         sensor_space_lower = OrderedDict(
             (key, np.full(value.shape, -np.inf))
             for key, value in sensor_measurements.items())
         sensor_space_upper = OrderedDict(
             (key, np.full(value.shape, np.inf))
             for key, value in sensor_measurements.items())
 
         # Replace inf bounds of the encoder sensor space
-        if encoder.type in sensor_measurements.keys():
-            sensor_list = self.robot.sensor_names[encoder.type]
-            for sensor_name in sensor_list:
-                # Get the position and velocity bounds of the sensor.
-                # Note that for rotary unbounded encoders, the sensor bounds
-                # cannot be extracted from the configuration vector limits
-                # since the representation is different: cos/sin for the
-                # configuration, and principal value of the angle for the
-                # sensor.
-                sensor = self.robot.get_sensor(encoder.type, sensor_name)
-                assert isinstance(sensor, encoder)
-                sensor_index = sensor.index
-                joint = self.robot.pinocchio_model.joints[sensor.joint_index]
-                if sensor.joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
-                    sensor_position_lower = -np.pi
-                    sensor_position_upper = np.pi
-                else:
-                    sensor_position_lower = position_space.low[joint.idx_q]
-                    sensor_position_upper = position_space.high[joint.idx_q]
-                sensor_velocity_limit = velocity_space.high[joint.idx_v]
-
-                # Update the bounds accordingly
-                sensor_space_lower[encoder.type][:, sensor_index] = (
-                    sensor_position_lower, -sensor_velocity_limit)
-                sensor_space_upper[encoder.type][:, sensor_index] = (
-                    sensor_position_upper, sensor_velocity_limit)
+        for sensor in self.robot.sensors.get(EncoderSensor.type, ()):
+            # Get the position bounds of the sensor.
+            # Note that for rotary unbounded encoders, the sensor bounds
+            # cannot be extracted from the motor because only the principal
+            # value of the angle is observed by the sensor.
+            assert isinstance(sensor, EncoderSensor)
+            joint = self.robot.pinocchio_model.joints[sensor.joint_index]
+            joint_type = jiminy.get_joint_type(joint)
+            if joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
+                sensor_position_lower = - np.pi
+                sensor_position_upper = np.pi
+            else:
+                try:
+                    motor = self.robot.motors[sensor.motor_index]
+                    sensor_position_lower = motor.position_limit_lower
+                    sensor_position_upper = motor.position_limit_upper
+                except IndexError:
+                    sensor_position_lower = position_limit_lower[joint.idx_q]
+                    sensor_position_upper = position_limit_upper[joint.idx_q]
+
+            # Update the bounds accordingly
+            sensor_space_lower[EncoderSensor.type][0, sensor.index] = (
+                sensor_position_lower)
+            sensor_space_upper[EncoderSensor.type][0, sensor.index] = (
+                sensor_position_upper)
 
         # Replace inf bounds of the effort sensor space
-        if effort.type in sensor_measurements.keys():
-            sensor_list = self.robot.sensor_names[effort.type]
-            for sensor_name in sensor_list:
-                sensor = self.robot.get_sensor(effort.type, sensor_name)
-                assert isinstance(sensor, effort)
-                sensor_index = sensor.index
-                motor_velocity_index = self.robot.motor_velocity_indices[
-                    sensor.motor_index]
-                sensor_space_lower[effort.type][0, sensor_index] = (
-                    -command_limit[motor_velocity_index])
-                sensor_space_upper[effort.type][0, sensor_index] = (
-                    command_limit[motor_velocity_index])
-
-        # Replace inf bounds of the imu sensor space
-        if self.enforce_bounded_spaces:
-            # Replace inf bounds of the contact sensor space
-            if contact.type in sensor_measurements.keys():
-                sensor_space_lower[contact.type][:] = -SENSOR_FORCE_MAX
-                sensor_space_upper[contact.type][:] = SENSOR_FORCE_MAX
-
-            # Replace inf bounds of the force sensor space
-            if force.type in sensor_measurements.keys():
-                sensor_space_lower[force.type][:3] = -SENSOR_FORCE_MAX
-                sensor_space_upper[force.type][:3] = SENSOR_FORCE_MAX
-                sensor_space_lower[force.type][3:] = -SENSOR_MOMENT_MAX
-                sensor_space_upper[force.type][3:] = SENSOR_MOMENT_MAX
-
-            # Replace inf bounds of the imu sensor space
-            if imu.type in sensor_measurements.keys():
-                gyro_index = [
-                    field.startswith('Gyro') for field in imu.fieldnames]
-                sensor_space_lower[imu.type][gyro_index] = -SENSOR_GYRO_MAX
-                sensor_space_upper[imu.type][gyro_index] = SENSOR_GYRO_MAX
-
-                accel_index = [
-                    field.startswith('Accel') for field in imu.fieldnames]
-                sensor_space_lower[imu.type][accel_index] = -SENSOR_ACCEL_MAX
-                sensor_space_upper[imu.type][accel_index] = SENSOR_ACCEL_MAX
+        for sensor in self.robot.sensors.get(EffortSensor.type, ()):
+            assert isinstance(sensor, EffortSensor)
+            motor = self.robot.motors[sensor.motor_index]
+            sensor_space_lower[EffortSensor.type][0, sensor.index] = (
+                - motor.effort_limit)
+            sensor_space_upper[EffortSensor.type][0, sensor.index] = (
+                motor.effort_limit)
 
         return spaces.Dict(OrderedDict(
             (key, spaces.Box(low=min_val, high=max_val, dtype=np.float64))
             for (key, min_val), max_val in zip(
                 sensor_space_lower.items(), sensor_space_upper.values())))
 
     def _initialize_action_space(self) -> None:
@@ -518,29 +447,20 @@
 
         .. warning::
             This method is called internally by `reset` method. It is not
             meant to be overloaded since the actual action space of the
             robot is uniquely defined.
         """
         # Get effort limit
-        command_limit = self.robot.command_limit
-
-        # Replace inf bounds of the effort limit if requested
-        if self.enforce_bounded_spaces:
-            for motor_name in self.robot.motor_names:
-                motor = self.robot.get_motor(motor_name)
-                motor_options = motor.get_options()
-                if not motor_options["enableCommandLimit"]:
-                    command_limit[motor.joint_velocity_index] = \
-                        MOTOR_EFFORT_MAX
+        command_limit = np.array([
+            motor.effort_limit for motor in self.robot.motors])
 
         # Set the action space
-        action_scale = command_limit[self.robot.motor_velocity_indices]
         self.action_space = spaces.Box(
-            low=-action_scale, high=action_scale, dtype=np.float64)
+            low=-command_limit, high=command_limit, dtype=np.float64)
 
     def _initialize_seed(self, seed: Optional[int] = None) -> None:
         """Specify the seed of the environment.
 
         .. note::
             This method is not meant to be called manually.
 
@@ -712,15 +632,15 @@
 
         # Reset the simulator.
         # Do NOT remove all forces since it has already been done before, and
         # because it would make it impossible to register forces in  `_setup`.
         self.simulator.reset(remove_all_forces=False)
 
         # Reset some internal buffers
-        self.num_steps = 0
+        self.num_steps[()] = 0
         self._num_steps_beyond_terminate = None
 
         # Create a new log file
         if self.debug:
             fd, self.log_path = tempfile.mkstemp(suffix=".data")
             os.close(fd)
 
@@ -794,17 +714,14 @@
         self.derived = env
 
         # Instantiate the actual controller.
         # Note that a weak reference must be used to avoid circular reference.
         self.robot.controller = jiminy.FunctionalController(
             partial(type(env)._controller_handle, weakref.proxy(env)))
 
-        # Configure the maximum number of steps
-        self.max_steps = int(self.simulation_duration_max // self.step_dt)
-
         # Register user-specified variables to the telemetry
         for header, value in self._registered_variables.values():
             register_variables(self.robot.controller, header, value)
 
         # Start the engine
         self.simulator.start(q_init, v_init)
 
@@ -844,16 +761,19 @@
         # Make sure there is no 'nan' value in observation
         for value in tree.flatten(obs):
             if is_nan(value):
                 raise RuntimeError(
                     f"'nan' value found in observation ({obs}). Something "
                     "went wrong with `refresh_observation` method.")
 
+        # Reset the extra information buffer
+        self._info.clear()
+
         # The simulation cannot be done before doing a single step.
-        if any(self.has_terminated()):
+        if any(self.has_terminated(self._info)):
             raise RuntimeError(
                 "The simulation has already terminated at `reset`. Check the "
                 "implementation of `has_terminated` if overloaded.")
 
         # Reset cumulative reward
         self.total_reward = 0.0
 
@@ -929,42 +849,45 @@
         try:
             self.simulator.step(self.step_dt)
         except Exception:
             # Stop the simulation before raising the exception
             self.simulator.stop()
             raise
 
+        # Make sure there is no 'nan' value in observation
+        if is_nan(self._robot_state_a):
+            raise RuntimeError(
+                "The acceleration of the system is 'nan'. Something went "
+                "wrong with jiminy engine.")
+
+        # Update number of (successful) steps
+        self.num_steps += 1
+
         # Update shared buffers
         self._refresh_buffers()
 
         # Update the observer at the end of the step.
         # This is necessary because, internally, it is called at the beginning
         # of the every integration steps, during the controller update.
         self.derived._observer_handle(
             self.stepper_state.t,
             self._robot_state_q,
             self._robot_state_v,
             self.robot.sensor_measurements)
 
-        # Make sure there is no 'nan' value in observation
-        if is_nan(self._robot_state_a):
-            raise RuntimeError(
-                "The acceleration of the system is 'nan'. Something went "
-                "wrong with jiminy engine.")
-
         # Reset the extra information buffer
         self._info.clear()
 
         # Check if the simulation is over.
         # Note that 'truncated' is forced to True if the integration failed or
         # if the maximum number of steps will be exceeded next step.
-        terminated, truncated = self.has_terminated()
+        terminated, truncated = self.has_terminated(self._info)
         truncated = (
             truncated or not self.is_simulation_running or
-            self.num_steps >= self.max_steps)
+            self.stepper_state.t + DT_EPS > self.simulation_duration_max)
 
         # Check if stepping after done and if it is an undefined behavior
         if self._num_steps_beyond_terminate is None:
             if terminated or truncated:
                 self._num_steps_beyond_terminate = 0
         else:
             if not self.is_training and self._num_steps_beyond_terminate == 0:
@@ -976,32 +899,29 @@
             self._num_steps_beyond_terminate += 1
 
         # Compute reward if not beyond termination
         if self._num_steps_beyond_terminate:
             reward = float('nan')
         else:
             # Compute reward and update extra information
-            reward = self.compute_reward(terminated, truncated, self._info)
+            reward = self.compute_reward(terminated, self._info)
 
             # Make sure the reward is not 'nan'
             if math.isnan(reward):
                 raise RuntimeError(
                     "The reward is 'nan'. Something went wrong with "
                     "`compute_reward` implementation.")
 
             # Update cumulative reward
             self.total_reward += reward
 
         # Write log file if simulation has just terminated in debug mode
         if self.debug and self._num_steps_beyond_terminate == 0:
             self.simulator.write_log(self.log_path, format="binary")
 
-        # Update number of (successful) steps
-        self.num_steps += 1
-
         # Clip (and copy) the most derived observation before returning it
         obs = self._get_clipped_env_observation()
 
         return obs, reward, terminated, truncated, deepcopy(self._info)
 
     def render(self) -> Optional[Union[RenderFrame, List[RenderFrame]]]:
         """Render the agent in its environment.
@@ -1095,15 +1015,15 @@
         # Note that backend is closed automatically is there is no viewer
         # backend available at this point, to reduce memory pressure, but it
         # will take time to restart it systematically for every recordings.
         if kwargs.get('record_video_path') is not None:
             kwargs['close_backend'] = not self.simulator.is_viewer_available
 
         # Stop any running simulation before replay if `has_terminated` is True
-        if self.is_simulation_running and any(self.has_terminated()):
+        if self.is_simulation_running and any(self.has_terminated({})):
             self.simulator.stop()
 
         with viewer_lock:
             # Call render before replay in order to take into account custom
             # backend viewer instantiation options, eg the initial camera pose,
             # and to update the ground profile.
             self.simulator.render(
@@ -1346,17 +1266,27 @@
             engine_options["stepper"]["logInternalStepperSteps"] = True
 
         # Set maximum computation time for single internal integration steps
         engine_options["stepper"]["timeout"] = self.step_dt * TIMEOUT_RATIO
         if self.debug:
             engine_options["stepper"]["timeout"] = 0.0
 
-        # Force disabling logging of geometries unless in debug or eval modes
-        if self.is_training and not self.debug:
-            engine_options["telemetry"]["isPersistent"] = False
+        # Enable full logging in debug and evaluation mode
+        if self.debug or not self.is_training:
+            # Enable telemetry at engine-level
+            telemetry_options = engine_options["telemetry"]
+            for key in telemetry_options.keys():
+                telemetry_options[key] = True
+
+            # Enable telemetry at robot-level
+            robot_options = self.robot.get_options()
+            robot_telemetry_options = robot_options["telemetry"]
+            for key in robot_telemetry_options.keys():
+                robot_telemetry_options[key] = True
+            self.robot.set_options(robot_options)
 
         # Update engine options
         self.simulator.set_options(engine_options)
 
     def _initialize_observation_space(self) -> None:
         """Configure the observation of the environment.
 
@@ -1392,16 +1322,16 @@
             initial state. It can be overloaded to ensure static stability of
             the configuration.
         """
         # Get the neutral configuration of the actual model
         q = pin.neutral(self.robot.pinocchio_model)
 
         # Make sure it is not out-of-bounds before returning
-        position_limit_lower = self.robot.position_limit_lower
-        position_limit_upper = self.robot.position_limit_upper
+        position_limit_lower = self.robot.pinocchio_model.lowerPositionLimit
+        position_limit_upper = self.robot.pinocchio_model.upperPositionLimit
         for idx, val in enumerate(q):
             lo, hi = position_limit_lower[idx], position_limit_upper[idx]
             if hi < val or val < lo:
                 q[idx] = 0.5 * (lo + hi)
         return q
 
     def _sample_state(self) -> Tuple[np.ndarray, np.ndarray]:
@@ -1418,16 +1348,16 @@
             This method is called internally by `reset` to generate the initial
             state. It can be overloaded to act as a random state generator.
         """
         # Get the neutral configuration
         q = self._neutral()
 
         # Make sure the configuration is not out-of-bound
-        q.clip(self.robot.position_limit_lower,
-               self.robot.position_limit_upper,
+        q.clip(self.robot.pinocchio_model.lowerPositionLimit,
+               self.robot.pinocchio_model.upperPositionLimit,
                out=q)
 
         # Make sure the configuration is normalized
         q = pin.normalize(self.robot.pinocchio_model, q)
 
         # Make sure the robot impacts the ground
         if self.robot.has_freeflyer:
@@ -1544,15 +1474,17 @@
         # Check if the action is out-of-bounds, in debug mode only
         if self.debug and not self._contains_action():
             LOGGER.warning("The action is out-of-bounds.")
 
         assert isinstance(action, np.ndarray)
         array_copyto(command, action)
 
-    def has_terminated(self) -> Tuple[bool, bool]:
+    def has_terminated(self,
+                       info: InfoType  # pylint: disable=unused-argument
+                       ) -> Tuple[bool, bool]:
         """Determine whether the episode is over, because a terminal state of
         the underlying MDP has been reached or an aborting condition outside
         the scope of the MDP has been triggered.
 
         By default, it always returns `terminated=False`, and `truncated=True`
         iif the observation is out-of-bounds. One can overload this method to
         implement custom termination conditions for the environment at hands.
@@ -1563,14 +1495,16 @@
             default value is extremely large, but it can be overwritten by the
             user to terminate the simulation earlier.
 
         .. note::
             This method is called after `refresh_observation`, so that the
             internal buffer 'observation' is up-to-date.
 
+        :param info: Dictionary of extra information for monitoring.
+
         :returns: terminated and truncated flags.
         """
         # Make sure that a simulation is running
         if not self.is_simulation_running:
             raise RuntimeError(
                 "No simulation running. Please start one before calling this "
                 "method.")
```

## gym_jiminy/common/envs/locomotion.py

```diff
@@ -1,22 +1,22 @@
 """Generic environment to learn locomotion skills for legged robots using
 Jiminy simulator as physics engine.
 """
 import os
 import pathlib
-from typing import Optional, Dict, Union, Any, Type, Sequence, Tuple
+from typing import Any, Dict, Optional, Tuple
 
 import numpy as np
 
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    EncoderSensor as encoder,
-    EffortSensor as effort,
-    ContactSensor as contact,
-    ForceSensor as force,
-    ImuSensor as imu,
+    EncoderSensor,
+    EffortSensor,
+    ContactSensor,
+    ForceSensor,
+    ImuSensor,
     PeriodicGaussianProcess,
     Robot)
 from jiminy_py.robot import BaseJiminyRobot
 from jiminy_py.simulator import Simulator
 
 import pinocchio as pin
 
@@ -34,33 +34,33 @@
 F_PROFILE_SCALE = 50.0
 F_PROFILE_WAVELENGTH = 0.2
 F_PROFILE_PERIOD = 1.0
 FLEX_STIFFNESS_SCALE = 1000
 FLEX_DAMPING_SCALE = 10
 
 SENSOR_DELAY_SCALE = {
-    encoder.type: 3.0e-3,
-    effort.type: 0.0,
-    contact.type: 0.0,
-    force.type: 0.0,
-    imu.type: 0.0
+    EncoderSensor: 3.0e-3,
+    EffortSensor: 0.0,
+    ContactSensor: 0.0,
+    ForceSensor: 0.0,
+    ImuSensor: 0.0
 }
 SENSOR_NOISE_SCALE = {
-    encoder.type:  np.array([0.0, 0.02]),
-    effort.type: np.array([10.0]),
-    contact.type: np.array([2.0, 2.0, 2.0, 10.0, 10.0, 10.0]),
-    force.type: np.array([2.0, 2.0, 2.0]),
-    imu.type:  np.array([0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.2, 0.2, 0.2])
+    EncoderSensor: np.array([0.0, 0.02]),
+    EffortSensor: np.array([10.0]),
+    ContactSensor: np.array([2.0, 2.0, 2.0, 10.0, 10.0, 10.0]),
+    ForceSensor: np.array([2.0, 2.0, 2.0]),
+    ImuSensor: np.array([0.0, 0.0, 0.0, 0.01, 0.01, 0.01, 0.2, 0.2, 0.2])
 }
 SENSOR_BIAS_SCALE = {
-    encoder.type:  np.array([0.0, 0.0]),
-    effort.type: np.array([0.0]),
-    contact.type: np.array([4.0, 4.0, 4.0, 20.0, 20.0, 20.0]),
-    force.type: np.array([4.0, 4.0, 4.0]),
-    imu.type:  np.array([0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0])
+    EncoderSensor: np.array([0.0, 0.0]),
+    EffortSensor: np.array([0.0]),
+    ContactSensor: np.array([4.0, 4.0, 4.0, 20.0, 20.0, 20.0]),
+    ForceSensor: np.array([4.0, 4.0, 4.0]),
+    ImuSensor: np.array([0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.0, 0.0, 0.0])
 }
 
 DEFAULT_SIMULATION_DURATION = 30.0  # (s) Default simulation duration
 DEFAULT_STEP_DT = 0.04              # (s) Stepper update period
 
 DEFAULT_HLC_TO_LLC_RATIO = 1  # (NA)
 
@@ -76,15 +76,14 @@
 
     def __init__(self,
                  urdf_path: Optional[str],
                  hardware_path: Optional[str] = None,
                  mesh_path_dir: Optional[str] = None,
                  simulation_duration_max: float = DEFAULT_SIMULATION_DURATION,
                  step_dt: float = DEFAULT_STEP_DT,
-                 enforce_bounded_spaces: bool = False,
                  reward_mixture: Optional[dict] = None,
                  std_ratio: Optional[dict] = None,
                  config_path: Optional[str] = None,
                  avoid_instable_collisions: bool = True,
                  debug: bool = False, *,
                  robot: Optional[Robot] = None,
                  viewer_kwargs: Optional[Dict[str, Any]] = None,
@@ -97,17 +96,14 @@
                               the same folder and with the same name.
         :param mesh_path_dir: Path to the folder containing the model meshes.
                               Optional: Env variable 'JIMINY_DATA_PATH' will be
                               used if available.
         :param simulation_duration_max: Maximum duration of a simulation before
                                         returning done.
         :param step_dt: Simulation timestep for learning.
-        :param enforce_bounded_spaces:
-            Whether to enforce finite bounds for the observation and action
-            spaces. If so, '\*_MAX' are used whenever it is necessary.
         :param reward_mixture: Weighting factors of selected contributions to
                                total reward.
         :param std_ratio: Relative standard deviation of selected contributions
                           to environment stochasticity.
         :param config_path: Configuration toml file to import. It will be
                             imported AFTER loading the hardware description
                             file. It can be automatically generated from an
@@ -202,16 +198,15 @@
                 config_path = str(pathlib.Path(
                     urdf_path).with_suffix('')) + '_options.toml'
                 if not os.path.exists(config_path):
                     config_path = ""
             simulator.import_options(config_path)
 
         # Initialize base class
-        super().__init__(
-            simulator, step_dt, enforce_bounded_spaces, debug, **kwargs)
+        super().__init__(simulator, step_dt, debug, **kwargs)
 
     def _setup(self) -> None:
         """Configure the environment.
 
         It is doing the following steps, successively:
 
             - updates some proxies that will be used for computing the
@@ -229,67 +224,67 @@
         super()._setup()
 
         if not self.robot.has_freeflyer:
             raise RuntimeError(
                 "`WalkerJiminyEnv` only supports robots with freeflyer.")
 
         # Update some internal buffers used for computing the reward
-        motor_effort_limit = self.robot.pinocchio_model.effortLimit[
-            self.robot.motor_velocity_indices]
-        motor_velocity_limit = self.robot.velocity_limit[
-            self.robot.motor_velocity_indices]
-        self._power_consumption_max = sum(
-            motor_effort_limit * motor_velocity_limit)
+        self._power_consumption_max = 0.0
+        for motor in self.robot.motors:
+            motor_power_max = motor.velocity_limit * motor.effort_limit
+            self._power_consumption_max += motor_power_max
 
         # Compute the height of the freeflyer in neutral configuration
         # TODO: Take into account the ground profile.
         q_init, _ = self._sample_state()
         self._height_neutral = q_init[2]
 
         # Get the options of robot and engine
         robot_options = self.robot.get_options()
         engine_options = self.simulator.get_options()
 
         # Make sure to log at least the required data for terminal reward
         # computation and log replay.
         engine_options['telemetry']['enableConfiguration'] = True
         engine_options['telemetry']['enableVelocity'] = True
-        engine_options['telemetry']['enableForceExternal'] = \
-            'disturbance' in self.std_ratio.keys()
+        if 'disturbance' in self.std_ratio.keys():
+            engine_options['telemetry']['enableForceExternal'] = True
 
         # ============= Add some stochasticity to the environment =============
 
         # Change ground friction
         engine_options['contacts']['friction'] = sample(
             *GROUND_FRICTION_RANGE,
             scale=self.std_ratio.get('ground', 0.0),
             enable_log_scale=True,
             rg=self.np_random)
 
         # Add sensor noise, bias and delay
         if 'sensors' in self.std_ratio.keys():
-            sensor_classes: Sequence[Union[
-                Type[encoder], Type[effort], Type[contact], Type[force],
-                Type[imu]]] = (encoder, effort, contact, force, imu)
-            for sensor in sensor_classes:
-                sensors_options = robot_options["sensors"][sensor.type]
+            for cls in (EncoderSensor,
+                        EffortSensor,
+                        ContactSensor,
+                        ForceSensor,
+                        ImuSensor):
+                sensors_options = robot_options["sensors"][cls.type]
                 for sensor_options in sensors_options.values():
                     for name in ("delay", "jitter"):
                         sensor_options[name] = sample(
                             low=0.0,
                             high=(self.std_ratio['sensors'] *
-                                  SENSOR_DELAY_SCALE[sensor.type]),
+                                  SENSOR_DELAY_SCALE[cls]),
                             rg=self.np_random)
                     for name in (
                             ("bias", SENSOR_BIAS_SCALE),
                             ("noiseStd", SENSOR_NOISE_SCALE)):
                         sensor_options[name] = sample(
                             scale=(self.std_ratio['sensors'] *
-                                   SENSOR_NOISE_SCALE[sensor.type]),
-                            shape=(len(sensor.fieldnames),),
+                                   SENSOR_NOISE_SCALE[cls]),
+                            shape=(len(
+                                cls.fieldnames),),  # type: ignore[arg-type]
                             rg=self.np_random)
 
         # Randomize the flexibility parameters
         if 'model' in self.std_ratio.keys():
             if self.robot.is_flexibility_enabled:
                 dynamics_options = robot_options["model"]["dynamics"]
                 for flexibility in dynamics_options["flexibilityConfig"]:
@@ -357,42 +352,41 @@
                        angular) [Fx, Fy, Fz, Mx, My, Mz].
         """
         # pylint: disable=unused-argument
         wrench[0] = F_PROFILE_SCALE * self._f_xy_profile[0](t)
         wrench[1] = F_PROFILE_SCALE * self._f_xy_profile[1](t)
         wrench[:2] *= self.std_ratio['disturbance']
 
-    def has_terminated(self) -> Tuple[bool, bool]:
+    def has_terminated(self, info: InfoType) -> Tuple[bool, bool]:
         """Determine whether the episode is over.
 
         It terminates (`terminated=True`) under the following conditions:
 
             - fall detection: the freeflyer goes lower than 75% of its height
               in neutral configuration.
 
         It is truncated under the following conditions:
 
             - observation out-of-bounds
             - maximum simulation duration exceeded
 
+        :param info: Dictionary of extra information for monitoring.
+
         :returns: terminated and truncated flags.
         """
         # Call base implementation
-        terminated, truncated = super().has_terminated()
+        terminated, truncated = super().has_terminated(info)
 
         # Check if the agent has successfully solved the task
         if self._robot_state_q[2] < self._height_neutral * 0.5:
             terminated = True
 
         return terminated, truncated
 
-    def compute_reward(self,
-                       terminated: bool,
-                       truncated: bool,
-                       info: InfoType) -> float:
+    def compute_reward(self, terminated: bool, info: InfoType) -> float:
         """Compute reward at current episode state.
 
         It computes the reward associated with each individual contribution
         according to 'reward_mixture'.
 
         .. note::
             This method can be overwritten to implement new contributions to
@@ -405,15 +399,15 @@
         # Define some proxies
         reward_mixture_keys = self.reward_mixture.keys()
 
         if 'survival' in reward_mixture_keys:
             reward_dict['survival'] = 1.0
 
         if 'energy' in reward_mixture_keys:
-            v_mot = self.robot.sensor_measurements[encoder.type][1]
+            _, v_mot = self.robot.sensor_measurements[EncoderSensor.type]
             command = self.robot_state.command
             power_consumption = np.sum(np.maximum(command * v_mot, 0.0))
             power_consumption_rel = \
                 power_consumption / self._power_consumption_max
             reward_dict['energy'] = - power_consumption_rel
 
         if terminated:
```

## gym_jiminy/common/quantities/__init__.py

```diff
@@ -1,15 +1,26 @@
 # pylint: disable=missing-module-docstring
 
 from .manager import QuantityManager
-from .generic import (AverageSpatialVelocityFrame,
-                      EulerAnglesFrame)
-from .locomotion import CenterOfMass, ZeroMomentPoint
+from .generic import (FrameEulerAngles,
+                      FrameXYZQuat,
+                      StackedQuantity,
+                      AverageFrameSpatialVelocity,
+                      MaskedQuantity,
+                      BinaryOpQuantity)
+from .locomotion import (AverageOdometryVelocity,
+                         CenterOfMass,
+                         ZeroMomentPoint)
 
 
 __all__ = [
     'QuantityManager',
-    'AverageSpatialVelocityFrame',
-    'EulerAnglesFrame',
+    'FrameEulerAngles',
+    'FrameXYZQuat',
+    'StackedQuantity',
+    'AverageFrameSpatialVelocity',
+    'MaskedQuantity',
+    'BinaryOpQuantity',
+    'AverageOdometryVelocity',
     'CenterOfMass',
     'ZeroMomentPoint',
 ]
```

## gym_jiminy/common/quantities/generic.py

```diff
@@ -1,282 +1,832 @@
 """Generic quantities that may be relevant for any kind of robot, regardless
 its topology (multiple or single branch, fixed or floating base...) and the
 application (locomotion, grasping...).
 """
+from copy import deepcopy
+from collections import deque
 from functools import partial
 from dataclasses import dataclass
-from typing import List, Dict, Set, Optional
+from typing import (
+    List, Dict, Set, Any, Optional, Protocol, Sequence, Tuple, TypeVar, Union,
+    Generic, Callable, runtime_checkable)
+from typing_extensions import TypeAlias
 
 import numpy as np
 
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
-    array_copyto, multi_array_copyto)
+    multi_array_copyto)
 import pinocchio as pin
 
-from ..bases import InterfaceJiminyEnv, AbstractQuantity
-from ..utils import fill, transforms_to_vector, matrix_to_rpy
+from ..bases import (
+    InterfaceJiminyEnv, InterfaceQuantity, AbstractQuantity, QuantityCreator,
+    QuantityEvalMode)
+from ..utils import (
+    fill, matrix_to_rpy, matrix_to_quat, quat_to_matrix,
+    quat_interpolate_middle)
+
+
+EllipsisType: TypeAlias = Any  # TODO: `EllipsisType` introduced in Python 3.10
+
+ValueT = TypeVar('ValueT')
+OtherValueT = TypeVar('OtherValueT')
+YetAnotherValueT = TypeVar('YetAnotherValueT')
+
+
+@runtime_checkable
+class FrameQuantity(Protocol):
+    """Protocol that must be satisfied by all quantities associated with one
+    particular frame.
+
+    This protocol is used when aggregating individual frame-level quantities
+    in a larger batch for computation vectorization on all frames at once.
+    Intermediate quantities managing these batches will make sure that all
+    their parents derive from one of the supported protocols, which includes
+    this one.
+    """
+    frame_name: str
+
+
+@runtime_checkable
+class MultiFrameQuantity(Protocol):
+    """Protocol that must be satisfied by all quantities associated with
+    a particular set of frames for which the same batched intermediary
+    quantities must be computed.
+
+    This protocol is involved in automatic computation vectorization. See
+    `FrameQuantity` documentation for details.
+    """
+    frame_names: Sequence[str]
 
 
 @dataclass(unsafe_hash=True)
-class AverageSpatialVelocityFrame(AbstractQuantity[np.ndarray]):
-    """Average spatial velocity of a given frame at the end of an agent step.
+class _MultiFramesRotationMatrix(AbstractQuantity[np.ndarray]):
+    """3D rotation matrix of the orientation of all frames involved in
+    quantities relying on it and are active since last reset of computation
+    tracking if shared cache is available, its parent otherwise.
+
+    This quantity only provides a performance benefit when managed by some
+    `QuantityManager`. It is not supposed to be instantiated manually but use
+    as requirement of some other quantity for computation vectorization on all
+    frames at once.
+
+    The data associated with each frame is exposed to the user as a batched 3D
+    contiguous array. The two first dimensions are rotation matrix elements,
+    while the last one are individual frames with the same ordering as
+    'self.frame_names'.
+
+    .. note::
+        This quantity does not allow for specifying frames directly. There is
+        no way to get the orientation of multiple frames at once for now.
+    """
+
+    identifier: int
+    """Uniquely identify its parent type.
+
+    This implies that quantities specifying `_MultiFramesRotationMatrix` as a
+    requirement will shared a unique batch with all the other ones having the
+    same type but not the others. This is essential to provide data access as a
+    batched ND contiguous array.
+    """
+
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: InterfaceQuantity,
+                 mode: QuantityEvalMode) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Make sure that a parent has been specified
+        assert isinstance(parent, (FrameQuantity, MultiFrameQuantity))
+
+        # Set unique identifier based on parent type
+        self.identifier = hash(type(parent))
+
+        # Call base implementation
+        super().__init__(
+            env, parent, requirements={}, mode=mode, auto_refresh=False)
+
+        # Initialize the ordered list of frame names
+        self.frame_names: Set[str] = set()
+
+        # Store all rotation matrices at once
+        self._rot_mat_batch: np.ndarray = np.array([])
+
+        # Define proxy for slices of the batch storing all rotation matrices
+        self._rot_mat_slices: List[np.ndarray] = []
+
+        # Define proxy for the rotation matrices of all frames
+        self._rot_mat_list: List[np.ndarray] = []
+
+    def initialize(self) -> None:
+        # Call base implementation
+        super().initialize()
+
+        # Update the frame names based on the cache owners of this quantity.
+        # Note that only active quantities are considered for efficiency, which
+        # may change dynamically. Delegating this responsibility to cache
+        # owners may be possible but difficult to implement because
+        # `frame_names` must be cleared first before re-registering themselves,
+        # just in case of optimal computation graph has changed, not only once
+        # to avoid getting rid of quantities that just registered themselves.
+        # Nevertheless, whenever re-initializing this quantity to take into
+        # account changes of the active set must be decided by cache owners.
+        assert isinstance(self.parent, (FrameQuantity, MultiFrameQuantity))
+        if isinstance(self.parent, FrameQuantity):
+            self.frame_names = {self.parent.frame_name}
+        else:
+            self.frame_names = set(self.parent.frame_names)
+        if self.has_cache:
+            for owner in self.cache.owners:
+                # We only consider active `_MultiFramesEulerAngles` instances
+                # instead of their parents. This is necessary because a derived
+                # quantity may feature `_MultiFramesEulerAngles` as requirement
+                # without actually relying on it depending on whether it is
+                # part of the optimal computation path at that time.
+                if owner.is_active(any_cache_owner=False):
+                    assert isinstance(
+                        owner.parent, (FrameQuantity, MultiFrameQuantity))
+                    if isinstance(owner.parent, FrameQuantity):
+                        self.frame_names.add(owner.parent.frame_name)
+                    else:
+                        self.frame_names.union(owner.parent.frame_names)
+
+        # Re-allocate memory as the number of frames is not known in advance.
+        # Note that Fortran memory layout (column-major) is used for speed up
+        # because it preserves contiguity when copying frame data.
+        nframes = len(self.frame_names)
+        self._rot_mat_batch = np.zeros((3, 3, nframes), order='F')
+
+        # Refresh proxies
+        self._rot_mat_slices.clear()
+        self._rot_mat_list.clear()
+        for i, frame_name in enumerate(self.frame_names):
+            frame_index = self.pinocchio_model.getFrameId(frame_name)
+            rot_matrix = self.pinocchio_data.oMf[frame_index].rotation
+            self._rot_mat_slices.append(self._rot_mat_batch[..., i])
+            self._rot_mat_list.append(rot_matrix)
+
+    def refresh(self) -> np.ndarray:
+        # Copy all rotation matrices in contiguous buffer
+        multi_array_copyto(self._rot_mat_slices, self._rot_mat_list)
+
+        # Return proxy directly without copy
+        return self._rot_mat_batch
+
+
+@dataclass(unsafe_hash=True)
+class _MultiFramesEulerAngles(AbstractQuantity[Dict[str, np.ndarray]]):
+    """Euler angles (Roll-Pitch-Yaw) of the orientation of all frames involved
+    in quantities relying on it and are active since last reset of computation
+    tracking if shared cache is available, its parent otherwise.
+
+    It is not supposed to be instantiated manually but use internally by
+    `FrameEulerAngles`. See `_MultiFramesRotationMatrix` documentation.
+
+    The orientation of all frames is exposed to the user as a dictionary whose
+    keys are the individual frame names. Internally, data are stored in batched
+    2D contiguous array for efficiency. The first dimension gathers the 3 Euler
+    angles (roll, pitch, yaw), while the second one are individual frames with
+    the same ordering as 'self.frame_names'.
+
+    The expected maximum speedup wrt computing Euler angles individually is
+    about x15, which is achieved asymptotically for more than 100 frames. It is
+    already x5 faster for 5 frames, x7 for 10 frames, and x9 for 20 frames.
+    """
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: "FrameEulerAngles",
+                 mode: QuantityEvalMode) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: `FrameEulerAngles` instance from which this quantity is
+                       a requirement.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Make sure that a suitable parent has been provided
+        assert isinstance(parent, FrameEulerAngles)
+
+        # Initialize the ordered list of frame names.
+        # Note that this must be done BEFORE calling base `__init__`, otherwise
+        # `isinstance(..., (FrameQuantity, MultiFrameQuantity))` will fail.
+        self.frame_names: Set[str] = set()
+
+        # Call base implementation
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(
+                rot_mat_batch=(_MultiFramesRotationMatrix, dict(
+                    mode=mode))),
+            mode=mode,
+            auto_refresh=False)
+
+        # Store Roll-Pitch-Yaw of all frames at once
+        self._rpy_batch: np.ndarray = np.array([])
+
+        # Mapping from frame name to individual Roll-Pitch-Yaw slices
+        self._rpy_map: Dict[str, np.ndarray] = {}
+
+    def initialize(self) -> None:
+        # Call base implementation
+        super().initialize()
+
+        # Update the frame names based on the cache owners of this quantity
+        assert isinstance(self.parent, FrameEulerAngles)
+        self.frame_names = {self.parent.frame_name}
+        if self.has_cache:
+            for owner in self.cache.owners:
+                if owner.is_active(any_cache_owner=False):
+                    assert isinstance(owner.parent, FrameEulerAngles)
+                    self.frame_names.add(owner.parent.frame_name)
+
+        # Re-allocate memory as the number of frames is not known in advance
+        nframes = len(self.frame_names)
+        self._rpy_batch = np.zeros((3, nframes), order='F')
+
+        # Re-assign mapping from frame name to their corresponding data
+        self._rpy_map = dict(zip(self.frame_names, self._rpy_batch.T))
+
+    def refresh(self) -> Dict[str, np.ndarray]:
+        # Convert all rotation matrices at once to Roll-Pitch-Yaw
+        matrix_to_rpy(self.rot_mat_batch, self._rpy_batch)
+
+        # Return proxy directly without copy
+        return self._rpy_map
+
+
+@dataclass(unsafe_hash=True)
+class FrameEulerAngles(InterfaceQuantity[np.ndarray]):
+    """Euler angles (Roll-Pitch-Yaw) of the orientation of a given frame in
+    world reference frame at the end of the agent step.
+    """
+
+    frame_name: str
+    """Name of the frame on which to operate.
+    """
+
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: Optional[InterfaceQuantity],
+                 frame_name: str,
+                 *,
+                 mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement if any, `None` otherwise.
+        :param frame_name: Name of the frame on which to operate.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Backup some user argument(s)
+        self.frame_name = frame_name
+
+        # Call base implementation
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(data=(_MultiFramesEulerAngles, dict(mode=mode))),
+            auto_refresh=False)
+
+    def initialize(self) -> None:
+        # Check if the quantity is already active
+        was_active = self._is_active
+
+        # Call base implementation.
+        # The quantity is now considered active at this point.
+        super().initialize()
+
+        # Force re-initializing shared data if the active set has changed
+        if not was_active:
+            # Must reset the tracking for shared computation systematically,
+            # just in case the optimal computation path has changed to the
+            # point that relying on batched quantity is no longer relevant.
+            self.requirements["data"].reset(reset_tracking=True)
+
+    def refresh(self) -> np.ndarray:
+        # Return a slice of batched data.
+        # Note that mapping from frame name to frame index in batched data
+        # cannot be pre-computed as it may changed dynamically.
+        return self.data[self.frame_name]
+
+
+@dataclass(unsafe_hash=True)
+class _MultiFramesXYZQuat(AbstractQuantity[Dict[str, np.ndarray]]):
+    """Vector representation (X, Y, Z, QuatX, QuatY, QuatZ, QuatW) of the
+    transform of all frames involved in quantities relying on it and are active
+    since last reset of computation tracking if shared cache is available, its
+    parent otherwise.
+
+    It is not supposed to be instantiated manually but use internally by
+    `FrameXYZQuat`. See `_MultiFramesRotationMatrix` documentation.
+
+    The transform of all frames is exposed to the user as a dictionary whose
+    keys are the individual frame names. Internally, data are stored in batched
+    2D contiguous array for efficiency. The first dimension gathers the 6
+    components (X, Y, Z, QuatX, QuatY, QuatZ, QuatW), while the second one are
+    individual frames with the same ordering as 'self.frame_names'.
+    """
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: "FrameXYZQuat",
+                 mode: QuantityEvalMode) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: `FrameXYZQuat` instance from which this quantity
+                       is a requirement.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Make sure that a suitable parent has been provided
+        assert isinstance(parent, FrameXYZQuat)
+
+        # Initialize the ordered list of frame names
+        self.frame_names: Set[str] = set()
+
+        # Call base implementation
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(
+                rot_mat_batch=(_MultiFramesRotationMatrix, dict(
+                    mode=mode))),
+            mode=mode,
+            auto_refresh=False)
+
+        # Define proxy for slices of the batch storing all translation vectors
+        self._translation_slices: List[np.ndarray] = []
+
+        # Define proxy for the translation vectors of all frames
+        self._translation_list: List[np.ndarray] = []
+
+        # Store XYZQuat of all frames at once
+        self._xyzquat_batch: np.ndarray = np.array([])
+
+        # Mapping from frame name to individual XYZQuat slices
+        self._xyzquat_map: Dict[str, np.ndarray] = {}
+
+    def initialize(self) -> None:
+        # Call base implementation
+        super().initialize()
+
+        # Update the frame names based on the cache owners of this quantity
+        assert isinstance(self.parent, FrameXYZQuat)
+        self.frame_names = {self.parent.frame_name}
+        if self.has_cache:
+            for owner in self.cache.owners:
+                if owner.is_active(any_cache_owner=False):
+                    assert isinstance(owner.parent, FrameXYZQuat)
+                    self.frame_names.add(owner.parent.frame_name)
+
+        # Re-allocate memory as the number of frames is not known in advance
+        nframes = len(self.frame_names)
+        self._xyzquat_batch = np.zeros((7, nframes), order='F')
+
+        # Refresh proxies
+        self._translation_slices.clear()
+        self._translation_list.clear()
+        for i, frame_name in enumerate(self.frame_names):
+            frame_index = self.pinocchio_model.getFrameId(frame_name)
+            translation = self.pinocchio_data.oMf[frame_index].translation
+            self._translation_slices.append(self._xyzquat_batch[:3, i])
+            self._translation_list.append(translation)
+
+        # Re-assign mapping from frame name to their corresponding data
+        self._xyzquat_map = dict(zip(self.frame_names, self._xyzquat_batch.T))
+
+    def refresh(self) -> Dict[str, np.ndarray]:
+        # Copy all translations in contiguous buffer
+        multi_array_copyto(self._translation_slices, self._translation_list)
+
+        # Convert all rotation matrices at once to XYZQuat representation
+        matrix_to_quat(self.rot_mat_batch, self._xyzquat_batch[-4:])
+
+        # Return proxy directly without copy
+        return self._xyzquat_map
+
+
+@dataclass(unsafe_hash=True)
+class FrameXYZQuat(InterfaceQuantity[np.ndarray]):
+    """Vector representation (X, Y, Z, QuatX, QuatY, QuatZ, QuatW) of the
+    transform of a given frame in world reference frame at the end of the
+    agent step.
+    """
+
+    frame_name: str
+    """Name of the frame on which to operate.
+    """
+
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: Optional[InterfaceQuantity],
+                 frame_name: str,
+                 *,
+                 mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement if any, `None` otherwise.
+        :param frame_name: Name of the frame on which to operate.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Backup some user argument(s)
+        self.frame_name = frame_name
+
+        # Call base implementation
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(data=(_MultiFramesXYZQuat, dict(mode=mode))),
+            auto_refresh=False)
+
+    def initialize(self) -> None:
+        # Check if the quantity is already active
+        was_active = self._is_active
+
+        # Call base implementation
+        super().initialize()
+
+        # Force re-initializing shared data if the active set has changed
+        if not was_active:
+            self.requirements["data"].reset(reset_tracking=True)
+
+    def refresh(self) -> np.ndarray:
+        # Return a slice of batched data
+        return self.data[self.frame_name]
+
+
+@dataclass(unsafe_hash=True)
+class StackedQuantity(InterfaceQuantity[Tuple[ValueT, ...]]):
+    """Keep track of a given quantity over time by automatically stacking its
+    value once per environment step since last reset.
+
+    .. note::
+        A new entry is added to the stack right before evaluating the reward
+        and termination conditions. Internal simulation steps, observer and
+        controller updates are ignored.
+    """
+
+    quantity: InterfaceQuantity
+    """Base quantity whose value must be stacked over time since last reset.
+    """
+
+    num_stack: Optional[int]
+    """Maximum number of values that keep in memory before starting to discard
+    the oldest one (FIFO). None if unlimited.
+    """
+
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: Optional[InterfaceQuantity],
+                 quantity: QuantityCreator[ValueT],
+                 *,
+                 num_stack: Optional[int] = None) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement if any, `None` otherwise.
+        :param quantity: Tuple gathering the class of the quantity whose values
+                         must be stacked, plus all its constructor keyword-
+                         arguments except environment 'env' and parent 'parent.
+        :param num_stack: Maximum number of values that keep in memory before
+                          starting to discard the oldest one (FIFO). None if
+                          unlimited.
+        """
+        # Backup user arguments
+        self.num_stack = num_stack
+
+        # Call base implementation
+        super().__init__(env,
+                         parent,
+                         requirements=dict(data=quantity),
+                         auto_refresh=True)
+
+        # Keep track of the quantity that must be stacked once instantiated
+        self.quantity = self.requirements["data"]
+
+        # Allocate deque buffer
+        self._deque: deque = deque(maxlen=self.num_stack)
+
+        # Keep track of the last time the quantity has been stacked
+        self._num_steps_prev = -1
+
+    def initialize(self) -> None:
+        # Call base implementation
+        super().initialize()
+
+        # Clear buffer
+        self._deque.clear()
+
+        # Reset step counter
+        self._num_steps_prev = -1
+
+    def refresh(self) -> Tuple[ValueT, ...]:
+        # Append value to the queue only once per step and only if a simulation
+        # is running. Note that data must be deep-copied to make sure it does
+        # not get altered afterward.
+        if self.env.is_simulation_running:
+            num_steps = self.env.num_steps
+            if num_steps != self._num_steps_prev:
+                assert num_steps == self._num_steps_prev + 1
+                self._deque.append(deepcopy(self.data))
+                self._num_steps_prev += 1
+
+        # Return the whole stack as a tuple to preserve the integrity of the
+        # underlying container and make the API robust to internal changes.
+        return tuple(self._deque)
+
+
+@dataclass(unsafe_hash=True)
+class AverageFrameSpatialVelocity(InterfaceQuantity[np.ndarray]):
+    """Average spatial velocity of a given frame at the end of the agent step.
 
     The average spatial velocity is obtained by finite difference. More
     precisely, it is defined here as the ratio of the geodesic distance in SE3
-    Lie  group between the pose of the frame at the end of previous and current
+    Lie Group between the pose of the frame at the end of previous and current
     step over the time difference between them. Notably, under this definition,
     the linear average velocity jointly depends on rate of change of the
     translation and rotation of the frame, which may be undesirable in some
     cases. Alternatively, the double geodesic distance could be used instead to
     completely decouple the translation from the rotation.
+
+    .. note::
+        The local frame for which the velocity is expressed is defined as the
+        midpoint interpolation between the previous and current frame pose.
+        This definition is arbitrary, in a sense that any other point for an
+        interpolation ratio going from 0.0 (previous pose) to 1.0 (current
+        pose) would be equally valid.
     """
 
     frame_name: str
     """Name of the frame on which to operate.
     """
 
     reference_frame: pin.ReferenceFrame
     """Whether the spatial velocity must be computed in local reference frame
     or re-aligned with world axes.
     """
 
     def __init__(self,
                  env: InterfaceJiminyEnv,
-                 parent: Optional[AbstractQuantity],
+                 parent: Optional[InterfaceQuantity],
                  frame_name: str,
-                 reference_frame: pin.ReferenceFrame = pin.LOCAL
-                 ) -> None:
+                 *,
+                 reference_frame: pin.ReferenceFrame = pin.LOCAL,
+                 mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
         """
         :param env: Base or wrapped jiminy environment.
         :param parent: Higher-level quantity from which this quantity is a
                        requirement if any, `None` otherwise.
         :param frame_name: Name of the frame on which to operate.
         :param reference_frame:
             Whether the spatial velocity must be computed in local reference
             frame (aka 'pin.LOCAL') or re-aligned with world axes (aka
             'pin.LOCAL_WORLD_ALIGNED').
+        :param mode: Desired mode of evaluation for this quantity.
         """
         # Make sure at requested reference frame is supported
         if reference_frame not in (pin.LOCAL, pin.LOCAL_WORLD_ALIGNED):
             raise ValueError("Reference frame must be either 'pin.LOCAL' or "
                              "'pin.LOCAL_WORLD_ALIGNED'.")
 
         # Backup some user argument(s)
         self.frame_name = frame_name
         self.reference_frame = reference_frame
 
         # Call base implementation
-        super().__init__(env, parent, requirements={})
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(xyzquat_stack=(StackedQuantity, dict(
+                quantity=(FrameXYZQuat, dict(
+                    frame_name=frame_name, mode=mode)),
+                num_stack=2))),
+            auto_refresh=False)
 
         # Define specialize difference operator on SE3 Lie group
         self._se3_diff = partial(
             pin.LieGroup.difference,
             pin.liegroups.SE3())  # pylint: disable=no-member
 
         # Inverse step size
         self._inv_step_dt = 0.0
 
-        # Pre-allocate memory to store current and previous frame pose vector
-        self._xyzquat_prev, self._xyzquat = (
-            np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]) for _ in range(2))
-
-        # Define proxy to the current frame pose (translation, rotation matrix)
-        self._pose = (np.zeros(3), np.eye(3))
+        # Allocate memory for the average quaternion and rotation matrix
+        self._quat_mean = np.zeros(4)
+        self._rot_mat_mean = np.eye(3)
 
         # Pre-allocate memory for the spatial velocity
         self._v_spatial: np.ndarray = np.zeros(6)
 
         # Reshape linear plus angular velocity vector to vectorize rotation
         self._v_lin_ang = np.reshape(self._v_spatial, (2, 3)).T
 
     def initialize(self) -> None:
         # Call base implementation
         super().initialize()
 
         # Compute inverse step size
         self._inv_step_dt = 1.0 / self.env.step_dt
 
-        # Refresh proxy to current frame pose
-        frame_index = self.pinocchio_model.getFrameId(self.frame_name)
-        transform = self.pinocchio_data.oMf[frame_index]
-        self._pose = (transform.translation, transform.rotation)
-
         # Re-initialize pre-allocated buffers
-        transforms_to_vector((self._pose,), self._xyzquat)
-        array_copyto(self._xyzquat_prev, self._xyzquat)
         fill(self._v_spatial, 0)
 
     def refresh(self) -> np.ndarray:
-        # Convert current transform to (XYZ, Quat) convention
-        transforms_to_vector((self._pose,), self._xyzquat)
+        # Fetch previous and current XYZQuat representation of frame transform.
+        # It will raise an exception if not enough data is available at this
+        # point. This should never occur in practice as it will be fine at
+        # the end of the first step already, before the reward and termination
+        # conditions are evaluated.
+        xyzquat_prev, xyzquat = self.xyzquat_stack
 
         # Compute average frame velocity in local frame since previous step
-        self._v_spatial[:] = self._se3_diff(self._xyzquat_prev, self._xyzquat)
+        self._v_spatial[:] = self._se3_diff(xyzquat_prev, xyzquat)
         self._v_spatial *= self._inv_step_dt
 
         # Translate local velocity to world frame
         if self.reference_frame == pin.LOCAL_WORLD_ALIGNED:
-            # TODO: x2 speedup can be expected using `np.dot` with  `nb.jit`
-            _, rot_mat = self._pose
-            self._v_lin_ang[:] = rot_mat @ self._v_lin_ang
+            # Define world frame as the "middle" between prev and next pose.
+            # The orientation difference has an effect on the translation
+            # difference, but not the other way around. Here, we only care
+            # about the middle rotation, so we can consider SO3 Lie Group
+            # algebra instead of SE3.
+            quat_interpolate_middle(
+                xyzquat_prev[-4:], xyzquat[-4:], self._quat_mean)
+            quat_to_matrix(self._quat_mean, self._rot_mat_mean)
 
-        # Backup current frame pose
-        array_copyto(self._xyzquat_prev, self._xyzquat)
+            # TODO: x2 speedup can be expected using `np.dot` with `nb.jit`
+            self._v_lin_ang[:] = self._rot_mat_mean @ self._v_lin_ang
 
         return self._v_spatial
 
 
 @dataclass(unsafe_hash=True)
-class _BatchEulerAnglesFrame(AbstractQuantity[Dict[str, np.ndarray]]):
-    """Euler angles (Roll-Pitch-Yaw) representation of the orientation of all
-    frames involved in quantities relying on it and are active since last reset
-    of computation tracking if shared cache is available, its parent otherwise.
-
-    This quantity only provides a performance benefit when managed by some
-    `QuantityManager`. It is not supposed to be instantiated manually but use
-    internally by `EulerAnglesFrame` as a requirement for vectorization of
-    computations for all frames at once.
+class MaskedQuantity(InterfaceQuantity[np.ndarray]):
+    """Extract elements from a given quantity whose value is a N-dimensional
+    array along an axis.
+
+    Elements will be extract by copy unless the indices of the elements to
+    extract to be written equivalently by a slice (ie they are evenly spaced),
+    and the array can be flattened while preserving memory contiguity if 'axis'
+    is `None`.
+    """
 
-    The orientation of all frames is exposed to the user as a dictionary whose
-    keys are the individual frame names. Internally, data are stored in batched
-    2D contiguous array for efficiency. The first dimension are the 3 Euler
-    angles (roll, pitch, yaw) components, while the second one are individual
-    frames with the same ordering as 'self.frame_names'.
+    quantity: InterfaceQuantity
+    """Base quantity whose elements must be extracted.
+    """
 
-    The expected maximum speedup wrt computing Euler angles individually is
-    about x15, which is achieved asymptotically for more than 100 frames. It is
-    already x5 faster for 5 frames, x7 for 10 frames, and x9 for 20 frames.
+    indices: Tuple[int, ...]
+    """Indices of the elements to extract.
+    """
 
-    .. note::
-        This quantity does not allow for specifying frames directly. There is
-        no way to get the orientation of multiple frames at once for now.
+    axis: Optional[int]
+    """Axis over which to extract elements. `None` to consider flattened array.
     """
+
     def __init__(self,
                  env: InterfaceJiminyEnv,
-                 parent: Optional[AbstractQuantity]) -> None:
+                 parent: Optional[InterfaceQuantity],
+                 quantity: QuantityCreator[np.ndarray],
+                 key: Union[Sequence[int], Sequence[bool]],
+                 *,
+                 axis: Optional[int] = None) -> None:
         """
         :param env: Base or wrapped jiminy environment.
         :param parent: Higher-level quantity from which this quantity is a
                        requirement if any, `None` otherwise.
-        :param frame_name: Name of the frame on which to operate.
+        :param quantity: Tuple gathering the class of the quantity whose values
+                         must be extracted, plus all its constructor keyword-
+                         arguments except environment 'env' and parent 'parent.
+        :param key: Sequence of indices or boolean mask that will be used to
+                    extract elements from the quantity along one axis.
+        :param axis: Axis over which to extract elements. `None` to consider
+                     flattened array.
+                     Optional: `None` by default.
         """
-        # Call base implementation
-        super().__init__(env, parent, requirements={})
-
-        # Initialize the ordered list of frame names
-        self.frame_names: Set[str] = set()
+        # Check if indices or boolean mask has been provided
+        if all(isinstance(e, bool) for e in key):
+            key = tuple(np.flatnonzero(key))
+        elif not all(isinstance(e, int) for e in key):
+            raise ValueError(
+                "Argument 'key' invalid. It must either be a boolean mask, or "
+                "a sequence of indices.")
+
+        # Backup user arguments
+        self.indices = tuple(key)
+        self.axis = axis
+
+        # Make sure that at least one index must be extracted
+        if not self.indices:
+            raise ValueError(
+                "No indices to extract from quantity. Data would be empty.")
+
+        # Check if the indices are evenly spaced
+        self._slices: Tuple[Union[slice, EllipsisType], ...] = ()
+        stride: Optional[int] = None
+        if len(self.indices) == 1:
+            stride = 1
+        if len(self.indices) > 1 and all(e >= 0 for e in self.indices):
+            spacing = np.unique(np.diff(self.indices))
+            if spacing.size == 1:
+                stride = spacing[0]
+        if stride is not None:
+            slice_ = slice(self.indices[0], self.indices[-1] + 1, stride)
+            if axis is None:
+                self._slices = (slice_,)
+            elif axis > 0:
+                self._slices = (*((slice(None),) * axis), slice_)
+            else:
+                self._slices = (
+                    Ellipsis, slice_, *((slice(None),) * (- axis - 1)))
 
-        # Store all rotation matrices at once
-        self._rot_mat_batch: np.ndarray = np.array([])
-
-        # Define proxy for slices of the batch storing all rotation matrices
-        self._rot_mat_views: List[np.ndarray] = []
-
-        # Define proxy for the rotation matrices of all frames
-        self._rot_mat_list: List[np.ndarray] = []
-
-        # Store Roll-Pitch-Yaw of all frames at once
-        self._rpy_batch: np.ndarray = np.array([])
+        # Call base implementation
+        super().__init__(env,
+                         parent,
+                         requirements=dict(data=quantity),
+                         auto_refresh=False)
 
-        # Mapping from frame name to individual Roll-Pitch-Yaw slices
-        self._rpy_map: Dict[str, np.ndarray] = {}
+        # Keep track of the quantity from which data must be extracted
+        self.quantity = self.requirements["data"]
 
     def initialize(self) -> None:
         # Call base implementation
         super().initialize()
 
-        # Update the list of frame names based on its cache owner list.
-        # Note that only active quantities are shared for efficiency. The list
-        # of active quantity may change dynamically. Re-initializing the class
-        # to take into account changes of the active set must be decided by
-        # `EulerAnglesFrame`.
-        assert isinstance(self.parent, EulerAnglesFrame)
-        self.frame_names = {self.parent.frame_name}
-        if self.cache:
-            for owner in self.cache.owners:
-                # We only consider active instances of `_BatchEulerAnglesFrame`
-                # instead of their corresponding parent `EulerAnglesFrame`.
-                # This is necessary because a derived quantity may feature
-                # `_BatchEulerAnglesFrame` as a requirement without actually
-                # relying on it depending on whether it is part of the optimal
-                # computation path at the time being or not.
-                if owner.is_active(any_cache_owner=False):
-                    assert isinstance(owner.parent, EulerAnglesFrame)
-                    self.frame_names.add(owner.parent.frame_name)
-
-        # Re-allocate memory as the number of frames is not known in advance.
-        # Note that Fortran memory layout (column-major) is used for speed up
-        # because it preserves contiguity when copying frame data.
-        nframes = len(self.frame_names)
-        self._rot_mat_batch = np.zeros((3, 3, nframes), order='F')
-        self._rpy_batch = np.zeros((3, nframes))
-
-        # Refresh proxies
-        self._rot_mat_views.clear()
-        self._rot_mat_list.clear()
-        for i, frame_name in enumerate(self.frame_names):
-            frame_index = self.pinocchio_model.getFrameId(frame_name)
-            rot_matrix = self.pinocchio_data.oMf[frame_index].rotation
-            self._rot_mat_views.append(self._rot_mat_batch[..., i])
-            self._rot_mat_list.append(rot_matrix)
-
-        # Re-assign mapping from frame name to their corresponding data
-        self._rpy_map = dict(zip(self.frame_names, self._rpy_batch.T))
-
-    def refresh(self) -> Dict[str, np.ndarray]:
-        # Copy all rotation matrices in contiguous buffer
-        multi_array_copyto(self._rot_mat_views, self._rot_mat_list)
+    def refresh(self) -> np.ndarray:
+        # Extract elements from quantity
+        if not self._slices:
+            # Note that `take` is faster than classical advanced indexing via
+            # `operator[]` (`__getitem__`) because the latter is more generic.
+            # Notably, `operator[]` supports boolean mask but `take` does not.
+            return self.data.take(self.indices, axis=self.axis)
+        if self.axis is None:
+            # `reshape` must be used instead of `flat` to get a view that can
+            # be sliced without copy.
+            return self.data.reshape((-1,))[self._slices]
+        return self.data[self._slices]
 
-        # Convert all rotation matrices at once to Roll-Pitch-Yaw
-        matrix_to_rpy(self._rot_mat_batch, self._rpy_batch)
 
-        # Return proxy directly without copy
-        return self._rpy_map
+@dataclass(unsafe_hash=True)
+class BinaryOpQuantity(InterfaceQuantity[ValueT],
+                       Generic[ValueT, OtherValueT, YetAnotherValueT]):
+    """Apply a given binary operator between two quantities.
+
+    This quantity is mainly useful for computing the error between the value of
+    a given quantity evaluated at the current simulation state and the state of
+    at the current simulation time for the reference trajectory being selected.
+    """
 
+    quantity_left: InterfaceQuantity[OtherValueT]
+    """Left-hand side quantity that will be forwarded to the binary operator.
+    """
 
-@dataclass(unsafe_hash=True)
-class EulerAnglesFrame(AbstractQuantity[np.ndarray]):
-    """Euler angles (Roll-Pitch-Yaw) representation of the orientation of a
-    given frame in world reference frame at the end of an agent step.
+    quantity_right: InterfaceQuantity[YetAnotherValueT]
+    """Right-hand side quantity that will be forwarded to the binary operator.
     """
 
-    frame_name: str
-    """Name of the frame on which to operate.
+    op: Callable[[OtherValueT, YetAnotherValueT], ValueT]
+    """Callable taking right- and left-hand side quantities as input argument.
     """
 
     def __init__(self,
                  env: InterfaceJiminyEnv,
-                 parent: Optional[AbstractQuantity],
-                 frame_name: str,
+                 parent: Optional[InterfaceQuantity],
+                 quantity_left: QuantityCreator[OtherValueT],
+                 quantity_right: QuantityCreator[YetAnotherValueT],
+                 op: Callable[[OtherValueT, YetAnotherValueT], ValueT]
                  ) -> None:
         """
         :param env: Base or wrapped jiminy environment.
         :param parent: Higher-level quantity from which this quantity is a
                        requirement if any, `None` otherwise.
-        :param frame_name: Name of the frame on which to operate.
+        :param quantity_left: Tuple gathering the class of the quantity that
+                              must be passed to left-hand side of the binary
+                              operator, plus all its constructor keyword-
+                              arguments except environment 'env' and parent
+                              'parent.
+        :param quantity_right: Quantity that must be passed to right-hand side
+                               of the binary operator as a tuple
+                               (class, keyword-arguments). See `quantity_left`
+                               argument for details.
+        :param op: Any callable taking the right- and left-hand side quantities
+                   as input argument. For example `operator.sub` to compute the
+                   difference.
         """
         # Backup some user argument(s)
-        self.frame_name = frame_name
+        self.op = op
 
         # Call base implementation
         super().__init__(
-            env, parent, requirements={"data": (_BatchEulerAnglesFrame, {})})
-
-    def initialize(self) -> None:
-        # Check if the quantity is already active
-        was_active = self._is_active
-
-        # Call base implementation.
-        # The quantity is now considered active at this point.
-        super().initialize()
-
-        # Force re-initializing shared data if the active set has changed
-        if not was_active:
-            # Must reset the tracking for shared computation systematically,
-            # just in case the optimal computation path has changed.
-            self.requirements["data"].reset(reset_tracking=True)
+            env,
+            parent,
+            requirements=dict(
+                value_left=quantity_left, value_right=quantity_right),
+            auto_refresh=False)
+
+        # Keep track of the left- and right-hand side quantities for hashing
+        self.quantity_left = self.requirements["value_left"]
+        self.quantity_right = self.requirements["value_right"]
 
-    def refresh(self) -> np.ndarray:
-        # Return a slice of batched data.
-        # Note that mapping from frame name to frame index in batched data
-        # cannot be pre-computed as it may changed dynamically.
-        return self.data[self.frame_name]
+    def refresh(self) -> ValueT:
+        return self.op(self.value_left, self.value_right)
```

## gym_jiminy/common/quantities/locomotion.py

```diff
@@ -2,68 +2,122 @@
 """
 from typing import Optional, Tuple
 from dataclasses import dataclass
 
 import numpy as np
 import pinocchio as pin
 
-from ..bases import InterfaceJiminyEnv, AbstractQuantity
+from ..bases import (
+    InterfaceJiminyEnv, InterfaceQuantity, AbstractQuantity, QuantityEvalMode)
 from ..utils import fill
 
+from ..quantities import MaskedQuantity, AverageFrameSpatialVelocity
+
+
+@dataclass(unsafe_hash=True)
+class AverageOdometryVelocity(InterfaceQuantity[np.ndarray]):
+    """Average odometry velocity in local-world-aligned frame at the end of the
+    agent step.
+
+    The odometry pose fully specifies the position of the robot in 2D world
+    plane. As such, it comprises the linear translation (X, Y) and the angular
+    velocity around Z axis (namely rate of change of Yaw Euler angle). The
+    average spatial velocity is obtained by finite difference. See
+    `AverageFrameSpatialVelocity` documentation for details.
+    """
+
+    def __init__(self,
+                 env: InterfaceJiminyEnv,
+                 parent: Optional[InterfaceQuantity],
+                 *,
+                 mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
+        """
+        :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement if any, `None` otherwise.
+        :param mode: Desired mode of evaluation for this quantity.
+        """
+        # Call base implementation
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(
+                data=(MaskedQuantity, dict(
+                    quantity=(AverageFrameSpatialVelocity, dict(
+                        frame_name="root_joint",
+                        reference_frame=pin.LOCAL_WORLD_ALIGNED,
+                        mode=mode)),
+                    key=(0, 1, 5)))),
+            auto_refresh=False)
+
+    def refresh(self) -> np.ndarray:
+        return self.data
+
 
 @dataclass(unsafe_hash=True)
 class CenterOfMass(AbstractQuantity[np.ndarray]):
     """Position, Velocity or Acceleration of the center of mass of the robot as
     a whole.
     """
 
     kinematic_level: pin.KinematicLevel
     """Kinematic level to compute, ie position, velocity or acceleration.
     """
 
     def __init__(
             self,
             env: InterfaceJiminyEnv,
-            parent: Optional[AbstractQuantity],
-            kinematic_level: pin.KinematicLevel = pin.POSITION
-            ) -> None:
+            parent: Optional[InterfaceQuantity],
+            *,
+            kinematic_level: pin.KinematicLevel = pin.POSITION,
+            mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
         """
         :param env: Base or wrapped jiminy environment.
         :param parent: Higher-level quantity from which this quantity is a
                        requirement if any, `None` otherwise.
         :para kinematic_level: Desired kinematic level, ie position, velocity
                                or acceleration.
+        :param mode: Desired mode of evaluation for this quantity.
         """
         # Backup some user argument(s)
         self.kinematic_level = kinematic_level
 
         # Call base implementation
-        super().__init__(env, parent, requirements={})
+        super().__init__(
+            env, parent, requirements={}, mode=mode, auto_refresh=False)
 
         # Pre-allocate memory for the CoM quantity
         self._com_data: np.ndarray = np.array([])
 
     def initialize(self) -> None:
         # Call base implementation
         super().initialize()
 
+        # Make sure that the state is consistent with required kinematic level
+        state = self.state
+        if ((self.kinematic_level == pin.ACCELERATION and state.a is None) or
+                (self.kinematic_level >= pin.VELOCITY and state.v is None)):
+            raise RuntimeError(
+                "State data inconsistent with required kinematic level")
+
         # Refresh CoM quantity proxy based on kinematic level
         if self.kinematic_level == pin.POSITION:
             self._com_data = self.pinocchio_data.com[0]
         elif self.kinematic_level == pin.VELOCITY:
             self._com_data = self.pinocchio_data.vcom[0]
         else:
             self._com_data = self.pinocchio_data.acom[0]
 
     def refresh(self) -> np.ndarray:
         # Jiminy does not compute the CoM acceleration automatically
-        if self.kinematic_level == pin.ACCELERATION:
+        if (self.mode == QuantityEvalMode.TRUE and
+                self.kinematic_level == pin.ACCELERATION):
             pin.centerOfMass(self.pinocchio_model,
                              self.pinocchio_data,
-                             self.kinematic_level)
+                             pin.ACCELERATION)
 
         # Return proxy directly without copy
         return self._com_data
 
 
 @dataclass(unsafe_hash=True)
 class ZeroMomentPoint(AbstractQuantity[np.ndarray]):
@@ -74,34 +128,49 @@
     pendulum is a relevant approximate dynamic model. It is involved in various
     dynamic stability metrics (usually only on flat ground), such as N-steps
     capturability. More precisely, the robot will keep balance if the ZMP is
     maintained inside the support polygon.
     """
     def __init__(self,
                  env: InterfaceJiminyEnv,
-                 parent: Optional[AbstractQuantity]) -> None:
+                 parent: Optional[InterfaceQuantity],
+                 *,
+                 mode: QuantityEvalMode = QuantityEvalMode.TRUE) -> None:
         """
         :param env: Base or wrapped jiminy environment.
+        :param parent: Higher-level quantity from which this quantity is a
+                       requirement if any, `None` otherwise.
+        :param mode: Desired mode of evaluation for this quantity.
         """
         # Call base implementation
-        super().__init__(env, parent, requirements={"com": (CenterOfMass, {})})
+        super().__init__(
+            env,
+            parent,
+            requirements=dict(com=(CenterOfMass, dict(mode=mode))),
+            mode=mode,
+            auto_refresh=False)
 
         # Weight of the robot
         self._robot_weight: float = -1
 
         # Proxy for the derivative of the spatial centroidal momentum
-        self.dhg: Tuple[np.ndarray, np.ndarray] = (np.ndarray([]),) * 2
+        self.dhg: Tuple[np.ndarray, np.ndarray] = (np.array([]),) * 2
 
         # Pre-allocate memory for the ZMP
         self._zmp = np.zeros(2)
 
     def initialize(self) -> None:
         # Call base implementation
         super().initialize()
 
+        # Make sure that the state is consistent with required kinematic level
+        if (self.state.v is None or self.state.a is None):
+            raise RuntimeError(
+                "State data inconsistent with required kinematic level")
+
         # Compute the weight of the robot
         gravity = abs(self.pinocchio_model.gravity.linear[2])
         robot_mass = self.pinocchio_data.mass[0]
         self._robot_weight = robot_mass * gravity
 
         # Refresh derivative of the spatial centroidal momentum
         self.dhg = ((dhg := self.pinocchio_data.dhg).linear, dhg.angular)
@@ -117,9 +186,8 @@
         f_z = dhg_linear[2] + self._robot_weight
 
         # Compute the center of pressure
         self._zmp[:] = com[:2] * (self._robot_weight / f_z)
         if abs(f_z) > np.finfo(np.float32).eps:
             self._zmp[0] -= (dhg_angular[1] + dhg_linear[0] * com[2]) / f_z
             self._zmp[1] += (dhg_angular[0] - dhg_linear[1] * com[2]) / f_z
-
         return self._zmp
```

## gym_jiminy/common/quantities/manager.py

```diff
@@ -5,79 +5,130 @@
 It is responsible for optimizing the computation path, which is expected to
 significantly increase the step collection throughput. This speedup is achieved
 by caching already computed that did not changed since then, computing
 redundant intermediary quantities only once per step, and gathering similar
 quantities in a large batch to leverage vectorization of math instructions.
 """
 from collections.abc import MutableMapping
-from typing import Any, Dict, List, Tuple, Iterator, Type
+from typing import Any, Dict, List, Tuple, Iterator, Literal, Type
 
-from ..bases import InterfaceJiminyEnv, AbstractQuantity, SharedCache
+from jiminy_py.dynamics import Trajectory
 
-
-QuantityCreator = Tuple[Type[AbstractQuantity], Dict[str, Any]]
+from ..bases import (
+    QuantityCreator, InterfaceJiminyEnv, InterfaceQuantity, SharedCache,
+    DatasetTrajectoryQuantity)
 
 
 class QuantityManager(MutableMapping):
     """This class centralizes the evaluation of all quantities involved in
-    reward or termination conditions evaluation to redundant and unnecessary
-    computations.
+    reward components or termination conditions evaluation to redundant and
+    unnecessary computations.
 
     It is responsible for making sure all quantities are evaluated on the same
-    environment, and internal buffers are re-initialized whenever necessary.
+    environment, and internal buffers are re-initialized whenever necessary. It
+    also manages a dataset of trajectories synchronized between all managed
+    quantities. These trajectories are involves in computation of quantities
+    deriving from `AbstractQuantity` for which the mode of evaluation is set to
+    `QuantityEvalMode.REFERENCE`. This dataset is initially empty. Trying to
+    evaluate quantities involving a reference trajectory without adding and
+    selecting one beforehand would raise an exception.
 
     .. note::
         Individual quantities can be accessed either as instance properties or
         items of a dictionary. Choosing one or the other is only a matter of
         taste since both options have been heavily optimized to  minimize
         overhead and should be equally efficient.
     """
     def __init__(self, env: InterfaceJiminyEnv) -> None:
         """
         :param env: Base or wrapped jiminy environment.
         """
         # Backup user argument(s)
         self.env = env
 
-        # List of already instantiated quantities to manager
-        self._quantities: Dict[str, AbstractQuantity] = {}
+        # List of instantiated quantities to manager
+        self.registry: Dict[str, InterfaceQuantity] = {}
 
         # Initialize shared caches for all managed quantities.
         # Note that keys are not quantities directly but pairs (class, hash).
         # This is necessary because using a quantity as key directly would
-        # prevent its garbage collection and break automatic reset of
+        # prevent its garbage collection, hence breaking automatic reset of
         # computation tracking for all quantities sharing its cache.
         self._caches: Dict[
-            Tuple[Type[AbstractQuantity], int], SharedCache] = {}
+            Tuple[Type[InterfaceQuantity], int], SharedCache] = {}
+
+        # Instantiate trajectory database.
+        # Note that this quantity is not added to the global registry to avoid
+        # exposing directly to the user. This way, it cannot be deleted.
+        self._trajectory_dataset = self._build_quantity(
+            (DatasetTrajectoryQuantity, {}))
 
     def reset(self, reset_tracking: bool = False) -> None:
         """Consider that all managed quantity must be re-initialized before
         being able to evaluate them once again.
 
         .. note::
             The cache is cleared automatically by the quantities themselves.
 
         :param reset_tracking: Do not consider any quantity as active anymore.
                                Optional: False by default.
         """
-        for quantity in self._quantities.values():
+        for quantity in self.registry.values():
             quantity.reset(reset_tracking)
 
     def clear(self) -> None:
         """Clear internal cache of quantities to force re-evaluating them the
         next time their value is fetched.
 
         .. note::
             This method is supposed to be called every time the state of the
             environment has changed (ie either the agent or world itself),
             thereby invalidating the value currently stored in cache if any.
         """
         for cache in self._caches.values():
             cache.reset()
 
+    def add_trajectory(self, name: str, trajectory: Trajectory) -> None:
+        """Add a new reference trajectory to the database synchronized between
+        all managed quantities.
+
+        :param name: Desired name of the trajectory. It must be unique. If a
+                     trajectory with the exact same name already exists, then
+                     it must be discarded first, so as to prevent silently
+                     overwriting it by mistake.
+        :param trajectory: Trajectory instance to register.
+        """
+        self._trajectory_dataset.add(name, trajectory)
+
+    def discard_trajectory(self, name: str) -> None:
+        """Discard a trajectory from the database synchronized between all
+        managed quantities.
+
+        :param name: Name of the trajectory to discard.
+        """
+        self._trajectory_dataset.discard(name)
+
+    def select_trajectory(self,
+                          name: str,
+                          mode: Literal['raise', 'wrap', 'clip'] = 'raise'
+                          ) -> None:
+        """Select an existing trajectory from the database shared synchronized
+        all managed quantities.
+
+        .. note::
+            There is no way to select a different reference trajectory for
+            individual quantities at the time being.
+
+        :param name: Name of the trajectory to select.
+        :param mode: Specifies how to deal with query time of are out of the
+                     time interval of the trajectory. See `Trajectory.get`
+                     documentation for details.
+        """
+        self._trajectory_dataset.select(name, mode)
+
     def __getattr__(self, name: str) -> Any:
         """Get access managed quantities as first-class properties, rather than
         dictionary-like values through `__getitem__`.
 
         .. warning::
             Getting quantities this way is convenient but unfortunately much
             slower than doing it through `__getitem__`. It takes 40ns on
@@ -91,74 +142,99 @@
 
     def __dir__(self) -> List[str]:
         """Attribute lookup.
 
         It is mainly used by autocomplete feature of Ipython. It is overloaded
         to get consistent autocompletion wrt `getattr`.
         """
-        return [*super().__dir__(), *self._quantities.keys()]
+        return [*super().__dir__(), *self.registry.keys()]
 
-    def __setitem__(self,
-                    name: str,
-                    quantity_creator: QuantityCreator) -> None:
-        """Instantiate a new top-level quantity to manage for now on.
+    def _build_quantity(
+            self, quantity_creator: QuantityCreator) -> InterfaceQuantity:
+        """Instantiate a quantity sharing caching with all identical quantities
+        that has been instantiated previously.
+
+        .. note::
+            This method is not meant to be called manually. It is used
+            internally for instantiating new quantities sharing cache with all
+            identical instances that has been instantiated previously by this
+            manager in particular. This method is not responsible for keeping
+            track of the new quantity and exposing it to the user by adding it
+            to the global registry of the manager afterward.
 
         :param name: Desired name of the quantity after instantiation. It will
                      raise an exception if another quantity with the exact same
                      name exists.
         :param quantity_creator: Tuple gathering the class of the new quantity
                                  to manage plus its keyword-arguments except
-                                 the environment 'env' as a dictionary.
+                                 environment and parent as a dictionary.
         """
-        # Make sure that no quantity with the same name is already managed to
-        # avoid silently overriding quantities being managed in user's back.
-        if name in self._quantities:
-            raise KeyError(
-                "A quantity with the exact same name already exists. Please "
-                "delete it first before adding a new one.")
-
         # Instantiate the new quantity
         quantity_cls, quantity_kwargs = quantity_creator
         top_quantity = quantity_cls(self.env, None, **(quantity_kwargs or {}))
 
         # Set a shared cache entry for all quantities involved in computations
         quantities_all = [top_quantity]
         while quantities_all:
             quantity = quantities_all.pop()
             key = (type(quantity), hash(quantity))
             quantity.cache = self._caches.setdefault(key, SharedCache())
             quantities_all += quantity.requirements.values()
 
-        # Add it to the map of already managed quantities
-        self._quantities[name] = top_quantity
+        return top_quantity
+
+    def __setitem__(self,
+                    name: str,
+                    quantity_creator: QuantityCreator) -> None:
+        """Instantiate new top-level quantity that will be managed for now on.
+
+        :param name: Desired name of the quantity after instantiation. It will
+                     raise an exception if another quantity with the exact same
+                     name exists.
+        :param quantity_creator: Tuple gathering the class of the new quantity
+                                 to manage plus its keyword-arguments except
+                                 environment and parent as a dictionary.
+        """
+        # Make sure that no quantity with the same name is already managed to
+        # avoid silently overriding quantities being managed in user's back.
+        if name in self.registry:
+            raise KeyError(
+                "A quantity with the exact same name already exists. Please "
+                "delete it first before adding a new one.")
+
+        # Instantiate new quantity
+        quantity = self._build_quantity(quantity_creator)
+
+        # Add it to the global registry of already managed quantities
+        self.registry[name] = quantity
 
     def __getitem__(self, name: str) -> Any:
         """Get the evaluated value of a given quantity.
 
         :param name: Name of the quantity for which to fetch the current value.
         """
-        return self._quantities[name].get()
+        return self.registry[name].get()
 
     def __delitem__(self, name: str) -> None:
         """Stop managing a quantity that is no longer relevant.
 
         .. warning::
             Deleting managed quantities modifies the computation graph, which
             would affect quantities that detect the optimal computation path
             dynamically. Computation tracking of all owners of a shared cache
             will be reset at garbage collection by the cache itself to get the
             opportunity to recover optimality.
 
         :param name: Name of the managed quantity to be discarded. It will
                      raise an exception if the specified name does not exists.
         """
-        del self._quantities[name]
+        del self.registry[name]
 
     def __iter__(self) -> Iterator[str]:
         """Iterate over names of managed quantities.
         """
-        return iter(self._quantities)
+        return iter(self.registry)
 
     def __len__(self) -> int:
         """Number of quantities being managed.
         """
-        return len(self._quantities)
+        return len(self.registry)
```

## gym_jiminy/common/utils/__init__.py

```diff
@@ -7,14 +7,15 @@
                    matrix_to_yaw,
                    quat_to_matrix,
                    quat_to_rpy,
                    quat_to_yaw,
                    quat_to_yaw_cos_sin,
                    quat_multiply,
                    quat_average,
+                   quat_interpolate_middle,
                    rpy_to_matrix,
                    rpy_to_quat,
                    transforms_to_vector,
                    compute_tilt_from_quat,
                    swing_from_vector,
                    remove_twist_from_quat)
 from .spaces import (StructNested,
@@ -36,29 +37,33 @@
                      build_normalize,
                      build_flatten)
 from .misc import (is_breakpoint,
                    is_nan,
                    get_fieldnames,
                    register_variables,
                    sample)
-from .pipeline import build_pipeline, load_pipeline
+from .pipeline import (save_trajectory_to_hdf5,
+                       load_trajectory_from_hdf5,
+                       build_pipeline,
+                       load_pipeline)
 
 
 __all__ = [
     'squared_norm_2',
     'matrix_to_quat',
     'matrices_to_quat',
     'matrix_to_rpy',
     'matrix_to_yaw',
     'quat_to_matrix',
     'quat_to_rpy',
     'quat_to_yaw',
     'quat_to_yaw_cos_sin',
     'quat_multiply',
     'quat_average',
+    'quat_interpolate_middle',
     'rpy_to_matrix',
     'rpy_to_quat',
     'transforms_to_vector',
     'compute_tilt_from_quat',
     'swing_from_vector',
     'remove_twist_from_quat',
     'StructNested',
@@ -80,10 +85,12 @@
     'build_contains',
     'build_normalize',
     'build_flatten',
     'is_breakpoint',
     'is_nan',
     'get_fieldnames',
     'register_variables',
+    'save_trajectory_to_hdf5',
+    'load_trajectory_from_hdf5',
     'build_pipeline',
     'load_pipeline'
 ]
```

## gym_jiminy/common/utils/math.py

```diff
@@ -518,7 +518,42 @@
         axis = (axis,)
     assert len(axis) > 0 and 0 not in axis
     q_perm = quat.transpose((
         *(i for i in range(1, quat.ndim) if i not in axis), 0, *axis))
     q_flat = q_perm.reshape((*q_perm.shape[:-len(axis)], -1))
     _, eigvec = np.linalg.eigh(q_flat @ np.swapaxes(q_flat, -1, -2))
     return np.moveaxis(eigvec[..., -1], -1, 0)
+
+
+@nb.jit(nopython=True, cache=True, fastmath=True)
+def quat_interpolate_middle(quat1: np.ndarray,
+                            quat2: np.ndarray,
+                            out: Optional[np.ndarray] = None) -> np.ndarray:
+    """Compute the midpoint interpolation between two batches of quaternions
+    [qx, qy, qz, qw].
+
+    The midpoint interpolation of two quaternion is defined as the integration
+    of half the difference between them, starting from the first one, ie
+    `q_mid = integrate(q1, 0.5 * difference(q1, d2))`, which is a special case
+    of the `slerp` method (spherical linear interpolation) for `alpha=0.5`.
+
+    For the midpoint in particular, one can show that the middle quaternion is
+    simply normalized sum of the previous and next quaternions.
+
+    :param quat1: First batch of quaternions as a N-dimensional array whose
+                  first dimension gathers the 4 quaternion coordinates.
+    :param quat2: Second batch of quaternions as a N-dimensional array.
+    :param out: A pre-allocated array into which the result is stored. If not
+                provided, a new array is freshly-allocated, which is slower.
+    """
+    assert quat1.ndim >= 1 and quat1.shape == quat2.shape
+    if out is None:
+        out_ = np.empty((4, *quat1.shape[1:]))
+    else:
+        assert out.shape == (4, *quat1.shape[1:])
+        out_ = out
+
+    dot = np.sum(quat1 * quat2, axis=0)
+    dot_ = dot if quat1.ndim == 1 else np.expand_dims(dot, axis=0)
+    out_[:] = (quat1 + np.sign(dot_) * quat2) / np.sqrt(2 * (1 + np.abs(dot_)))
+
+    return out_
```

## gym_jiminy/common/utils/pipeline.py

```diff
@@ -6,133 +6,350 @@
 It enables to break down a complex control architectures in many submodules,
 making it easier to maintain and avoiding code duplications between use cases.
 """
 import re
 import json
 import pathlib
 from pydoc import locate
+from dataclasses import asdict
 from functools import partial
 from typing import (
-    Dict, Any, Optional, Union, Type, Sequence, Callable, TypedDict)
+    Dict, Any, Optional, Union, Type, Sequence, Callable, TypedDict, Literal,
+    cast)
 
+import h5py
 import toml
+import numpy as np
 import gymnasium as gym
 
+import jiminy_py.core as jiminy
+from jiminy_py.dynamics import State, Trajectory
+
 from ..bases import (InterfaceJiminyEnv,
                      InterfaceBlock,
                      BaseControllerBlock,
                      BaseObserverBlock,
                      BasePipelineWrapper,
                      ObservedJiminyEnv,
-                     ControlledJiminyEnv)
+                     ControlledJiminyEnv,
+                     ComposedJiminyEnv,
+                     AbstractReward,
+                     BaseQuantityReward,
+                     BaseMixtureReward)
 from ..envs import BaseJiminyEnv
 
 
+class RewardConfig(TypedDict, total=False):
+    """Store information required for instantiating a given reward.
+
+    Specifically, it is a dictionary comprising the class of the reward, which
+    must derive from `AbstractReward`, and optionally some keyword-arguments
+    that must be passed to its corresponding constructor.
+    """
+
+    cls: Union[Type[AbstractReward], str]
+    """Reward class type.
+
+    .. note::
+        Both class type or fully qualified dotted path are supported.
+    """
+
+    kwargs: Dict[str, Any]
+    """Environment constructor keyword-arguments.
+
+    This attribute can be omitted.
+    """
+
+
+class TrajectoriesConfig(TypedDict, total=False):
+    """Store information required for adding a database of reference
+    trajectories to the environment.
+
+    Specifically, it is a dictionary comprising a set of named trajectories as
+    a dictionary whose keys are the name of the trajectories and values are
+    either the trajectory itself or the path of a file storing its dump in HDF5
+    format, the name of the selected trajectory, and its interpolation mode.
+    """
+
+    dataset: Dict[str, Union[str, Trajectory]]
+    """Set of named trajectories as a dictionary.
+
+    .. note::
+        Both `Trajectory` objects or path (absolute or relative) are supported.
+    """
+
+    name: str
+    """Name of the selected trajectory if any.
+
+    This attribute can be omitted.
+    """
+
+    mode: Literal['raise', 'wrap', 'clip']
+    """Interpolation mode of the selected trajectory if any.
+
+    This attribute can be omitted.
+    """
+
+
 class EnvConfig(TypedDict, total=False):
+    """Store information required for instantiating a given base environment
+    and compose it with some additional reward components and termination
+    conditions.
+
+    Specifically, it is a dictionary comprising the class of the base
+    environment, which must derive from `BaseJiminyEnv`, optionally some
+    keyword-arguments that must be passed to its corresponding constructor, and
+    eventually the configuration of some additional reward with which to
+    compose the base environment.
+    """
+
+    cls: Union[Type[BaseJiminyEnv], str]
     """Environment class type.
 
     .. note::
         Both class type or fully qualified dotted path are supported.
     """
-    cls: Union[Type[BaseJiminyEnv], str]
 
+    kwargs: Dict[str, Any]
     """Environment constructor default arguments.
 
     This attribute can be omitted.
     """
-    kwargs: Dict[str, Any]
+
+    reward: RewardConfig
+    """Reward configuration.
+
+    This attribute can be omitted.
+    """
+
+    trajectories: TrajectoriesConfig
+    """Reference trajectories configuration.
+
+    This attribute can be omitted.
+    """
 
 
 class BlockConfig(TypedDict, total=False):
+    """Store information required for instantiating a given observation or
+    control block.
+
+    Specifically, it is a dictionary comprising the class of the block, which
+    must derive from `BaseControllerBlock` or `BaseObserverBlock`, and
+    optionally some keyword-arguments that must be passed to its corresponding
+    constructor.
+    """
+
+    cls: Union[Type[BaseControllerBlock], Type[BaseObserverBlock], str]
     """Block class type. If must derive from `BaseControllerBlock` for
     controller blocks or from `BaseObserverBlock` for observer blocks.
 
     .. note::
         Both class type or fully qualified dotted path are supported.
     """
-    cls: Union[Type[BaseControllerBlock], Type[BaseObserverBlock], str]
 
+    kwargs: Dict[str, Any]
     """Block constructor default arguments.
 
     This attribute can be omitted.
     """
-    kwargs: Dict[str, Any]
 
 
 class WrapperConfig(TypedDict, total=False):
+    """Store information required for instantiating a given environment
+    pipeline wrapper.
+
+    Specifically, it is a dictionary comprising the class of the wrapper, which
+    must derive from `BasePipelineWrapper`, and optionally some
+    keyword-arguments that must be passed to its corresponding constructor.
+    """
+
+    cls: Union[Type[BasePipelineWrapper], str]
     """Wrapper class type.
 
     .. note::
         Both class type or fully qualified dotted path are supported.
     """
-    cls: Union[Type[BasePipelineWrapper], str]
 
+    kwargs: Dict[str, Any]
     """Wrapper constructor default arguments.
 
     This attribute can be omitted.
     """
-    kwargs: Dict[str, Any]
 
 
 class LayerConfig(TypedDict, total=False):
-    """Block constructor default arguments.
+    """Store information required for instantiating a given environment
+    pipeline layer, ie either a wrapper, or the combination of an observer /
+    controller block with its corresponding wrapper.
+
+    Specifically, it is a dictionary comprising the configuration of the block
+    if any, and optionally the configuration of the reward. It is generally
+    sufficient to specify either one or the other. See the documentation of the
+    both fields for details.
+    """
+
+    block: BlockConfig
+    """Block configuration.
 
     This attribute can be omitted. If so, then 'wrapper_cls' must be
     specified and must not require any block. Typically, it happens when the
     wrapper is not doing any computation on its own but just transforming the
     action or observation, e.g. stacking observation frames.
     """
-    block: Optional[BlockConfig]
 
+    wrapper: WrapperConfig
     """Wrapper configuration.
 
     This attribute can be omitted. If so, then 'block' must be specified and
     must this block must be associated with a unique wrapper type to allow for
     automatic type inference. It works with any observer and controller block.
     """
-    wrapper: WrapperConfig
 
 
 def build_pipeline(env_config: EnvConfig,
-                   layers_config: Sequence[LayerConfig]
+                   layers_config: Sequence[LayerConfig],
+                   *,
+                   root_path: Optional[Union[str, pathlib.Path]] = None
                    ) -> Callable[..., InterfaceJiminyEnv]:
     """Wrap together an environment inheriting from `BaseJiminyEnv` with any
     number of layers, as a unified pipeline environment class inheriting from
     `BasePipelineWrapper`. Each layer is wrapped individually and successively.
 
     :param env_config:
         Configuration of the environment, as a dict of type `EnvConfig`.
 
     :param layers_config:
         Configuration of the blocks, as a list. The list is ordered from the
         lowest level layer to the highest, each element corresponding to the
         configuration of a individual layer, as a dict of type `LayerConfig`.
     """
+    # Define helper to sanitize reward configuration
+    def sanitize_reward_config(reward_config: RewardConfig) -> None:
+        """Sanitize reward configuration in-place.
+
+        :param reward_config: Configuration of the reward, as a dict of type
+                              `RewardConfig`.
+        """
+        # Get reward class type
+        cls = reward_config["cls"]
+        if isinstance(cls, str):
+            obj = locate(cls)
+            assert isinstance(obj, type) and issubclass(obj, AbstractReward)
+            reward_config["cls"] = cls = obj
+
+        # Get reward constructor keyword-arguments
+        kwargs = reward_config.get("kwargs", {})
+
+        # Special handling for `BaseMixtureReward`
+        if issubclass(cls, BaseMixtureReward):
+            for component_config in kwargs["components"]:
+                sanitize_reward_config(component_config)
+
+    # Define helper to build the reward
+    def build_reward(env: InterfaceJiminyEnv,
+                     reward_config: RewardConfig) -> AbstractReward:
+        """Instantiate a reward associated with a given environment provided
+        some reward configuration.
+
+        :param env: Base environment or pipeline wrapper to wrap.
+        :param reward_config: Configuration of the reward, as a dict of type
+                              `RewardConfig`.
+        """
+        # Get reward class type
+        cls = reward_config["cls"]
+        assert isinstance(cls, type) and issubclass(cls, AbstractReward)
+
+        # Get reward constructor keyword-arguments
+        kwargs = reward_config.get("kwargs", {})
+
+        # Special handling for `BaseMixtureReward`
+        if issubclass(cls, BaseMixtureReward):
+            kwargs["components"] = tuple(
+                build_reward(env, reward_config)
+                for reward_config in kwargs["components"])
+
+        # Special handling for `BaseQuantityReward`
+        if cls is BaseQuantityReward:
+            quantity_config = kwargs["quantity"]
+            kwargs["quantity"] = (
+                quantity_config["cls"], quantity_config["kwargs"])
+
+        return cls(env, **kwargs)
+
+    # Define helper to build reward
+    def build_composition(env_creator: Callable[..., InterfaceJiminyEnv],
+                          reward_config: Optional[RewardConfig],
+                          trajectories_config: Optional[TrajectoriesConfig],
+                          **env_kwargs: Any) -> InterfaceJiminyEnv:
+        """Helper adding reward on top of a base environment or a pipeline
+        using `ComposedJiminyEnv` wrapper.
+
+        :param env_creator: Callable that takes optional keyword arguments as
+                            input and returns an pipeline or base environment.
+        :param reward_config: Configuration of the reward, as a dict of type
+                              `RewardConfig`.
+        :param trajectories: Set of named trajectories as a dictionary. See
+                             `ComposedJiminyEnv` documentation for details.
+        :param env_kwargs: Keyword arguments to forward to the constructor of
+                           the wrapped environment. Note that it will only
+                           overwrite the default value, so it will still be
+                           possible to set different values by explicitly
+                           defining them when calling the constructor of the
+                           generated wrapper.
+        """
+        # Instantiate the environment, which may be a lower-level wrapper
+        env = env_creator(**env_kwargs)
+
+        # Instantiate the reward
+        reward = None
+        if reward_config is not None:
+            reward = build_reward(env, reward_config)
+
+        # Get trajectory dataset
+        trajectories: Dict[str, Trajectory] = {}
+        if trajectories_config is not None:
+            trajectories = cast(
+                Dict[str, Trajectory], trajectories_config["dataset"])
+
+        # Instantiate the composition wrapper if necessary
+        if reward or trajectories:
+            env = ComposedJiminyEnv(
+                env, reward=reward, trajectories=trajectories)
+
+        # Select the reference trajectory if specified
+        if trajectories_config is not None:
+            name = trajectories_config.get("name")
+            if name is not None:
+                mode = trajectories_config.get("mode", "raise")
+                env.quantities.select_trajectory(name, mode)
+
+        return env
+
     # Define helper to wrap a single layer
     def build_layer(env_creator: Callable[..., InterfaceJiminyEnv],
                     wrapper_cls: Type[BasePipelineWrapper],
                     wrapper_kwargs: Dict[str, Any],
                     block_cls: Optional[Type[InterfaceBlock]],
                     block_kwargs: Dict[str, Any],
                     **env_kwargs: Any
                     ) -> BasePipelineWrapper:
         """Helper wrapping a base environment or a pipeline with additional
         layer, typically an observer or a controller.
 
         :param env_creator: Callable that takes optional keyword arguments as
                             input and returns an pipeline or base environment.
+        :param wrapper_cls: Type of wrapper to use to gather the environment
+                              and the block.
+        :param wrapper_kwargs: Keyword arguments to forward to the constructor
+                               of the wrapper. See 'env_kwargs'.
         :param block_cls: Type of block to connect to the environment, if
                             any. `None` to disable.
                             Optional: Disabled by default
         :param block_kwargs: Keyword arguments to forward to the constructor of
                              the wrapped block. See 'env_kwargs'.
-        :param wrapper_cls: Type of wrapper to use to gather the environment
-                              and the block.
-        :param wrapper_kwargs: Keyword arguments to forward to the constructor
-                               of the wrapper. See 'env_kwargs'.
         :param env_kwargs: Keyword arguments to forward to the constructor of
                            the wrapped environment. Note that it will only
                            overwrite the default value, so it will still be
                            possible to set different values by explicitly
                            defining them when calling the constructor of the
                            generated wrapper.
         """
@@ -166,23 +383,51 @@
 
             block = block_cls(block_name, env, **block_kwargs)
             args.append(block)
 
         # Instantiate the wrapper
         return wrapper_cls(*args, **wrapper_kwargs)
 
-    # Define callback for instantiating the base environment
-    env_cls: Union[Type[InterfaceJiminyEnv], str] = env_config["cls"]
+    # Define callable for instantiating the base environment
+    env_cls = env_config["cls"]
     if isinstance(env_cls, str):
         obj = locate(env_cls)
-        assert isinstance(obj, type) and issubclass(obj, InterfaceJiminyEnv)
+        assert isinstance(obj, type) and issubclass(obj, BaseJiminyEnv)
         env_cls = obj
     pipeline_creator: Callable[..., InterfaceJiminyEnv] = partial(
         env_cls, **env_config.get("kwargs", {}))
 
+    # Parse reward configuration
+    reward_config = env_config.get("reward")
+    if reward_config is not None:
+        sanitize_reward_config(reward_config)
+
+    # Parse trajectory configuration
+    trajectories_config = env_config.get("trajectories")
+    if trajectories_config is not None:
+        trajectories = trajectories_config['dataset']
+        assert isinstance(trajectories, dict)
+        for name, path_or_traj in trajectories.items():
+            if isinstance(path_or_traj, Trajectory):
+                continue
+            path = pathlib.Path(path_or_traj)
+            if not path.is_absolute():
+                if root_path is None:
+                    raise RuntimeError(
+                        "The argument 'root_path' must be provided when "
+                        "specifying relative trajectory paths.")
+                path = pathlib.Path(root_path) / path
+            trajectories[name] = load_trajectory_from_hdf5(path)
+
+    # Compose base environment with an extra user-specified reward
+    pipeline_creator = partial(build_composition,
+                               pipeline_creator,
+                               reward_config,
+                               trajectories_config)
+
     # Generate pipeline recursively
     for layer_config in layers_config:
         # Extract block and wrapper config
         block_config = layer_config.get("block") or {}
         wrapper_config = layer_config.get("wrapper") or {}
 
         # Make sure block and wrappers are class type and parse them if string
@@ -235,19 +480,98 @@
                                    wrapper_kwargs,
                                    block_cls_,
                                    block_kwargs)
 
     return pipeline_creator
 
 
-def load_pipeline(fullpath: str) -> Callable[..., InterfaceJiminyEnv]:
+def load_pipeline(fullpath: Union[str, pathlib.Path]
+                  ) -> Callable[..., InterfaceJiminyEnv]:
     """Load pipeline from JSON or TOML configuration file.
 
     :param: Fullpath of the configuration file.
     """
-    file_ext = pathlib.Path(fullpath).suffix
+    fullpath = pathlib.Path(fullpath)
+    root_path, file_ext = fullpath.parent, fullpath.suffix
     with open(fullpath, 'r') as f:
         if file_ext == '.json':
-            return build_pipeline(**json.load(f))
+            return build_pipeline(**json.load(f), root_path=root_path)
         if file_ext == '.toml':
-            return build_pipeline(**toml.load(f))
+            return build_pipeline(**toml.load(f), root_path=root_path)
     raise ValueError("Only json and toml formats are supported.")
+
+
+def save_trajectory_to_hdf5(trajectory: Trajectory,
+                            fullpath: Union[str, pathlib.Path]) -> None:
+    """Export a trajectory object to HDF5 format.
+
+    :param trajectory: Trajectory object to save.
+    :param fullpath: Fullpath of the generated HDF5 file.
+    """
+    # Create HDF5 file
+    hdf_obj = h5py.File(fullpath, "w")
+
+    # Dump each state attribute that are specified for all states at once
+    if trajectory.states:
+        state_dict = asdict(trajectory.states[0])
+        state_fields = tuple(
+            key for key, value in state_dict.items() if value is not None)
+        for key in state_fields:
+            data = np.stack([
+                getattr(state, key) for state in trajectory.states], axis=0)
+            hdf_obj.create_dataset(name=f"states/{key}", data=data)
+
+    # Dump serialized robot
+    robot_data = jiminy.save_to_binary(trajectory.robot)
+    dataset = hdf_obj.create_dataset(name="robot", data=np.array(robot_data))
+
+    # Dump whether to use the theoretical model of the robot
+    dataset.attrs["use_theoretical_model"] = trajectory.use_theoretical_model
+
+    # Close the HDF5 file
+    hdf_obj.close()
+
+
+def load_trajectory_from_hdf5(
+        fullpath: Union[str, pathlib.Path]) -> Trajectory:
+    """Import a trajectory object from file in HDF5 format.
+
+    :param fullpath: Fullpath of the HDF5 file to import.
+
+    :returns: Loaded trajectory object.
+    """
+    # Open HDF5 file
+    hdf_obj = h5py.File(fullpath, "r")
+
+    # Get all state attributes that are specified
+    states_dict = {}
+    if 'states' in hdf_obj.keys():
+        for key, value in hdf_obj['states'].items():
+            states_dict[key] = value[...]
+
+    # Re-construct state sequence
+    states = []
+    for args in zip(*states_dict.values()):
+        states.append(State(**dict(zip(states_dict.keys(), args))))
+
+    # Build trajectory from data.
+    # Null char '\0' must be added at the end to match original string length.
+    dataset = hdf_obj['robot']
+    robot_data = dataset[()]
+    robot_data += b'\0' * (
+        dataset.nbytes - len(robot_data))  # pylint: disable=no-member
+    try:
+        robot = jiminy.load_from_binary(robot_data)
+    except MemoryError as e:
+        raise MemoryError(
+            "Impossible to build robot from serialized binary data. Make sure "
+            "that data has been generated on a machine with the same hardware "
+            "as this one.") from e
+
+    # Load whether to use the theoretical model of the robot
+    use_theoretical_model = dataset.attrs["use_theoretical_model"]
+
+    # Close the HDF5 file
+    hdf_obj.close()
+
+    # Re-construct the whole trajectory
+    return Trajectory(states, robot, use_theoretical_model)
```

## gym_jiminy/common/utils/spaces.py

```diff
@@ -404,15 +404,15 @@
                 return partial(_reduce, fn_1, fn_2)
             if is_out_1 and is_out_2:
                 def _reduce(fn_1, fn_2, delayed):
                     fn_2(delayed)
                     fn_1(delayed)
                 return partial(_reduce, fn_1, fn_2)
             if is_out_1 and not is_out_2:
-                if has_args:
+                if has_args:  # pylint: disable=possibly-used-before-assignment
                     def _reduce(fn_1, fn_2, field_2, args_2, delayed):
                         fn_2(delayed[field_2], *args_2)
                         fn_1(delayed)
                     return partial(_reduce, fn_1, fn_2, field_2, args_2)
 
                 def _reduce(fn_1, fn_2, field_2, delayed):
                     fn_2(delayed[field_2])
```

## gym_jiminy/common/wrappers/__init__.py

```diff
@@ -1,16 +1,16 @@
 # pylint: disable=missing-module-docstring
 
 from .observation_filter import FilterObservation
-from .observation_stack import StackedJiminyEnv
+from .observation_stack import StackObservation
 from .normalize import NormalizeAction, NormalizeObservation
 from .flatten import FlattenAction, FlattenObservation
 
 
 __all__ = [
     'FilterObservation',
-    'StackedJiminyEnv',
+    'StackObservation',
     'NormalizeAction',
     'NormalizeObservation',
     'FlattenAction',
-    'FlattenObservation',
+    'FlattenObservation'
 ]
```

## gym_jiminy/common/wrappers/observation_stack.py

```diff
@@ -1,8 +1,10 @@
-""" TODO: Write documentation.
+"""This module implements a wrapper for stacking observations over time.
+
+This wrapper
 """
 import logging
 from collections import deque
 from typing import List, Optional, Tuple, Set, Sequence, Union, Generic
 from typing_extensions import TypeAlias
 
 import numpy as np
@@ -21,21 +23,26 @@
 
 
 StackedObsT: TypeAlias = NestedObsT
 
 LOGGER = logging.getLogger(__name__)
 
 
-class StackedJiminyEnv(
+class StackObservation(
         BasePipelineWrapper[StackedObsT, ActT, NestedObsT, ActT],
         Generic[NestedObsT, ActT]):
     """Partially stack observations in a rolling manner.
 
     This wrapper combines and extends OpenAI Gym wrappers `FrameStack` and
-    `FilteredJiminyEnv` to support nested filter keys.
+    `FilteredJiminyEnv` to support nested filter keys. It derives from
+    `BasePipelineWrapper` rather than `gym.Wrapper`. This means that
+    observations can be stacked at observation update period rather than step
+    update period. It is also possible to access the stacked observation from
+    any block of the environment pipeline, and it will be taken into account
+    when calling `evaluate` or `play_interactive`.
 
     It adds one extra dimension to all the leaves of the original observation
     spaces that must be stacked. In such a case, the first dimension
     corresponds to the individual timesteps (from oldest `0` to latest `-1`).
 
     .. note::
         The standard container spaces `gym.spaces.Dict` and `gym.spaces.Tuple`
```

## Comparing `gym_jiminy-1.8.5.post1.dist-info/METADATA` & `gym_jiminy-1.8.6.dist-info/METADATA`

 * *Files 16% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 Metadata-Version: 2.1
 Name: gym-jiminy
-Version: 1.8.5.post1
+Version: 1.8.6
 Summary: Python-native OpenAI Gym interface between Jiminy open-source simulator and Reinforcement Learning frameworks.
 Home-page: https://github.com/duburcqa/jiminy
-Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.5.post1.tar.gz
+Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.6.tar.gz
 Author: Alexis Duburcq
 Author-email: alexis.duburcq@gmail.com
 Maintainer: Alexis Duburcq
 License: MIT
 Keywords: reinforcement-learning robotics gym jiminy
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Science/Research
@@ -16,23 +16,23 @@
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.12
 Requires-Python: >=3.8,<3.13
-Requires-Dist: jiminy-py ~=1.8.5.post1
-Requires-Dist: numpy
+Requires-Dist: jiminy-py ~=1.8.6
+Requires-Dist: h5py
 Requires-Dist: numba >=0.54.0
 Requires-Dist: gymnasium <1.0,>=0.28
 Requires-Dist: typing-extensions
 Provides-Extra: all
-Requires-Dist: gym-jiminy-rllib ~=1.8.5.post1 ; extra == 'all'
-Requires-Dist: gym-jiminy-toolbox ~=1.8.5.post1 ; extra == 'all'
-Requires-Dist: gym-jiminy-zoo ~=1.8.5.post1 ; extra == 'all'
+Requires-Dist: gym-jiminy-zoo ~=1.8.6 ; extra == 'all'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.6 ; extra == 'all'
+Requires-Dist: gym-jiminy-rllib ~=1.8.6 ; extra == 'all'
 Provides-Extra: rllib
-Requires-Dist: gym-jiminy-rllib ~=1.8.5.post1 ; extra == 'rllib'
+Requires-Dist: gym-jiminy-rllib ~=1.8.6 ; extra == 'rllib'
 Provides-Extra: toolbox
-Requires-Dist: gym-jiminy-toolbox ~=1.8.5.post1 ; extra == 'toolbox'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.6 ; extra == 'toolbox'
 Provides-Extra: zoo
-Requires-Dist: gym-jiminy-zoo ~=1.8.5.post1 ; extra == 'zoo'
+Requires-Dist: gym-jiminy-zoo ~=1.8.6 ; extra == 'zoo'
```

## Comparing `gym_jiminy-1.8.5.post1.dist-info/RECORD` & `gym_jiminy-1.8.6.dist-info/RECORD`

 * *Files 13% similar despite different names*

```diff
@@ -1,35 +1,39 @@
 gym_jiminy/common/__init__.py,sha256=8BemhrCxALdOEEKFpFRutfsu4t2guZIMIIpjx0bIU08,230
 gym_jiminy/common/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-gym_jiminy/common/bases/__init__.py,sha256=BIqho7mjwOk7wLawJHh38NCa64dMJiKwo2mAQEgaQQo,1548
+gym_jiminy/common/bases/__init__.py,sha256=eq4So8P9naFQVallAu_aSOiTG8pjWjTrWLHkvaA8aS8,2111
 gym_jiminy/common/bases/blocks.py,sha256=jYyInWm3d2LWrBDmO1wh2TsTnrzJ1lYANIdpPlxoURw,10466
-gym_jiminy/common/bases/interfaces.py,sha256=atMhcFbqAo9EJPOddv_mIfzPhj2nvuUy40Y7aikUG80,14953
-gym_jiminy/common/bases/pipeline.py,sha256=X2RlAWyUpuoXM8_29ob0oThj5HSfecW0kpbprDPCxb0,40957
-gym_jiminy/common/bases/quantity.py,sha256=HWSSByxc1RPQReCZqTgQi2pQpOcUBBH1jduwPdiPraY,18035
+gym_jiminy/common/bases/compositions.py,sha256=MHPFL__FNm9_HXsmjXPmjjFHHraHYsGUMQCc3VjjSCc,15016
+gym_jiminy/common/bases/interfaces.py,sha256=Mrz_AcnXhv8RIVtf1faoIbfYaBPylPBlShhyNzsJaKc,15008
+gym_jiminy/common/bases/pipeline.py,sha256=a7b9AG_gCmLh6XPMnYMFX8IU4l0mXGOZLlCVcTjKHbg,45685
+gym_jiminy/common/bases/quantities.py,sha256=TUj-QyzD82dPtyx_A8ER1o4ztdL7u5jUcsKbjuVGZcE,40273
 gym_jiminy/common/blocks/__init__.py,sha256=zpuD5GgmxEUAAWih0H-Zwy_JF8BlouStEAAPKQ5koWc,385
-gym_jiminy/common/blocks/deformation_estimator.py,sha256=1T1ZAvaqOdwl6mKQ3jZ0jFxgQ7SWQnT3sP56GWl2ekY,37430
-gym_jiminy/common/blocks/mahony_filter.py,sha256=3JwBb1ushRwOXKPvbitbYVlqwU-Pooth-sgCJQbJvoY,17212
-gym_jiminy/common/blocks/motor_safety_limit.py,sha256=3H_6gzkXTbM-nYyTYiVh3I4BP25DXFKci6dhXMNd0EA,10089
-gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=o6NYJ3C5jTgBu9nG4RgQTXrK-bALsaMBUbG8VP3GpyQ,26459
+gym_jiminy/common/blocks/deformation_estimator.py,sha256=Mp5dpBohZ7mYzvYPImRY7pPJyg23PCua89po-xOg7vc,38819
+gym_jiminy/common/blocks/mahony_filter.py,sha256=HhG8TL4L20EvC9WuX7FqCnt7sc4gCDzWrVU-xzH7ZRg,17162
+gym_jiminy/common/blocks/motor_safety_limit.py,sha256=XA-mFGnJbJvGIfUPQ9vghias6avqzBXlnRoy9uJsWGQ,10420
+gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=1Rt2mUX7eJfslk-VO4Sacj-0OLRjR0SLCBtfu4KV6sE,25999
+gym_jiminy/common/compositions/__init__.py,sha256=J1bKd4kdzkeLAYHB-h-MoQx2pvQ6uE19laS0VDhBaUM,427
+gym_jiminy/common/compositions/generic.py,sha256=6_i4mk5--ANjJ38uT5yC_TtZOfA2LTHpdjuhXU2nvYQ,8443
+gym_jiminy/common/compositions/locomotion.py,sha256=4-QKJSOKOsqDj3dbNKE8OX2WqBkGWwZZn6y-ZTeWtfo,1695
 gym_jiminy/common/envs/__init__.py,sha256=A5GYVURVmtE_IIPZfBliGhvfwSvifbZmkNWlLClRUO4,178
-gym_jiminy/common/envs/generic.py,sha256=e3YgGmkfdNy49mGBk3JDKGv34-F4-m-iXElfQ2N2EQ0,70853
-gym_jiminy/common/envs/locomotion.py,sha256=iU2-3bYCtGV70QxymSESW99oD-bHIvv8Q8UDKv9yO4w,18748
+gym_jiminy/common/envs/generic.py,sha256=Ytqlx_LOON_r7UviTUvVfmz_KdZIIPJTpE4qfJERhrI,67627
+gym_jiminy/common/envs/locomotion.py,sha256=gRNT3ASoOXZIjnilrUY5tJDI_R-40Yjo35aK-kxeO_U,18319
 gym_jiminy/common/envs/internal/__init__.py,sha256=TKkRy9iC7oL2yPlYzQBPXeJ5h7yEVbJlOfR2-ZKkcKw,118
 gym_jiminy/common/envs/internal/play.py,sha256=Rh87t2tL4HzpON0fihDwxYIMEK-w5xWjoVi_VYwsFsI,9350
-gym_jiminy/common/quantities/__init__.py,sha256=YtyCZAotxhOJzwFKyXvlKIbJteTLgvvtqIfIuxtUS6E,367
-gym_jiminy/common/quantities/generic.py,sha256=xItEGZubWW2s4tNEwh35SBBHQGbqZ_dFBwbU02y-XrQ,11998
-gym_jiminy/common/quantities/locomotion.py,sha256=7LV4FiJ978gdK7TGV7VR-B02vBTkOrwXYvl8TD3Ma0k,4496
-gym_jiminy/common/quantities/manager.py,sha256=AG7BGubkqaIq1uEqF6qfXdG3CSVv4S31MdFXVnqADBo,7024
-gym_jiminy/common/utils/__init__.py,sha256=4ZPCvwPQODSDf_4Xq-uFlTgH-Uq4wfHMqHtldDX3cUo,2318
-gym_jiminy/common/utils/math.py,sha256=XjP4Gx1CGqfmjPaeEBCje_lUXs65_s6bJcDgGmKTWfQ,21000
+gym_jiminy/common/quantities/__init__.py,sha256=y0AfYwxGVNc-cvTLSVOCqHFu9nqEkiUj2GFOZfKyz-I,717
+gym_jiminy/common/quantities/generic.py,sha256=zPkiDttTpUQJCeXZeLyVCNEdIxQiS3Pfe5qY6z6ZUhc,34327
+gym_jiminy/common/quantities/locomotion.py,sha256=LPlIDSnP2w3rfUeD1t6VgUv_u9KR1WitUn-luUJPBmE,7415
+gym_jiminy/common/quantities/manager.py,sha256=JAHRYK4SZ65bSDdG4OXPNReeqFpqza6tUAZUMd-Tgyk,10684
+gym_jiminy/common/utils/__init__.py,sha256=gSIktUR0jvppWrxyMB6tnC9g_T4Dq0dDcWEKWhAcTwo,2580
+gym_jiminy/common/utils/math.py,sha256=Vlv606l7YaTd8z7Zy4Zxaqo7d3VVBNBoQrS5aM4WB_8,22567
 gym_jiminy/common/utils/misc.py,sha256=R9awz80KH3BoXzifTmmQ0evB2GQbbnAsHHwaDuNfdGk,8920
-gym_jiminy/common/utils/pipeline.py,sha256=Zf8WlE3nux5rt7c-OQ6-4taMSj5f-81q3J-fM1u1u_o,10189
-gym_jiminy/common/utils/spaces.py,sha256=nvCRfl4p6bCKIFi4DdY1N3jMqud9Etzn939aXDJCwi8,54010
-gym_jiminy/common/wrappers/__init__.py,sha256=6azq0upqUnzeW2ejJ4OB2yGcUFZDWY-ggMUtQDhZz4I,421
+gym_jiminy/common/utils/pipeline.py,sha256=uzzVHy7wmSKLCuzfdo0WroenA6xBjM1LTmvv3Ot1Jz8,22481
+gym_jiminy/common/utils/spaces.py,sha256=Bo3cKnFPc59C0Fc0wtjiK4pxlGBS5Wk92VkPJOSraBw,54061
+gym_jiminy/common/wrappers/__init__.py,sha256=EbzeWiKrvyMmFAu6_2HQvAz8-l8bcGUSEGjumqHCMO8,420
 gym_jiminy/common/wrappers/flatten.py,sha256=kWvJlyvmswsA6Uv94oJ5c3zNRT5bXR7wdM1yuUWUzsQ,6153
 gym_jiminy/common/wrappers/normalize.py,sha256=TD3SnkMDydC2688ozpnNR7Y2_BIOEYcAIa6OtSb11B8,4039
 gym_jiminy/common/wrappers/observation_filter.py,sha256=UTQ2WhOdmsFleY6W9nhd9G4oKYUv7xj5U-ThP3juhMg,7770
-gym_jiminy/common/wrappers/observation_stack.py,sha256=1TswIefJ5N5JXRmkyyeTZ0NbBGHSBvpvzQh7xfK0F1s,10955
-gym_jiminy-1.8.5.post1.dist-info/METADATA,sha256=74G9CqsMN6ykUd7cbpabvbN-9WbtpdKBC03rLiwFzsE,1659
-gym_jiminy-1.8.5.post1.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-gym_jiminy-1.8.5.post1.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
-gym_jiminy-1.8.5.post1.dist-info/RECORD,,
+gym_jiminy/common/wrappers/observation_stack.py,sha256=vHI7ZtGYPopZ_bxdWd1yft_2I24k9ZpY72SXX2wc0FY,11380
+gym_jiminy-1.8.6.dist-info/METADATA,sha256=0HkpCga1VKHXA1fz2FiZA57QNerOvfF84PAhKNYIyyA,1604
+gym_jiminy-1.8.6.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+gym_jiminy-1.8.6.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
+gym_jiminy-1.8.6.dist-info/RECORD,,
```

