# Comparing `tmp/cwstorm-0.2.0-py2.py3-none-any.whl.zip` & `tmp/cwstorm-0.2.0b2-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,38 @@
-Zip file size: 26883 bytes, number of entries: 36
--rw-r--r--  2.0 unx       29 b- defN 24-May-24 19:02 cwstorm/__init__.py
--rw-r--r--  2.0 unx     9929 b- defN 24-May-24 19:02 cwstorm/cli.py
--rw-r--r--  2.0 unx     2577 b- defN 24-May-24 19:02 cwstorm/deserializer.py
--rw-r--r--  2.0 unx     3984 b- defN 24-May-24 19:02 cwstorm/validator.py
--rw-r--r--  2.0 unx       15 b- defN 24-May-24 19:02 cwstorm/version.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-24 19:02 cwstorm/dsl/__init__.py
--rw-r--r--  2.0 unx      496 b- defN 24-May-24 19:02 cwstorm/dsl/cmd.py
--rw-r--r--  2.0 unx     4167 b- defN 24-May-24 19:02 cwstorm/dsl/dag_node.py
--rw-r--r--  2.0 unx     2457 b- defN 24-May-24 19:02 cwstorm/dsl/job.py
--rw-r--r--  2.0 unx     4367 b- defN 24-May-24 19:02 cwstorm/dsl/node.py
--rw-r--r--  2.0 unx     8824 b- defN 24-May-24 19:02 cwstorm/dsl/node_metaclass.py
--rw-r--r--  2.0 unx     1909 b- defN 24-May-24 19:02 cwstorm/dsl/task.py
--rw-r--r--  2.0 unx     1219 b- defN 24-May-24 19:02 cwstorm/dsl/upload.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-24 19:02 cwstorm/examples/__init__.py
--rw-r--r--  2.0 unx      149 b- defN 24-May-24 19:02 cwstorm/examples/ass_comp_heavy.py
--rw-r--r--  2.0 unx      147 b- defN 24-May-24 19:02 cwstorm/examples/ass_comp_light.py
--rw-r--r--  2.0 unx      148 b- defN 24-May-24 19:02 cwstorm/examples/ass_comp_normal.py
--rw-r--r--  2.0 unx      905 b- defN 24-May-24 19:02 cwstorm/examples/ass_export.py
--rw-r--r--  2.0 unx      760 b- defN 24-May-24 19:02 cwstorm/examples/frames.py
--rw-r--r--  2.0 unx      176 b- defN 24-May-24 19:02 cwstorm/examples/one_task.py
--rw-r--r--  2.0 unx      100 b- defN 24-May-24 19:02 cwstorm/examples/simple_qt.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-24 19:02 cwstorm/serializers/__init__.py
--rw-r--r--  2.0 unx     2365 b- defN 24-May-24 19:02 cwstorm/serializers/default.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-24 19:02 tests/__init__.py
--rw-r--r--  2.0 unx      438 b- defN 24-May-24 19:02 tests/test_cmd.py
--rw-r--r--  2.0 unx     4629 b- defN 24-May-24 19:02 tests/test_dag_node.py
--rw-r--r--  2.0 unx     4733 b- defN 24-May-24 19:02 tests/test_deserializer.py
--rw-r--r--  2.0 unx      664 b- defN 24-May-24 19:02 tests/test_job.py
--rw-r--r--  2.0 unx     8916 b- defN 24-May-24 19:02 tests/test_node.py
--rw-r--r--  2.0 unx     1774 b- defN 24-May-24 19:02 tests/test_serializers.py
--rw-r--r--  2.0 unx      666 b- defN 24-May-24 19:02 tests/test_task.py
--rw-r--r--  2.0 unx     5328 b- defN 24-May-24 19:02 cwstorm-0.2.0.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-May-24 19:02 cwstorm-0.2.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       43 b- defN 24-May-24 19:02 cwstorm-0.2.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       14 b- defN 24-May-24 19:02 cwstorm-0.2.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2863 b- defN 24-May-24 19:02 cwstorm-0.2.0.dist-info/RECORD
-36 files, 74901 bytes uncompressed, 22331 bytes compressed:  70.2%
+Zip file size: 25813 bytes, number of entries: 36
+-rw-r--r--  2.0 unx       29 b- defN 24-Feb-28 00:09 cwstorm/__init__.py
+-rw-r--r--  2.0 unx     4697 b- defN 24-Feb-28 00:09 cwstorm/cli.py
+-rw-r--r--  2.0 unx     2657 b- defN 24-Feb-28 00:09 cwstorm/deserializer.py
+-rw-r--r--  2.0 unx     4020 b- defN 24-Feb-28 00:09 cwstorm/validator.py
+-rw-r--r--  2.0 unx       15 b- defN 24-Feb-28 00:09 cwstorm/version.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/dsl/__init__.py
+-rw-r--r--  2.0 unx      286 b- defN 24-Feb-28 00:09 cwstorm/dsl/cmd.py
+-rw-r--r--  2.0 unx     4472 b- defN 24-Feb-28 00:09 cwstorm/dsl/dag_node.py
+-rw-r--r--  2.0 unx     2315 b- defN 24-Feb-28 00:09 cwstorm/dsl/job.py
+-rw-r--r--  2.0 unx     4367 b- defN 24-Feb-28 00:09 cwstorm/dsl/node.py
+-rw-r--r--  2.0 unx     8824 b- defN 24-Feb-28 00:09 cwstorm/dsl/node_metaclass.py
+-rw-r--r--  2.0 unx     1611 b- defN 24-Feb-28 00:09 cwstorm/dsl/task.py
+-rw-r--r--  2.0 unx     1123 b- defN 24-Feb-28 00:09 cwstorm/dsl/upload.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/examples/__init__.py
+-rw-r--r--  2.0 unx      149 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_heavy.py
+-rw-r--r--  2.0 unx      147 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_light.py
+-rw-r--r--  2.0 unx      148 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_comp_normal.py
+-rw-r--r--  2.0 unx      905 b- defN 24-Feb-28 00:09 cwstorm/examples/ass_export.py
+-rw-r--r--  2.0 unx      760 b- defN 24-Feb-28 00:09 cwstorm/examples/frames.py
+-rw-r--r--  2.0 unx      176 b- defN 24-Feb-28 00:09 cwstorm/examples/one_task.py
+-rw-r--r--  2.0 unx      100 b- defN 24-Feb-28 00:09 cwstorm/examples/simple_qt.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 cwstorm/serializers/__init__.py
+-rw-r--r--  2.0 unx     2552 b- defN 24-Feb-28 00:09 cwstorm/serializers/default.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-28 00:09 tests/__init__.py
+-rw-r--r--  2.0 unx      438 b- defN 24-Feb-28 00:09 tests/test_cmd.py
+-rw-r--r--  2.0 unx     4629 b- defN 24-Feb-28 00:09 tests/test_dag_node.py
+-rw-r--r--  2.0 unx     4829 b- defN 24-Feb-28 00:09 tests/test_deserializer.py
+-rw-r--r--  2.0 unx      664 b- defN 24-Feb-28 00:09 tests/test_job.py
+-rw-r--r--  2.0 unx     8916 b- defN 24-Feb-28 00:09 tests/test_node.py
+-rw-r--r--  2.0 unx     1774 b- defN 24-Feb-28 00:09 tests/test_serializers.py
+-rw-r--r--  2.0 unx      666 b- defN 24-Feb-28 00:09 tests/test_task.py
+-rw-r--r--  2.0 unx     8808 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       43 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       14 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2873 b- defN 24-Feb-28 00:10 cwstorm-0.2.0b2.dist-info/RECORD
+36 files, 73117 bytes uncompressed, 21241 bytes compressed:  70.9%
```

## zipnote {}

```diff
@@ -87,23 +87,23 @@
 
 Filename: tests/test_serializers.py
 Comment: 
 
 Filename: tests/test_task.py
 Comment: 
 
-Filename: cwstorm-0.2.0.dist-info/METADATA
+Filename: cwstorm-0.2.0b2.dist-info/METADATA
 Comment: 
 
-Filename: cwstorm-0.2.0.dist-info/WHEEL
+Filename: cwstorm-0.2.0b2.dist-info/WHEEL
 Comment: 
 
-Filename: cwstorm-0.2.0.dist-info/entry_points.txt
+Filename: cwstorm-0.2.0b2.dist-info/entry_points.txt
 Comment: 
 
-Filename: cwstorm-0.2.0.dist-info/top_level.txt
+Filename: cwstorm-0.2.0b2.dist-info/top_level.txt
 Comment: 
 
-Filename: cwstorm-0.2.0.dist-info/RECORD
+Filename: cwstorm-0.2.0b2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cwstorm/__init__.py

```diff
@@ -1 +1 @@
-__schema_version__ = "0.2.0"
+__schema_version__ = "0.1.1"
```

## cwstorm/cli.py

```diff
@@ -1,39 +1,17 @@
 import os
 import click
 import importlib
 import json
 import yaml
-import sys
 from cwstorm.version import VERSION
 from cwstorm.serializers import default
 from cwstorm import validator
+from tabulate import tabulate
 import textwrap
-import re
-
-from cwstorm.dsl.cmd import Cmd
-from cwstorm.dsl.task import Task
-from cwstorm.dsl.upload import Upload
-from cwstorm.dsl.job import Job
-from cwstorm.dsl.dag_node import DagNode
-
-import markdown
-import io
-import tempfile
-import webbrowser
-
-from cwstorm import __schema_version__
-
-import traceback
-
-
-PURE = """
-<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css" integrity="sha384-X38yfunGUhNzHpBaEBsWLO+A0HDYOQi8ufWDkZ0k9e0eXz/tH3II7uKZ9msv++Ls" crossorigin="anonymous">
-<meta name="viewport" content="width=device-width, initial-scale=1">
-"""
 
 EXAMPLES_FOLDER = os.path.join(os.path.dirname(os.path.realpath(__file__)), "examples")
 EXAMPLE_MODULES_PREFIX = "cwstorm.examples."
 GET_JOB_FUNCTION_NAME = "get_job"
 
 
 EXAMPLE_FILES = os.listdir(EXAMPLES_FOLDER)
@@ -62,274 +40,115 @@
 
 
 SERIALIZE_HELP = """The structure of serialized DAG. 
 
 default: is a list of nodes and a list of edges. The edges contain source and target pointers to node labels. This is the simplest and easiest to understand. It is also understood by the UI.
 """
 
-FORMAT_HELP = """The output format. JSON and YAML are implemented. Pretty is a pretty-printed JSON.
+FORMAT_HELP = """The output format. JSON and YAML are implemented. XML is not yet implemented.
 """
 
 EXAMPLE_HELP = """The example job to serialize. The examples are in the storm/examples folder. The examples are python modules that contain a function called get_job that returns a job object.
 """
 
 
 ########################### SERIALIZE #############################
 @main.command()
 @click.option(
     "-f",
     "--fmt",
     "--format",
     help=FORMAT_HELP,
     default="json",
-    type=click.Choice(choices=["json", "pretty", "yaml"], case_sensitive=False),
+    type=click.Choice(choices=["json", "pretty", "yaml", "xml"], case_sensitive=False),
 )
 @click.option(
     "-x",
     "--example",
     help=EXAMPLE_HELP,
     default="simple",
-    type=click.Choice(choices=MODULE_NAMES + ["all"], case_sensitive=True),
-)
-@click.argument(
-    "output",
-    required=False,
-    type=click.Path(file_okay=False, dir_okay=True, resolve_path=True),
+    type=click.Choice(choices=MODULE_NAMES, case_sensitive=True),
 )
+@click.argument("output", nargs=1, type=click.Path(exists=False, resolve_path=True))
 def serialize(fmt, example, output):
     """
     Serialize a job to json or yaml.
 
     Examples:
 
-    # Output json to stdout.
-    storm serialize -f json -x frames
-
     # Output json to a file for visualization.
-    storm serialize -f json -x frames ~/Desktop
+
+    storm serialize -f json -x frames ~/Desktop/frames.json
+
+    storm serialize -f json -x ass_comp_light -s fargo ~/Desktop/ass_comp_light.json
 
     # Output yaml to a file for using the the assex job example.
-    storm serialize -f yaml -s storm  -x assex ~/Desktop
 
-    """
-    if example == "all":
-        for example in MODULE_NAMES:
-            _serialize(fmt, example, output)
-    else:
-        _serialize(fmt, example, output)
+    storm serialize -f yaml -s storm  -x assex  ~/Desktop/assex.yaml
 
+    # ARGO is not yet implemented
+
+    """
 
-def _serialize(fmt, example, output):
     module_name = EXAMPLE_MODULES_PREFIX + example
     module = importlib.import_module(module_name)
     storm_script = getattr(module, GET_JOB_FUNCTION_NAME)
     job = storm_script()
 
     serialized = default.serialize(job)
-    # Determine the output method (stdout or file)
-    if output:
-        ext = {
-            "json": "json",
-            "pretty": "json",
-            "yaml": "yml",
-        }
-        fh = open(os.path.join(output, f"{example}.{ext[fmt]}"), "w", encoding="utf-8")
-    else:
-        fh = sys.stdout
-    try:
-        if fmt == "json":
+
+    if fmt == "json":
+        with open(output, "w", encoding="utf-8") as fh:
             json.dump(serialized, fh)
-        elif fmt == "pretty":
+    elif fmt == "pretty":
+        with open(output, "w", encoding="utf-8") as fh:
             json.dump(serialized, fh, indent=3)
-        elif fmt == "yaml":
+    elif fmt == "yaml":
+        with open(output, "w", encoding="utf-8") as fh:
             yaml.dump(serialized, fh)
-        else:
-            raise ValueError(f"Unknown format: {fmt}")
-    finally:
-        # Only close the file if we're not writing to stdout
-        if output:
-            fh.close()
+    elif fmt == "xml":
+        raise NotImplementedError("XML serialization not implemented yet.")
+    else:
+        raise ValueError(f"Unknown format: {fmt}")
 
 
-# storm serialize -x all  /Volumes/xhf/dev/cio/cioapp/public/graphs/ done
+# for s in a ss_comp_heavy a ss_comp_light a ss_comp_normal a ss_export frames one_task simple_qt ; do  storm serialize -x $s  /Volumes/xhf/dev/cio/inst_tag_assign/public/graphs/$s.json; done
 
 
-########################### VALIDATE #############################
+########################### DESERIALIZER #############################
+VALIDATOR_INPUT_HELP = """
+    Deserializer input format. The input format is the same as the output format.
+"""
 
 
 @main.command()
-@click.option(
-    "-f",
-    "--fmt",
-    "--format",
-    help=FORMAT_HELP,
-    default="html",
-    type=click.Choice(choices=["markdown", "html"], case_sensitive=False),
-)
 @click.argument("infile", nargs=1, type=click.Path(exists=True, resolve_path=True))
-def validate(fmt, infile):
+def validate(infile):
     """
     Validate a JSON file.
 
     storm validate /path/to/file.json
 
 
     """
-
-    md = _as_markdown(infile)
-    if fmt == "markdown":
-        print(md)
-    else:  # fmt == "html":
-        html = markdown.markdown(md, extensions=["markdown.extensions.tables"])
-        html = decorate(html)
-
-        with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False) as f:
-            f.write(html)
-            webbrowser.open("file://" + f.name, new=2)
-
-
-def _as_markdown(infile):
-    stream = io.StringIO()
-    stream.write(f"# Storm Validation Report:\n\n{infile}")
-
+    print(f"\nValidating {infile}")
     with open(infile, "r", encoding="utf-8") as fh:
         data = json.load(fh)
-        try:
-            validation = validator.validate(data)
-        except Exception:
-            tb_lines = traceback.format_exc().splitlines()
-            stream.write("\n\n".join(["```python"] + tb_lines + ["```"]))
-            return stream.getvalue()
-
-    stream.write("\n\n## Input Counts\n\n")
-    stream.write("| Type | Count |\n")
-    stream.write("|------|-------|\n")
-    for key, value in validation["input_info"]:
-        stream.write(f"| {key} | {value} |\n")
-
-    stream.write("\n\n## Deserialized Job Info\n\n")
-    stream.write("| Param | Value | Valid |\n")
-    stream.write("|-------|-------|-------|\n")
-    for key, value, valid in validation["job_info"]:
-        stream.write(f"| {key} | {value} | {valid} |\n")
-    result = stream.getvalue()
-    stream.close()
-    return result
+        result = validator.validate(data)
+    MAX_LINE_LENGTH = 40
+    for line in result["job_info"]:
+        if len(str(line[1])) > MAX_LINE_LENGTH:
+            line[1] = _wrap_text(str(line[1]), MAX_LINE_LENGTH)
 
+    print(f"******** Input counts ********")
 
-########################### DISPLAY #############################
-@main.command()
-@click.option(
-    "-f",
-    "--fmt",
-    "--format",
-    help=FORMAT_HELP,
-    default="html",
-    type=click.Choice(choices=["markdown", "html"], case_sensitive=False),
-)
-def spec(fmt):
-    """
-    Display the spec.
-    
-    Shows the attribites of classes in the DSL in a web page or as markdown.
-    """
-    if fmt == "markdown":
-        display_schema_markdown(DagNode, Job, Task, Cmd, Upload)
-    elif fmt == "html":
-        display_schema_html(DagNode, Job, Task, Cmd, Upload)
+    print(tabulate(result["input_info"], headers=["Type", "Count"], tablefmt="grid"))
 
+    print(f"\n******** Deserialized job info ********")
 
-def display_schema_markdown(*klasses):
-    stream = io.StringIO()
-    stream.write(
-        "# Storm DSL Specification - Version {}\n\n".format(__schema_version__)
+    print(
+        tabulate(
+            result["job_info"], headers=["Param", "Value", "Valid"], tablefmt="grid"
+        )
     )
 
-    for klass in klasses:
-        class_schema_to_stream(klass, stream)
-    print(stream.getvalue())
-
-
-def display_schema_html(*klasses):
-    stream = io.StringIO()
-    stream.write(
-        "# Storm DSL Specification - Version {}\n\n".format(__schema_version__)
-    )
-
-    for klass in klasses:
-        class_schema_to_stream(klass, stream)
-    html = markdown.markdown(
-        stream.getvalue(), extensions=["markdown.extensions.tables"]
-    )
-    html = decorate(html)
-    stream.close()
-    with tempfile.NamedTemporaryFile(mode="w", suffix=".html", delete=False) as f:
-        f.write(html)
-        webbrowser.open("file://" + f.name, new=2)
-
-
-def class_schema_to_stream(klass, stream):
-    class_name = klass.__name__
-    base_class = klass.__bases__[0].__name__
-    docstring_paragraphs = re.split(r"\n\s*\n", klass.__doc__) if klass.__doc__ else []
-    docstring_paragraphs = [p.strip() for p in docstring_paragraphs]
-    class_description = (
-        "\n\n".join(docstring_paragraphs[1:])
-        if len(docstring_paragraphs) > 1
-        else "No description available."
-    )
-
-    desc = f"## Class: {class_name} ({base_class})\n\n#### Description:\n{class_description}\n\n"
-    stream.write(desc)
-
-    if len(klass.ATTRS) == 0:
-        stream.write("\n\n")
-        return
-    headers = ["Name", "Type", "Default", "Validator"]
-    rows = [format_attr(name, attr) for name, attr in klass.ATTRS.items()]
-    column_widths = [max(len(str(item)) for item in col) for col in zip(headers, *rows)]
-    row_format = (
-        "| " + " | ".join("{:<" + str(width) + "}" for width in column_widths) + " |"
-    )
-    stream.write(row_format.format(*headers))
-    stream.write("\n")
-    stream.write("|-" + "-|-".join("-" * width for width in column_widths) + "-|")
-    stream.write("\n")
-    for row in rows:
-        stream.write(row_format.format(*row))
-        stream.write("\n")
-    stream.write("\n\n")
-    stream.write("---\n\n")
-
-
-def format_attr(name, attr):
-    # Format type
-    type_str = (
-        attr["type"]
-        .replace("list:", "List of ")
-        .replace("int", "Integer")
-        .replace("str", "String")
-        .replace("dict", "Dictionary")
-    )
-
-    # Format default value
-    default_str = str(attr.get("default", ""))
-
-    # Format validator
-    validator_str = ""
-    if "validator" in attr:
-        if isinstance(attr["validator"], re.Pattern):
-            validator_str = f"Regex: {attr['validator'].pattern}"
-
-        else:
-            validator_str = str(attr["validator"])
-        validator_str = validator_str.replace("|", "\\|")
-        validator_str = f"<code>{validator_str}</code>"
-    return [name, type_str, default_str, validator_str]
-
-
-def decorate(html):
-    html = html.replace("<table>", '<table class="pure-table pure-table-bordered">')
-    html = '<html><head>{}</head><body style="margin: 2em;width=800px">{}</body></html>'.format(
-        PURE, html
-    )
-    return html
+    # click.echo(result)
```

## cwstorm/deserializer.py

```diff
@@ -8,43 +8,45 @@
 
 logging.basicConfig(level=logging.DEBUG)
 logger = logging.getLogger(__name__)
 
 def create_job(data):
     j = Job(data.get('id'))
     j.comment(data.get('comment', 'No comment'))
-    j.author(data.get('author', 'No author'))
     j.project(data.get('project', 'No project'))
     j.status(data.get('status', 'WAITING'))
-    j.location(data.get('location', ""))
+    j.location(data.get('location', "52:3D:5C:11:56:AD"))
     j.schema_version(data.get('schema_version', '1.0.0'))
+    j.author(data.get('author', 'No author'))
     j.email(data.get('email', 'noemail@nowhere.com'))
     j.metadata(data.get('metadata', {}))
     return j
 
 def create_task(data):
     t = Task(data.get('id'))
     for cmd in data.get('commands', []):  # Use a default empty list if 'commands' is not present
         t.push_commands(Cmd(*cmd.get('argv', [])))  # Use a default empty list if 'argv' is not present
     t.env(data.get('env' , {}))
     t.initial_state(data.get('initial_state', 'HOLD'))
     t.hardware(data.get('hardware', 'No hardware'))
-    t.preemptible(data.get('preemptible', 1))
-    for pkg in data.get('packages', []):  # Use a default empty list if 'packages' is not present
-        t.push_packages(pkg)
     t.lifecycle(data.get('lifecycle', {}))
     t.attempts(data.get('attempts', 1))
-    t.output_path(data.get('output_path', '/tmp/'))
+    outputs = data.get('outputs', [])
+    if outputs:  # Need to check if outputs is not None since we're unpacking
+        t.outputs(*outputs)
     t.status(data.get('status', 'WAITING'))
     return t
 
 def create_upload(data):
     u = Upload(data.get('id'))
     for file_info in data.get('files', []):  # Use a default empty list if 'files' is not present
         u.push_files(file_info)
+    outputs = data.get('outputs', [])
+    if outputs:  # Need to check if outputs is not None since we're unpacking
+        u.outputs(*outputs)
     u.initial_state(data.get('initial_state', 'HOLD'))
     u.status(data.get('status', 'WAITING'))
     return u
 
 
 # Function to deserialize JSON data
 def deserialize(dikt):
```

## cwstorm/validator.py

```diff
@@ -112,23 +112,23 @@
     density = 0
     if len(nodes) > 1:
         density = len(edges) / (len(nodes) * (len(nodes) - 1))
 
     has_cycle_ = has_cycle(job)
 
     job_params = [
-        ["Name", job.name(), True],
-        ["Schema version", job.schema_version(), True],
-        ["Comment", job.comment(), True],
-        ["Project", job.project(), True],
-        ["Status", job.status(), True],
-        ["Location", job.location(), True],
-        ["Author", job.author(), True],
-        ["Email", job.email(), True],
-        ["Created at", job.created_at(), True],
+        ["Job name", job.name(), True],
+        ["Job schema version", job.schema_version(), True],
+        ["Job comment", job.comment(), True],
+        ["Job project", job.project(), True],
+        ["Job status", job.status(), True],
+        ["Job location", job.location(), True],
+        ["Job author", job.author(), True],
+        ["Job email", job.email(), True],
+        ["Job created at", job.created_at(), True],
     ]
     job_params.append(["Source nodes", num_source_nodes, num_source_nodes > 0])
     job_params.append(["Connected nodes", num_connected_nodes, num_connected_nodes_okay])
     job_params.append(["Longest path", longest, longest > 0])
     job_params.append(["Density", density, density > 0])
     job_params.append(["Has cycle", has_cycle_, not has_cycle_])
```

## cwstorm/version.py

```diff
@@ -1 +1 @@
-VERSION="0.2.0"
+VERSION="0.1.0"
```

## cwstorm/dsl/cmd.py

```diff
@@ -1,20 +1,15 @@
 from cwstorm.dsl.node import Node
 import re
 
 
 class Cmd(Node):
-    """
-    Cmd.
-    
-    A Cmd represents a single command line to be executed. Tasks hold a list of commands, and Cmd arguments are held in a list. Lists of commands in a task run in serial.
-    """
     ATTRS = {
         "argv": {
             "type": "list:str",
-            "validator": re.compile(r"^[a-zA-Z0-9_@,\-\.\/\s%:*?<>$()+%s]+$", re.IGNORECASE)
+            "validator": re.compile(r"^[a-zA-Z0-9_@,\-\.\/\s%:]+$", re.IGNORECASE),
         },
 
     }
 
     def __init__(self, *args):
         self.argv(*args)
```

## cwstorm/dsl/dag_node.py

```diff
@@ -3,19 +3,31 @@
 
 
 VALID_NAME_REGEX = re.compile(r"^[a-zA-Z][a-zA-Z0-9_\-]*$")
 NAME_NUMBER_PADDING = 5
 
 
 class DagNode(Node):
-    """
-    A specialized version of Node that represents a node within a directed acyclic graph (DAG).
 
-    This class maintains unique naming for each instance and provides functionality to manage
-    DAG-specific properties and relationships such as parents, children, and instance tracking.
+    """A node in a directed acyclic graph.
+
+    Note: No node removal (ever)
+
+    Subclasses are Job and Task.
+
+    Job can never be a child, but it is a dag_node as
+    its useful to inherit the add() method.
+
+    An Instance is task that is a child of more than one parent
+    It is represented by one node in the DAG. However it must
+    be written many times in the output serialize.
+    During  traversal it is visited repeatedly, from differnt
+    parents. So it is considered the original task with
+    respect to its first parent, and an instance task with
+    respect to all other parents.
     """
 
     instances = {}  # Class dictionary to hold instances
     name_counter = {}  # Dictionary to keep track of class_name and number
 
     @classmethod
     def reset(cls):
```

## cwstorm/dsl/job.py

```diff
@@ -1,19 +1,17 @@
 import re
 import os
 import platform
 from cwstorm.dsl.dag_node import DagNode
 from datetime import datetime
 from cwstorm import __schema_version__
 
+
 class Job(DagNode):
-    """Job node.
-    
-    There's exactly one job node for each workflow. The job node summarizes the workflow and its status once tasks start running.
-    """
+    """job node."""
 
     ATTRS = {
         "comment": {
             "type": "str",
             "validator": re.compile(r'^[_a-z0-9 ,.!?\'"]+$', re.IGNORECASE),
         },
         "project": {
@@ -28,15 +26,15 @@
         },
         "author": {
             "type": "str",
             "validator": re.compile(r"^[a-z\s]+$", re.IGNORECASE),
         },
         "location": {
             "type": "str",
-            "validator": re.compile(r'^(?:[a-z][a-z0-9]*$|([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$|^$)', re.IGNORECASE),
+            "validator": re.compile(r'^(?:[a-z][a-z0-9]+$|([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$)', re.IGNORECASE),
         },
         "created_at": {
             "type": "str",
             "validator": re.compile(r"^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2} UTC$"),
         },
         "account_id": {"type": "str", "validator": re.compile(r"^\d{16}$")},
         "metadata": {"type": "dict"},
```

## cwstorm/dsl/task.py

```diff
@@ -1,36 +1,31 @@
 from cwstorm.dsl.dag_node import DagNode
 
 # from cwstorm.dsl.cmd import Cmd
 import re
 
 
 class Task(DagNode):
-    """Task node.
-
-    Tasks contain commands. They may be added to other Tasks as children or to the Job. A task may be the child of many parents.
-    """
+    """task node."""
 
     ATTRS = {
         "commands": {"type": "list:Cmd"},
         "hardware": {
             "type": "str",
             "validator": re.compile(r"^[a-z0-9_\-\.\s]+$", re.IGNORECASE),
         },
-        "preemptible": {"type": "int", "default": 1},
         "env": {"type": "dict"},
         "lifecycle": {"type": "dict", "validator": {"keys": ["minsec", "maxsec"]}},
         "attempts": {"type": "int", "min": 1, "max": 10},
         "initial_state": {
             "type": "str",
             "validator": re.compile(r"^(HOLD|START)$"),
             "default": "HOLD",
         },
-        "output_path": {"type": "str",  "default": "/tmp/"},
-        "packages": {"type": "list:str", "validator": re.compile(r"^[a-fA-F0-9]{32}$")},
+        "outputs": {"type": "list:str"},
         "status": {
             "type": "str",
             "validator": re.compile(r"^(WAITING|\d{1,3}|RUNNING|SUCCESS|FAILED)$"),
             "default": "WAITING",
         },
     }
```

## cwstorm/dsl/upload.py

```diff
@@ -1,22 +1,20 @@
 from cwstorm.dsl.dag_node import DagNode
 
 # from cwstorm.dsl.cmd import Cmd
 import re
 
 
 class Upload(DagNode):
-    """Upload node.
-    
-    Uploads contain lists of filepaths. They are a special kind of task and can be added anywhere a Task can be added.
-    """
+    """Upload node."""
 
     ATTRS = {
-        "files": {"type": "list:dict", "validator": {"keys":["path", "size", "md5" ]}},
+        "files": {"type": "list:dict", "validator": {"keys":["path", "size"]}},
         "initial_state": {"type": "str", "validator": re.compile(r"^(HOLD|START)$"), "default": "HOLD"},
+        "outputs": {"type": "list:str"},
         "status": {"type": "str", "validator": re.compile(r"^(WAITING|\d{1,3}|RUNNING|SUCCESS|FAILED)$"), "default": "WAITING"},
     }
 
     def is_original(self, parent=None):
         """True if the parent is the first parent or there are no parents."""
         if not parent:
             return True
```

## cwstorm/serializers/default.py

```diff
@@ -1,8 +1,9 @@
- 
+import json
+
 
 def serialize(node):
     elements = _serialize(node)
     result = {"nodes": [], "edges": []}
     for el in elements:
         if el.get("position"):
             result["nodes"].append(el)
@@ -19,14 +20,20 @@
     node_element["type"] = node_type
     if node_type == "job":
         node_element.update(get_job_attrs(node))
     elif node_type == "task":
         node_element.update(get_task_attrs(node))
     elif node_type == "upload":
         node_element.update(get_upload_attrs(node))
+
+    node_element["num_children"] = len(node.children)
+    node_element["num_parents"] = len(node.parents)
+    node_element["num_ancestors"] = node.count_ancestors()
+    node_element["num_descendants"] = node.count_descendents()
+
     elements.append({"data": node_element, "position": {"x": 0, "y": order}})
 
     # edges
     for c in node.children:
         edge_element = {}
         edge_element["source"] = c.name()
         edge_element["target"] = node.name()
@@ -54,27 +61,26 @@
     attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
 
 
 def get_task_attrs(task):
     attrs = {}
     attrs["commands"] = [dict(c) for c in task.commands()]
-    attrs["output_path"] = task.output_path()
+    attrs["outputs"] = task.outputs()
     attrs["hardware"] = task.hardware()
-    attrs["preemptible"] = task.preemptible()
-    attrs["packages"] = task.packages()
     attrs["env"] = task.env()
     attrs["lifecycle"] = task.lifecycle()
     attrs["attempts"] = task.attempts()
     attrs["initial_state"] = task.initial_state()
     stat = task.status()
     attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
 
 
 def get_upload_attrs(upload):
     attrs = {}
     attrs["files"] = upload.files()
+    attrs["outputs"] = upload.outputs()
     attrs["initial_state"] = upload.initial_state()
     stat = upload.status()
     attrs["status"] = "SUCCESS" if stat == "100" else stat
     return attrs
```

## tests/test_deserializer.py

```diff
@@ -8,15 +8,15 @@
 class TestJobCreation(unittest.TestCase):
     def setUp(self):
         self.job_data = {
             'id': 'job1',
             'comment': 'Test job',
             'project': 'ProjectX',
             'status': 'WAITING',
-            'location': 'Location',
+            'location': 'LocationY',
             'schema_version': '1.0.0',
             'author': 'AuthorZ',
             'email': 'author@example.com',
             'metadata': {'key': 'value'}
         }
     
     def tearDown(self):
@@ -30,29 +30,30 @@
         self.assertEqual(job.status(), self.job_data['status'])
         self.assertEqual(job.location(), self.job_data['location'])
         self.assertEqual(job.schema_version(), self.job_data['schema_version'])
         self.assertEqual(job.author(), self.job_data['author'])
         self.assertEqual(job.email(), self.job_data['email'])
         self.assertEqual(job.metadata(), self.job_data['metadata'])
         
- 
+        # ... continue for all fields
+
 class TestTaskCreation(unittest.TestCase):
     def setUp(self):
         self.task_data = {
             'id': 'task1',
             'commands': [
                 {'argv': ['echo', 'Hello World']}, 
                 {'argv': ['echo', 'Goodbye Cruel World']}
             ],
             'env': {'PATH': '/usr/bin'},
             'initial_state': 'HOLD',
             'hardware': 'x86_64',
             'lifecycle':  {'minsec': 30, 'maxsec': 1500},
             'attempts': 3,
-            'output_path': '/tmp/output',
+            'outputs': ['output.log'],
             'status': 'WAITING'
         }
         
     def tearDown(self):
         DagNode.reset()
 
     def test_create_task(self):
@@ -60,40 +61,42 @@
         self.assertEqual(task.name(), self.task_data['id'])
         self.assertEqual(len(task.commands()), 2)
         self.assertEqual(task.env(), self.task_data['env'])
         self.assertEqual(task.initial_state(), self.task_data['initial_state'])
         self.assertEqual(task.hardware(), self.task_data['hardware'])
         self.assertEqual(task.lifecycle(), self.task_data['lifecycle'])
         self.assertEqual(task.attempts(), self.task_data['attempts'])
-        self.assertEqual(task.output_path(), self.task_data['output_path'])
+        self.assertEqual(len(task.outputs()), 1)
         self.assertEqual(task.status(), self.task_data['status'])
         
         # ... continue for all fields
 
 class TestUploadCreation(unittest.TestCase):
     def setUp(self):
         self.upload_data = {
             'id': 'upload1',
             'files': [
                 {'path': '/tmp/file.txt', 'size': 1024},
                 {'path': '/tmp/other.txt', 'size': 2048}
             ],
+            'outputs': ['file.txt'],
             'initial_state': 'START',
             'status': 'SUCCESS'
         }
         
     def tearDown(self):
         DagNode.reset()
 
     def test_create_upload(self):
         upload = create_upload(self.upload_data)
         self.assertEqual(upload.name(), self.upload_data['id'])
         self.assertEqual(len(upload.files()), 2)
         self.assertEqual(upload.status(), self.upload_data['status'])
         self.assertEqual(upload.initial_state(), self.upload_data['initial_state'])
+        self.assertEqual(len(upload.outputs()), 1)
         
 
 class TestDeserialization(unittest.TestCase):
     def setUp(self):
         self.deserialized_data = {
             'nodes': [
                 {'data': {'type': 'job', 'id': 'job1'}},
```

## Comparing `cwstorm-0.2.0.dist-info/RECORD` & `cwstorm-0.2.0b2.dist-info/RECORD`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-cwstorm/__init__.py,sha256=vsJ8_CgfAHf8mGT2URSkA6zMcyiKSNOgiYciq2ZrFGg,29
-cwstorm/cli.py,sha256=AzZMpbQZXPZsjhjHxZRDRT18WxKz1965m91B23MEuEk,9929
-cwstorm/deserializer.py,sha256=yd6N8cT9skY1jS6fCXOQABMrrDv75iy5dzbsheYPtFs,2577
-cwstorm/validator.py,sha256=BqjirXMU5R2SJC9vEaz7G1PjdYFE2Gr3rZK_9UUl2Qw,3984
-cwstorm/version.py,sha256=wgtBV7EphkTMBjayq6Agl-BcveMj_0_p1r1opa5aHgc,15
+cwstorm/__init__.py,sha256=UHyiWcm9JmXEfGswZoQ3HdsL91HIQK2xrFeMKmPw4pg,29
+cwstorm/cli.py,sha256=HE1FiPvYDMX4teVLCJ-Xy6ikjKweWwwnFWkM70GMU1E,4697
+cwstorm/deserializer.py,sha256=h0aPaQVF8Uol8N9wK9iHbk5GHT7XIuf3E_6cdHg4UmU,2657
+cwstorm/validator.py,sha256=Vvkl8nfvdw-Lh7XdlK1oTseP8PbIoXcgM7MAcDuZ3pE,4020
+cwstorm/version.py,sha256=O58-s1kzqvR10C2rxlryPZBVejADEvOeOngtkvWly9k,15
 cwstorm/dsl/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-cwstorm/dsl/cmd.py,sha256=HHbuYHleSgFA0x-x86M-nrreI_xN4DW0PJxCbEKbVas,496
-cwstorm/dsl/dag_node.py,sha256=wFaoIQQVlYBhzIWFHUZNrdLbQ3KPalOXdiT3tDDx2Oo,4167
-cwstorm/dsl/job.py,sha256=zsPztEkgZZHJHxyOwVapnlDhc6Qq0nfduWata5Wge_U,2457
+cwstorm/dsl/cmd.py,sha256=5k97B8m0OeSvAHnJEabjlpTujNiI_ZhRUqD1N19Sdkk,286
+cwstorm/dsl/dag_node.py,sha256=fyN03mDYlMfznd_PpXBOMVuh4Nbzk3f4AoCvEEazeeA,4472
+cwstorm/dsl/job.py,sha256=C9eBP6feClY0c46VlsN_gA2oZk_vpD3PZlAkU_L-YtI,2315
 cwstorm/dsl/node.py,sha256=eY4gPxt9pDrJDMzSo-nrTh4gFH3ABi08hPnq2HPTt_k,4367
 cwstorm/dsl/node_metaclass.py,sha256=n9wcUklSTL9_RkN9TkwBp677H_zpkI8DrxMA73aV6Xw,8824
-cwstorm/dsl/task.py,sha256=ZhnLWfG_z5tGqRn5CzdAINTHvwXq0p7pVjLFiaP65fI,1909
-cwstorm/dsl/upload.py,sha256=B5VxWzcsBafSWOxHb87pPAoJDjT3Ak0j5jVs6LszUeI,1219
+cwstorm/dsl/task.py,sha256=-UUnFIYllya8nyeJ7eq1NrVB4rscDFL2Izut8Hof3xw,1611
+cwstorm/dsl/upload.py,sha256=YNuIMf_4xZg5GNUk7IanRV1xG9M0lxADw8-KGERAF7Q,1123
 cwstorm/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 cwstorm/examples/ass_comp_heavy.py,sha256=tzwyv100QeoaRrkbB7u4UDuNCO5weD6ugjrWLvaWgWY,149
 cwstorm/examples/ass_comp_light.py,sha256=O-uKkaVoBjOtjeRPFJPBjpjrow220tCQFCVAn2YgcoY,147
 cwstorm/examples/ass_comp_normal.py,sha256=79NveUK-nflhyFRJTaKI7hTcn7-h1yTwC52uXXo_8Lo,148
 cwstorm/examples/ass_export.py,sha256=ZXCY7pRPYtFKb84rfbOF9XpBGz3exLnDFiBCR1vqGAQ,905
 cwstorm/examples/frames.py,sha256=o_SshWfNBcngJHHfNwnys-i3IqRysZUvXr-cVGQ4wlE,760
 cwstorm/examples/one_task.py,sha256=LbiN47G21wasDG4B4cwH_tgk2LYDJL4jnAbh2b1KQJM,176
 cwstorm/examples/simple_qt.py,sha256=JUXvvAhXhLKtEbkpETQV9wMfizpUyPytmbTbJ5ZN7lA,100
 cwstorm/serializers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-cwstorm/serializers/default.py,sha256=LVrwRbr-r1oNz5cRyeBElwZLfWs3chO1YEqhjI9a4hQ,2365
+cwstorm/serializers/default.py,sha256=GUTrOubRQmmWRT-tAYCJRje2mRJKMY56Ao_x3bi5mg8,2552
 tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/test_cmd.py,sha256=0Ck4zCKxmtxJQVA0kdWrN9e53n-2LtZrk0HaSOudw3g,438
 tests/test_dag_node.py,sha256=WYeK0YRrJ3b0rtgoXdhmTHR4Z0NIMl5jRDRCXbSvhrw,4629
-tests/test_deserializer.py,sha256=r1gvYEY3jtNhym7O2W5yRWZR_PR0SNGL8PKama_Aa1Y,4733
+tests/test_deserializer.py,sha256=x6YvXWDnW0SCWgKS77VET8cy0_nKxjQ2c29qVznZoO4,4829
 tests/test_job.py,sha256=exclkTKudgnAAOHkJ5_MuZf-4SIrFqrH1K-MGKwjoIs,664
 tests/test_node.py,sha256=Dp36E9aUChz6XrKcBR4hKvoj7xmwnIP2kiAOCq7OANY,8916
 tests/test_serializers.py,sha256=ibfBNjL0Qpj3LqapBzjIyxeL8Z5gURTzR86N1inAMVY,1774
 tests/test_task.py,sha256=LxcoUsWmoqMTa98s9MIa8piQooi530AaV3Fsi9tF5c0,666
-cwstorm-0.2.0.dist-info/METADATA,sha256=P6sQfLjRcb1rIUzSxNl9WRy2_Bm_GyZ5mKPG25gy2mU,5328
-cwstorm-0.2.0.dist-info/WHEEL,sha256=DZajD4pwLWue70CAfc7YaxT1wLUciNBvN_TTcvXpltE,110
-cwstorm-0.2.0.dist-info/entry_points.txt,sha256=TMHyKhmQ_Zlzoa19R0QhyB-c1qbDKEP5n0Xhchow1Ts,43
-cwstorm-0.2.0.dist-info/top_level.txt,sha256=MnbHmaUJEo7Oos1-P4L7ydVazanb4M0hIVtigvhqHkw,14
-cwstorm-0.2.0.dist-info/RECORD,,
+cwstorm-0.2.0b2.dist-info/METADATA,sha256=xq3tP7uIQGmKI9ziL_FOKC_brkeNPmM5yeq2dd4PyMo,8808
+cwstorm-0.2.0b2.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
+cwstorm-0.2.0b2.dist-info/entry_points.txt,sha256=TMHyKhmQ_Zlzoa19R0QhyB-c1qbDKEP5n0Xhchow1Ts,43
+cwstorm-0.2.0b2.dist-info/top_level.txt,sha256=MnbHmaUJEo7Oos1-P4L7ydVazanb4M0hIVtigvhqHkw,14
+cwstorm-0.2.0b2.dist-info/RECORD,,
```

