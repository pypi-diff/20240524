# Comparing `tmp/laboneq-2.8.0-py3-none-any.whl.zip` & `tmp/laboneq-2.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,313 +1,317 @@
-Zip file size: 1004041 bytes, number of entries: 311
--rw-rw-rw-  2.0 unx        5 b- defN 23-Jun-08 11:42 laboneq/VERSION.txt
--rw-r--r--  2.0 unx      239 b- defN 23-Jun-01 08:47 laboneq/__init__.py
--rw-r--r--  2.0 unx     2829 b- defN 23-Feb-02 07:13 laboneq/_token.py
--rw-r--r--  2.0 unx      928 b- defN 23-Jun-01 08:47 laboneq/_utils.py
--rw-r--r--  2.0 unx      238 b- defN 23-Feb-02 07:13 laboneq/_version.py
--rw-r--r--  2.0 unx     1565 b- defN 23-Jun-01 12:35 laboneq/simple.py
--rw-r--r--  2.0 unx      184 b- defN 23-Feb-02 07:13 laboneq/_observability/__init__.py
--rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/_observability/tracing/__init__.py
--rw-r--r--  2.0 unx      893 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_noop_tracer.py
--rw-r--r--  2.0 unx     2309 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_tracer.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/application_management/__init__.py
--rw-r--r--  2.0 unx     2658 b- defN 23-Jun-01 08:47 laboneq/application_management/application_manager.py
--rw-r--r--  2.0 unx      444 b- defN 23-Feb-02 07:13 laboneq/compiler/__init__.py
--rw-r--r--  2.0 unx      204 b- defN 23-Feb-02 07:13 laboneq/compiler/fastlogging.py
--rw-rw-rw-  2.0 unx    22524 b- defN 23-May-17 00:03 laboneq/compiler/qccs-schema_2_5_0.json
--rw-r--r--  2.0 unx      666 b- defN 23-Feb-02 07:13 laboneq/compiler/remote.py
--rw-r--r--  2.0 unx      654 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/__init__.py
--rw-r--r--  2.0 unx    18669 b- defN 23-Jun-07 10:17 laboneq/compiler/code_generator/analyze_events.py
--rw-r--r--  2.0 unx    26669 b- defN 23-Jun-07 10:17 laboneq/compiler/code_generator/analyze_playback.py
--rw-r--r--  2.0 unx    71964 b- defN 23-Jun-08 11:34 laboneq/compiler/code_generator/code_generator.py
--rw-r--r--  2.0 unx     4026 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/command_table_tracker.py
--rw-r--r--  2.0 unx     2880 b- defN 23-May-17 00:03 laboneq/compiler/code_generator/compressor.py
--rw-r--r--  2.0 unx     1414 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/feedback_register_allocator.py
--rw-r--r--  2.0 unx    10355 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/interval_calculator.py
--rw-r--r--  2.0 unx    17825 b- defN 23-Jun-01 08:47 laboneq/compiler/code_generator/measurement_calculator.py
--rw-r--r--  2.0 unx    30380 b- defN 23-Jun-01 08:47 laboneq/compiler/code_generator/sampled_event_handler.py
--rw-r--r--  2.0 unx    18722 b- defN 23-Jun-01 08:47 laboneq/compiler/code_generator/seq_c_generator.py
--rw-r--r--  2.0 unx     6333 b- defN 23-Jun-01 08:47 laboneq/compiler/code_generator/seqc_tracker.py
--rw-r--r--  2.0 unx    10031 b- defN 23-Jun-01 08:47 laboneq/compiler/code_generator/signatures.py
--rw-r--r--  2.0 unx     3500 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/utils.py
--rw-r--r--  2.0 unx     9102 b- defN 23-Jun-08 08:55 laboneq/compiler/code_generator/wave_compressor.py
--rw-r--r--  2.0 unx     1476 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/wave_index_tracker.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/common/__init__.py
--rw-r--r--  2.0 unx     1093 b- defN 23-Jun-08 11:34 laboneq/compiler/common/awg_info.py
--rw-r--r--  2.0 unx     1926 b- defN 23-Jun-01 08:47 laboneq/compiler/common/awg_sampled_event.py
--rw-r--r--  2.0 unx      480 b- defN 23-Feb-02 07:13 laboneq/compiler/common/awg_signal_type.py
--rw-r--r--  2.0 unx     4015 b- defN 23-Jun-01 08:47 laboneq/compiler/common/compiler_settings.py
--rw-r--r--  2.0 unx     6058 b- defN 23-Jun-01 08:47 laboneq/compiler/common/device_type.py
--rw-r--r--  2.0 unx     1624 b- defN 23-Jun-01 08:47 laboneq/compiler/common/event_type.py
--rw-r--r--  2.0 unx      229 b- defN 23-Mar-07 13:19 laboneq/compiler/common/play_wave_type.py
--rw-r--r--  2.0 unx      580 b- defN 23-May-17 00:03 laboneq/compiler/common/pulse_parameters.py
--rw-r--r--  2.0 unx     2541 b- defN 23-Jun-07 10:17 laboneq/compiler/common/signal_obj.py
--rw-r--r--  2.0 unx      400 b- defN 23-Feb-02 07:13 laboneq/compiler/common/trigger_mode.py
--rw-r--r--  2.0 unx      154 b- defN 23-Feb-02 07:13 laboneq/compiler/experiment_access/__init__.py
--rw-r--r--  2.0 unx      222 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/acquire_info.py
--rw-r--r--  2.0 unx      349 b- defN 23-May-17 00:03 laboneq/compiler/experiment_access/device_info.py
--rw-r--r--  2.0 unx    45124 b- defN 23-Jun-06 11:55 laboneq/compiler/experiment_access/dsl_loader.py
--rw-r--r--  2.0 unx    16726 b- defN 23-Jun-06 11:55 laboneq/compiler/experiment_access/experiment_dao.py
--rw-r--r--  2.0 unx    14122 b- defN 23-Jun-01 12:35 laboneq/compiler/experiment_access/json_dumper.py
--rw-r--r--  2.0 unx    20825 b- defN 23-Jun-06 11:55 laboneq/compiler/experiment_access/json_loader.py
--rw-r--r--  2.0 unx     6256 b- defN 23-Jun-08 11:34 laboneq/compiler/experiment_access/loader_base.py
--rw-r--r--  2.0 unx      270 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/marker.py
--rw-r--r--  2.0 unx      286 b- defN 23-May-17 00:03 laboneq/compiler/experiment_access/oscillator_info.py
--rw-r--r--  2.0 unx      197 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/param_ref.py
--rw-r--r--  2.0 unx     1311 b- defN 23-Jun-01 08:47 laboneq/compiler/experiment_access/pulse_def.py
--rw-r--r--  2.0 unx      817 b- defN 23-Jun-01 12:35 laboneq/compiler/experiment_access/section_info.py
--rw-r--r--  2.0 unx     1069 b- defN 23-May-26 09:40 laboneq/compiler/experiment_access/section_signal_pulse.py
--rw-r--r--  2.0 unx      387 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/signal_info.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/__init__.py
--rw-r--r--  2.0 unx     3265 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/case_schedule.py
--rw-r--r--  2.0 unx     7439 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/interval_schedule.py
--rw-r--r--  2.0 unx     3327 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/loop_iteration_schedule.py
--rw-r--r--  2.0 unx     8576 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/loop_schedule.py
--rw-r--r--  2.0 unx    10468 b- defN 23-Jun-07 10:17 laboneq/compiler/scheduler/match_schedule.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/oscillator_schedule.py
--rw-r--r--  2.0 unx     1761 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/phase_reset_schedule.py
--rw-r--r--  2.0 unx     1808 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/preorder_map.py
--rw-r--r--  2.0 unx     3821 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/pulse_phase.py
--rw-r--r--  2.0 unx     6958 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/pulse_schedule.py
--rw-r--r--  2.0 unx      621 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/reserve_schedule.py
--rw-r--r--  2.0 unx     1367 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/root_schedule.py
--rw-r--r--  2.0 unx     1949 b- defN 23-Jun-03 00:03 laboneq/compiler/scheduler/sampling_rate_tracker.py
--rw-r--r--  2.0 unx     1115 b- defN 23-Jun-03 00:03 laboneq/compiler/scheduler/schedule_data.py
--rw-r--r--  2.0 unx    41072 b- defN 23-Jun-08 11:34 laboneq/compiler/scheduler/scheduler.py
--rw-r--r--  2.0 unx    13191 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/section_schedule.py
--rw-r--r--  2.0 unx      757 b- defN 23-Jun-01 08:47 laboneq/compiler/scheduler/utils.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/workflow/__init__.py
--rw-r--r--  2.0 unx    47515 b- defN 23-Jun-08 11:34 laboneq/compiler/workflow/compiler.py
--rw-r--r--  2.0 unx    12424 b- defN 23-Feb-28 13:10 laboneq/compiler/workflow/precompensation_helpers.py
--rw-r--r--  2.0 unx     6847 b- defN 23-Jun-08 11:34 laboneq/compiler/workflow/realtime_compiler.py
--rw-r--r--  2.0 unx    12441 b- defN 23-Jun-08 11:34 laboneq/compiler/workflow/recipe_generator.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
--rw-r--r--  2.0 unx     4511 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
--rw-r--r--  2.0 unx     3379 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
--rw-r--r--  2.0 unx     2833 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/__init__.py
--rw-r--r--  2.0 unx     6272 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/example_notebook_helper.py
--rw-r--r--  2.0 unx     4116 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/feedback_helper.py
--rw-r--r--  2.0 unx     3581 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/qubit_helper.py
--rw-r--r--  2.0 unx     8830 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/data_analysis/__init__.py
--rw-r--r--  2.0 unx     6670 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/__init__.py
--rw-r--r--  2.0 unx      502 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/hdawg.py
--rw-r--r--  2.0 unx      956 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
--rw-r--r--  2.0 unx     1887 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfqc.py
--rw-r--r--  2.0 unx     1639 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg.py
--rw-r--r--  2.0 unx     2472 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
--rw-r--r--  2.0 unx     2160 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
--rw-r--r--  2.0 unx     2708 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
--rw-r--r--  2.0 unx       77 b- defN 23-May-17 00:03 laboneq/contrib/example_helpers/plotting/__init__.py
--rw-r--r--  2.0 unx    12182 b- defN 23-Jun-01 12:35 laboneq/contrib/example_helpers/plotting/plot_helpers.py
--rw-r--r--  2.0 unx      308 b- defN 23-Feb-13 10:57 laboneq/controller/__init__.py
--rw-r--r--  2.0 unx     3380 b- defN 23-Jun-01 08:47 laboneq/controller/attribute_value_tracker.py
--rw-r--r--  2.0 unx     1479 b- defN 23-Feb-02 07:13 laboneq/controller/cache.py
--rw-r--r--  2.0 unx    13604 b- defN 23-Jun-01 08:47 laboneq/controller/communication.py
--rw-r--r--  2.0 unx    30852 b- defN 23-Jun-08 11:34 laboneq/controller/controller.py
--rw-r--r--  2.0 unx     4892 b- defN 23-Jun-01 08:47 laboneq/controller/laboneq_logging.py
--rw-r--r--  2.0 unx     4671 b- defN 23-Jun-07 10:17 laboneq/controller/near_time_runner.py
--rw-r--r--  2.0 unx      337 b- defN 23-Feb-02 07:13 laboneq/controller/protected_session.py
--rw-r--r--  2.0 unx    12301 b- defN 23-Jun-08 11:34 laboneq/controller/recipe_1_4_0.py
--rw-r--r--  2.0 unx      529 b- defN 23-Jun-07 10:17 laboneq/controller/recipe_enums.py
--rw-r--r--  2.0 unx    21441 b- defN 23-Jun-08 11:34 laboneq/controller/recipe_processor.py
--rw-r--r--  2.0 unx     1902 b- defN 23-Jun-07 10:17 laboneq/controller/results.py
--rw-r--r--  2.0 unx     1594 b- defN 23-Feb-13 10:57 laboneq/controller/toolkit_adapter.py
--rw-r--r--  2.0 unx     1178 b- defN 23-Jun-01 08:47 laboneq/controller/util.py
--rw-r--r--  2.0 unx      281 b- defN 23-Mar-07 07:28 laboneq/controller/versioning.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/controller/devices/__init__.py
--rw-r--r--  2.0 unx    15692 b- defN 23-Jun-06 11:55 laboneq/controller/devices/device_collection.py
--rw-r--r--  2.0 unx     1275 b- defN 23-May-17 00:03 laboneq/controller/devices/device_factory.py
--rw-r--r--  2.0 unx    24400 b- defN 23-Jun-06 11:55 laboneq/controller/devices/device_hdawg.py
--rw-r--r--  2.0 unx      491 b- defN 23-May-22 14:36 laboneq/controller/devices/device_nonqc.py
--rw-r--r--  2.0 unx     7898 b- defN 23-Jun-08 11:34 laboneq/controller/devices/device_pqsc.py
--rw-r--r--  2.0 unx     4441 b- defN 23-Jun-01 08:47 laboneq/controller/devices/device_setup_dao.py
--rw-r--r--  2.0 unx     2064 b- defN 23-Jun-06 11:55 laboneq/controller/devices/device_shf_base.py
--rw-r--r--  2.0 unx     4408 b- defN 23-Jun-01 12:35 laboneq/controller/devices/device_shfppc.py
--rw-r--r--  2.0 unx    41523 b- defN 23-Jun-07 10:17 laboneq/controller/devices/device_shfqa.py
--rw-r--r--  2.0 unx    20499 b- defN 23-Jun-07 10:17 laboneq/controller/devices/device_shfsg.py
--rw-r--r--  2.0 unx    29497 b- defN 23-Jun-06 11:55 laboneq/controller/devices/device_uhfqa.py
--rw-r--r--  2.0 unx    32396 b- defN 23-Jun-07 10:17 laboneq/controller/devices/device_zi.py
--rw-r--r--  2.0 unx    29980 b- defN 23-Jun-06 11:55 laboneq/controller/devices/zi_emulator.py
--rw-r--r--  2.0 unx    10358 b- defN 23-May-24 09:57 laboneq/controller/devices/zi_node_monitor.py
--rw-r--r--  2.0 unx       97 b- defN 23-Feb-02 07:13 laboneq/core/__init__.py
--rw-r--r--  2.0 unx     2015 b- defN 23-May-17 00:03 laboneq/core/path.py
--rw-r--r--  2.0 unx     1338 b- defN 23-Feb-02 07:13 laboneq/core/validators.py
--rw-r--r--  2.0 unx      126 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/__init__.py
--rw-r--r--  2.0 unx      123 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/laboneq_exception.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/serialization/__init__.py
--rw-r--r--  2.0 unx    19090 b- defN 23-May-09 12:50 laboneq/core/serialization/simple_serialization.py
--rw-r--r--  2.0 unx      161 b- defN 23-Feb-02 07:13 laboneq/core/types/__init__.py
--rw-r--r--  2.0 unx     5075 b- defN 23-Jun-07 10:17 laboneq/core/types/compiled_experiment.py
--rw-r--r--  2.0 unx     1473 b- defN 23-Feb-02 07:13 laboneq/core/types/uid.py
--rw-r--r--  2.0 unx      660 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/__init__.py
--rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 16:25 laboneq/core/types/enums/acquisition_type.py
--rw-r--r--  2.0 unx      213 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/averaging_mode.py
--rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/carrier_type.py
--rw-r--r--  2.0 unx      227 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/dsl_version.py
--rw-r--r--  2.0 unx      185 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/execution_type.py
--rw-r--r--  2.0 unx      333 b- defN 23-Jun-01 08:47 laboneq/core/types/enums/high_pass_compensation_clearing.py
--rw-r--r--  2.0 unx      157 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_direction.py
--rw-r--r--  2.0 unx      268 b- defN 23-May-17 00:03 laboneq/core/types/enums/io_signal_type.py
--rw-r--r--  2.0 unx      316 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/mixer_type.py
--rw-r--r--  2.0 unx      200 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/modulation_type.py
--rw-r--r--  2.0 unx      152 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/port_mode.py
--rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/reference_clock_source.py
--rw-r--r--  2.0 unx      198 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/repetition_mode.py
--rw-r--r--  2.0 unx      170 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/section_alignment.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/utilities/__init__.py
--rw-r--r--  2.0 unx     1813 b- defN 23-Jun-01 08:47 laboneq/core/utilities/compressed_formatter.py
--rw-r--r--  2.0 unx     8039 b- defN 23-May-17 00:03 laboneq/core/utilities/pulse_sampler.py
--rw-r--r--  2.0 unx     9873 b- defN 23-Jun-07 10:17 laboneq/core/utilities/replace_pulse.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/data/__init__.py
--rw-r--r--  2.0 unx     3627 b- defN 23-Jun-01 08:47 laboneq/data/data_helper.py
--rw-r--r--  2.0 unx     1738 b- defN 23-Jun-08 11:34 laboneq/data/calibration/__init__.py
--rw-r--r--  2.0 unx     3199 b- defN 23-Jun-01 08:47 laboneq/data/compilation_job/__init__.py
--rw-r--r--  2.0 unx     3887 b- defN 23-Jun-07 10:17 laboneq/data/execution_payload/__init__.py
--rw-r--r--  2.0 unx      842 b- defN 23-Jun-01 08:47 laboneq/data/execution_payload/execution_payload_helper.py
--rw-r--r--  2.0 unx     5188 b- defN 23-Jun-08 11:34 laboneq/data/experiment_description/__init__.py
--rw-r--r--  2.0 unx      583 b- defN 23-Jun-01 08:47 laboneq/data/experiment_description/experiment_helper.py
--rw-r--r--  2.0 unx      950 b- defN 23-Jun-08 11:34 laboneq/data/experiment_results/__init__.py
--rw-r--r--  2.0 unx      761 b- defN 23-Jun-01 08:47 laboneq/data/experiment_schedule/__init__.py
--rw-r--r--  2.0 unx     1782 b- defN 23-Jun-01 08:47 laboneq/data/scheduled_experiment/__init__.py
--rw-r--r--  2.0 unx     3367 b- defN 23-Jun-01 08:47 laboneq/data/setup_description/__init__.py
--rw-r--r--  2.0 unx     2845 b- defN 23-Jun-01 08:47 laboneq/data/setup_description/setup_helper.py
--rw-r--r--  2.0 unx      178 b- defN 23-Jun-06 11:55 laboneq/dsl/__init__.py
--rw-r--r--  2.0 unx     2947 b- defN 23-Jun-01 08:47 laboneq/dsl/laboneq_facade.py
--rw-r--r--  2.0 unx     2552 b- defN 23-Jun-08 11:34 laboneq/dsl/parameter.py
--rw-r--r--  2.0 unx    25670 b- defN 23-Jun-01 13:02 laboneq/dsl/session.py
--rw-r--r--  2.0 unx     2296 b- defN 23-Feb-02 07:13 laboneq/dsl/utils.py
--rw-r--r--  2.0 unx      529 b- defN 23-May-17 00:03 laboneq/dsl/calibration/__init__.py
--rw-r--r--  2.0 unx      946 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/amplifier_pump.py
--rw-r--r--  2.0 unx      545 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibratable.py
--rw-r--r--  2.0 unx     2313 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/calibration.py
--rw-r--r--  2.0 unx      111 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration_item.py
--rw-r--r--  2.0 unx      992 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/mixer_calibration.py
--rw-r--r--  2.0 unx     3403 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/observable.py
--rw-r--r--  2.0 unx     2134 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/oscillator.py
--rw-r--r--  2.0 unx     3140 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/precompensation.py
--rw-r--r--  2.0 unx     5614 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/signal_calibration.py
--rw-r--r--  2.0 unx      553 b- defN 23-Jun-08 11:34 laboneq/dsl/calibration/units.py
--rw-r--r--  2.0 unx      363 b- defN 23-Feb-02 07:13 laboneq/dsl/device/__init__.py
--rw-r--r--  2.0 unx    45826 b- defN 23-May-17 00:03 laboneq/dsl/device/_device_setup_generator.py
--rw-r--r--  2.0 unx      601 b- defN 23-Jun-08 11:34 laboneq/dsl/device/connection.py
--rw-r--r--  2.0 unx    13663 b- defN 23-Jun-08 11:34 laboneq/dsl/device/device_setup.py
--rw-r--r--  2.0 unx     2551 b- defN 23-Apr-06 14:15 laboneq/dsl/device/device_setup_helper.py
--rw-r--r--  2.0 unx     1362 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instrument.py
--rw-r--r--  2.0 unx     1893 b- defN 23-Jun-08 11:34 laboneq/dsl/device/logical_signal_group.py
--rw-r--r--  2.0 unx     1729 b- defN 23-Jun-08 11:34 laboneq/dsl/device/physical_channel_group.py
--rw-r--r--  2.0 unx      538 b- defN 23-Jun-08 11:34 laboneq/dsl/device/ports.py
--rw-r--r--  2.0 unx      215 b- defN 23-Jun-08 11:34 laboneq/dsl/device/server.py
--rw-r--r--  2.0 unx      328 b- defN 23-May-17 00:03 laboneq/dsl/device/instruments/__init__.py
--rw-r--r--  2.0 unx     1778 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/hdawg.py
--rw-r--r--  2.0 unx      466 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/nonqc.py
--rw-r--r--  2.0 unx      948 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/pqsc.py
--rw-r--r--  2.0 unx      927 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/shfppc.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/shfqa.py
--rw-r--r--  2.0 unx     1659 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/shfsg.py
--rw-r--r--  2.0 unx     2312 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/uhfqa.py
--rw-r--r--  2.0 unx      888 b- defN 23-Jun-08 11:34 laboneq/dsl/device/instruments/zi_standard_instrument.py
--rw-r--r--  2.0 unx      187 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/__init__.py
--rw-r--r--  2.0 unx    12750 b- defN 23-Jun-08 11:34 laboneq/dsl/device/io_units/logical_signal.py
--rw-r--r--  2.0 unx     3828 b- defN 23-Jun-08 11:34 laboneq/dsl/device/io_units/physical_channel.py
--rw-r--r--  2.0 unx      114 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/__init__.py
--rw-r--r--  2.0 unx      704 b- defN 23-Jun-08 11:34 laboneq/dsl/device/servers/data_server.py
--rw-r--r--  2.0 unx      718 b- defN 23-Feb-02 07:13 laboneq/dsl/enums/__init__.py
--rw-r--r--  2.0 unx      508 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/__init__.py
--rw-r--r--  2.0 unx      972 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/acquire.py
--rw-r--r--  2.0 unx      814 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/call.py
--rw-r--r--  2.0 unx      780 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/delay.py
--rw-r--r--  2.0 unx    40011 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/experiment.py
--rw-r--r--  2.0 unx     8216 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/experiment_signal.py
--rw-r--r--  2.0 unx      401 b- defN 23-Jun-08 08:19 laboneq/dsl/experiment/operation.py
--rw-r--r--  2.0 unx     1647 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/play_pulse.py
--rw-r--r--  2.0 unx     3953 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/pulse.py
--rw-r--r--  2.0 unx     8194 b- defN 23-Jun-01 08:47 laboneq/dsl/experiment/pulse_library.py
--rw-r--r--  2.0 unx      890 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/reserve.py
--rw-r--r--  2.0 unx    11431 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/section.py
--rw-r--r--  2.0 unx      640 b- defN 23-Jun-08 11:34 laboneq/dsl/experiment/set.py
--rw-r--r--  2.0 unx      323 b- defN 23-May-26 09:40 laboneq/dsl/experiment/utils.py
--rw-r--r--  2.0 unx      224 b- defN 23-Jun-01 08:47 laboneq/dsl/quantum/__init__.py
--rw-r--r--  2.0 unx     3423 b- defN 23-Jun-08 08:19 laboneq/dsl/quantum/quantum_operations.py
--rw-r--r--  2.0 unx    10892 b- defN 23-Jun-08 11:34 laboneq/dsl/quantum/qubits.py
--rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 15:16 laboneq/dsl/result/__init__.py
--rw-r--r--  2.0 unx     1766 b- defN 23-Jun-08 11:34 laboneq/dsl/result/acquired_result.py
--rw-r--r--  2.0 unx     7189 b- defN 23-Jun-08 11:34 laboneq/dsl/result/results.py
--rw-r--r--  2.0 unx      113 b- defN 23-Feb-02 07:13 laboneq/dsl/serialization/__init__.py
--rw-r--r--  2.0 unx     5394 b- defN 23-Jun-01 08:47 laboneq/dsl/serialization/serializer.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/executor/__init__.py
--rw-r--r--  2.0 unx     3819 b- defN 23-Feb-16 12:45 laboneq/executor/execution_from_experiment.py
--rw-r--r--  2.0 unx     8152 b- defN 23-Jun-08 11:34 laboneq/executor/executor.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/compilation_service/__init__.py
--rw-r--r--  2.0 unx     1156 b- defN 23-Jun-01 08:47 laboneq/implementation/compilation_service/compilation_service.py
--rw-r--r--  2.0 unx     7894 b- defN 23-Jun-01 08:47 laboneq/implementation/compilation_service/compilation_service_legacy.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/data_storage/__init__.py
--rw-r--r--  2.0 unx      916 b- defN 23-Jun-01 13:41 laboneq/implementation/data_storage/l1q_database_wrapper.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/data_storage_service/__init__.py
--rw-r--r--  2.0 unx     6103 b- defN 23-Jun-01 08:47 laboneq/implementation/data_storage_service/data_storage_service_sqlite_dict.py
--rw-r--r--  2.0 unx      130 b- defN 23-Jun-01 08:47 laboneq/implementation/experiment_workflow/__init__.py
--rw-r--r--  2.0 unx    16908 b- defN 23-Jun-01 08:47 laboneq/implementation/experiment_workflow/device_setup_generator.py
--rw-r--r--  2.0 unx     6106 b- defN 23-Jun-01 08:47 laboneq/implementation/experiment_workflow/experiment_workflow.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/legacy_adapters/__init__.py
--rw-r--r--  2.0 unx     3084 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/dynamic_converter.py
--rw-r--r--  2.0 unx      950 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/simple2.py
--rw-r--r--  2.0 unx     7740 b- defN 23-Jun-08 11:34 laboneq/implementation/legacy_adapters/converters_calibration/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/converters_calibration/post_process_calibration.py
--rw-r--r--  2.0 unx    22847 b- defN 23-Jun-08 11:34 laboneq/implementation/legacy_adapters/converters_experiment_description/__init__.py
--rw-r--r--  2.0 unx     1659 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/converters_experiment_description/post_process_experiment_description.py
--rw-r--r--  2.0 unx     1741 b- defN 23-Jun-08 11:34 laboneq/implementation/legacy_adapters/converters_experiment_results/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/converters_experiment_results/post_process_experiment_results.py
--rw-r--r--  2.0 unx     4376 b- defN 23-Jun-08 11:34 laboneq/implementation/legacy_adapters/converters_scheduled_experiment/__init__.py
--rw-r--r--  2.0 unx      131 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/converters_scheduled_experiment/post_process_scheduled_experiment.py
--rw-r--r--  2.0 unx    13804 b- defN 23-Jun-08 11:34 laboneq/implementation/legacy_adapters/converters_setup_description/__init__.py
--rw-r--r--  2.0 unx     5165 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/converters_setup_description/post_process_setup_description.py
--rw-r--r--  2.0 unx     9204 b- defN 23-Jun-01 08:47 laboneq/implementation/legacy_adapters/legacy_dsl_adapters/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/implementation/payload_builder/__init__.py
--rw-r--r--  2.0 unx    25577 b- defN 23-Jun-07 10:17 laboneq/implementation/payload_builder/payload_builder.py
--rw-r--r--  2.0 unx      105 b- defN 23-Jun-01 08:47 laboneq/implementation/runner/__init__.py
--rw-r--r--  2.0 unx     2293 b- defN 23-Jun-01 08:47 laboneq/implementation/runner/runner.py
--rw-r--r--  2.0 unx    14574 b- defN 23-Jun-07 10:17 laboneq/implementation/runner/runner_legacy.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/interfaces/__init__.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/interfaces/application_management/__init__.py
--rw-r--r--  2.0 unx      384 b- defN 23-Jun-01 08:47 laboneq/interfaces/application_management/laboneq_settings.py
--rw-r--r--  2.0 unx      137 b- defN 23-Jun-01 08:47 laboneq/interfaces/compilation_service/__init__.py
--rw-r--r--  2.0 unx      779 b- defN 23-Jun-01 08:47 laboneq/interfaces/compilation_service/compilation_service_api.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/interfaces/data_storage/__init__.py
--rw-r--r--  2.0 unx     2272 b- defN 23-Jun-01 08:47 laboneq/interfaces/data_storage/data_storage_api.py
--rw-r--r--  2.0 unx      120 b- defN 23-Jun-01 08:47 laboneq/interfaces/experiment/__init__.py
--rw-r--r--  2.0 unx     2004 b- defN 23-Jun-01 08:47 laboneq/interfaces/experiment/experiment_api.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/interfaces/payload_builder/__init__.py
--rw-r--r--  2.0 unx      892 b- defN 23-Jun-01 08:47 laboneq/interfaces/payload_builder/payload_builder_api.py
--rw-r--r--  2.0 unx       77 b- defN 23-Jun-07 10:17 laboneq/interfaces/runner/__init__.py
--rw-r--r--  2.0 unx      766 b- defN 23-Jun-01 08:47 laboneq/interfaces/runner/runner_api.py
--rw-r--r--  2.0 unx      793 b- defN 23-Jun-01 08:47 laboneq/interfaces/runner/runner_control_api.py
--rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 15:16 laboneq/openqasm3/__init__.py
--rw-r--r--  2.0 unx     8903 b- defN 23-Jun-01 08:47 laboneq/openqasm3/expression.py
--rw-r--r--  2.0 unx     1671 b- defN 23-Jun-05 13:15 laboneq/openqasm3/gate_store.py
--rw-r--r--  2.0 unx     2593 b- defN 23-Jun-01 08:47 laboneq/openqasm3/namespace.py
--rw-r--r--  2.0 unx    15459 b- defN 23-Jun-05 13:15 laboneq/openqasm3/openqasm3_importer.py
--rw-r--r--  2.0 unx     1732 b- defN 23-May-17 00:03 laboneq/openqasm3/openqasm_error.py
--rw-r--r--  2.0 unx     4850 b- defN 23-Jun-01 08:47 laboneq/openqasm3/reset_gate_factory.py
--rw-r--r--  2.0 unx     1517 b- defN 23-Jun-01 08:47 laboneq/openqasm3/signal_store.py
--rw-r--r--  2.0 unx      127 b- defN 23-Feb-02 07:13 laboneq/pulse_sheet_viewer/__init__.py
--rw-r--r--  2.0 unx     2059 b- defN 23-Feb-16 12:45 laboneq/pulse_sheet_viewer/event_graph_viewer.py
--rw-r--r--  2.0 unx     2692 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/interactive_psv.py
--rw-r--r--  2.0 unx     3288 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
--rw-rw-rw-  2.0 unx  1443040 b- defN 23-May-17 00:03 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
--rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 15:16 laboneq/simulator/__init__.py
--rw-r--r--  2.0 unx     6090 b- defN 23-Jun-08 11:34 laboneq/simulator/output_simulator.py
--rw-r--r--  2.0 unx    41644 b- defN 23-Jun-08 11:34 laboneq/simulator/seqc_parser.py
--rw-r--r--  2.0 unx    17091 b- defN 23-Jun-06 11:55 laboneq/simulator/wave_scroller.py
--rw-rw-rw-  2.0 unx       22 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/AUTHORS
--rw-rw-rw-  2.0 unx    11358 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3255 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    31232 b- defN 23-Jun-08 11:43 laboneq-2.8.0.dist-info/RECORD
-311 files, 3091552 bytes uncompressed, 953027 bytes compressed:  69.2%
+Zip file size: 1012998 bytes, number of entries: 315
+-rw-rw-rw-  2.0 unx        5 b- defN 23-Jun-27 07:54 laboneq/VERSION.txt
+-rw-r--r--  2.0 unx      239 b- defN 23-Jun-14 11:42 laboneq/__init__.py
+-rw-r--r--  2.0 unx      457 b- defN 23-Jun-26 11:54 laboneq/_token.py
+-rw-r--r--  2.0 unx      928 b- defN 23-Jun-16 19:26 laboneq/_utils.py
+-rw-r--r--  2.0 unx      238 b- defN 23-Jun-14 11:42 laboneq/_version.py
+-rw-r--r--  2.0 unx     1628 b- defN 23-Jun-27 00:03 laboneq/simple.py
+-rw-r--r--  2.0 unx      184 b- defN 23-Jun-14 11:42 laboneq/_observability/__init__.py
+-rw-r--r--  2.0 unx      538 b- defN 23-Jun-14 11:42 laboneq/_observability/tracing/__init__.py
+-rw-r--r--  2.0 unx      893 b- defN 23-Jun-14 11:42 laboneq/_observability/tracing/_noop_tracer.py
+-rw-r--r--  2.0 unx     2309 b- defN 23-Jun-14 11:42 laboneq/_observability/tracing/_tracer.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/application_management/__init__.py
+-rw-r--r--  2.0 unx     2658 b- defN 23-Jun-14 11:42 laboneq/application_management/application_manager.py
+-rw-r--r--  2.0 unx      444 b- defN 23-Jun-14 11:42 laboneq/compiler/__init__.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-14 11:42 laboneq/compiler/fastlogging.py
+-rw-rw-rw-  2.0 unx    22524 b- defN 23-Jun-16 19:26 laboneq/compiler/qccs-schema_2_5_0.json
+-rw-r--r--  2.0 unx      666 b- defN 23-Jun-14 11:42 laboneq/compiler/remote.py
+-rw-r--r--  2.0 unx      654 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/__init__.py
+-rw-r--r--  2.0 unx    18669 b- defN 23-Jun-27 07:19 laboneq/compiler/code_generator/analyze_events.py
+-rw-r--r--  2.0 unx    26669 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/analyze_playback.py
+-rw-r--r--  2.0 unx    72969 b- defN 23-Jun-20 07:59 laboneq/compiler/code_generator/code_generator.py
+-rw-r--r--  2.0 unx     4026 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/command_table_tracker.py
+-rw-r--r--  2.0 unx     2880 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/compressor.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/feedback_register_allocator.py
+-rw-r--r--  2.0 unx    10355 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/interval_calculator.py
+-rw-r--r--  2.0 unx    18174 b- defN 23-Jun-19 07:46 laboneq/compiler/code_generator/measurement_calculator.py
+-rw-r--r--  2.0 unx    30752 b- defN 23-Jun-27 07:19 laboneq/compiler/code_generator/sampled_event_handler.py
+-rw-r--r--  2.0 unx    18722 b- defN 23-Jun-27 07:19 laboneq/compiler/code_generator/seq_c_generator.py
+-rw-r--r--  2.0 unx     6333 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/seqc_tracker.py
+-rw-r--r--  2.0 unx    10031 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/signatures.py
+-rw-r--r--  2.0 unx     3500 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/utils.py
+-rw-r--r--  2.0 unx     9102 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/wave_compressor.py
+-rw-r--r--  2.0 unx     1476 b- defN 23-Jun-14 11:42 laboneq/compiler/code_generator/wave_index_tracker.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/compiler/common/__init__.py
+-rw-r--r--  2.0 unx     1079 b- defN 23-Jun-14 11:42 laboneq/compiler/common/awg_info.py
+-rw-r--r--  2.0 unx     1926 b- defN 23-Jun-14 11:42 laboneq/compiler/common/awg_sampled_event.py
+-rw-r--r--  2.0 unx      480 b- defN 23-Jun-14 11:42 laboneq/compiler/common/awg_signal_type.py
+-rw-r--r--  2.0 unx     4015 b- defN 23-Jun-14 11:42 laboneq/compiler/common/compiler_settings.py
+-rw-r--r--  2.0 unx     6058 b- defN 23-Jun-14 11:42 laboneq/compiler/common/device_type.py
+-rw-r--r--  2.0 unx     1624 b- defN 23-Jun-14 11:42 laboneq/compiler/common/event_type.py
+-rw-r--r--  2.0 unx      229 b- defN 23-Jun-14 11:42 laboneq/compiler/common/play_wave_type.py
+-rw-r--r--  2.0 unx      580 b- defN 23-Jun-14 11:42 laboneq/compiler/common/pulse_parameters.py
+-rw-r--r--  2.0 unx     2541 b- defN 23-Jun-14 11:42 laboneq/compiler/common/signal_obj.py
+-rw-r--r--  2.0 unx      400 b- defN 23-Jun-14 11:42 laboneq/compiler/common/trigger_mode.py
+-rw-r--r--  2.0 unx      154 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/__init__.py
+-rw-r--r--  2.0 unx      222 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/acquire_info.py
+-rw-r--r--  2.0 unx      349 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/device_info.py
+-rw-r--r--  2.0 unx    45626 b- defN 23-Jun-27 00:03 laboneq/compiler/experiment_access/dsl_loader.py
+-rw-r--r--  2.0 unx    16726 b- defN 23-Jun-27 07:54 laboneq/compiler/experiment_access/experiment_dao.py
+-rw-r--r--  2.0 unx    14122 b- defN 23-Jun-16 19:26 laboneq/compiler/experiment_access/json_dumper.py
+-rw-r--r--  2.0 unx    20860 b- defN 23-Jun-19 06:30 laboneq/compiler/experiment_access/json_loader.py
+-rw-r--r--  2.0 unx     6253 b- defN 23-Jun-16 19:26 laboneq/compiler/experiment_access/loader_base.py
+-rw-r--r--  2.0 unx      270 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/marker.py
+-rw-r--r--  2.0 unx      286 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/oscillator_info.py
+-rw-r--r--  2.0 unx      197 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/param_ref.py
+-rw-r--r--  2.0 unx     1311 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/pulse_def.py
+-rw-r--r--  2.0 unx      838 b- defN 23-Jun-19 06:30 laboneq/compiler/experiment_access/section_info.py
+-rw-r--r--  2.0 unx     1069 b- defN 23-Jun-16 19:26 laboneq/compiler/experiment_access/section_signal_pulse.py
+-rw-r--r--  2.0 unx      387 b- defN 23-Jun-14 11:42 laboneq/compiler/experiment_access/signal_info.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/__init__.py
+-rw-r--r--  2.0 unx     3265 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/case_schedule.py
+-rw-r--r--  2.0 unx     7439 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/interval_schedule.py
+-rw-r--r--  2.0 unx     3327 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/loop_iteration_schedule.py
+-rw-r--r--  2.0 unx     8576 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/loop_schedule.py
+-rw-r--r--  2.0 unx    11090 b- defN 23-Jun-20 07:59 laboneq/compiler/scheduler/match_schedule.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/oscillator_schedule.py
+-rw-r--r--  2.0 unx     2574 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/parameter_store.py
+-rw-r--r--  2.0 unx     1761 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/phase_reset_schedule.py
+-rw-r--r--  2.0 unx     1808 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/preorder_map.py
+-rw-r--r--  2.0 unx     3821 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/pulse_phase.py
+-rw-r--r--  2.0 unx     6958 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/pulse_schedule.py
+-rw-r--r--  2.0 unx      621 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/reserve_schedule.py
+-rw-r--r--  2.0 unx     1367 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/root_schedule.py
+-rw-r--r--  2.0 unx     1949 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/sampling_rate_tracker.py
+-rw-r--r--  2.0 unx     1115 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/schedule_data.py
+-rw-r--r--  2.0 unx    41574 b- defN 23-Jun-19 06:30 laboneq/compiler/scheduler/scheduler.py
+-rw-r--r--  2.0 unx    13191 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/section_schedule.py
+-rw-r--r--  2.0 unx      757 b- defN 23-Jun-14 11:42 laboneq/compiler/scheduler/utils.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/compiler/workflow/__init__.py
+-rw-r--r--  2.0 unx    49079 b- defN 23-Jun-19 07:46 laboneq/compiler/workflow/compiler.py
+-rw-r--r--  2.0 unx     5657 b- defN 23-Jun-20 12:26 laboneq/compiler/workflow/neartime_execution.py
+-rw-r--r--  2.0 unx    12424 b- defN 23-Jun-14 11:42 laboneq/compiler/workflow/precompensation_helpers.py
+-rw-r--r--  2.0 unx     6979 b- defN 23-Jun-14 11:42 laboneq/compiler/workflow/realtime_compiler.py
+-rw-r--r--  2.0 unx    13073 b- defN 23-Jun-19 06:30 laboneq/compiler/workflow/recipe_generator.py
+-rw-r--r--  2.0 unx     7061 b- defN 23-Jun-20 12:26 laboneq/compiler/workflow/rt_linker.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
+-rw-r--r--  2.0 unx     4511 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
+-rw-r--r--  2.0 unx     3379 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
+-rw-r--r--  2.0 unx     2833 b- defN 23-Jun-14 11:42 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/__init__.py
+-rw-r--r--  2.0 unx     6272 b- defN 23-Jun-27 07:31 laboneq/contrib/example_helpers/example_notebook_helper.py
+-rw-r--r--  2.0 unx     4112 b- defN 23-Jun-19 06:30 laboneq/contrib/example_helpers/feedback_helper.py
+-rw-r--r--  2.0 unx     3581 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/qubit_helper.py
+-rw-r--r--  2.0 unx     8830 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/data_analysis/__init__.py
+-rw-r--r--  2.0 unx     6670 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/__init__.py
+-rw-r--r--  2.0 unx      502 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/hdawg.py
+-rw-r--r--  2.0 unx      956 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
+-rw-r--r--  2.0 unx     1887 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/shfqc.py
+-rw-r--r--  2.0 unx     1639 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/shfsg.py
+-rw-r--r--  2.0 unx     2472 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
+-rw-r--r--  2.0 unx     2160 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
+-rw-r--r--  2.0 unx     2708 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/plotting/__init__.py
+-rw-r--r--  2.0 unx    12182 b- defN 23-Jun-14 11:42 laboneq/contrib/example_helpers/plotting/plot_helpers.py
+-rw-r--r--  2.0 unx      308 b- defN 23-Jun-14 11:42 laboneq/controller/__init__.py
+-rw-r--r--  2.0 unx     3380 b- defN 23-Jun-14 11:42 laboneq/controller/attribute_value_tracker.py
+-rw-r--r--  2.0 unx     1479 b- defN 23-Jun-14 11:42 laboneq/controller/cache.py
+-rw-r--r--  2.0 unx    13484 b- defN 23-Jun-26 11:54 laboneq/controller/communication.py
+-rw-r--r--  2.0 unx    30444 b- defN 23-Jun-20 12:26 laboneq/controller/controller.py
+-rw-r--r--  2.0 unx     4892 b- defN 23-Jun-14 11:42 laboneq/controller/laboneq_logging.py
+-rw-r--r--  2.0 unx     4472 b- defN 23-Jun-20 12:26 laboneq/controller/near_time_runner.py
+-rw-r--r--  2.0 unx      337 b- defN 23-Jun-14 11:42 laboneq/controller/protected_session.py
+-rw-r--r--  2.0 unx    13105 b- defN 23-Jun-19 06:30 laboneq/controller/recipe_1_4_0.py
+-rw-r--r--  2.0 unx      776 b- defN 23-Jun-19 07:46 laboneq/controller/recipe_enums.py
+-rw-r--r--  2.0 unx    21227 b- defN 23-Jun-20 12:26 laboneq/controller/recipe_processor.py
+-rw-r--r--  2.0 unx     1902 b- defN 23-Jun-14 11:42 laboneq/controller/results.py
+-rw-r--r--  2.0 unx     1594 b- defN 23-Jun-14 11:42 laboneq/controller/toolkit_adapter.py
+-rw-r--r--  2.0 unx     1178 b- defN 23-Jun-14 11:42 laboneq/controller/util.py
+-rw-r--r--  2.0 unx      281 b- defN 23-Jun-14 11:42 laboneq/controller/versioning.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/controller/devices/__init__.py
+-rw-r--r--  2.0 unx    15911 b- defN 23-Jun-20 07:59 laboneq/controller/devices/device_collection.py
+-rw-r--r--  2.0 unx     1275 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_factory.py
+-rw-r--r--  2.0 unx    24400 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_hdawg.py
+-rw-r--r--  2.0 unx      491 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_nonqc.py
+-rw-r--r--  2.0 unx     7901 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_pqsc.py
+-rw-r--r--  2.0 unx     4441 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_setup_dao.py
+-rw-r--r--  2.0 unx     2064 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_shf_base.py
+-rw-r--r--  2.0 unx     4408 b- defN 23-Jun-14 11:42 laboneq/controller/devices/device_shfppc.py
+-rw-r--r--  2.0 unx    42675 b- defN 23-Jun-20 07:59 laboneq/controller/devices/device_shfqa.py
+-rw-r--r--  2.0 unx    20499 b- defN 23-Jun-20 12:26 laboneq/controller/devices/device_shfsg.py
+-rw-r--r--  2.0 unx    29590 b- defN 23-Jun-19 07:46 laboneq/controller/devices/device_uhfqa.py
+-rw-r--r--  2.0 unx    32470 b- defN 23-Jun-20 12:26 laboneq/controller/devices/device_zi.py
+-rw-r--r--  2.0 unx    29980 b- defN 23-Jun-20 12:26 laboneq/controller/devices/zi_emulator.py
+-rw-r--r--  2.0 unx    10358 b- defN 23-Jun-20 12:26 laboneq/controller/devices/zi_node_monitor.py
+-rw-r--r--  2.0 unx       97 b- defN 23-Jun-14 11:42 laboneq/core/__init__.py
+-rw-r--r--  2.0 unx     2015 b- defN 23-Jun-14 11:42 laboneq/core/path.py
+-rw-r--r--  2.0 unx     1338 b- defN 23-Jun-14 11:42 laboneq/core/validators.py
+-rw-r--r--  2.0 unx      126 b- defN 23-Jun-14 11:42 laboneq/core/exceptions/__init__.py
+-rw-r--r--  2.0 unx      123 b- defN 23-Jun-14 11:42 laboneq/core/exceptions/laboneq_exception.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/core/serialization/__init__.py
+-rw-r--r--  2.0 unx    19090 b- defN 23-Jun-14 11:42 laboneq/core/serialization/simple_serialization.py
+-rw-r--r--  2.0 unx      161 b- defN 23-Jun-14 11:42 laboneq/core/types/__init__.py
+-rw-r--r--  2.0 unx     5075 b- defN 23-Jun-15 09:11 laboneq/core/types/compiled_experiment.py
+-rw-r--r--  2.0 unx     1473 b- defN 23-Jun-14 11:42 laboneq/core/types/uid.py
+-rw-r--r--  2.0 unx      660 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/__init__.py
+-rw-r--r--  2.0 unx     1579 b- defN 23-Jun-19 07:46 laboneq/core/types/enums/acquisition_type.py
+-rw-r--r--  2.0 unx      213 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/averaging_mode.py
+-rw-r--r--  2.0 unx      188 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/carrier_type.py
+-rw-r--r--  2.0 unx      227 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/dsl_version.py
+-rw-r--r--  2.0 unx      185 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/execution_type.py
+-rw-r--r--  2.0 unx      333 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/high_pass_compensation_clearing.py
+-rw-r--r--  2.0 unx      157 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/io_direction.py
+-rw-r--r--  2.0 unx      268 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/io_signal_type.py
+-rw-r--r--  2.0 unx      316 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/mixer_type.py
+-rw-r--r--  2.0 unx      200 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/modulation_type.py
+-rw-r--r--  2.0 unx      152 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/port_mode.py
+-rw-r--r--  2.0 unx      188 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/reference_clock_source.py
+-rw-r--r--  2.0 unx      198 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/repetition_mode.py
+-rw-r--r--  2.0 unx      170 b- defN 23-Jun-14 11:42 laboneq/core/types/enums/section_alignment.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/core/utilities/__init__.py
+-rw-r--r--  2.0 unx     1813 b- defN 23-Jun-14 11:42 laboneq/core/utilities/compressed_formatter.py
+-rw-r--r--  2.0 unx     8039 b- defN 23-Jun-14 11:42 laboneq/core/utilities/pulse_sampler.py
+-rw-r--r--  2.0 unx     9873 b- defN 23-Jun-14 11:42 laboneq/core/utilities/replace_pulse.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/data/__init__.py
+-rw-r--r--  2.0 unx     3627 b- defN 23-Jun-14 11:42 laboneq/data/data_helper.py
+-rw-r--r--  2.0 unx     1748 b- defN 23-Jun-14 11:42 laboneq/data/calibration/__init__.py
+-rw-r--r--  2.0 unx     3227 b- defN 23-Jun-19 06:30 laboneq/data/compilation_job/__init__.py
+-rw-r--r--  2.0 unx     3887 b- defN 23-Jun-14 11:42 laboneq/data/execution_payload/__init__.py
+-rw-r--r--  2.0 unx      842 b- defN 23-Jun-14 11:42 laboneq/data/execution_payload/execution_payload_helper.py
+-rw-r--r--  2.0 unx     5198 b- defN 23-Jun-16 19:26 laboneq/data/experiment_description/__init__.py
+-rw-r--r--  2.0 unx      583 b- defN 23-Jun-14 11:42 laboneq/data/experiment_description/experiment_helper.py
+-rw-r--r--  2.0 unx      909 b- defN 23-Jun-14 11:42 laboneq/data/experiment_results/__init__.py
+-rw-r--r--  2.0 unx      761 b- defN 23-Jun-14 11:42 laboneq/data/experiment_schedule/__init__.py
+-rw-r--r--  2.0 unx     1782 b- defN 23-Jun-14 11:42 laboneq/data/scheduled_experiment/__init__.py
+-rw-r--r--  2.0 unx     3367 b- defN 23-Jun-14 11:42 laboneq/data/setup_description/__init__.py
+-rw-r--r--  2.0 unx     2845 b- defN 23-Jun-14 11:42 laboneq/data/setup_description/setup_helper.py
+-rw-r--r--  2.0 unx      220 b- defN 23-Jun-19 06:30 laboneq/dsl/__init__.py
+-rw-r--r--  2.0 unx     1965 b- defN 23-Jun-19 06:30 laboneq/dsl/_inspect.py
+-rw-r--r--  2.0 unx      844 b- defN 23-Jun-19 06:30 laboneq/dsl/dsl_dataclass_decorator.py
+-rw-r--r--  2.0 unx     2947 b- defN 23-Jun-14 11:42 laboneq/dsl/laboneq_facade.py
+-rw-r--r--  2.0 unx     2989 b- defN 23-Jun-27 00:03 laboneq/dsl/parameter.py
+-rw-r--r--  2.0 unx    25670 b- defN 23-Jun-14 11:42 laboneq/dsl/session.py
+-rw-r--r--  2.0 unx     2296 b- defN 23-Jun-14 11:42 laboneq/dsl/utils.py
+-rw-r--r--  2.0 unx      529 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/__init__.py
+-rw-r--r--  2.0 unx     1025 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/amplifier_pump.py
+-rw-r--r--  2.0 unx      545 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/calibratable.py
+-rw-r--r--  2.0 unx     2392 b- defN 23-Jun-26 09:05 laboneq/dsl/calibration/calibration.py
+-rw-r--r--  2.0 unx      111 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/calibration_item.py
+-rw-r--r--  2.0 unx     1071 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/mixer_calibration.py
+-rw-r--r--  2.0 unx     3403 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/observable.py
+-rw-r--r--  2.0 unx     2213 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/oscillator.py
+-rw-r--r--  2.0 unx     3283 b- defN 23-Jun-16 19:26 laboneq/dsl/calibration/precompensation.py
+-rw-r--r--  2.0 unx     5693 b- defN 23-Jun-16 19:26 laboneq/dsl/calibration/signal_calibration.py
+-rw-r--r--  2.0 unx      633 b- defN 23-Jun-14 11:42 laboneq/dsl/calibration/units.py
+-rw-r--r--  2.0 unx      363 b- defN 23-Jun-14 11:42 laboneq/dsl/device/__init__.py
+-rw-r--r--  2.0 unx    45826 b- defN 23-Jun-14 11:42 laboneq/dsl/device/_device_setup_generator.py
+-rw-r--r--  2.0 unx      680 b- defN 23-Jun-14 11:42 laboneq/dsl/device/connection.py
+-rw-r--r--  2.0 unx    13732 b- defN 23-Jun-14 11:42 laboneq/dsl/device/device_setup.py
+-rw-r--r--  2.0 unx     2551 b- defN 23-Jun-14 11:42 laboneq/dsl/device/device_setup_helper.py
+-rw-r--r--  2.0 unx     1431 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instrument.py
+-rw-r--r--  2.0 unx     1962 b- defN 23-Jun-14 11:42 laboneq/dsl/device/logical_signal_group.py
+-rw-r--r--  2.0 unx     1808 b- defN 23-Jun-14 11:42 laboneq/dsl/device/physical_channel_group.py
+-rw-r--r--  2.0 unx      617 b- defN 23-Jun-14 11:42 laboneq/dsl/device/ports.py
+-rw-r--r--  2.0 unx      295 b- defN 23-Jun-14 11:42 laboneq/dsl/device/server.py
+-rw-r--r--  2.0 unx      328 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/__init__.py
+-rw-r--r--  2.0 unx     1848 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/hdawg.py
+-rw-r--r--  2.0 unx      536 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/nonqc.py
+-rw-r--r--  2.0 unx     1018 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/pqsc.py
+-rw-r--r--  2.0 unx      997 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/shfppc.py
+-rw-r--r--  2.0 unx     2318 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/shfqa.py
+-rw-r--r--  2.0 unx     1729 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/shfsg.py
+-rw-r--r--  2.0 unx     2382 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/uhfqa.py
+-rw-r--r--  2.0 unx      958 b- defN 23-Jun-14 11:42 laboneq/dsl/device/instruments/zi_standard_instrument.py
+-rw-r--r--  2.0 unx      187 b- defN 23-Jun-14 11:42 laboneq/dsl/device/io_units/__init__.py
+-rw-r--r--  2.0 unx    12952 b- defN 23-Jun-16 19:26 laboneq/dsl/device/io_units/logical_signal.py
+-rw-r--r--  2.0 unx     4095 b- defN 23-Jun-14 11:42 laboneq/dsl/device/io_units/physical_channel.py
+-rw-r--r--  2.0 unx      114 b- defN 23-Jun-14 11:42 laboneq/dsl/device/servers/__init__.py
+-rw-r--r--  2.0 unx      774 b- defN 23-Jun-14 11:42 laboneq/dsl/device/servers/data_server.py
+-rw-r--r--  2.0 unx      718 b- defN 23-Jun-14 11:42 laboneq/dsl/enums/__init__.py
+-rw-r--r--  2.0 unx      508 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/__init__.py
+-rw-r--r--  2.0 unx     1041 b- defN 23-Jun-16 19:26 laboneq/dsl/experiment/acquire.py
+-rw-r--r--  2.0 unx      883 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/call.py
+-rw-r--r--  2.0 unx      859 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/delay.py
+-rw-r--r--  2.0 unx    40479 b- defN 23-Jun-27 00:03 laboneq/dsl/experiment/experiment.py
+-rw-r--r--  2.0 unx     8295 b- defN 23-Jun-16 19:26 laboneq/dsl/experiment/experiment_signal.py
+-rw-r--r--  2.0 unx      401 b- defN 23-Jun-15 11:43 laboneq/dsl/experiment/operation.py
+-rw-r--r--  2.0 unx     1716 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/play_pulse.py
+-rw-r--r--  2.0 unx     4064 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/pulse.py
+-rw-r--r--  2.0 unx     8194 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/pulse_library.py
+-rw-r--r--  2.0 unx      959 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/reserve.py
+-rw-r--r--  2.0 unx    11673 b- defN 23-Jun-19 06:30 laboneq/dsl/experiment/section.py
+-rw-r--r--  2.0 unx      709 b- defN 23-Jun-14 11:42 laboneq/dsl/experiment/set.py
+-rw-r--r--  2.0 unx      323 b- defN 23-Jun-16 19:26 laboneq/dsl/experiment/utils.py
+-rw-r--r--  2.0 unx      224 b- defN 23-Jun-14 11:42 laboneq/dsl/quantum/__init__.py
+-rw-r--r--  2.0 unx     3423 b- defN 23-Jun-15 11:43 laboneq/dsl/quantum/quantum_operations.py
+-rw-r--r--  2.0 unx    11423 b- defN 23-Jun-27 07:31 laboneq/dsl/quantum/qubits.py
+-rw-r--r--  2.0 unx      151 b- defN 23-Jun-14 11:42 laboneq/dsl/result/__init__.py
+-rw-r--r--  2.0 unx     1846 b- defN 23-Jun-14 11:42 laboneq/dsl/result/acquired_result.py
+-rw-r--r--  2.0 unx     7258 b- defN 23-Jun-14 11:42 laboneq/dsl/result/results.py
+-rw-r--r--  2.0 unx      113 b- defN 23-Jun-14 11:42 laboneq/dsl/serialization/__init__.py
+-rw-r--r--  2.0 unx     5394 b- defN 23-Jun-14 11:42 laboneq/dsl/serialization/serializer.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/executor/__init__.py
+-rw-r--r--  2.0 unx     6010 b- defN 23-Jun-20 12:26 laboneq/executor/execution_from_experiment.py
+-rw-r--r--  2.0 unx     9198 b- defN 23-Jun-20 12:26 laboneq/executor/executor.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/compilation_service/__init__.py
+-rw-r--r--  2.0 unx     1156 b- defN 23-Jun-14 11:42 laboneq/implementation/compilation_service/compilation_service.py
+-rw-r--r--  2.0 unx     7894 b- defN 23-Jun-14 11:42 laboneq/implementation/compilation_service/compilation_service_legacy.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/data_storage/__init__.py
+-rw-r--r--  2.0 unx      916 b- defN 23-Jun-14 11:42 laboneq/implementation/data_storage/l1q_database_wrapper.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/data_storage_service/__init__.py
+-rw-r--r--  2.0 unx     6103 b- defN 23-Jun-14 11:42 laboneq/implementation/data_storage_service/data_storage_service_sqlite_dict.py
+-rw-r--r--  2.0 unx      130 b- defN 23-Jun-14 11:42 laboneq/implementation/experiment_workflow/__init__.py
+-rw-r--r--  2.0 unx    16908 b- defN 23-Jun-14 11:42 laboneq/implementation/experiment_workflow/device_setup_generator.py
+-rw-r--r--  2.0 unx     6106 b- defN 23-Jun-14 11:42 laboneq/implementation/experiment_workflow/experiment_workflow.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/__init__.py
+-rw-r--r--  2.0 unx     3084 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/dynamic_converter.py
+-rw-r--r--  2.0 unx      950 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/simple2.py
+-rw-r--r--  2.0 unx     7593 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_calibration/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_calibration/post_process_calibration.py
+-rw-r--r--  2.0 unx    24071 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_experiment_description/__init__.py
+-rw-r--r--  2.0 unx     1659 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_experiment_description/post_process_experiment_description.py
+-rw-r--r--  2.0 unx     2017 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_experiment_results/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_experiment_results/post_process_experiment_results.py
+-rw-r--r--  2.0 unx     4542 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_scheduled_experiment/__init__.py
+-rw-r--r--  2.0 unx      131 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_scheduled_experiment/post_process_scheduled_experiment.py
+-rw-r--r--  2.0 unx    13366 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_setup_description/__init__.py
+-rw-r--r--  2.0 unx     5165 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/converters_setup_description/post_process_setup_description.py
+-rw-r--r--  2.0 unx     9204 b- defN 23-Jun-14 11:42 laboneq/implementation/legacy_adapters/legacy_dsl_adapters/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/implementation/payload_builder/__init__.py
+-rw-r--r--  2.0 unx    25577 b- defN 23-Jun-14 11:42 laboneq/implementation/payload_builder/payload_builder.py
+-rw-r--r--  2.0 unx      105 b- defN 23-Jun-14 11:42 laboneq/implementation/runner/__init__.py
+-rw-r--r--  2.0 unx     2293 b- defN 23-Jun-14 11:42 laboneq/implementation/runner/runner.py
+-rw-r--r--  2.0 unx    14577 b- defN 23-Jun-20 12:26 laboneq/implementation/runner/runner_legacy.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/interfaces/__init__.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/interfaces/application_management/__init__.py
+-rw-r--r--  2.0 unx      384 b- defN 23-Jun-14 11:42 laboneq/interfaces/application_management/laboneq_settings.py
+-rw-r--r--  2.0 unx      137 b- defN 23-Jun-14 11:42 laboneq/interfaces/compilation_service/__init__.py
+-rw-r--r--  2.0 unx      779 b- defN 23-Jun-14 11:42 laboneq/interfaces/compilation_service/compilation_service_api.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/interfaces/data_storage/__init__.py
+-rw-r--r--  2.0 unx     2272 b- defN 23-Jun-14 11:42 laboneq/interfaces/data_storage/data_storage_api.py
+-rw-r--r--  2.0 unx      120 b- defN 23-Jun-14 11:42 laboneq/interfaces/experiment/__init__.py
+-rw-r--r--  2.0 unx     2004 b- defN 23-Jun-14 11:42 laboneq/interfaces/experiment/experiment_api.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/interfaces/payload_builder/__init__.py
+-rw-r--r--  2.0 unx      892 b- defN 23-Jun-14 11:42 laboneq/interfaces/payload_builder/payload_builder_api.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Jun-14 11:42 laboneq/interfaces/runner/__init__.py
+-rw-r--r--  2.0 unx      766 b- defN 23-Jun-14 11:42 laboneq/interfaces/runner/runner_api.py
+-rw-r--r--  2.0 unx      793 b- defN 23-Jun-14 11:42 laboneq/interfaces/runner/runner_control_api.py
+-rw-r--r--  2.0 unx      145 b- defN 23-Jun-14 11:42 laboneq/openqasm3/__init__.py
+-rw-r--r--  2.0 unx     8903 b- defN 23-Jun-14 11:42 laboneq/openqasm3/expression.py
+-rw-r--r--  2.0 unx     1871 b- defN 23-Jun-19 06:30 laboneq/openqasm3/gate_store.py
+-rw-r--r--  2.0 unx     2593 b- defN 23-Jun-14 11:42 laboneq/openqasm3/namespace.py
+-rw-r--r--  2.0 unx    16724 b- defN 23-Jun-19 06:30 laboneq/openqasm3/openqasm3_importer.py
+-rw-r--r--  2.0 unx     1732 b- defN 23-Jun-14 11:42 laboneq/openqasm3/openqasm_error.py
+-rw-r--r--  2.0 unx     4850 b- defN 23-Jun-16 19:26 laboneq/openqasm3/reset_gate_factory.py
+-rw-r--r--  2.0 unx     1517 b- defN 23-Jun-14 11:42 laboneq/openqasm3/signal_store.py
+-rw-r--r--  2.0 unx      127 b- defN 23-Jun-14 11:42 laboneq/pulse_sheet_viewer/__init__.py
+-rw-r--r--  2.0 unx     2692 b- defN 23-Jun-14 11:42 laboneq/pulse_sheet_viewer/interactive_psv.py
+-rw-r--r--  2.0 unx     3268 b- defN 23-Jun-20 07:59 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
+-rw-rw-rw-  2.0 unx  1443040 b- defN 23-Jun-14 11:42 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
+-rw-r--r--  2.0 unx      152 b- defN 23-Jun-14 11:42 laboneq/simulator/__init__.py
+-rw-r--r--  2.0 unx     6893 b- defN 23-Jun-14 11:42 laboneq/simulator/output_simulator.py
+-rw-r--r--  2.0 unx    42297 b- defN 23-Jun-20 07:59 laboneq/simulator/seqc_parser.py
+-rw-r--r--  2.0 unx    18324 b- defN 23-Jun-20 07:59 laboneq/simulator/wave_scroller.py
+-rw-rw-rw-  2.0 unx       22 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/AUTHORS
+-rw-rw-rw-  2.0 unx    11358 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3276 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    31606 b- defN 23-Jun-27 07:55 laboneq-2.9.0.dist-info/RECORD
+315 files, 3126877 bytes uncompressed, 961394 bytes compressed:  69.3%
```

## zipnote {}

```diff
@@ -189,14 +189,17 @@
 
 Filename: laboneq/compiler/scheduler/match_schedule.py
 Comment: 
 
 Filename: laboneq/compiler/scheduler/oscillator_schedule.py
 Comment: 
 
+Filename: laboneq/compiler/scheduler/parameter_store.py
+Comment: 
+
 Filename: laboneq/compiler/scheduler/phase_reset_schedule.py
 Comment: 
 
 Filename: laboneq/compiler/scheduler/preorder_map.py
 Comment: 
 
 Filename: laboneq/compiler/scheduler/pulse_phase.py
@@ -228,23 +231,29 @@
 
 Filename: laboneq/compiler/workflow/__init__.py
 Comment: 
 
 Filename: laboneq/compiler/workflow/compiler.py
 Comment: 
 
+Filename: laboneq/compiler/workflow/neartime_execution.py
+Comment: 
+
 Filename: laboneq/compiler/workflow/precompensation_helpers.py
 Comment: 
 
 Filename: laboneq/compiler/workflow/realtime_compiler.py
 Comment: 
 
 Filename: laboneq/compiler/workflow/recipe_generator.py
 Comment: 
 
+Filename: laboneq/compiler/workflow/rt_linker.py
+Comment: 
+
 Filename: laboneq/contrib/__init__.py
 Comment: 
 
 Filename: laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
 Comment: 
 
 Filename: laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
@@ -531,14 +540,20 @@
 
 Filename: laboneq/data/setup_description/setup_helper.py
 Comment: 
 
 Filename: laboneq/dsl/__init__.py
 Comment: 
 
+Filename: laboneq/dsl/_inspect.py
+Comment: 
+
+Filename: laboneq/dsl/dsl_dataclass_decorator.py
+Comment: 
+
 Filename: laboneq/dsl/laboneq_facade.py
 Comment: 
 
 Filename: laboneq/dsl/parameter.py
 Comment: 
 
 Filename: laboneq/dsl/session.py
@@ -885,17 +900,14 @@
 
 Filename: laboneq/openqasm3/signal_store.py
 Comment: 
 
 Filename: laboneq/pulse_sheet_viewer/__init__.py
 Comment: 
 
-Filename: laboneq/pulse_sheet_viewer/event_graph_viewer.py
-Comment: 
-
 Filename: laboneq/pulse_sheet_viewer/interactive_psv.py
 Comment: 
 
 Filename: laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
 Comment: 
 
 Filename: laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
@@ -909,26 +921,26 @@
 
 Filename: laboneq/simulator/seqc_parser.py
 Comment: 
 
 Filename: laboneq/simulator/wave_scroller.py
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/AUTHORS
+Filename: laboneq-2.9.0.dist-info/AUTHORS
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/LICENSE
+Filename: laboneq-2.9.0.dist-info/LICENSE
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/METADATA
+Filename: laboneq-2.9.0.dist-info/METADATA
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/WHEEL
+Filename: laboneq-2.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/top_level.txt
+Filename: laboneq-2.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: laboneq-2.8.0.dist-info/RECORD
+Filename: laboneq-2.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## laboneq/VERSION.txt

```diff
@@ -1 +1 @@
-2.8.0
+2.9.0
```

## laboneq/_token.py

```diff
@@ -1,91 +1,17 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-import importlib
-import os
-import subprocess
-import sys
-from hashlib import sha256
-from pathlib import Path
-from tempfile import TemporaryDirectory
-
-MISSING_TOKEN_MSG = """\n
-LabOne Q is currently in a monitored beta phase and requires an access token
-to unlock all functionality.
-
-Please see the following page for instructions to obtain a token:
-<https://www.zhinst.com/ch/en/install-labone-q-today>
-
-If you already have a token, please provide it to the software
-
-  a) through the LABONEQ_TOKEN environment variable, or
-  b) by installing it through LabOne Q:
-
-     >>> from laboneq.simple import install_token
-     >>> install_token("your-token-goes-here")
-"""
-
-PYPROJECT_TOML_TEMPLATE = """\
-[project]
-name = "laboneq_token"
-description = "LabOne Q User Token"
-version = "1.0.0"
-"""
-
-TOKEN_SHA = "339b6ddce1bca6b78305474c13183baedaa4951e6460c5ddb59ea525d901c1fe"
+import warnings
 
 
 def install_token(token: str):
-    """Install the LabOne Q access token as a Python package.
-
-    Note: the `LABONEQ_TOKEN` environment variable can be used
-          alternatively and takes precedence in checks.
-    """
-    print("Installing LabOne Q token as a Python package (`laboneq_token`) ...")
-    with TemporaryDirectory() as tmp_dir:
-        tmp_dir = Path(tmp_dir)
-        src_dir = tmp_dir / "src"
-        src_dir.mkdir()
-        (tmp_dir / "pyproject.toml").write_text(PYPROJECT_TOML_TEMPLATE)
-        (src_dir / "laboneq_token.py").write_text(f'TOKEN = "{token}"')
-        subprocess.check_call(
-            [sys.executable, "-m", "pip", "install", "-qqq", "--force-reinstall", "."],
-            cwd=tmp_dir,
-        )
-    print("Token successfully installed.")
-
-
-def get_token():
-    token = os.getenv("LABONEQ_TOKEN")
-    if not token:
-        try:
-            module = sys.modules.get("laboneq_token", None)
-            if module is None:
-                module = importlib.import_module("laboneq_token")
-            else:
-                module = importlib.reload(module)
-            token = module.TOKEN
-        except ModuleNotFoundError:
-            return None
-    return token
+    warnings.warn("An access token is no longer required for LabOne Q.", FutureWarning)
 
 
 def is_valid_token(token):
-    return sha256(token.encode("utf-8")).hexdigest() == TOKEN_SHA
+    warnings.warn("An access token is no longer required for LabOne Q.", FutureWarning)
+    return True
 
 
 def token_check():
-    # Note for hackers: If you have read this far, you probably don't want to
-    # contact us for a free and immediate access token. In that case, add a line
-    # with a return statement below. Contact us anytime at support@zhinst.com
-    # for _free_ and friendly support.
-    token = get_token()
-    if token is not None and is_valid_token(token):
-        return
-
-    if token is None:
-        error_msg = "Token missing!" + MISSING_TOKEN_MSG
-    else:
-        error_msg = "The provided token is invalid!" + MISSING_TOKEN_MSG
-
-    raise RuntimeError(error_msg)
+    warnings.warn("An access token is no longer required for LabOne Q.", FutureWarning)
```

## laboneq/simple.py

```diff
@@ -48,9 +48,10 @@
     pulse_library,
 )
 from laboneq.dsl.quantum import QuantumOperation, Qubit, QubitParameters
 from laboneq.dsl.result import Results
 from laboneq.dsl.session import Session
 from laboneq.dsl.utils import has_onboard_lo
 from laboneq.implementation.data_storage.l1q_database_wrapper import L1QDatabase
+from laboneq.openqasm3.openqasm3_importer import exp_from_qasm
 from laboneq.pulse_sheet_viewer.pulse_sheet_viewer import show_pulse_sheet
 from laboneq.simulator.output_simulator import OutputSimulator
```

## laboneq/compiler/code_generator/code_generator.py

```diff
@@ -261,18 +261,18 @@
             else:
                 self._settings = CompilerSettings(**settings)
         else:
             self._settings = CompilerSettings()
 
         self._signals: dict[str, SignalObj] = {}
         self._code = {}
-        self._src = []
-        self._wave_indices_all = []
-        self._waves = []
-        self._command_tables: List[Dict[str, Any]] = []
+        self._src: dict[AwgKey, dict[str, str]] = {}
+        self._wave_indices_all: dict[AwgKey, dict] = {}
+        self._waves: dict[str, Any] = {}
+        self._command_tables: dict[AwgKey, dict[str, Any]] = {}
         self._pulse_map: Dict[str, PulseMapEntry] = {}
         self._sampled_signatures: Dict[str, Dict[WaveformSignature, Dict]] = {}
         self._awgs: Dict[AwgKey, AWGInfo] = {}
         self._events_in_samples = {}
         self._integration_times: IntegrationTimes = None
         self._signal_delays: SignalDelays = None
         self._integration_weights = None
@@ -322,15 +322,18 @@
             pulse_map_entry.waveforms[sig_string] = pulse_waveform_map
 
     def _save_wave_bin(
         self, samples, signature_pulse_map, sig_string: str, suffix: str
     ):
         filename = sig_string + suffix + ".wave"
         wave = {"filename": filename, "samples": samples}
-        self._waves.append(wave)
+        assert filename not in self._waves or np.allclose(
+            self._waves[filename]["samples"], wave["samples"]
+        )
+        self._waves[filename] = wave
         self._append_to_pulse_map(signature_pulse_map, sig_string)
 
     def gen_waves(self):
         if _logger.getEffectiveLevel() == logging.DEBUG:
             _logger.debug("Sampled signatures: %s", self._sampled_signatures)
         for awg in self._awgs.values():
             # Handle integration weights separately
@@ -474,15 +477,15 @@
                     else:
                         raise RuntimeError(
                             f"Device type {signal_obj.awg.device_type} has invalid supported waves config."
                         )
 
         # check that there are no duplicate filenames in the wave pool (QCSW-1079)
         waves = sorted(
-            [(wave["filename"], wave["samples"]) for wave in self._waves],
+            [(filename, wave["samples"]) for filename, wave in self._waves.items()],
             key=lambda w: w[0],
         )
         for _, group in groupby(waves, key=lambda w: w[0]):
             group = list(group)
             assert all(np.all(group[0][1] == g[1]) for g in group[1:])
 
         if _logger.getEffectiveLevel() == logging.DEBUG:
@@ -516,15 +519,14 @@
         ) = self._measurement_calculator.calculate_integration_times(
             signal_info_map, events
         )
 
         for signal_id, signal_obj in self._signals.items():
             code_generation_delay = self._signal_delays.get(signal_id)
             if code_generation_delay is not None:
-
                 signal_obj.total_delay = (
                     signal_obj.start_delay
                     + signal_obj.delay_signal
                     + code_generation_delay.code_generation
                 )
                 signal_obj.on_device_delay = code_generation_delay.on_device
             else:
@@ -541,51 +543,33 @@
                 EngNumber(signal_obj.on_device_delay),
             )
 
         self._total_execution_time = events[-1].get("time") if len(events) > 0 else None
         self.sort_signals()
         self._integration_weights = {}
 
-        ignore_pulses = set()
-        for pulse_id, pulse_def in pulse_defs.items():
-            if (
-                abs(pulse_def.effective_amplitude) < 1e-12
-            ):  # ignore zero amplitude pulses
-                ignore_pulses.add(pulse_id)
-        if len(ignore_pulses) > 0:
-            _logger.debug(
-                "Ignoring pulses because of zero amplitude: %s", ignore_pulses
-            )
-
-        filtered_events: List[Any] = [
-            event
-            for event in events
-            if "play_wave_id" not in event or event["play_wave_id"] not in ignore_pulses
-        ]
-
         self._feedback_register_allocator = FeedbackRegisterAllocator(
-            self._signals, filtered_events
+            self._signals, events
         )
 
         for _, awg in sorted(
             self._awgs.items(),
             key=lambda item: item[0].device_id + str(item[0].awg_number),
         ):
-            self._gen_seq_c_per_awg(awg, filtered_events, pulse_defs)
+            self._gen_seq_c_per_awg(awg, events, pulse_defs)
 
         return self._signal_delays
 
     @staticmethod
     def _calc_global_awg_params(awg: AWGInfo) -> Tuple[float, float]:
         global_sampling_rate = None
         global_delay = None
         signals_so_far = set()
         all_relevant_delays = {}
         for signal_obj in awg.signals:
-
             _logger.debug(f"considering signal {signal_obj.id}")
             if awg.device_type == DeviceType.UHFQA:
                 # on the UHFQA, we allow an individual delay_signal on the measure (play) line, even though we can't
                 # shift the play time with a node on the device
                 # for this to work, we need to ignore the play delay when generating code for loop events
                 # and we use the start delay (lead time) to calculate the global delay
                 relevant_delay = signal_obj.start_delay
@@ -599,24 +583,22 @@
             ):
                 raise RuntimeError(
                     f"Delay {relevant_delay} s = {round(relevant_delay*signal_obj.awg.sampling_rate)} samples on signal {signal_obj.id} is not compatible with the sample multiple of {signal_obj.awg.device_type.sample_multiple} on {signal_obj.awg.device_type}"
                 )
             all_relevant_delays[signal_obj.id] = relevant_delay
 
             if signal_obj.signal_type != "integration":
-
                 if awg.signal_type != AWGSignalType.IQ and global_delay is not None:
                     if global_delay != relevant_delay:
                         raise RuntimeError(
                             f"Delay {relevant_delay * 1e9:.2f} ns on signal "
                             f"{signal_obj.id} is different from other delays "
                             f"({global_delay * 1e9:.2f} ns) on the same AWG, on signals {signals_so_far}"
                         )
                 if global_delay is not None:
-
                     if relevant_delay < global_delay:
                         # use minimum delay as global delay
                         # this makes sure that loop start events happen first and are not shifted beyond loop body events
                         global_delay = relevant_delay
                 else:
                     global_delay = relevant_delay
 
@@ -694,34 +676,59 @@
 
             if pi.end > pj.start and pi.can_compress != pj.can_compress:
                 return False
 
         return True
 
     def _compress_waves(
-        self, sampled_events, sampled_signatures, signal_id, min_play_wave, pulse_defs
+        self,
+        sampled_events,
+        sampled_signatures,
+        signal_id,
+        min_play_wave,
+        pulse_defs,
+        device_type,
     ):
         compressed_waveform_signatures = set()
         for event_group in sampled_events.sequence.values():
             event_replacement = {}
             for i, event in enumerate(event_group):
+                if event.type == AWGEventType.ACQUIRE:
+                    if pulse_defs[event.params["play_wave_id"]].can_compress:
+                        _logger.warn(
+                            "Compression for integration pulses is not supported. %s, for which compression has been requested, will not be compressed.",
+                            event.params["play_wave_id"],
+                        )
                 if event.type == AWGEventType.PLAY_WAVE:
                     wave_form = event.params["playback_signature"].waveform
                     pulses_not_in_pulsedef = [
                         pulse.pulse
                         for pulse in wave_form.pulses
                         if pulse.pulse not in pulse_defs
                     ]
                     assert all(
                         pulse is None or pulse == "dummy_precomp_reset"
                         for pulse in pulses_not_in_pulsedef
                     )
                     if len(pulses_not_in_pulsedef) > 0:
                         continue
-
+                    if any(
+                        pulse_defs[pulse.pulse].can_compress
+                        for pulse in wave_form.pulses
+                    ) and device_type in [DeviceType.UHFQA, DeviceType.SHFQA]:
+                        pulse_names = [
+                            pulse.pulse
+                            for pulse in wave_form.pulses
+                            if pulse_defs[pulse.pulse].can_compress
+                        ]
+                        _logger.warn(
+                            "Requested to compress pulse(s) %s which are to be played on a QA device, which does not support playHold",
+                            ",".join(pulse_names),
+                        )
+                        continue
                     if all(
                         not pulse_defs[pulse.pulse].can_compress
                         for pulse in wave_form.pulses
                     ):
                         continue
                     sampled_signature = sampled_signatures[wave_form]
                     sample_dict = {
@@ -838,20 +845,19 @@
         pulse_defs: Dict[str, PulseDef],
     ):
         function_defs_generator = SeqCGenerator()
         declarations_generator = SeqCGenerator()
         _logger.debug("Generating seqc for awg %d of %s", awg.awg_number, awg.device_id)
         _logger.debug("AWG Object = \n%s", awg)
         sampled_events = AWGSampledEventSequence()
-        filename = awg.seqc
 
         global_sampling_rate, global_delay = self._calc_global_awg_params(awg)
         if self.EMIT_TIMING_COMMENTS:
             declarations_generator.add_comment(
-                f"{awg.seqc} global delay {EngNumber(global_delay)} sampling_rate: {EngNumber(global_sampling_rate)}Sa/s "
+                f"{awg.device_type}/{awg.awg_number} global delay {EngNumber(global_delay)} sampling_rate: {EngNumber(global_sampling_rate)}Sa/s "
             )
 
         use_command_table = (
             awg.device_type == DeviceType.HDAWG
             and self._settings.HDAWG_FORCE_COMMAND_TABLE
         ) or (
             awg.device_type == DeviceType.SHFSG
@@ -931,15 +937,14 @@
 
         loop_events = analyze_loop_times(
             awg, events, global_sampling_rate, global_delay
         )
         sampled_events.merge(loop_events)
 
         for signal_obj in awg.signals:
-
             set_oscillator_events = analyze_set_oscillator_times(
                 events,
                 signal_obj,
             )
             sampled_events.merge(set_oscillator_events)
 
             trigger_events = analyze_trigger_events(events, signal_obj, loop_events)
@@ -1027,14 +1032,15 @@
             )
             self._compress_waves(
                 sampled_events=sampled_events,
                 sampled_signatures=sampled_signatures,
                 signal_id=virtual_signal_id,
                 min_play_wave=min_play_waves[0],
                 pulse_defs=pulse_defs,
+                device_type=device_type,
             )
 
             if virtual_signal_id in self._sampled_signatures:
                 for sig, sampled in self._sampled_signatures[virtual_signal_id].items():
                     if not sampled:
                         continue
                     sig_string = sig.signature_string()
@@ -1047,15 +1053,14 @@
                         length,
                         False,
                         False,
                     )
 
         elif awg.signal_type != AWGSignalType.DOUBLE:
             for signal_obj in awg.signals:
-
                 if signal_obj.awg.device_type == DeviceType.SHFQA:
                     sub_channel = signal_obj.channels[0]
                 else:
                     sub_channel = None
                 interval_events = analyze_play_wave_times(
                     events=events,
                     signals={signal_obj.id: signal_obj},
@@ -1086,14 +1091,15 @@
 
                 self._compress_waves(
                     sampled_events=sampled_events,
                     sampled_signatures=sampled_signatures,
                     signal_id=signal_obj.id,
                     min_play_wave=signal_obj.awg.device_type.min_play_wave,
                     pulse_defs=pulse_defs,
+                    device_type=signal_obj.awg.device_type,
                 )
 
                 if signal_obj.id in self._sampled_signatures:
                     signature_infos = []
                     for sig, sampled in self._sampled_signatures[signal_obj.id].items():
                         has_marker1 = False
                         has_marker2 = False
@@ -1154,14 +1160,15 @@
 
             self._compress_waves(
                 sampled_events=sampled_events,
                 sampled_signatures=sampled_signatures,
                 signal_id=virtual_signal_id,
                 min_play_wave=signal_a.awg.device_type.min_play_wave,
                 pulse_defs=pulse_defs,
+                device_type=awg.device_type,
             )
 
             if virtual_signal_id in self._sampled_signatures:
                 for sig, sampled in self._sampled_signatures[virtual_signal_id].items():
                     if not sampled:
                         continue
                     sig_string = sig.signature_string()
@@ -1244,25 +1251,22 @@
             seq_c_generator.add_function_call_statement("setDIO", ["0"])
 
         seq_c_text = seq_c_generator.generate_seq_c()
 
         for line in seq_c_text.splitlines():
             _logger.debug(line)
 
-        self._src.append({"filename": filename, "text": seq_c_text})
-        self._wave_indices_all.append(
-            {
-                "filename": filename,
-                "value": handler.wave_indices.wave_indices(),
-            }
-        )
+        awg_key = AwgKey(awg.device_id, awg.awg_number)
+
+        self._src[awg_key] = {"text": seq_c_text}
+        self._wave_indices_all[awg_key] = {"value": handler.wave_indices.wave_indices()}
         if use_command_table:
-            self._command_tables.append(
-                {"seqc": filename, "ct": handler.command_table_tracker.command_table()}
-            )
+            self._command_tables[awg_key] = {
+                "ct": handler.command_table_tracker.command_table()
+            }
 
     def waveform_size_hints(self, device: DeviceType):
         settings = self._settings
 
         def sanitize_min_playwave_hint(n: int, multiple: int) -> int:
             if n % multiple != 0:
                 n2 = round_min_playwave_hint(n, multiple)
@@ -1522,15 +1526,19 @@
                     pm = PulseWaveformMap(
                         sampling_rate=sampling_rate,
                         length_samples=pulse_part.length,
                         signal_type=sampling_signal_type,
                         mixer_type=mixer_type,
                     )
                     signature_pulse_map[pulse_def.id] = pm
-                amplitude_multiplier = amplitude / pulse_def.effective_amplitude
+                amplitude_multiplier = (
+                    amplitude / pulse_def.effective_amplitude
+                    if pulse_def.effective_amplitude
+                    else 0.0
+                )
                 pm.instances.append(
                     PulseInstance(
                         offset_samples=pulse_part.start,
                         amplitude=amplitude_multiplier,
                         length=pulse_part.length,
                         modulation_frequency=used_oscillator_frequency,
                         modulation_phase=oscillator_phase,
```

## laboneq/compiler/code_generator/measurement_calculator.py

```diff
@@ -6,14 +6,15 @@
 from itertools import groupby
 from typing import Any, Dict, Iterator, Optional, Tuple
 
 from engineering_notation import EngNumber
 
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.fastlogging import NullLogger
+from laboneq.core.types.enums import AcquisitionType
 
 _logger = logging.getLogger(__name__)
 if _logger.getEffectiveLevel() == logging.DEBUG:
     _dlogger = _logger
     _dlog = True
 else:
     _logger.info("Debug logging disabled for %s", __name__)
@@ -139,17 +140,22 @@
                             if event["event_type"] == "ACQUIRE_START":
                                 signal_integration_info.is_play = False
 
                                 signal_integration_info.start = (
                                     event["time"] + delay_signal
                                 )
                                 acquisition_type = event.get("acquisition_type")
-                                if (
-                                    acquisition_type is not None
-                                    and "spectroscopy" in acquisition_type
+                                if acquisition_type and set(
+                                    acquisition_type
+                                ).intersection(
+                                    [
+                                        AcquisitionType.SPECTROSCOPY_IQ.value,
+                                        AcquisitionType.SPECTROSCOPY.value,
+                                        AcquisitionType.SPECTROSCOPY_PSD.value,
+                                    ]
                                 ):
                                     signal_integration_info.is_spectroscopy = True
                                 else:
                                     signal_integration_info.is_spectroscopy = False
 
                             if event["event_type"] == "ACQUIRE_END":
                                 signal_integration_info.end = (
```

## laboneq/compiler/code_generator/sampled_event_handler.py

```diff
@@ -17,14 +17,15 @@
     AWGEvent,
     AWGEventType,
     AWGSampledEventSequence,
 )
 from laboneq.compiler.common.compiler_settings import EXECUTETABLEENTRY_LATENCY
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.core.exceptions import LabOneQException
+from laboneq.core.types.enums import AcquisitionType
 
 if TYPE_CHECKING:
     from laboneq.compiler.code_generator.command_table_tracker import (
         CommandTableTracker,
     )
     from laboneq.compiler.code_generator.seqc_tracker import SeqCTracker
     from laboneq.compiler.code_generator.signatures import WaveformSignature
@@ -343,16 +344,26 @@
         if len(generator_channels) > 0:
             generator_mask = "|".join(
                 map(lambda x: "QA_GEN_" + str(x), generator_channels)
             )
         else:
             generator_mask = "QA_GEN_NONE"
 
-        if "spectroscopy" in sampled_event.params["acquisition_type"]:
-            args = [0, 0, 0, 0, 1]
+        is_spectroscopy = bool(
+            set(sampled_event.params["acquisition_type"]).intersection(
+                [
+                    AcquisitionType.SPECTROSCOPY_IQ.value,
+                    AcquisitionType.SPECTROSCOPY.value,
+                    AcquisitionType.SPECTROSCOPY_PSD.value,
+                ]
+            )
+        )
+        if is_spectroscopy:
+            mask_val_for_spectroscopy = 0
+            args = [mask_val_for_spectroscopy, 0, 0, 0, 1]
         else:
             args = [
                 generator_mask,
                 integrator_mask,
                 "1" if "RAW" in sampled_event.params["acquisition_type"] else "0",
             ]
             feedback_register = sampled_event.params["feedback_register"]
@@ -361,15 +372,15 @@
 
         self.seqc_tracker.add_required_playzeros(sampled_event)
 
         if sampled_event.end > self.seqc_tracker.current_time:
             self.seqc_tracker.add_timing_comment(sampled_event.end)
 
         self.seqc_tracker.add_function_call_statement("startQA", args, deferred=True)
-        if "spectroscopy" in sampled_event.params["acquisition_type"]:
+        if is_spectroscopy:
             self.seqc_tracker.add_function_call_statement(
                 "setTrigger", [0], deferred=True
             )
 
         ev: AWGEvent
         for ev in sampled_event.params["acquire_events"]:
             for h in ev.params["acquire_handles"]:
```

## laboneq/compiler/common/awg_info.py

```diff
@@ -21,15 +21,14 @@
 
 
 @dataclass
 class AWGInfo:
     device_id: str
     signal_type: AWGSignalType
     awg_number: int
-    seqc: str
     device_type: DeviceType
     sampling_rate: float
     trigger_mode: TriggerMode = TriggerMode.NONE
     reference_clock_source: Optional[str] = None
     signal_channels: List[Tuple[str, int]] = field(default_factory=list)
     signals: List[SignalObj] = field(default_factory=list)
```

## laboneq/compiler/experiment_access/dsl_loader.py

```diff
@@ -1,16 +1,16 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import copy
+import itertools
 import logging
 import typing
-import uuid
 from dataclasses import dataclass
 from numbers import Number
 from types import SimpleNamespace
 from typing import Any, Callable, Dict, Tuple
 
 from laboneq.compiler.experiment_access.acquire_info import AcquireInfo
 from laboneq.compiler.experiment_access.loader_base import LoaderBase
@@ -62,15 +62,14 @@
 
         reference_clock = None
         for device in device_setup.instruments:
             if hasattr(device, "reference_clock"):
                 reference_clock = device.reference_clock
 
         for device in sorted(device_setup.instruments, key=lambda x: x.uid):
-
             server = device.server_uid
 
             driver = type(device).__name__.lower()
             serial = device.address
             interface = device.interface
             is_global_leader = 0
             if global_leader_device_id == device.uid:
@@ -425,15 +424,14 @@
         for signal, lsuid in experiment.get_signal_map().items():
             local_paths = dest_path_devices[lsuid].get("local_paths")
 
             remote_ports = dest_path_devices[lsuid].get("remote_ports")
 
             channels = []
             if local_paths:
-
                 device = dest_path_devices[lsuid]["device"]
 
                 local_ports = dest_path_devices[lsuid].get("local_ports")
 
                 for i, local_port in enumerate(local_ports):
                     current_port = device_setup.instrument_by_uid(device).output_by_uid(
                         local_port
@@ -618,24 +616,42 @@
                 current_acquisition_type,
                 section_uid_map,
                 acquisition_type_map,
                 exchanger_map,
                 parent_instance_id=instance_id,
             )
 
+    def _extract_markers(self, operation):
+        markers_raw = getattr(operation, "marker", None)
+        if markers_raw is None:
+            return None
+
+        return [
+            Marker(
+                k,
+                enable=v.get("enable"),
+                start=v.get("start"),
+                length=v.get("length"),
+                pulse_id=v.get("waveform", {}).get("$ref", None),
+            )
+            for k, v in markers_raw.items()
+        ]
+
     def _insert_section(
         self,
         section,
         acquisition_type,
         exchanger_map: Callable[[Any], Any],
         instance_id: str,
     ):
         has_repeat = False
         count = 1
 
+        _auto_pulse_id = (f"{section.uid}__auto_pulse_{i}" for i in itertools.count())
+
         if hasattr(section, "count"):
             has_repeat = True
             count = section.count
 
         if hasattr(section, "parameters"):
             for parameter in section.parameters:
                 values_list = None
@@ -711,28 +727,31 @@
         if hasattr(section, "local"):
             local = section.local
 
         trigger = [
             {"signal_id": k, "state": v["state"]} for k, v in section.trigger.items()
         ]
 
+        chunk_count = getattr(section, "chunk_count", 1)
+
         acquisition_types = None
         for operation in exchanger_map(section).operations:
             if hasattr(operation, "handle"):
                 # an acquire event - add acquisition_types
                 acquisition_types = [acquisition_type.value]
 
         self.add_section(
             instance_id,
             SectionInfo(
                 section_id=instance_id,
                 section_display_name=section.uid,
                 has_repeat=has_repeat,
                 execution_type=execution_type,
                 count=count,
+                chunk_count=chunk_count,
                 acquisition_types=acquisition_types,
                 align=align,
                 on_system_grid=on_system_grid,
                 length=length,
                 averaging_mode=averaging_mode,
                 repetition_mode=repetition_mode,
                 repetition_time=repetition_time,
@@ -758,15 +777,14 @@
 
         for operation in exchanger_map(section).operations:
             if hasattr(operation, "signal"):
                 pulse_offset = None
                 pulse_offset_param = None
 
                 if hasattr(operation, "time"):  # Delay operation
-
                     pulse_offset = operation.time
                     precompensation_clear = (
                         getattr(operation, "precompensation_clear", None) or False
                     )
                     if not isinstance(operation.time, float) and not isinstance(
                         operation.time, int
                     ):
@@ -779,39 +797,55 @@
                         offset_param=pulse_offset_param,
                         precompensation_clear=precompensation_clear,
                     )
                     self.add_section_signal_pulse(instance_id, operation.signal, ssp)
                 else:  # All operations, except Delay
                     pulse = None
                     operation_length_param = None
+                    markers = self._extract_markers(operation)
 
-                    if hasattr(operation, "pulse"):
-                        pulse = getattr(operation, "pulse")
-                    if hasattr(operation, "kernel"):
-                        pulse = getattr(operation, "kernel")
                     length = getattr(operation, "length", None)
                     operation_length = length
                     if (
                         operation_length is not None
                         and not isinstance(operation_length, float)
                         and not isinstance(operation_length, complex)
                         and not isinstance(operation_length, int)
                     ):
                         operation_length_param = operation_length.uid
                         operation_length = None
+
+                    if hasattr(operation, "pulse"):
+                        pulse = getattr(operation, "pulse")
+                    if hasattr(operation, "kernel"):
+                        pulse = getattr(operation, "kernel")
                     if pulse is None and length is not None:
                         pulse = SimpleNamespace()
-                        setattr(pulse, "uid", uuid.uuid4().hex)
+                        setattr(pulse, "uid", next(_auto_pulse_id))
                         setattr(pulse, "length", length)
+                    if pulse is None and markers:
+                        # generate an zero amplitude pulse to play the markers
+                        pulse = SimpleNamespace()
+                        pulse.uid = next(_auto_pulse_id)
+                        pulse.function = "const"
+                        pulse.amplitude = 0.0
+                        pulse.length = max([m.start + m.length for m in markers])
+                        pulse.can_compress = False
+                        pulse.pulse_parameters = None
+                    if markers:
+                        for m in markers:
+                            if m.pulse_id is None:
+                                m.pulse_id = pulse.uid
+
                     if hasattr(operation, "handle") and pulse is None:
                         raise RuntimeError(
                             f"Either 'kernel' or 'length' must be provided for the acquire operation with handle '{getattr(operation, 'handle')}'."
                         )
-                    if pulse is not None:
 
+                    if pulse is not None:
                         function = None
                         length = None
 
                         pulse_parameters = getattr(pulse, "pulse_parameters", None)
 
                         if pulse.uid not in self._pulses:
                             samples = None
@@ -887,35 +921,19 @@
                             for param, val in operation_pulse_parameters.items():
                                 if hasattr(val, "uid"):
                                     # Take the presence of "uid" as a proxy for isinstance(val, SweepParameter)
                                     operation_pulse_parameters[param] = ParamRef(
                                         val.uid
                                     )
 
-                        markers = None
-                        if hasattr(operation, "marker"):
-                            markers_raw = operation.marker
-                            if markers_raw is not None:
-                                markers = []
-                                for k, v in markers_raw.items():
-                                    marker_pulse_id = None
-                                    pulse_ref = v.get("waveform")
-                                    if pulse_ref is not None:
-                                        marker_pulse_id = pulse_ref["$ref"]
-
-                                    markers.append(
-                                        Marker(
-                                            k,
-                                            enable=v.get("enable"),
-                                            start=v.get("start"),
-                                            length=v.get("length"),
-                                            pulse_id=marker_pulse_id,
-                                        )
-                                    )
-                                    self.add_signal_marker(operation.signal, k)
+                        if markers:
+                            for m in markers:
+                                self.add_signal_marker(
+                                    operation.signal, m.marker_selector
+                                )
 
                         ssp = SectionSignalPulse(
                             signal_id=operation.signal,
                             pulse_id=pulse.uid,
                             offset=pulse_offset,
                             offset_param=pulse_offset_param,
                             amplitude=pulse_amplitude,
```

## laboneq/compiler/experiment_access/json_loader.py

```diff
@@ -353,14 +353,15 @@
                 instance_id,
                 SectionInfo(
                     section_id=instance_id,
                     section_display_name=section["id"],
                     has_repeat=has_repeat,
                     execution_type=execution_type,
                     count=count,
+                    chunk_count=1,
                     acquisition_types=acquisition_types,
                     align=align,
                     on_system_grid=on_system_grid,
                     length=length,
                     averaging_mode=averaging_mode,
                     repetition_mode=repetition_mode,
                     repetition_time=repetition_time,
```

## laboneq/compiler/experiment_access/loader_base.py

```diff
@@ -34,15 +34,15 @@
         self._section_tree = {}
         self._servers = {}
         self._signals = {}
         self._signal_connections = {}
         self._signal_markers = {}
         self._signal_oscillator = {}
         self._signal_trigger = {}
-        self._root_sections = set()
+        self._root_sections = []
         self._handle_acquires = {}
 
     def data(self) -> dict[str, Any]:
         return {
             "devices": self._devices,
             "device_oscillators": self._device_oscillators,
             "oscillators": self._oscillators,
```

## laboneq/compiler/experiment_access/section_info.py

```diff
@@ -10,14 +10,15 @@
 @dataclass
 class SectionInfo:
     section_id: str
     has_repeat: bool
     execution_type: Optional[str]
     acquisition_types: Optional[List[str]]
     count: int
+    chunk_count: int
     align: Optional[str]
     on_system_grid: bool
     length: Optional[float]
     averaging_mode: Optional[str]
     repetition_mode: Optional[str]
     repetition_time: Optional[float]
     play_after: Optional[Union[str, List[str]]]
```

## laboneq/compiler/scheduler/match_schedule.py

```diff
@@ -109,16 +109,14 @@
 
     if qa_signal_obj.is_qc:
         toolkit_qatype = QAType.SHFQC
     else:
         toolkit_qatype = {"shfqa": QAType.SHFQA, "shfqc": QAType.SHFQC}.get(
             qa_device_type.str_value
         )
-    if toolkit_qatype is None:
-        raise LabOneQException("Feedback not supported for an aquisition on a UHFQA.")
 
     acq_start = acquire_pulse.absolute_start * schedule_data.TINYSAMPLE
     acq_length = acquire_pulse.length * schedule_data.TINYSAMPLE
     qa_lead_time = qa_signal_obj.start_delay or 0.0
     qa_delay_signal = qa_signal_obj.delay_signal or 0.0
     qa_port_delay = qa_signal_obj.port_delay or 0.0
     qa_base_delay_signal = qa_signal_obj.base_delay_signal or 0.0
@@ -158,41 +156,61 @@
             toolkit_sgtype = {
                 "hdawg": SGType.HDAWG,
                 "shfsg": SGType.SHFSG,
                 "shfqc": SGType.SHFQC,
             }[sg_device_type.str_value]
 
         model = FeedbackTimingModel if not local else QCCSFeedbackModel
-        time_of_arrival_at_register = model(
-            description=get_feedback_system_description(
-                generator_type=toolkit_sgtype,
-                analyzer_type=toolkit_qatype,
-                pqsc_mode=None if local else PQSCMode.REGISTER_FORWARD,
-                feedback_path=FeedbackPath.INTERNAL if local else FeedbackPath.ZSYNC,
-            )
-        ).get_latency(acquire_end_in_samples)
-
-        # We also add three latency cycles here, which then, in the code generator, will
-        # be subtracted again for the latency argument of executeTableEntry. The reason
-        # is that there is an additional latency of three cycles from the execution
-        # of the command in the sequencer until the arrival of the chosen waveform in
-        # the wave player queue. For now, we look at the time the pulse is played
-        # (arrival time of data in register + 3), which also simplifies phase
-        # calculation for software modulated signals, and take care of subtracting it
-        # later
+        if toolkit_qatype is not None:
+            time_of_arrival_at_register = model(
+                description=get_feedback_system_description(
+                    generator_type=toolkit_sgtype,
+                    analyzer_type=toolkit_qatype,
+                    pqsc_mode=None if local else PQSCMode.REGISTER_FORWARD,
+                    feedback_path=FeedbackPath.INTERNAL
+                    if local
+                    else FeedbackPath.ZSYNC,
+                )
+            ).get_latency(acquire_end_in_samples)
+
+            # We also add three latency cycles here, which then, in the code generator, will
+            # be subtracted again for the latency argument of executeTableEntry. The reason
+            # is that there is an additional latency of three cycles from the execution
+            # of the command in the sequencer until the arrival of the chosen waveform in
+            # the wave player queue. For now, we look at the time the pulse is played
+            # (arrival time of data in register + 3), which also simplifies phase
+            # calculation for software modulated signals, and take care of subtracting it
+            # later
 
-        time_of_pulse_played = time_of_arrival_at_register + EXECUTETABLEENTRY_LATENCY
+            time_of_pulse_played = (
+                time_of_arrival_at_register + EXECUTETABLEENTRY_LATENCY
+            )
 
-        sg_seq_rate = schedule_data.sampling_rate_tracker.sequencer_rate_for_device(
-            sg_signal_obj.awg.device_id
-        )
-        sg_seq_dt_for_latency_in_ts = round(
-            1 / (2 * sg_seq_rate * schedule_data.TINYSAMPLE)
-        )
-        latency_in_ts = time_of_pulse_played * sg_seq_dt_for_latency_in_ts
+            sg_seq_rate = schedule_data.sampling_rate_tracker.sequencer_rate_for_device(
+                sg_signal_obj.awg.device_id
+            )
+            sg_seq_dt_for_latency_in_ts = round(
+                1 / (2 * sg_seq_rate * schedule_data.TINYSAMPLE)
+            )
+            latency_in_ts = time_of_pulse_played * sg_seq_dt_for_latency_in_ts
+        else:
+            # gen 1 system
+            latency = 750e-9  # https://www.zhinst.com/ch/en/blogs/practical-active-qubit-reset
+            latency_in_ts = int(
+                (
+                    latency
+                    + acq_start
+                    + acq_length
+                    + qa_lead_time
+                    + qa_delay_signal
+                    + qa_base_delay_signal
+                    + qa_total_port_delay / qa_sampling_rate
+                )
+                / schedule_data.TINYSAMPLE
+            )
 
         # Calculate the shift of compiler zero time for the SG; we may subtract this
         # from the time of arrival (which is measured since the trigger) to get the
         # start point in compiler time. The following elements need to be considered:
         # - The lead time of the acquisition AWG
         # - The setting of the delay_signal parameter for the acquisition AWG
         # - The time of arrival computed above
```

## laboneq/compiler/scheduler/scheduler.py

```diff
@@ -4,14 +4,15 @@
 from __future__ import annotations
 
 import copy
 import dataclasses
 import itertools
 import logging
 from dataclasses import replace
+from math import ceil
 from typing import (
     TYPE_CHECKING,
     Any,
     Dict,
     FrozenSet,
     Iterable,
     List,
@@ -36,14 +37,15 @@
 from laboneq.compiler.scheduler.loop_iteration_schedule import LoopIterationSchedule
 from laboneq.compiler.scheduler.loop_schedule import LoopSchedule
 from laboneq.compiler.scheduler.match_schedule import MatchSchedule
 from laboneq.compiler.scheduler.oscillator_schedule import (
     OscillatorFrequencyStepSchedule,
     SweptHardwareOscillator,
 )
+from laboneq.compiler.scheduler.parameter_store import ParameterStore
 from laboneq.compiler.scheduler.phase_reset_schedule import PhaseResetSchedule
 from laboneq.compiler.scheduler.preorder_map import calculate_preorder_map
 from laboneq.compiler.scheduler.pulse_phase import calculate_osc_phase
 from laboneq.compiler.scheduler.pulse_schedule import (
     PrecompClearSchedule,
     PulseSchedule,
 )
@@ -101,17 +103,17 @@
         self._TINYSAMPLE = self._schedule_data.TINYSAMPLE
 
         self._system_grid = self.grid(*self._experiment_dao.signals())[1]
         self._root_schedule: Optional[IntervalSchedule] = None
         self._scheduled_sections = {}
 
     @trace("scheduler.run()", {"version": "v2"})
-    def run(self, nt_parameters=None):
+    def run(self, nt_parameters: Optional[ParameterStore] = None):
         if nt_parameters is None:
-            nt_parameters = {}
+            nt_parameters = ParameterStore()
         self._root_schedule = self._schedule_root(nt_parameters)
         _logger.info("Schedule completed")
         for _, (
             warning_generator,
             warning_data,
         ) in self._schedule_data.combined_warnings.items():
             warning_generator(warning_data)
@@ -169,15 +171,17 @@
 
     def event_timing(self, expand_loops=False, max_events: Optional[int] = None):
         if max_events is None:
             # inf is not an int, but a good enough substitute!
             max_events = float("inf")
         return self.generate_event_list(expand_loops, max_events)
 
-    def _schedule_root(self, nt_parameters: Dict[str, float]) -> Optional[RootSchedule]:
+    def _schedule_root(
+        self, nt_parameters: ParameterStore[str, float]
+    ) -> Optional[RootSchedule]:
         root_sections = self._experiment_dao.root_rt_sections()
         if len(root_sections) == 0:
             return None
 
         self._repetition_info = self._resolve_repetition_time(root_sections)
 
         # todo: we do currently not actually support multiple root sections in the DSL.
@@ -191,38 +195,36 @@
 
         root_schedule = RootSchedule(grid=1, signals=signals, children=schedules)  # type: ignore
         root_schedule.calculate_timing(self._schedule_data, 0, False)
 
         for handle, acquire_pulses in self._schedule_data.acquire_pulses.items():
             for a, b in pairwise(acquire_pulses):
                 if assert_valid(a.absolute_start) > assert_valid(b.absolute_start):
-                    _logger.warn(
-                        "Topological order of the acquires for handle"
-                        f" {handle} does not match time order."
+                    _logger.warning(
+                        f"Topological order of the acquires for handle {handle} does"
+                        " not match time order."
                     )
 
         return root_schedule
 
     def _schedule_section(
         self,
         section_id: str,
-        current_parameters: Dict[str, float],
+        current_parameters: ParameterStore[str, float],
     ) -> SectionSchedule:
         """Schedule the given section as the top level.
 
         ``current_parameters`` represents the parameter context from the parent.
         """
 
         try:
             # todo: do not hash the entire current_parameters dict, but just the param values
             # todo: reduce key to those parameters actually required by the section
             return copy.deepcopy(
-                self._scheduled_sections[
-                    (section_id, frozenset(current_parameters.items()))
-                ]
+                self._scheduled_sections[(section_id, current_parameters.frozen())]
             )
         except KeyError:
             pass
 
         section_info = self._experiment_dao.section_info(section_id)
         sweep_parameters = self._experiment_dao.section_parameters(section_id)
         for param in sweep_parameters:
@@ -246,15 +248,15 @@
             )
             schedule = self._schedule_children(
                 section_id, section_info, children_schedules
             )
 
         if schedule.cacheable:
             self._scheduled_sections[
-                (section_id, frozenset(current_parameters.items()))
+                (section_id, current_parameters.frozen())
             ] = schedule
 
         return schedule
 
     def _swept_hw_oscillators(
         self, sweep_parameters: Set[str], signals: Set[str]
     ) -> Dict[str, SweptHardwareOscillator]:
@@ -284,15 +286,15 @@
 
         return oscillator_param_lookup
 
     def _schedule_loop(
         self,
         section_id,
         section_info: SectionInfo,
-        current_parameters: Dict[str, float],
+        current_parameters: ParameterStore[str, float],
         sweep_parameters: List[Dict],
     ) -> LoopSchedule:
         """Schedule the individual iterations of the loop ``section_id``.
 
         Args:
           section_id: The ID of the loop
           section_info: Section info of the loop
@@ -303,66 +305,80 @@
         repetition_mode, repetition_time = (
             (self._repetition_info.mode, self._repetition_info.time)
             if self._repetition_info is not None
             and self._repetition_info.section == section_id
             else (None, None)
         )
 
+        this_chunk_size = section_info.count
+
         children_schedules = []
         for param in sweep_parameters:
             if param["values"] is not None:
                 assert len(param["values"]) >= section_info.count
         # todo: unroll loops that are too short
         if len(sweep_parameters) == 0:
             compressed = section_info.count > 1
             prototype = self._schedule_loop_iteration(
                 section_id,
-                iteration=0,
+                local_iteration=0,
+                global_iteration=0,
                 num_repeats=section_info.count,
                 all_parameters=current_parameters,
                 sweep_parameters=[],
                 swept_hw_oscillators={},
             )
             children_schedules.append(prototype)
         else:
             compressed = False
             signals = self._experiment_dao.section_signals_with_children(section_id)
             swept_hw_oscillators = self._swept_hw_oscillators(
                 {p["id"] for p in sweep_parameters}, signals
             )
 
-            for iteration in range(section_info.count):
+            if section_info.chunk_count > 1:
+                max_chunk_size = ceil(section_info.count / section_info.chunk_count)
+                chunk_index = current_parameters["__pipeline_index"]
+                global_iterations = range(
+                    chunk_index * max_chunk_size,
+                    min((chunk_index + 1) * max_chunk_size, section_info.count),
+                )
+            else:
+                global_iterations = range(section_info.count)
+            this_chunk_size = len(global_iterations)
+
+            for local_iteration, global_iteration in enumerate(global_iterations):
                 new_parameters = {
                     param["id"]: (
-                        param["values"][iteration]
+                        param["values"][global_iteration]
                         if param["values"] is not None
-                        else param["start"] + param["step"] * iteration
+                        else param["start"] + param["step"] * global_iteration
                     )
                     for param in sweep_parameters
                 }
-                all_parameters = {**current_parameters, **new_parameters}
-
-                children_schedules.append(
-                    self._schedule_loop_iteration(
-                        section_id,
-                        iteration,
-                        section_info.count,
-                        all_parameters,
-                        sweep_parameters,
-                        swept_hw_oscillators,
+                with current_parameters.extend(new_parameters):
+                    children_schedules.append(
+                        self._schedule_loop_iteration(
+                            section_id,
+                            local_iteration,
+                            global_iteration,
+                            this_chunk_size,
+                            current_parameters,
+                            sweep_parameters,
+                            swept_hw_oscillators,
+                        )
                     )
-                )
 
         schedule = self._schedule_children(section_id, section_info, children_schedules)
 
         return LoopSchedule.from_section_schedule(
             schedule,
             compressed=compressed,
             sweep_parameters=sweep_parameters,
-            iterations=section_info.count,
+            iterations=this_chunk_size,
             repetition_mode=repetition_mode,
             repetition_time=to_tinysample(repetition_time, self._TINYSAMPLE),
         )
 
     def _schedule_oscillator_frequency_step(
         self,
         swept_hw_oscillators: Dict[str, SweptHardwareOscillator],
@@ -469,25 +485,27 @@
                 reset_sw_oscillators=reset_sw_oscillators,
             )
         ]
 
     def _schedule_loop_iteration(
         self,
         section_id: str,
-        iteration: int,
+        local_iteration: int,
+        global_iteration: int,
         num_repeats: int,
-        all_parameters: Dict[str, float],
+        all_parameters: ParameterStore[str, float],
         sweep_parameters: List[Dict],
         swept_hw_oscillators: Dict[str, SweptHardwareOscillator],
     ) -> LoopIterationSchedule:
         """Schedule a single iteration of a loop.
 
         Args:
             section_id: The loop section.
-            iteration: The iteration to be scheduled
+            local_iteration: The iteration index in the current chunk
+            global_iteration: The global iteration index across all chunks
             num_repeats: The total number of iterations
             all_parameters: The parameter context. Includes the parameter swept in the loop.
             sweep_parameters: The parameters swept in this loop.
             swept_hw_oscillators: The hardware oscillators driven by the sweep parameters.
         """
 
         # add child sections
@@ -498,21 +516,14 @@
 
         for c in children_schedules:
             signals.update(c.signals)
 
         section_info = self._experiment_dao.section_info(section_id)
         hw_osc_reset_signals = set()
         if section_info.reset_oscillator_phase:
-            # todo: This behaves differently than the legacy scheduler.
-            #  The old scheduler would reset ALL devices in the setup.
-            #  Unfortunately, the section grid of the loop (and hence of the phase
-            #  reset) was still defined by the *section signals*. This would potentially
-            #  lead to problems when resetting an otherwise unused device that cannot
-            #  align with the loop grid.
-            #  The new scheduler does not reset devices with unused signals.
             for signal in self._experiment_dao.section_signals_with_children(
                 section_id
             ):
                 osc_info = self._experiment_dao.signal_oscillator(signal)
                 if osc_info is not None and osc_info.hardware:
                     hw_osc_reset_signals.add(signal)
 
@@ -531,15 +542,15 @@
             )
         )
 
         if len(swept_hw_oscillators):
             osc_sweep = [
                 self._schedule_oscillator_frequency_step(
                     swept_hw_oscillators,
-                    iteration,
+                    global_iteration,
                     sweep_parameters,
                     signals,
                     grid,
                     section_id,
                 ),
             ]
         else:
@@ -551,16 +562,16 @@
 
         children_schedules = [*osc_phase_reset, *osc_sweep, *children_schedules]
         schedule = self._schedule_children(
             section_id, section_info, children_schedules, grid
         )
         return LoopIterationSchedule.from_section_schedule(
             schedule,
-            iteration=iteration,
-            shadow=iteration > 0,
+            iteration=local_iteration,
+            shadow=local_iteration > 0,
             num_repeats=num_repeats,
             sweep_parameters=sweep_parameters,
         )
 
     def _schedule_children(
         self, section_id, section_info, children: List[IntervalSchedule], grid=1
     ) -> SectionSchedule:
@@ -612,15 +623,15 @@
 
         return schedule
 
     def _schedule_pulse(
         self,
         pulse: SectionSignalPulse,
         section: str,
-        current_parameters: Dict[str, float],
+        current_parameters: ParameterStore[str, float],
     ) -> PulseSchedule:
 
         # todo: add memoization
 
         grid, _ = self.grid(pulse.signal_id)
 
         def resolve_value_or_parameter(name, default):
@@ -733,15 +744,15 @@
             markers=markers,
         )
 
     def _schedule_match(
         self,
         section_id: str,
         section_info: SectionInfo,
-        current_parameters: Dict[str, float],
+        current_parameters: ParameterStore[str, float],
     ) -> MatchSchedule:
 
         dao = self._schedule_data.experiment_dao
         children_schedules = []
         section_children = dao.direct_section_children(section_id)
         if len(section_children) == 0:
             raise LabOneQException("Must provide at least one branch option")
@@ -808,22 +819,22 @@
             section=section_id,
             play_after=play_after,
             handle=handle,
             local=local,
             compressed_loop_grid=compressed_loop_grid,
         )
 
-    def _schedule_case(self, section_id, current_parameters) -> CaseSchedule:
+    def _schedule_case(
+        self, section_id: str, current_parameters: ParameterStore
+    ) -> CaseSchedule:
         try:
             # todo: do not hash the entire current_parameters dict, but just the param values
             # todo: reduce key to those parameters actually required by the section
             return copy.deepcopy(
-                self._scheduled_sections[
-                    (section_id, frozenset(current_parameters.items()))
-                ]
+                self._scheduled_sections[(section_id, current_parameters.frozen())]
             )
         except KeyError:
             pass
 
         section_info = self._schedule_data.experiment_dao.section_info(section_id)
 
         assert not section_info.has_repeat  # case must not be a loop
@@ -842,15 +853,15 @@
         # We don't want any branches that are empty, but we don't know yet what signals
         # the placeholder should cover. So we defer the creation of placeholders to
         # `_schedule_match()`.
         schedule = self._schedule_children(section_id, section_info, children_schedules)
         schedule = CaseSchedule.from_section_schedule(schedule, state)
         if schedule.cacheable:
             self._scheduled_sections[
-                (section_id, frozenset(current_parameters.items()))
+                (section_id, current_parameters.frozen())
             ] = schedule
 
         return schedule
 
     def _schedule_precomp_clear(self, pulse: PulseSchedule):
         signal = pulse.pulse.signal_id
         _, grid = self.grid(signal)
@@ -860,15 +871,15 @@
         return PrecompClearSchedule(
             grid=grid,
             length=0,
             pulse=pulse,
         )
 
     def _collect_children_schedules(
-        self, section_id: str, parameters: Dict[str, float]
+        self, section_id: str, parameters: ParameterStore[str, float]
     ):
         """Return a list of the schedules of the children"""
         subsection_schedules = []
         section_children = self._schedule_data.experiment_dao.direct_section_children(
             section_id
         )
         for child_section in section_children:
```

## laboneq/compiler/workflow/compiler.py

```diff
@@ -26,29 +26,34 @@
 )
 from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.common.trigger_mode import TriggerMode
 from laboneq.compiler.experiment_access.device_info import DeviceInfo
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
 from laboneq.compiler.scheduler.scheduler import Scheduler
+from laboneq.compiler.workflow import rt_linker
+from laboneq.compiler.workflow.neartime_execution import (
+    NtCompilerExecutor,
+    legacy_execution_program,
+)
 from laboneq.compiler.workflow.precompensation_helpers import (
     compute_precompensation_delays_on_grid,
     compute_precompensations_and_delays,
     precompensation_is_nonzero,
     verify_precompensation_parameters,
 )
-from laboneq.compiler.workflow.realtime_compiler import (
-    RealtimeCompiler,
-    RealtimeCompilerOutput,
-)
+from laboneq.compiler.workflow.realtime_compiler import RealtimeCompiler
 from laboneq.compiler.workflow.recipe_generator import RecipeGenerator
+from laboneq.compiler.workflow.rt_linker import CombinedRealtimeCompilerOutput
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.compiled_experiment import CompiledExperiment
-from laboneq.core.types.enums.acquisition_type import AcquisitionType
+from laboneq.core.types.enums.acquisition_type import AcquisitionType, is_spectroscopy
 from laboneq.core.types.enums.mixer_type import MixerType
+from laboneq.executor.execution_from_experiment import ExecutionFactoryFromExperiment
+from laboneq.executor.executor import Statement
 
 _logger = logging.getLogger(__name__)
 
 
 @dataclass
 class LeaderProperties:
     global_leader: str | None = None
@@ -58,20 +63,20 @@
 
 _AWGMapping = Dict[str, Dict[int, AWGInfo]]
 
 
 class Compiler:
     def __init__(self, settings: Optional[Dict] = None):
         self._osc_numbering = None
-        self._section_grids = {}
         self._experiment_dao: ExperimentDAO = None
+        self._execution: Statement = None
         self._settings = compiler_settings.from_dict(settings)
         self._sampling_rate_tracker: SamplingRateTracker = None
         self._scheduler: Scheduler = None
-        self._rt_compiler_output: RealtimeCompilerOutput = None
+        self._combined_compiler_output: CombinedRealtimeCompilerOutput = None
 
         self._leader_properties = LeaderProperties()
         self._clock_settings: Dict[str, Any] = {}
         self._integration_unit_allocation = None
         self._awgs: _AWGMapping = {}
         self._precompensations: Dict[
             str, Dict[str, Union[Dict[str, Any], float]]
@@ -92,25 +97,26 @@
             ) / self._settings.TINYSAMPLE
             delta = abs(round(num_tinysamples_per_sample) - num_tinysamples_per_sample)
             if delta > 1e-11:
                 raise RuntimeError(
                     f"TINYSAMPLE is not commensurable with sampling rate of {t}, has {num_tinysamples_per_sample} tinysamples per sample, which is not an integer"
                 )
 
-    def print_section_graph(self):
-        self._section_graph_object.log_graph()
-
     def use_experiment(self, experiment):
         if "experiment" in experiment and "setup" in experiment:
             _logger.debug("Processing DSLv3 setup and experiment")
             self._experiment_dao = ExperimentDAO(
                 None, experiment["setup"], experiment["experiment"]
             )
+            self._execution = ExecutionFactoryFromExperiment().make(
+                experiment["experiment"]
+            )
         else:
             self._experiment_dao = ExperimentDAO(experiment)
+            self._execution = legacy_execution_program()
 
     def _analyze_setup(self):
         def get_first_instr_of(device_infos: List[DeviceInfo], type) -> DeviceInfo:
             return next((instr for instr in device_infos if instr.device_type == type))
 
         device_infos = self._experiment_dao.device_infos()
         device_type_list = [i.device_type for i in device_infos]
@@ -231,16 +237,27 @@
 
         rt_compiler = RealtimeCompiler(
             self._experiment_dao,
             self._sampling_rate_tracker,
             self._signal_objects,
             self._settings,
         )
+        executor = NtCompilerExecutor(rt_compiler)
+        executor.run(self._execution)
 
-        self._rt_compiler_output = rt_compiler.run()
+        self._combined_compiler_output = executor.combined_compiler_output()
+        if self._combined_compiler_output is None:
+            # Some of our tests do not have an RT averaging loop, so the RT compiler will
+            # not have been run. For backwards compatibility, we still run it once.
+            _logger.warning("Experiment has no real-time averaging loop")
+            rt_compiler_output = rt_compiler.run()
+
+            self._combined_compiler_output = rt_linker.from_single_run(
+                rt_compiler_output, [0]
+            )
 
     @staticmethod
     def _get_total_rounded_delay(delay, signal_id, device_type, sampling_rate):
         if delay < 0:
             raise RuntimeError(
                 f"Negative signal delay for signal {signal_id} specified."
             )
@@ -306,23 +323,30 @@
                         filter(
                             lambda x: x["device_id"] == device_id
                             and x["awg_nr"] == awg_nr,
                             self._integration_unit_allocation.values(),
                         )
                     )
                 )
-
+                if (
+                    self._experiment_dao.acquisition_type
+                    == AcquisitionType.SPECTROSCOPY_PSD
+                ):
+                    if device_type == device_type.UHFQA:
+                        raise LabOneQException(
+                            "`AcquisitionType` `SPECTROSCOPY_PSD` not allowed on UHFQA"
+                        )
                 integrators_per_signal = (
                     device_type.num_integration_units_per_acquire_signal
                     if self._experiment_dao.acquisition_type
                     in [
                         AcquisitionType.RAW,
-                        AcquisitionType.SPECTROSCOPY,
                         AcquisitionType.INTEGRATION,
                     ]
+                    or is_spectroscopy(self._experiment_dao.acquisition_type)
                     else 1
                 )
 
                 self._integration_unit_allocation[signal_id] = {
                     "device_id": device_id,
                     "awg_nr": awg_nr,
                     "channels": [
@@ -388,15 +412,14 @@
                     # Treat "integration" signal type same as "iq" at AWG level
                     if signal_type == "integration":
                         signal_type = "iq"
                     awg = AWGInfo(
                         device_id=device_id,
                         signal_type=AWGSignalType(signal_type),
                         awg_number=awg_number,
-                        seqc="seq_" + device_id + "_" + str(awg_number) + ".seqc",
                         device_type=device_type,
                         sampling_rate=None,
                     )
                     device_awgs[awg_number] = awg
 
                 awg.signal_channels.append((signal_id, channel))
 
@@ -917,15 +940,15 @@
 
     def _generate_recipe(self):
         recipe_generator = RecipeGenerator()
         recipe_generator.from_experiment(
             self._experiment_dao, self._leader_properties, self._clock_settings
         )
 
-        for output in self.calc_outputs(self._rt_compiler_output.signal_delays):
+        for output in self.calc_outputs(self._combined_compiler_output.signal_delays):
             _logger.debug("Adding output %s", output)
             recipe_generator.add_output(
                 output["device_id"],
                 output["channel"],
                 output["offset"],
                 output["diagonal"],
                 output["off_diagonal"],
@@ -939,15 +962,15 @@
                 output_range_unit=output["range_unit"],
                 port_delay=output["port_delay"],
                 scheduler_port_delay=output["scheduler_port_delay"],
                 marker_mode=output.get("marker_mode"),
                 amplitude=output["amplitude"],
             )
 
-        for input in self.calc_inputs(self._rt_compiler_output.signal_delays):
+        for input in self.calc_inputs(self._combined_compiler_output.signal_delays):
             _logger.debug("Adding input %s", input)
             recipe_generator.add_input(
                 input["device_id"],
                 input["channel"],
                 lo_frequency=input["lo_frequency"],
                 input_range=input["range"],
                 input_range_unit=input["range_unit"],
@@ -967,81 +990,86 @@
                     awg_signals = {c for c, _ in awg.signal_channels}
                 if signal_type == AWGSignalType.MULTI:
                     signal_type = AWGSignalType.IQ
                 # Find the acquire signal from which we read the feedback from and which
                 # is used via a match/state construct for the drive signals of this awg
                 qa_signal_ids = {
                     h.acquire
-                    for h in self._rt_compiler_output.feedback_connections.values()
+                    for h in self._combined_compiler_output.feedback_connections.values()
                     if h.drive.intersection(awg_signals)
                 }
                 if len(qa_signal_ids) > 1:
                     raise Exception(
                         f"The drive signal(s) ({set(awg_signals)}) can only react to "
                         f"one acquire signal for feedback, got {qa_signal_ids}."
                     )
                 recipe_generator.add_awg(
                     device_id=device_id,
                     awg_number=awg.awg_number,
                     signal_type=signal_type.value,
                     qa_signal_id=next(iter(qa_signal_ids), None),
-                    command_table_match_offset=self._rt_compiler_output.command_table_match_offsets.get(
+                    command_table_match_offset=self._combined_compiler_output.command_table_match_offsets.get(
                         awg.key
                     ),
-                    feedback_register=self._rt_compiler_output.feedback_registers.get(
+                    feedback_register=self._combined_compiler_output.feedback_registers.get(
                         awg.key
                     ),
                 )
-                recipe_generator.add_realtime_step(
-                    device_id=device_id,
-                    awg_id=awg.awg_number,
-                    seqc_filename=awg.seqc,
-                    wave_indices_name="",  # todo
-                    nt_loop_indices=[],  # todo
-                )
 
-        assert self._rt_compiler_output is not None
+        for step in self._combined_compiler_output.realtime_steps:
+            recipe_generator.add_realtime_step(
+                device_id=step.device_id,
+                awg_id=step.awg_id,
+                seqc_filename=step.seqc_ref,
+                wave_indices_name=step.wave_indices_ref,
+                nt_loop_indices=step.nt_step,
+            )
+
+        assert self._combined_compiler_output is not None
         recipe_generator.add_oscillator_params(self._experiment_dao)
         recipe_generator.add_integrator_allocations(
             self._integration_unit_allocation,
             self._experiment_dao,
-            self._rt_compiler_output.integration_weights,
+            self._combined_compiler_output.integration_weights,
         )
 
         recipe_generator.add_acquire_lengths(
-            integration_times=self._rt_compiler_output.integration_times
+            integration_times=self._combined_compiler_output.integration_times
         )
 
         recipe_generator.add_measurements(
             self.calc_measurement_map(
-                integration_times=self._rt_compiler_output.integration_times
+                integration_times=self._combined_compiler_output.integration_times
             )
         )
 
         recipe_generator.add_simultaneous_acquires(
-            self._rt_compiler_output.simultaneous_acquires
+            self._combined_compiler_output.simultaneous_acquires
         )
 
         recipe_generator.add_total_execution_time(
-            self._rt_compiler_output.total_execution_time
+            self._combined_compiler_output.total_execution_time
+        )
+        recipe_generator.add_max_step_execution_time(
+            self._combined_compiler_output.max_execution_time_per_step
         )
 
         self._recipe = recipe_generator.recipe()
         _logger.debug("Recipe generation completed")
 
     def compiler_output(self) -> CompiledExperiment:
         return CompiledExperiment(
             recipe=self._recipe,
-            src=self._rt_compiler_output.src,
-            waves=self._rt_compiler_output.waves,
-            wave_indices=self._rt_compiler_output.wave_indices,
-            command_tables=self._rt_compiler_output.command_tables,
-            schedule=self._rt_compiler_output.schedule,
+            src=self._combined_compiler_output.src,
+            waves=list(self._combined_compiler_output.waves.values()),
+            wave_indices=self._combined_compiler_output.wave_indices,
+            command_tables=self._combined_compiler_output.command_tables,
+            schedule=self._combined_compiler_output.schedule,
             experiment_dict=ExperimentDAO.dump(self._experiment_dao),
-            pulse_map=self._rt_compiler_output.pulse_map,
+            pulse_map=self._combined_compiler_output.pulse_map,
         )
 
     def dump_src(self, info=False):
         for src in self.compiler_output().src:
             if info:
                 _logger.info("*** %s", src["filename"])
             else:
@@ -1059,14 +1087,15 @@
     @trace("compiler.run()")
     def run(self, data) -> CompiledExperiment:
         _logger.debug("ES Compiler run")
 
         self.use_experiment(data)
         self._analyze_setup()
         self._process_experiment()
+
         self._generate_recipe()
 
         retval = self.compiler_output()
 
         total_seqc_lines = 0
         for f in retval.src:
             total_seqc_lines += f["text"].count("\n")
@@ -1107,15 +1136,7 @@
         return settings.UHFQA_LEAD_PQSC
     elif device_type == DeviceType.SHFQA:
         return settings.SHFQA_LEAD_PQSC
     elif device_type == DeviceType.SHFSG:
         return settings.SHFSG_LEAD_PQSC
     else:
         raise RuntimeError(f"Unsupported device type {device_type}")
-
-
-def find_obj_by_id(object_list, id):
-    for i in object_list:
-        if i["id"] == id:
-            return i
-
-    return None
```

## laboneq/compiler/workflow/realtime_compiler.py

```diff
@@ -2,45 +2,46 @@
 # SPDX-License-Identifier: Apache-2.0
 
 
 from __future__ import annotations
 
 import logging
 from dataclasses import dataclass
-from typing import Any, Dict, List, Optional
+from typing import Any, Dict, Optional
 
 from laboneq._observability.tracing import trace
 from laboneq.compiler import CodeGenerator, CompilerSettings
 from laboneq.compiler.code_generator import IntegrationTimes
 from laboneq.compiler.code_generator.measurement_calculator import SignalDelays
 from laboneq.compiler.code_generator.sampled_event_handler import FeedbackConnection
 from laboneq.compiler.common.awg_info import AwgKey
 from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.experiment_access import ExperimentDAO
+from laboneq.compiler.scheduler.parameter_store import ParameterStore
 from laboneq.compiler.scheduler.sampling_rate_tracker import SamplingRateTracker
 from laboneq.compiler.scheduler.scheduler import Scheduler
 from laboneq.core.types.compiled_experiment import PulseMapEntry
 
 _logger = logging.getLogger(__name__)
 
 
 @dataclass
 class RealtimeCompilerOutput:
     command_table_match_offsets: Dict[AwgKey, int]
     feedback_connections: Dict[str, FeedbackConnection]
     feedback_registers: Dict[AwgKey, int]
     signal_delays: SignalDelays
-    integration_weights: Any
+    integration_weights: Dict
     integration_times: IntegrationTimes
     simultaneous_acquires: Dict[float, Dict[str, str]]
     total_execution_time: float
-    src: List[Dict[str, Any]]
-    waves: List[Dict[str, Any]]
-    wave_indices: List[Dict[str, Any]]
-    command_tables: List[Dict[str, Any]]
+    src: Dict[AwgKey, Dict[str, Any]]
+    waves: Dict[str, Dict[str, Any]]
+    wave_indices: Dict[AwgKey, Dict[str, Any]]
+    command_tables: Dict[AwgKey, Dict[str, Any]]
     pulse_map: Dict[str, PulseMapEntry]
     schedule: Dict[str, Any]
 
 
 class RealtimeCompiler:
     def __init__(
         self,
@@ -85,17 +86,16 @@
             events,
             {k: self._experiment_dao.pulse(k) for k in self._experiment_dao.pulses()},
         )
         code_generator.gen_waves()
 
         _logger.debug("Code generation completed")
 
-    def run(self):
-        # todo: near-time parameters
-        self._scheduler.run()
+    def run(self, near_time_parameters: Optional[ParameterStore] = None):
+        self._scheduler.run(near_time_parameters)
         self._generate_code()
 
         compiler_output = RealtimeCompilerOutput(
             command_table_match_offsets=self._code_generator.command_table_match_offsets(),
             feedback_connections=self._code_generator.feedback_connections(),
             feedback_registers=self._code_generator.feedback_registers(),
             signal_delays=self._code_generator.signal_delays(),
```

## laboneq/compiler/workflow/recipe_generator.py

```diff
@@ -5,14 +5,15 @@
 
 import logging
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from laboneq.compiler.code_generator.measurement_calculator import IntegrationTimes
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
+from laboneq.core.types.enums.acquisition_type import AcquisitionType
 
 if TYPE_CHECKING:
     from laboneq.compiler.workflow.compiler import LeaderProperties
 
 _logger = logging.getLogger(__name__)
 
 
@@ -101,14 +102,21 @@
             devices.append(
                 {"device_uid": device.id, "driver": device.device_type.upper()}
             )
             initializations.append({"device_uid": device.id, "config": {}})
         self._recipe["devices"] = devices
         self._recipe["experiment"]["initializations"] = initializations
 
+    def add_acquisition_type_from_experiment(self, experiment_dao: ExperimentDAO):
+        self._recipe["experiment"]["acquisition_type"] = (
+            AcquisitionType.INTEGRATION.value
+            if experiment_dao.acquisition_type is None
+            else experiment_dao.acquisition_type.value
+        )
+
     def _find_initialization(self, device_uid):
         for initialization in self._recipe["experiment"]["initializations"]:
             if initialization["device_uid"] == device_uid:
                 return initialization
         return None
 
     def add_connectivity_from_experiment(
@@ -289,26 +297,32 @@
         leader_properties: LeaderProperties,
         clock_settings: Dict[str, Any],
     ):
         self.add_devices_from_experiment(experiment_dao)
         self.add_connectivity_from_experiment(
             experiment_dao, leader_properties, clock_settings
         )
+        self.add_acquisition_type_from_experiment(experiment_dao)
 
     def add_simultaneous_acquires(
         self, simultaneous_acquires: Dict[float, Dict[str, str]]
     ):
         # Keys are of no interest, only order and simultaneity is important
         self._recipe["experiment"]["simultaneous_acquires"] = list(
             simultaneous_acquires.values()
         )
 
     def add_total_execution_time(self, total_execution_time):
         self._recipe["experiment"]["total_execution_time"] = total_execution_time
 
+    def add_max_step_execution_time(self, add_max_step_execution_time):
+        self._recipe["experiment"][
+            "max_step_execution_time"
+        ] = add_max_step_execution_time
+
     def recipe(self):
         return self._recipe
 
     def add_measurements(self, measurement_map):
         for initialization in self._recipe["experiment"]["initializations"]:
             device_uid = initialization["device_uid"]
             if device_uid in measurement_map:
```

## laboneq/contrib/example_helpers/feedback_helper.py

```diff
@@ -91,14 +91,14 @@
                 exp.play(signal="measure0", pulse=measure0)
                 exp.acquire(signal="acquire", handle="data0", kernel=kernel)
                 # with exp.match_local(handle="data0"):
                 #     with exp.case(0):
                 #         exp.play()
                 #     with exp.case(1):
                 #         pass
-                exp.delay(signal="measure0", time=100e-9)
+                exp.delay(signal="measure0", time=1e-6)
             with exp.section():
                 exp.play(signal="measure1", pulse=measure1)
                 exp.acquire(signal="acquire", handle="data1", kernel=kernel)
-                exp.delay(signal="measure1", time=100e-9)
+                exp.delay(signal="measure1", time=1e-6)
 
     return exp
```

## laboneq/controller/communication.py

```diff
@@ -201,19 +201,14 @@
         super().__init__(name)
         self._server_qualifier = server_qualifier
         self._is_valid = False
         self._dataserver_version = LabOneVersion.LATEST
         self._vector_counter = 0
         self.node_monitor = None
 
-        if not server_qualifier.dry_run:
-            from laboneq._token import token_check
-
-            token_check()
-
         ZiApiClass = ziDAQServerEmulator if server_qualifier.dry_run else zi.ziDAQServer
 
         try:
             self._zi_api_object = ZiApiClass(
                 self.server_qualifier.host,
                 self.server_qualifier.port,
                 self.server_qualifier.api_level,
```

## laboneq/controller/controller.py

```diff
@@ -157,20 +157,14 @@
                     initialization, self._recipe_data
                 )
             )
         batch_set(nodes_to_initialize)
 
     @tracing.trace("awg-program-handler")
     def _upload_awg_programs(self, nt_step: NtStepKey):
-        if any(i != 0 for i in nt_step.indices):
-            # Only execute for the 1st NT step
-            # TODO(2K): remove, once NT steps are properly passed in the recipe.
-            # See also commented out condition on selection of realtime_execution_init
-            # element below
-            return
         # Mise en place:
         awg_data: dict[DeviceZI, list[_UploadItem]] = defaultdict(list)
         compile_data: dict[DeviceZI, list[_SeqCCompileItem]] = defaultdict(list)
         recipe_data = self._recipe_data
         acquisition_type = RtExecutionInfo.get_acquisition_type(
             recipe_data.rt_execution_infos
         )
@@ -184,31 +178,29 @@
                 awg_index = awg_obj.awg
                 rt_exec_step = next(
                     (
                         r
                         for r in recipe_data.recipe.experiment.realtime_execution_init
                         if r.device_id == initialization.device_uid
                         and r.awg_id == awg_obj.awg
-                        # and r.nt_step == nt_step # TODO(2K): Enable once ready in recipe
+                        and r.nt_step == nt_step
                     ),
                     None,
                 )
                 if rt_exec_step is None:
                     continue
 
                 seqc_code = device.prepare_seqc(
                     recipe_data.compiled, rt_exec_step.seqc_ref
                 )
-                # TODO(2K): rt_exec_step.wave_indices_ref instead of seqc_ref
                 waves = device.prepare_waves(
-                    recipe_data.compiled, rt_exec_step.seqc_ref
+                    recipe_data.compiled, rt_exec_step.wave_indices_ref
                 )
-                # TODO(2K): rt_exec_step.ct_ref instead of seqc_ref
                 command_table = device.prepare_command_table(
-                    recipe_data.compiled, rt_exec_step.seqc_ref
+                    recipe_data.compiled, rt_exec_step.wave_indices_ref
                 )
 
                 seqc_item = _SeqCCompileItem(
                     awg_index=awg_index,
                 )
 
                 if seqc_code is not None:
@@ -220,15 +212,16 @@
                     _UploadItem(
                         seqc_item=seqc_item,
                         waves=waves,
                         command_table=command_table,
                     )
                 )
 
-        self._awg_compile(compile_data)
+        if compile_data:
+            self._awg_compile(compile_data)
 
         # Upload AWG programs, waveforms, and command tables:
         elf_node_settings: dict[DaqWrapper, list[DaqNodeSetAction]] = defaultdict(list)
         elf_upload_conditions: dict[DaqWrapper, dict[str, Any]] = defaultdict(dict)
         wf_node_settings: dict[DaqWrapper, list[DaqNodeSetAction]] = defaultdict(list)
         for device, items in awg_data.items():
             for item in items:
@@ -395,15 +388,15 @@
         nodes_to_execute = []
 
         for _, device in self._devices.leaders:
             nodes_to_execute.extend(device.collect_execution_nodes())
         batch_set(nodes_to_execute)
 
     def _wait_execution_to_stop(self, acquisition_type: AcquisitionType):
-        min_wait_time = self._recipe_data.recipe.experiment.total_execution_time
+        min_wait_time = self._recipe_data.recipe.experiment.max_step_execution_time
         if min_wait_time is None:
             _logger.warning(
                 "No estimation available for the execution time, assuming 10 sec."
             )
             min_wait_time = 10.0
         elif min_wait_time > 5:  # Only inform about RT executions taking longer than 5s
             _logger.info("Estimated RT execution time: %.2f s.", min_wait_time)
@@ -496,14 +489,16 @@
                 NearTimeRunner(controller=self).run(self._recipe_data.execution)
             _logger.info("Finished near-time execution.")
             for _, device in self._devices.all:
                 device.check_errors()
         finally:
             self._devices.stop_monitor()
 
+        self._devices.on_experiment_end()
+
         if self._run_parameters.shut_down is True:
             self.shut_down()
 
         if self._run_parameters.disconnect is True:
             self.disconnect()
 
     def _find_awg(self, seqc_name: str) -> tuple[str, int]:
```

## laboneq/controller/near_time_runner.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 import traceback
+from contextlib import contextmanager
 from typing import TYPE_CHECKING, Any
 
 from numpy import typing as npt
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
@@ -16,15 +17,15 @@
     batch_set,
 )
 from laboneq.controller.protected_session import ProtectedSession
 from laboneq.controller.recipe_enums import NtStepKey
 from laboneq.controller.util import LabOneQControllerException, SweepParamsTracker
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
-from laboneq.executor.executor import ExecutorBase, LoopingMode, LoopType
+from laboneq.executor.executor import ExecutorBase, LoopFlags, LoopingMode
 
 if TYPE_CHECKING:
     from laboneq.controller.controller import Controller
 
 _logger = logging.getLogger(__name__)
 
 
@@ -65,67 +66,61 @@
         index: int,
         value: float,
         axis_name: str,
         values: npt.ArrayLike,
     ):
         self.sweep_params_tracker.set_param(name, value)
 
-    def for_loop_handler(
-        self, count: int, index: int, loop_type: LoopType, enter: bool
-    ):
-        if enter:
-            self.nt_loop_indices.append(index)
-        else:
-            self.nt_loop_indices.pop()
+    @contextmanager
+    def for_loop_handler(self, count: int, index: int, loop_flags: LoopFlags):
+        self.nt_loop_indices.append(index)
+        yield
+        self.nt_loop_indices.pop()
 
+    @contextmanager
     def rt_handler(
         self,
         count: int,
         uid: str,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-        enter: bool,
     ):
-        if enter:
-            self.controller._initialize_awgs(nt_step=self.nt_step())
-            self.controller._configure_triggers()
-            attribute_value_tracker = (
-                self.controller._recipe_data.attribute_value_tracker
+        self.controller._initialize_awgs(nt_step=self.nt_step())
+        self.controller._configure_triggers()
+        attribute_value_tracker = self.controller._recipe_data.attribute_value_tracker
+        for param in self.sweep_params_tracker.updated_params():
+            attribute_value_tracker.update(
+                param, self.sweep_params_tracker.get_param(param)
             )
-            for param in self.sweep_params_tracker.updated_params():
-                attribute_value_tracker.update(
-                    param, self.sweep_params_tracker.get_param(param)
-                )
-            self.sweep_params_tracker.clear_for_next_step()
+        self.sweep_params_tracker.clear_for_next_step()
 
-            nt_sweep_nodes: list[DaqNodeAction] = []
-            for device_uid, device in self.controller._devices.all:
-                nt_sweep_nodes.extend(
-                    device.collect_prepare_nt_step_nodes(
-                        attribute_value_tracker.device_view(device_uid),
-                        self.controller._recipe_data,
-                    )
+        nt_sweep_nodes: list[DaqNodeAction] = []
+        for device_uid, device in self.controller._devices.all:
+            nt_sweep_nodes.extend(
+                device.collect_prepare_nt_step_nodes(
+                    attribute_value_tracker.device_view(device_uid),
+                    self.controller._recipe_data,
                 )
-
-            step_prepare_nodes = self.controller._prepare_rt_execution(
-                rt_section_uid=uid
             )
 
-            batch_set([*self.user_set_nodes, *nt_sweep_nodes, *step_prepare_nodes])
-            self.user_set_nodes.clear()
+        step_prepare_nodes = self.controller._prepare_rt_execution(rt_section_uid=uid)
 
-            for retry in range(3):  # Up to 3 retries
-                if retry > 0:
-                    _logger.info("Step retry %s of 3...", retry + 1)
-                    batch_set(step_prepare_nodes)
-                try:
-                    self.controller._execute_one_step(acquisition_type)
-                    self.controller._read_one_step_results(
-                        nt_step=self.nt_step(), rt_section_uid=uid
-                    )
-                    break
-                except LabOneQControllerException:  # TODO(2K): introduce "hard" controller exceptions
-                    self.controller._report_step_error(
-                        nt_step=self.nt_step(),
-                        rt_section_uid=uid,
-                        message=traceback.format_exc(),
-                    )
+        batch_set([*self.user_set_nodes, *nt_sweep_nodes, *step_prepare_nodes])
+        self.user_set_nodes.clear()
+
+        for retry in range(3):  # Up to 3 retries
+            if retry > 0:
+                _logger.info("Step retry %s of 3...", retry + 1)
+                batch_set(step_prepare_nodes)
+            try:
+                self.controller._execute_one_step(acquisition_type)
+                self.controller._read_one_step_results(
+                    nt_step=self.nt_step(), rt_section_uid=uid
+                )
+                break
+            except LabOneQControllerException:  # TODO(2K): introduce "hard" controller exceptions
+                self.controller._report_step_error(
+                    nt_step=self.nt_step(),
+                    rt_section_uid=uid,
+                    message=traceback.format_exc(),
+                )
+        yield
```

## laboneq/controller/recipe_1_4_0.py

```diff
@@ -4,15 +4,21 @@
 from __future__ import annotations
 
 from dataclasses import dataclass, field
 from typing import Any
 
 from marshmallow import EXCLUDE, Schema, fields, post_load
 
-from .recipe_enums import NtStepKey, RefClkType, SignalType, TriggeringMode
+from .recipe_enums import (
+    AcquisitionType,
+    NtStepKey,
+    RefClkType,
+    SignalType,
+    TriggeringMode,
+)
 from .util import LabOneQControllerException
 
 
 class QCCSSchema(Schema):
     @post_load
     def from_json(self, data, **kwargs):
         return self.Data(**data)
@@ -244,14 +250,30 @@
     def _serialize(self, value, attr, obj, **kwargs):
         return value.name
 
     def _deserialize(self, value, attr, data, **kwargs):
         return TriggeringMode[value.upper()]
 
 
+class AcquisitionTypeField(fields.Field):
+    def __init__(self, *args, **kwargs) -> None:
+        kwargs["allow_none"] = True
+        super().__init__(*args, **kwargs)
+
+    def _serialize(self, value, attr, obj, **kwargs):
+        if value is None:
+            return None
+        return value.name
+
+    def _deserialize(self, value, attr, data, **kwargs):
+        if value is None:
+            return None
+        return AcquisitionType[value.upper()]
+
+
 class Config(QCCSSchema):
     class Meta:
         fields = (
             "repetitions",
             "reference_clock",
             "holdoff",
             "triggering_mode",
@@ -401,40 +423,46 @@
             "initializations",
             "realtime_execution_init",
             "oscillator_params",
             "integrator_allocations",
             "acquire_lengths",
             "simultaneous_acquires",
             "total_execution_time",
+            "max_step_execution_time",
+            "acquisition_type",
         )
         ordered = True
 
     @dataclass
     class Data:
         initializations: list[Initialization.Data]
         realtime_execution_init: list[RealtimeExecutionInit.Data]
         oscillator_params: list[OscillatorParam.Data] = field(default_factory=list)
         integrator_allocations: list[IntegratorAllocation.Data] = field(
             default_factory=list
         )
         acquire_lengths: list[AcquireLength.Data] = field(default_factory=list)
         simultaneous_acquires: list[dict[str, str]] = field(default_factory=list)
         total_execution_time: float = None
+        max_step_execution_time: float = None
+        acquisition_type: AcquisitionType = AcquisitionTypeField()
 
     initializations = fields.List(fields.Nested(Initialization))
     realtime_execution_init = fields.List(fields.Nested(RealtimeExecutionInit))
     oscillator_params = fields.List(fields.Nested(OscillatorParam), required=False)
     integrator_allocations = fields.List(
         fields.Nested(IntegratorAllocation), required=False
     )
     acquire_lengths = fields.List(fields.Nested(AcquireLength), required=False)
     simultaneous_acquires = fields.List(
         fields.Dict(fields.Str(), fields.Str()), required=False, allow_none=True
     )
     total_execution_time = fields.Float(required=False, allow_none=True)
+    max_step_execution_time = fields.Float(required=False, allow_none=True)
+    acquisition_type = AcquisitionTypeField()
 
 
 class Recipe(QCCSSchema):
     class Meta:
         unknown = EXCLUDE
         fields = ("line_endings", "experiment", "servers", "devices")
         ordered = False
```

## laboneq/controller/recipe_enums.py

```diff
@@ -24,7 +24,16 @@
     DESKTOP_DIO_FOLLOWER = 4
     INTERNAL_FOLLOWER = 5
 
 
 @dataclass(frozen=True)
 class NtStepKey:
     indices: tuple[int]
+
+
+class AcquisitionType(Enum):
+    INTEGRATION_TRIGGER = "integration_trigger"
+    SPECTROSCOPY_IQ = "spectroscopy"
+    SPECTROSCOPY_PSD = "spectroscopy_psd"
+    SPECTROSCOPY = SPECTROSCOPY_IQ
+    DISCRIMINATION = "discrimination"
+    RAW = "raw"
```

## laboneq/controller/recipe_processor.py

```diff
@@ -1,13 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from collections import defaultdict
+from contextlib import contextmanager
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Optional, Set, Tuple, Union
 
 import numpy as np
 from numpy import typing as npt
 
 from laboneq.controller.attribute_value_tracker import (
@@ -17,16 +18,16 @@
 )
 from laboneq.controller.util import LabOneQControllerException
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 from laboneq.executor.execution_from_experiment import ExecutionFactoryFromExperiment
 from laboneq.executor.executor import (
     ExecutorBase,
+    LoopFlags,
     LoopingMode,
-    LoopType,
     Sequence,
     Statement,
 )
 
 from .recipe_1_4_0 import IO
 from .recipe_1_4_0 import Experiment as RecipeExperiment
 from .recipe_1_4_0 import Initialization, Recipe
@@ -244,14 +245,15 @@
 
         self.result_shapes: HandleResultShapes = {}
         self.rt_execution_infos: RtExecutionInfos = {}
 
         self._loop_stack: List[_LoopStackEntry] = []
         self._current_rt_uid: str = None
         self._current_rt_info: RtExecutionInfo = None
+        self._pipeline_index: int | None = None
 
     def _single_shot_axis(self) -> npt.ArrayLike:
         return np.linspace(
             0, self._current_rt_info.averages - 1, self._current_rt_info.averages
         )
 
     def acquire_handler(self, handle: str, signal: str, parent_uid: str):
@@ -262,102 +264,102 @@
             self._current_rt_info.averaging_mode == AveragingMode.SINGLE_SHOT
         )
         shape = [
             loop.count
             for loop in self._loop_stack
             if not loop.is_averaging or single_shot_cyclic
         ]
-        # if single_shot_sequential:
-        #     shape.append(self.current_rt_info.averages)
         known_shape = self.result_shapes.get(handle)
         if known_shape is None:
             axis_name = [
                 loop.axis_name
                 for loop in self._loop_stack
                 if not loop.is_averaging or single_shot_cyclic
             ]
             axis = [
                 loop.axis
                 for loop in self._loop_stack
                 if not loop.is_averaging or single_shot_cyclic
             ]
-            # if single_shot_sequential:
-            #     axis_name.append(self.current_rt_uid)
-            #     axis.append(self._single_shot_axis())
             self.result_shapes[handle] = HandleResultShape(
                 base_shape=shape, base_axis_name=axis_name, base_axis=axis
             )
         elif known_shape.base_shape == shape:
             known_shape.additional_axis += 1
         else:
             raise LabOneQControllerException(
                 f"Multiple acquire events with the same handle ('{handle}') and different result shapes are not allowed."
             )
 
     def set_sw_param_handler(
         self, name: str, index: int, value: float, axis_name: str, values: npt.ArrayLike
     ):
+        if name == "__pipeline_index":
+            self._pipeline_index = value
+            return
         self._loop_stack[-1].axis_names.append(name if axis_name is None else axis_name)
         self._loop_stack[-1].axis_points.append(values)
 
-    def for_loop_handler(
-        self, count: int, index: int, loop_type: LoopType, enter: bool
-    ):
-        if enter:
-            is_averaging = loop_type in [LoopType.RT_AVERAGE, LoopType.AVERAGE]
-            self._loop_stack.append(
-                _LoopStackEntry(count=count, is_averaging=is_averaging)
+    @contextmanager
+    def for_loop_handler(self, count: int, index: int, loop_flags: LoopFlags):
+        if loop_flags & LoopFlags.PIPELINE:
+            yield
+            self._pipeline_index = None
+            return
+
+        is_averaging = bool(loop_flags & LoopFlags.AVERAGE)
+        self._loop_stack.append(_LoopStackEntry(count=count, is_averaging=is_averaging))
+        if is_averaging:
+            single_shot_cyclic = (
+                self._current_rt_info.averaging_mode == AveragingMode.SINGLE_SHOT
             )
-            if is_averaging:
-                single_shot_cyclic = (
-                    self._current_rt_info.averaging_mode == AveragingMode.SINGLE_SHOT
-                )
-                # TODO(2K): single_shot_sequential
-                if single_shot_cyclic:
-                    self._loop_stack[-1].axis_names.append(self._current_rt_uid)
-                    self._loop_stack[-1].axis_points.append(self._single_shot_axis())
-        else:
-            self._loop_stack.pop()
+            if single_shot_cyclic:
+                self._loop_stack[-1].axis_names.append(self._current_rt_uid)
+                self._loop_stack[-1].axis_points.append(self._single_shot_axis())
+
+        yield
 
+        self._loop_stack.pop()
+
+    @contextmanager
     def rt_handler(
         self,
         count: int,
         uid: str,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-        enter: bool,
     ):
-        if enter:
-            if averaging_mode != AveragingMode.SINGLE_SHOT:
-                max_hw_averages = (
-                    pow(2, 15)
-                    if acquisition_type == AcquisitionType.RAW
-                    else pow(2, 17)
-                )
-                if count > max_hw_averages:
-                    raise LabOneQControllerException(
-                        f"Maximum number of hardware averages is {max_hw_averages}, but {count} was given"
-                    )
-
-            self._current_rt_uid = uid
-            self._current_rt_info = self.rt_execution_infos.setdefault(
-                uid,
-                RtExecutionInfo(
-                    averages=count,
-                    averaging_mode=averaging_mode,
-                    acquisition_type=acquisition_type,
-                ),
+
+        if averaging_mode != AveragingMode.SINGLE_SHOT:
+            max_hw_averages = (
+                pow(2, 15) if acquisition_type == AcquisitionType.RAW else pow(2, 17)
             )
-        else:
-            if self._current_rt_info is None:
+            if count > max_hw_averages:
                 raise LabOneQControllerException(
-                    "Nested 'acquire_loop_rt' are not allowed."
+                    f"Maximum number of hardware averages is {max_hw_averages}, but {count} was given"
                 )
-            self._current_rt_uid = None
-            self._current_rt_info = None
+
+        self._current_rt_uid = uid
+        self._current_rt_info = self.rt_execution_infos.setdefault(
+            uid,
+            RtExecutionInfo(
+                averages=count,
+                averaging_mode=averaging_mode,
+                acquisition_type=acquisition_type,
+            ),
+        )
+
+        yield
+
+        if self._current_rt_info is None:
+            raise LabOneQControllerException(
+                "Nested 'acquire_loop_rt' are not allowed."
+            )
+        self._current_rt_uid = None
+        self._current_rt_info = None
 
 
 def _calculate_result_shapes(
     execution: Statement,
 ) -> Tuple[HandleResultShapes, RtExecutionInfos]:
     # Skip for recipe-only execution (used in older tests)
     if execution is None:
@@ -519,20 +521,22 @@
 
     device_settings: DeviceSettings = defaultdict(DeviceRecipeData)
     for initialization in recipe.experiment.initializations:
         device_settings[initialization.device_uid] = DeviceRecipeData(
             iq_settings=_pre_process_iq_settings_hdawg(initialization)
         )
 
+    # todo: remove legacy code
     if hasattr(compiled_experiment, "execution"):
         execution = compiled_experiment.execution
     else:
         execution = ExecutionFactoryFromExperiment().make(
             compiled_experiment.experiment
         )
+
     result_shapes, rt_execution_infos = _calculate_result_shapes(execution)
     awg_configs = _calculate_awg_configs(rt_execution_infos, recipe.experiment)
     attribute_value_tracker, oscillator_ids = _pre_process_attributes(
         recipe.experiment, devices
     )
 
     recipe_data = RecipeData(
```

## laboneq/controller/devices/device_collection.py

```diff
@@ -261,14 +261,20 @@
         for device in self._devices.values():
             device.shut_down()
 
     def free_allocations(self):
         for device in self._devices.values():
             device.free_allocations()
 
+    def on_experiment_end(self):
+        all_actions: list[DaqNodeSetAction] = []
+        for device in self._devices.values():
+            all_actions.extend(device.on_experiment_end())
+        batch_set(all_actions)
+
     def start_monitor(self):
         for daq in self._daqs.values():
             daq.node_monitor.stop()
             daq.node_monitor.start()
 
     def flush_monitor(self):
         for daq in self._daqs.values():
```

## laboneq/controller/devices/device_pqsc.py

```diff
@@ -68,15 +68,15 @@
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
     ) -> list[DaqNodeAction]:
         return []
 
     def configure_feedback(self, recipe_data: RecipeData) -> list[DaqNodeAction]:
         # TODO(2K): Code duplication with Controller._wait_execution_to_stop
         # Make this mandatory in the recipe instead.
-        min_wait_time = recipe_data.recipe.experiment.total_execution_time
+        min_wait_time = recipe_data.recipe.experiment.max_step_execution_time
         if min_wait_time is None:
             min_wait_time = 10.0
         # This is required because PQSC is only receiving the feedback events
         # during the holdoff time, even for a single trigger.
         feedback_actions = [
             DaqNodeSetAction(
                 self.daq, f"/{self.serial}/execution/holdoff", min_wait_time
```

## laboneq/controller/devices/device_shfqa.py

```diff
@@ -38,15 +38,15 @@
     AwgKey,
     DeviceRecipeData,
     RecipeData,
     RtExecutionInfo,
     get_wave,
 )
 from laboneq.controller.util import LabOneQControllerException
-from laboneq.core.types.enums.acquisition_type import AcquisitionType
+from laboneq.core.types.enums.acquisition_type import AcquisitionType, is_spectroscopy
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 
 _logger = logging.getLogger(__name__)
 
 INTERNAL_TRIGGER_CHANNEL = 1024  # PQSC style triggering on the SHFSG/QC
 SOFTWARE_TRIGGER_CHANNEL = 8  # Software triggering on the SHFQA
 
@@ -157,21 +157,34 @@
                         f"/{self.serial}/qachannels/{ch}/output/on",
                         0,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
                 )
         return channels_to_disable
 
+    def on_experiment_end(self):
+        nodes = super().on_experiment_end()
+        return [
+            *nodes,
+            # in CW spectroscopy mode, turn off the tone
+            DaqNodeSetAction(
+                self._daq,
+                f"/{self.serial}/qachannels/*/spectroscopy/envelope/enable",
+                1,
+            ),
+        ]
+
     def _nodes_to_monitor_impl(self) -> list[str]:
         nodes = super()._nodes_to_monitor_impl()
         for awg in range(self._get_num_awgs()):
             nodes.extend(
                 [
                     f"/{self.serial}/qachannels/{awg}/generator/enable",
                     f"/{self.serial}/qachannels/{awg}/generator/ready",
+                    f"/{self.serial}/qachannels/{awg}/spectroscopy/psd/enable",
                     f"/{self.serial}/qachannels/{awg}/spectroscopy/result/enable",
                     f"/{self.serial}/qachannels/{awg}/readout/result/enable",
                 ]
             )
         return nodes
 
     def configure_acquisition(
@@ -191,15 +204,15 @@
                 awg_key,
                 awg_config,
                 integrator_allocations,
                 averages,
                 average_mode,
             ),
             *self._configure_spectroscopy(
-                acquisition_type == AcquisitionType.SPECTROSCOPY,
+                acquisition_type,
                 awg_key.awg_index,
                 awg_config.result_length,
                 averages,
                 average_mode,
             ),
             *self._configure_scope(
                 enable=acquisition_type == AcquisitionType.RAW,
@@ -253,15 +266,18 @@
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/qachannels/{channel}/readout/result/enable",
                         0,
                     ),
                 ]
             )
-            if acquisition_type == AcquisitionType.DISCRIMINATION:
+            if acquisition_type in [
+                AcquisitionType.INTEGRATION,
+                AcquisitionType.DISCRIMINATION,
+            ]:
                 for integrator in integrator_allocations:
                     if (
                         integrator.device_id != awg_key.device_uid
                         or integrator.signal_id not in awg_config.acquire_signals
                     ):
                         continue
                     assert len(integrator.channels) == 1
@@ -281,22 +297,22 @@
                 1 if enable else 0,
             )
         )
         return nodes_to_initialize_readout
 
     def _configure_spectroscopy(
         self,
-        enable: bool,
+        acq_type: AcquisitionType,
         channel: int,
         result_length: int,
         averages: int,
         average_mode: int,
     ):
         nodes_to_initialize_spectroscopy = []
-        if enable:
+        if is_spectroscopy(acq_type):
             nodes_to_initialize_spectroscopy.extend(
                 [
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/qachannels/{channel}/spectroscopy/result/length",
                         result_length,
                     ),
@@ -308,24 +324,39 @@
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/qachannels/{channel}/spectroscopy/result/mode",
                         average_mode,
                     ),
                     DaqNodeSetAction(
                         self._daq,
+                        f"/{self.serial}/qachannels/{channel}/spectroscopy/psd/enable",
+                        0,
+                    ),
+                    DaqNodeSetAction(
+                        self._daq,
                         f"/{self.serial}/qachannels/{channel}/spectroscopy/result/enable",
                         0,
                     ),
                 ]
             )
+
+        if acq_type == AcquisitionType.SPECTROSCOPY_PSD:
+            nodes_to_initialize_spectroscopy.append(
+                DaqNodeSetAction(
+                    self._daq,
+                    f"/{self.serial}/qachannels/{channel}/spectroscopy/psd/enable",
+                    1,
+                ),
+            )
+
         nodes_to_initialize_spectroscopy.append(
             DaqNodeSetAction(
                 self._daq,
                 f"/{self.serial}/qachannels/{channel}/spectroscopy/result/enable",
-                1 if enable else 0,
+                1 if is_spectroscopy(acq_type) else 0,
             )
         )
         return nodes_to_initialize_spectroscopy
 
     def _configure_scope(
         self, enable: bool, channel: int, averages: int, acquire_length: int
     ):
@@ -433,15 +464,15 @@
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
     ) -> dict[str, Any]:
         conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/qachannels/{awg_index}/generator/enable"] = 0
-            if acquisition_type == AcquisitionType.SPECTROSCOPY:
+            if is_spectroscopy(acquisition_type):
                 conditions[
                     f"/{self.serial}/qachannels/{awg_index}/spectroscopy/result/enable"
                 ] = 0
             elif acquisition_type in [
                 AcquisitionType.INTEGRATION,
                 AcquisitionType.DISCRIMINATION,
             ]:
@@ -592,15 +623,15 @@
                 0.0
                 if input_scheduler_port_delay is None
                 else input_scheduler_port_delay + (input_port_delay or 0.0)
             )
             set_input = input_updated and input_scheduler_port_delay is not None
 
             base_channel_path = f"/{self.serial}/qachannels/{ch}"
-            if acquisition_type == AcquisitionType.SPECTROSCOPY:
+            if is_spectroscopy(acquisition_type):
                 output_delay_path = f"{base_channel_path}/spectroscopy/envelope/delay"
                 meas_delay_path = f"{base_channel_path}/spectroscopy/delay"
             else:
                 output_delay_path = f"{base_channel_path}/generator/delay"
                 meas_delay_path = f"{base_channel_path}/readout/integration/delay"
                 measurement_delay += output_delay
                 set_input = set_input or set_output
@@ -645,34 +676,34 @@
         self,
         filename: str,
         waveform: npt.ArrayLike,
         awg_index: int,
         wave_index: int,
         acquisition_type: AcquisitionType,
     ):
-        assert acquisition_type != AcquisitionType.SPECTROSCOPY or wave_index == 0
+        assert not is_spectroscopy(acquisition_type) or wave_index == 0
         return DaqNodeSetAction(
             self._daq,
             f"/{self.serial}/qachannels/{awg_index}/spectroscopy/envelope/wave"
-            if acquisition_type == AcquisitionType.SPECTROSCOPY
+            if is_spectroscopy(acquisition_type)
             else f"/{self.serial}/qachannels/{awg_index}/generator/waveforms/{wave_index}/wave",
             waveform,
             filename=filename,
             caching_strategy=CachingStrategy.NO_CACHE,
         )
 
     def prepare_upload_all_binary_waves(
         self,
         awg_index,
         waves: list[tuple[str, npt.ArrayLike]],
         acquisition_type: AcquisitionType,
     ):
         waves_upload: list[DaqNodeSetAction] = []
         has_spectroscopy_envelope = False
-        if acquisition_type == AcquisitionType.SPECTROSCOPY:
+        if is_spectroscopy(acquisition_type):
             if len(waves) > 1:
                 raise LabOneQControllerException(
                     f"{self.dev_repr}: Only one envelope waveform per channel is possible in "
                     f"spectroscopy mode. Check play commands for channel {awg_index}."
                 )
             max_len = 65536
             for wave_index, (filename, waveform) in enumerate(waves):
@@ -822,15 +853,15 @@
         )
 
         for measurement in initialization.measurements:
             nodes_to_initialize_measurement.append(
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/qachannels/{measurement.channel}/mode",
-                    0 if acquisition_type == AcquisitionType.SPECTROSCOPY else 1,
+                    0 if is_spectroscopy(acquisition_type) else 1,
                 )
             )
 
             dev_input = next(
                 (
                     inp
                     for inp in initialization.inputs
@@ -842,15 +873,15 @@
                 (
                     output
                     for output in initialization.outputs
                     if output.channel == measurement.channel
                 ),
                 None,
             )
-            if acquisition_type == AcquisitionType.SPECTROSCOPY:
+            if is_spectroscopy(acquisition_type):
                 nodes_to_initialize_measurement.extend(
                     self._configure_spectroscopy_mode_nodes(dev_input, measurement)
                 )
             else:
                 nodes_to_initialize_measurement.extend(
                     self._configure_readout_mode_nodes(
                         dev_input,
@@ -952,15 +983,15 @@
         result_indices: list[int],
         num_results: int,
         hw_averages: int,
     ):
         assert len(result_indices) == 1
         result_path = f"/{self.serial}/qachannels/{channel}/" + (
             "spectroscopy/result/data/wave"
-            if acquisition_type == AcquisitionType.SPECTROSCOPY
+            if is_spectroscopy(acquisition_type)
             else f"readout/result/data/{result_indices[0]}/wave"
         )
         attempts = 3  # Hotfix HBAR-949
         while attempts > 0:
             attempts -= 1
             # @TODO(andreyk): replace the raw daq reply parsing on site here and hide it
             # inside Communication class
@@ -987,19 +1018,15 @@
         node_data = self._daq.get_raw(result_path_ch)
         data = node_data[result_path_ch][0]["vector"][0:num_results]
         return data
 
     def check_results_acquired_status(
         self, channel, acquisition_type: AcquisitionType, result_length, hw_averages
     ):
-        unit = (
-            "spectroscopy"
-            if acquisition_type == AcquisitionType.SPECTROSCOPY
-            else "readout"
-        )
+        unit = "spectroscopy" if is_spectroscopy(acquisition_type) else "readout"
         results_acquired_path = (
             f"/{self.serial}/qachannels/{channel}/{unit}/result/acquired"
         )
         batch_get_results = self._daq.batch_get(
             [
                 DaqNodeGetAction(
                     self._daq,
@@ -1035,14 +1062,22 @@
                 0,
                 caching_strategy=CachingStrategy.NO_CACHE,
             )
         )
         reset_nodes.append(
             DaqNodeSetAction(
                 self._daq,
+                f"/{self.serial}/qachannels/*/spectroscopy/psd/enable",
+                0,
+                caching_strategy=CachingStrategy.NO_CACHE,
+            )
+        )
+        reset_nodes.append(
+            DaqNodeSetAction(
+                self._daq,
                 f"/{self.serial}/qachannels/*/spectroscopy/result/enable",
                 0,
                 caching_strategy=CachingStrategy.NO_CACHE,
             )
         )
         reset_nodes.append(
             DaqNodeSetAction(
```

## laboneq/controller/devices/device_uhfqa.py

```diff
@@ -488,15 +488,18 @@
                                     integrator_allocation.weights + "_q.wave",
                                     recipe_data.compiled.waves,
                                 )
                             ),
                         ),
                     ]
                 )
-                if acquisition_type == AcquisitionType.DISCRIMINATION:
+                if acquisition_type in [
+                    AcquisitionType.INTEGRATION,
+                    AcquisitionType.DISCRIMINATION,
+                ]:
                     nodes_to_set_for_standard_mode.extend(
                         [
                             DaqNodeSetAction(
                                 self._daq,
                                 f"/{self.serial}/qas/0/thresholds/"
                                 f"{integration_unit_index}/correlation/enable",
                                 0,
@@ -546,15 +549,15 @@
 
     def collect_awg_before_upload_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
     ):
         acquisition_type = RtExecutionInfo.get_acquisition_type(
             recipe_data.rt_execution_infos
         )
-        if acquisition_type == AcquisitionType.SPECTROSCOPY:
+        if acquisition_type == AcquisitionType.SPECTROSCOPY_IQ:
             return self._configure_spectroscopy_mode_nodes()
         else:
             return self._configure_standard_mode_nodes(
                 acquisition_type, initialization.device_uid, recipe_data
             )
 
     def collect_awg_after_upload_nodes(self, initialization: Initialization.Data):
@@ -627,15 +630,15 @@
             )
 
         triggering_mode = initialization.config.triggering_mode
 
         if triggering_mode == TriggeringMode.DIO_FOLLOWER or triggering_mode is None:
             nodes_to_configure_triggers.extend(
                 [
-                    DaqNodeSetAction(self._daq, f"/{self.serial}/dios/0/mode", 2),
+                    DaqNodeSetAction(self._daq, f"/{self.serial}/dios/0/mode", 4),
                     DaqNodeSetAction(self._daq, f"/{self.serial}/dios/0/drive", 0x3),
                     DaqNodeSetAction(self._daq, f"/{self.serial}/dios/0/extclk", 0x2),
                 ]
             )
         elif triggering_mode == TriggeringMode.DESKTOP_DIO_FOLLOWER:
             nodes_to_configure_triggers.extend(
                 [
```

## laboneq/controller/devices/device_zi.py

```diff
@@ -368,14 +368,18 @@
         return []
 
     def shut_down(self):
         _logger.debug(
             "%s: Turning off signal output (stub, not implemented).", self.dev_repr
         )
 
+    def on_experiment_end(self):
+        nodes = []
+        return nodes
+
     def free_allocations(self):
         self._allocated_oscs.clear()
         self._allocated_awgs.clear()
 
     def _nodes_to_monitor_impl(self):
         nodes = []
         nodes.extend([node.path for node in self.clock_source_control_nodes()])
```

## laboneq/core/types/enums/acquisition_type.py

```diff
@@ -1,27 +1,51 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from enum import Enum
+from typing import Any, Union
 
 
 class AcquisitionType(Enum):
     """Acquisition type
 
     The following acquisition types supported:
+
         INTEGRATION:
             Returns acquired signal after demodulation and integration, using weighting vectors (kernel) up to 4096 points.
 
-        SPECTROSCOPY:
+        SPECTROSCOPY_IQ:
             Returns acquired signal after demodulation and integration, using oscillator frequency (not limited to 4096 points).
 
+        SPECTROSCOPY_PSD:
+            Power Spectral density (PSD) mode. PSD is calculated on the hardware.
+
+        SPECTROSCOPY:
+            Same as `SPECTROSCOPY_IQ`.
+
         DISCRIMINATION:
             Returns the list of qubit states determined from demodulated and integrated signal after thresholding.
 
         RAW:
             Returns raw data after ADC up to 4096 samples. Only a single raw acquire event within an averaging loop per experiment is allowed.
+
+    .. versionchanged:: 2.9
+
+        Added `SPECTROSCOPY_IQ` (same as `SPECTROSCOPY`)
+
+        Added `SPECTROSCOPY_PSD` for PSD Spectroscopy mode.
     """
 
     INTEGRATION = "integration_trigger"
-    SPECTROSCOPY = "spectroscopy"
+    SPECTROSCOPY_IQ = "spectroscopy"
+    SPECTROSCOPY_PSD = "spectroscopy_psd"
+    SPECTROSCOPY = SPECTROSCOPY_IQ
     DISCRIMINATION = "discrimination"
     RAW = "RAW"
+
+
+def is_spectroscopy(obj: Union[AcquisitionType, Any]) -> bool:
+    return obj in (
+        AcquisitionType.SPECTROSCOPY,
+        AcquisitionType.SPECTROSCOPY_IQ,
+        AcquisitionType.SPECTROSCOPY_PSD,
+    )
```

## laboneq/data/calibration/__init__.py

```diff
@@ -34,14 +34,20 @@
 
 #
 # Data Classes
 #
 
 
 @dataclass
+class BounceCompensation:
+    delay: float = None
+    amplitude: float = None
+
+
+@dataclass
 class Calibration:
     calibration_items: Dict = field(default_factory=dict)
 
 
 @dataclass
 class MixerCalibration:
     uid: str = None
@@ -51,20 +57,14 @@
 
 @dataclass
 class Signal:
     uid: str = None
 
 
 @dataclass
-class BounceCompensation:
-    delay: float = None
-    amplitude: float = None
-
-
-@dataclass
 class ExponentialCompensation:
     timeconstant: float = None
     amplitude: float = None
 
 
 @dataclass
 class FIRCompensation:
@@ -75,15 +75,15 @@
 class HighPassCompensation:
     timeconstant: float = None
 
 
 @dataclass
 class Oscillator:
     uid: str = None
-    frequency: Any = None
+    frequency: Optional[Any] = None
     modulation_type: ModulationType = None
     carrier_type: CarrierType = None
 
 
 @dataclass
 class Precompensation:
     uid: str = None
```

## laboneq/data/compilation_job/__init__.py

```diff
@@ -85,14 +85,15 @@
 
 @dataclass
 class SectionInfo:
     uid: str = None
     length: float = None
     alignment: SectionInfoAlignment = None
     count: int = None
+    chunk_count: int = None
     execution_type: str = None
     averaging_type: str = None
     children: List[Any] = field(default_factory=list)
     on_system_grid: bool = None
     trigger: Dict = field(default_factory=dict)
```

## laboneq/data/experiment_description/__init__.py

```diff
@@ -72,15 +72,15 @@
     local_oscillator: Optional[Any] = None
     mixer_calibration: Optional[Any] = None
     precompensation: Optional[Any] = None
     port_delay: Optional[Any] = None
     port_mode: Optional[Any] = None
     delay_signal: Optional[Any] = None
     voltage_offset: Optional[Any] = None
-    range: Any = None
+    range: Optional[Any] = None
     threshold: Optional[Any] = None
     amplitude: Optional[Any] = None
 
 
 @dataclass
 class Operation:
     uid: str = None
```

## laboneq/data/experiment_results/__init__.py

```diff
@@ -2,15 +2,15 @@
 # SPDX-License-Identifier: Apache-2.0
 
 
 # __init__.py of 'experiment_results' package - autogenerated, do not edit
 from __future__ import annotations
 
 from dataclasses import dataclass, field
-from typing import Dict, List, Union
+from typing import Any, Dict, List, Optional
 
 from numpy.typing import ArrayLike
 
 #
 # Enums
 #
 
@@ -19,15 +19,15 @@
 #
 
 
 @dataclass
 class AcquiredResult:
     data: ArrayLike = None
     axis_name: List = field(default_factory=list)
-    axis: List[Union[ArrayLike, List[ArrayLike]]] = field(default_factory=list)
+    axis: Optional[Any] = None
     last_nt_step: List[int] = field(default_factory=list)
 
 
 @dataclass
 class ExperimentResults:
     uid: str = None
     acquired_results: Dict[str, AcquiredResult] = field(default_factory=dict)
```

## laboneq/dsl/__init__.py

```diff
@@ -1,5 +1,7 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from laboneq.dsl._inspect import inspect
+
 from .parameter import LinearSweepParameter, Parameter, SweepParameter
 from .session import Session
```

## laboneq/dsl/parameter.py

```diff
@@ -6,14 +6,16 @@
 from abc import ABC
 from dataclasses import dataclass, field
 from numbers import Number
 
 import numpy as np
 from numpy.typing import ArrayLike
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
+
 parameter_id = 0
 
 
 def parameter_id_generator():
     global parameter_id
     retval = f"par{parameter_id}"
     parameter_id += 1
@@ -26,40 +28,47 @@
             return False
         if not len(a) == len(b):
             return False
         return all(map(lambda x: _compare_nested(x[0], x[1]), zip(a, b)))
     return a == b
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Parameter(ABC):
     """Parent class for sweep parameters in a LabOne Q Experiment."""
 
     uid: str = field(default_factory=parameter_id_generator)
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class SweepParameter(Parameter):
     """An arbitrary sweep parameter."""
 
     #: An arbitrary numpy array whose values are used as the sweep parameter.
     values: ArrayLike = field(default_factory=lambda x: np.array([]))
 
-    #: The name of the sweep axis for this parameter used in the results. If this
-    #: argument is not defined, the uid of the object will be used instead.
+    #: The name of the sweep axis for this parameter used in the results.
+    #:
+    #: If this argument is not defined, the uid of the object will be used instead.
     axis_name: str = field(default=None)
 
     def __eq__(self, other):
         if self is other:
             return True
         return self.axis_name == other.axis_name and _compare_nested(
             self.values, other.values
         )
 
+    def __len__(self) -> int:
+        return len(self.values)
 
+
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class LinearSweepParameter(Parameter):
     """A linear sweep parameter"""
 
     #: The starting value of the parameter sweep.
     start: Number = field(default=None)
 
@@ -70,16 +79,26 @@
     count: int = field(default=None)
 
     #: The name of the sweep axis for this parameter used in the results.
     #:
     #: If this argument is not defined, the uid of the object will be used instead.
     axis_name: str = field(default=None)
 
+    def __eq__(self, other):
+        if self is other:
+            return True
+        return self.axis_name == other.axis_name and _compare_nested(
+            self.values, other.values
+        )
+
     def __post_init__(self):
         if self.count is None or self.start is None or self.stop is None:
             raise RuntimeError(
                 f"LinearSweepParameter {self.uid}: one of start, stop, count is None"
             )
 
+    def __len__(self) -> int:
+        return self.count
+
     @property
     def values(self):
         return np.linspace(start=self.start, stop=self.stop, num=self.count)
```

## laboneq/dsl/calibration/amplifier_pump.py

```diff
@@ -1,26 +1,28 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.parameter import Parameter
 
 amplifier_pump_id = 0
 
 
 def amplifier_pump_id_generator():
     global amplifier_pump_id
     retval = f"ap{amplifier_pump_id}"
     amplifier_pump_id += 1
     return retval
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class AmplifierPump:
     """Data object containing settings for the Parametric Pump Controller."""
 
     #: Unique identifier. If left blank, a new unique ID will be generated.
     uid: str = field(default_factory=amplifier_pump_id_generator)
```

## laboneq/dsl/calibration/calibration.py

```diff
@@ -1,25 +1,27 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Any, Dict
 
 from laboneq.dsl.calibration.calibration_item import CalibrationItem
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 
 def _sanitize_key(key: Any) -> str:
     try:
         return key.path
     except AttributeError as error:
         if not isinstance(key, str):
             raise TypeError("Key must be a string.") from error
         return key
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Calibration:
     """Calibration object containing a dict of :class:`~.CalibrationItem`.
 
     The dictionary has the path i.e. UID to the :py:class:`~.Calibratable` object as
     key and the actual :py:class:`~.CalibrationItem` object as value.
     """
```

## laboneq/dsl/calibration/mixer_calibration.py

```diff
@@ -3,25 +3,27 @@
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
 from typing import List, Optional
 
 from laboneq.dsl.calibration.observable import Observable
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 mixer_calib_id = 0
 
 
 def mixer_calib_id_generator():
     global mixer_calib_id
     retval = f"mc{mixer_calib_id}"
     mixer_calib_id += 1
     return retval
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class MixerCalibration(Observable):
     """Data object containing mixer calibration correction settings."""
 
     #: Unique identifier. If left blank, a new unique ID will be generated.
     uid: str = field(default_factory=mixer_calib_id_generator)
```

## laboneq/dsl/calibration/oscillator.py

```diff
@@ -3,14 +3,15 @@
 
 from __future__ import annotations
 
 import warnings
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.enums import CarrierType, ModulationType
 
 if TYPE_CHECKING:
     from laboneq.dsl import Parameter
 
 oscillator_id = 0
 
@@ -18,14 +19,15 @@
 def oscillator_uid_generator():
     global oscillator_id
     retval = f"osc_{oscillator_id}"
     oscillator_id += 1
     return retval
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Oscillator:
     """
     This oscillator class represents an oscillator on a `PhysicalChannel`.
     All pulses played on any signal line attached to this physical channel will be modulated with the oscillator assigned to that channel.
 
     Args:
```

## laboneq/dsl/calibration/precompensation.py

```diff
@@ -8,35 +8,38 @@
 from typing import List, Optional
 
 import numpy as np
 from numpy.typing import ArrayLike
 
 from laboneq.core.types.enums import HighPassCompensationClearing
 from laboneq.dsl.calibration.observable import Observable, RecursiveObservable
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 precompensation_id = 0
 
 
 def precompensation_id_generator():
     global precompensation_id
     retval = f"mc{precompensation_id}"
     precompensation_id += 1
     return retval
 
 
+@classformatter
 @dataclass
 class ExponentialCompensation(Observable):
     """Data object containing exponential filter parameters for the signal precompensation"""
 
     #: Exponential filter timeconstant
     timeconstant: float = 1e-6
     #: Exponential filter amplitude
     amplitude: float = 0.0
 
 
+@classformatter
 @dataclass
 class HighPassCompensation(Observable):
     """Data object containing highpass filter parameters for the signal precompensation.
 
     .. versionchanged:: 2.8
 
         Deprecated `clearing` argument: It has no functionality.
@@ -54,32 +57,35 @@
                 FutureWarning,
             )
         else:
             self.clearing = HighPassCompensationClearing.RISE
         super().__post_init__()
 
 
+@classformatter
 @dataclass
 class FIRCompensation(Observable):
     """Data object containing FIR filter parameters for the signal precompensation"""
 
     #: FIR filter coefficients
     coefficients: ArrayLike = field(default_factory=lambda: np.zeros(40))
 
 
+@classformatter
 @dataclass
 class BounceCompensation(Observable):
     """Data object containing parameters for the bounce compensation component of the signal precompensation"""
 
     #: Delay time to compensate
     delay: float = 0.0
     #: bounce compensation amplitude
     amplitude: float = 0.0
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Precompensation(RecursiveObservable):
     """Data object containing a collection of parameters for the different filters possible to enable for precompensation of signal distortion."""
 
     #: Unique identifier. If left blank, a new unique ID will be generated.
     uid: str = field(default_factory=precompensation_id_generator)
```

## laboneq/dsl/calibration/signal_calibration.py

```diff
@@ -7,17 +7,19 @@
 
 from laboneq.core.types.enums import PortMode
 from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.mixer_calibration import MixerCalibration
 from laboneq.dsl.calibration.observable import Observable
 from laboneq.dsl.calibration.oscillator import Oscillator
 from laboneq.dsl.calibration.precompensation import Precompensation
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.parameter import Parameter
 
 
+@classformatter
 @dataclass(init=False, order=True)
 class SignalCalibration(Observable):
     """Dataclass containing all calibration parameters
     and settings related to a :class:`~.LogicalSignal`.
     """
 
     #: The oscillator assigned to the :class:`~.LogicalSignal`
```

## laboneq/dsl/calibration/units.py

```diff
@@ -1,14 +1,16 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 
 import dataclasses
 from enum import Enum
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
+
 
 def Volt(val):
     return Quantity(val, Unit.volt)
 
 
 def dBm(val):
     return Quantity(val, Unit.dBm)
@@ -22,11 +24,12 @@
 
 
 class Unit(StrEnum):
     volt = "volt"
     dBm = "dBm"
 
 
+@classformatter
 @dataclasses.dataclass(frozen=True)
 class Quantity:
     value: float
     unit: Unit
```

## laboneq/dsl/device/connection.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Optional
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.enums import IODirection, IOSignalType
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Connection:
     direction: IODirection = field(default=IODirection.OUT)
     local_path: Optional[str] = field(default=None)
     local_port: Optional[str] = field(default=None)
     remote_path: Optional[str] = field(default=None)
     remote_port: Optional[str] = field(default=None)
```

## laboneq/dsl/device/device_setup.py

```diff
@@ -9,28 +9,30 @@
 from laboneq.core import path as qct_path
 from laboneq.core.exceptions import LabOneQException
 from laboneq.dsl.calibration import Calibratable, Calibration, CalibrationItem
 from laboneq.dsl.device.logical_signal_group import LogicalSignalGroup
 from laboneq.dsl.device.physical_channel_group import PhysicalChannelGroup
 from laboneq.dsl.serialization import Serializer
 
+from ..dsl_dataclass_decorator import classformatter
 from ._device_setup_generator import (
     ConnectionsType,
     DataServersType,
     InstrumentsType,
     _DeviceSetupGenerator,
 )
 
 if TYPE_CHECKING:
     from laboneq.dsl.device.logical_signal_group import LogicalSignal
     from laboneq.dsl.device.servers import DataServer
 
     from .instrument import Instrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class DeviceSetup:
     """Data object describing the device setup of a QCCS system."""
 
     #: Unique identifier.
     uid: str = field(default=None)
```

## laboneq/dsl/device/instrument.py

```diff
@@ -6,17 +6,19 @@
 import typing
 from dataclasses import dataclass, field
 from typing import List
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device.ports import Port
 
+from ..dsl_dataclass_decorator import classformatter
 from .connection import Connection
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Instrument:
     """Class representing an instrument."""
 
     #: Unique identifier.
     uid: str = field(default=None)
```

## laboneq/dsl/device/logical_signal_group.py

```diff
@@ -3,17 +3,19 @@
 
 from dataclasses import dataclass, field
 from typing import Dict
 
 import laboneq.core.path as qct_path
 
 from ..calibration import Calibratable
+from ..dsl_dataclass_decorator import classformatter
 from .io_units import LogicalSignal
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class LogicalSignalGroup:
     """Group of logical signals. This could be used as a qubit representation with
     multiple logical signals driving a single qubit.
     """
 
     uid: str = field(default=None)
```

## laboneq/dsl/device/physical_channel_group.py

```diff
@@ -3,16 +3,18 @@
 
 from dataclasses import dataclass, field
 from typing import Dict
 
 import laboneq.core.path as qct_path
 from laboneq.dsl.calibration import Calibratable
 from laboneq.dsl.device.io_units.physical_channel import PhysicalChannel
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 
+@classformatter
 @dataclass
 class PhysicalChannelGroup:
     #: Unique identifier.
     uid: str = field(default=None)
 
     #: The physical channels in this group.
     channels: Dict[str, PhysicalChannel] = field(default_factory=dict)
```

## laboneq/dsl/device/ports.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import List
 
 from laboneq.core.types.enums import IODirection, IOSignalType
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Port:
     """Abstraction of a port"""
 
     direction: IODirection
     uid: str = field(default=None)
     connector_labels: List[str] = field(default_factory=list)
```

## laboneq/dsl/device/server.py

```diff
@@ -1,9 +1,12 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
+
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Server:
     uid: str = field(default=None)
```

## laboneq/dsl/device/instruments/hdawg.py

```diff
@@ -3,17 +3,19 @@
 
 from dataclasses import dataclass
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 from laboneq.dsl.enums import IOSignalType
 
+from ...dsl_dataclass_decorator import classformatter
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class HDAWG(ZIStandardInstrument):
     """Class representing a ZI HDAWG instrument."""
 
     @property
     def ports(self):
         """Input and output ports that are part of this instrument."""
```

## laboneq/dsl/device/instruments/nonqc.py

```diff
@@ -1,15 +1,17 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 
+from ...dsl_dataclass_decorator import classformatter
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class NonQC(ZIStandardInstrument):
     """Class representing a ZI instrument that is of type not directly handled by L1Q."""
 
     dev_type: str = None
 
     def calc_options(self):
```

## laboneq/dsl/device/instruments/pqsc.py

```diff
@@ -3,17 +3,19 @@
 
 from dataclasses import dataclass, field
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 from laboneq.dsl.enums import IOSignalType
 
+from ...dsl_dataclass_decorator import classformatter
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class PQSC(ZIStandardInstrument):
     """Class representing a ZI PQSC instrument."""
 
     #: The reference clock frequency
     reference_clock: float = field(default=None)
```

## laboneq/dsl/device/instruments/shfppc.py

```diff
@@ -2,18 +2,20 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 
+from ...dsl_dataclass_decorator import classformatter
 from ...enums import IOSignalType
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class SHFPPC(ZIStandardInstrument):
     """Class representing a ZI SHFPPC instrument."""
 
     @property
     def ports(self):
         """Ports that are part of this instrument."""
```

## laboneq/dsl/device/instruments/shfqa.py

```diff
@@ -2,18 +2,20 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 
+from ...dsl_dataclass_decorator import classformatter
 from ...enums import IOSignalType
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class SHFQA(ZIStandardInstrument):
     """Class representing a ZI SHFQA instrument."""
 
     is_qc: bool = False
 
     def calc_options(self):
```

## laboneq/dsl/device/instruments/shfsg.py

```diff
@@ -2,18 +2,20 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 
+from ...dsl_dataclass_decorator import classformatter
 from ...enums import IOSignalType
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class SHFSG(ZIStandardInstrument):
     """Class representing a ZI SHFSG instrument."""
 
     is_qc: bool = False
     qc_with_qa: bool = False
```

## laboneq/dsl/device/instruments/uhfqa.py

```diff
@@ -2,18 +2,20 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device import Port
 
+from ...dsl_dataclass_decorator import classformatter
 from ...enums import IOSignalType
 from .zi_standard_instrument import ZIStandardInstrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class UHFQA(ZIStandardInstrument):
     """Class representing a ZI UHFQA instrument."""
 
     @property
     def ports(self):
         """Input and output ports that are part of this instrument."""
```

## laboneq/dsl/device/instruments/zi_standard_instrument.py

```diff
@@ -1,17 +1,19 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 
 from laboneq.core.types.enums import ReferenceClockSource
 
+from ...dsl_dataclass_decorator import classformatter
 from ..instrument import Instrument
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class ZIStandardInstrument(Instrument):
     """Base class representing a ZI instrument controlled via a LabOne Data Server."""
 
     #: Unique identifier of the server where that device is controlled from.
     server_uid: str = field(default=None)
```

## laboneq/dsl/device/io_units/logical_signal.py

```diff
@@ -1,25 +1,27 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from contextlib import contextmanager
-from dataclasses import dataclass
+from dataclasses import dataclass, fields
 from typing import Optional, Union
 
 from laboneq.core.exceptions.laboneq_exception import LabOneQException
 from laboneq.core.types.enums import IODirection
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
 from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.calibratable import Calibratable
 from laboneq.dsl.device.io_units.physical_channel import (
     PHYSICAL_CHANNEL_CALIBRATION_FIELDS,
     PhysicalChannel,
 )
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 
+@classformatter
 @dataclass(init=False, repr=False, order=True)
 class LogicalSignal(Calibratable):
     uid: str
     name: Optional[str]
     _calibration: Optional[SignalCalibration]
     _physical_channel: Optional[PhysicalChannel]
     path: Optional[str]
@@ -53,24 +55,24 @@
         # because it is mutable, and thus cannot safely be used as a key in a dict (the
         # hash might change while it is stored). Assuming that both the uid and the path
         # are indeed unique and permanent (at least among those instances used as keys
         # in a dict), we can use this implementation safely.
         return hash((self.uid, self.path))
 
     def __repr__(self):
-        return (
-            f"{self.__class__.__name__}("
-            f"uid={repr(self.uid)}, "
-            f"direction={repr(self.direction)}, "
-            f"name={repr(self.name)}, "
-            f"calibration={repr(self.calibration)}, "
-            f"path={repr(self.path)}, "
-            f"physical_channel={repr(self.physical_channel)}"
-            f")"
-        )
+        field_values = []
+        for field in fields(self):
+            value = getattr(self, field.name)
+            if field.name == "_calibration":
+                field_values.append(f"calibration={value!r}")
+            elif field.name == "_physical_channel":
+                field_values.append(f"physical_channel={value!r}")
+            else:
+                field_values.append(f"{field.name}={value!r}")
+        return f"{self.__class__.__name__}({', '.join(field_values)})"
 
     @property
     def mixer_calibration(self):
         return self.calibration.mixer_calibration if self.is_calibrated() else None
 
     @mixer_calibration.setter
     def mixer_calibration(self, value):
```

## laboneq/dsl/device/io_units/physical_channel.py

```diff
@@ -1,18 +1,19 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-from dataclasses import dataclass
+from dataclasses import dataclass, fields
 from enum import Enum
 from typing import Optional
 
 from laboneq.dsl.calibration import Calibratable, SignalCalibration
 from laboneq.dsl.calibration.observable import Signal
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 
 class PhysicalChannelType(Enum):
     IQ_CHANNEL = "iq_channel"
     RF_CHANNEL = "rf_channel"
 
 
@@ -24,14 +25,15 @@
     "voltage_offset",
     "mixer_calibration",
     "precompensation",
     "amplitude",
 )
 
 
+@classformatter
 @dataclass(init=False, repr=False, order=True)
 class PhysicalChannel(Calibratable):
     #: Unique identifier. Typically of the form
     # ``<device uid>/<channel name>``.
     uid: str
 
     #: The name of the channel, == <channel name>.
@@ -62,18 +64,22 @@
         self.path = path
         self._calibration = calibration
         if self._calibration is not None:
             self._calibration.has_changed().connect(self._on_calibration_changed)
         self._signal_calibration_changed = Signal(self)
 
     def __repr__(self):
-        return (
-            f"{self.__class__.__name__}(uid={self.uid}, type={self.type}, "
-            f"name={self.name}, path={self.path}, calibration={self.calibration})"
-        )
+        field_values = []
+        for field in fields(self):
+            value = getattr(self, field.name)
+            if field.name == "_calibration":
+                field_values.append(f"calibration={value!r}")
+            else:
+                field_values.append(f"{field.name}={value!r}")
+        return f"{self.__class__.__name__}({', '.join(field_values)})"
 
     def __hash__(self):
         # By default, dataclass does not generate a __hash__() method for
         # PhysicalChannel, because it is mutable, and thus cannot safely be used as a
         # key in a dict (the hash might change while it is stored). Assuming that both
         # the uid and the path are indeed unique and permanent (at least among those
         # instances used as keys in a dict), we can use this implementation safely.
```

## laboneq/dsl/device/servers/data_server.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Union
 
+from ...dsl_dataclass_decorator import classformatter
 from .. import Server
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class DataServer(Server):
     """Class representing a LabOne Data Server."""
 
     #: Unique identifier.
     uid: str = field(default=None)
     #: API level that is used to communicate with the data server.
```

## laboneq/dsl/experiment/acquire.py

```diff
@@ -1,17 +1,19 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Any, Dict, Optional
 
+from ..dsl_dataclass_decorator import classformatter
 from .operation import Operation
 from .pulse import Pulse
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Acquire(Operation):
     """Class representing an acquire operation that is used to acquire results."""
 
     #: Unique identifier of the signal where the result should be acquired.
     signal: str = field(default=None)
```

## laboneq/dsl/experiment/call.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Any, Callable, Dict, Union
 
+from ..dsl_dataclass_decorator import classformatter
 from .operation import Operation
 
 
+@classformatter
 @dataclass(init=False, repr=True, order=True)
 class Call(Operation):
     """Class abstracting a function call."""
 
     func_name: Union[str, Callable] = field(default=None)
     args: Dict[str, Any] = field(default=None)
```

## laboneq/dsl/experiment/delay.py

```diff
@@ -2,20 +2,22 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Optional, Union
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.experiment.operation import Operation
 
 if TYPE_CHECKING:
     from laboneq.dsl import Parameter
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Delay(Operation):
     """Class representing a delay operation for a specific signal."""
 
     #: Unique identifier of the signal where the delay should be applied.
     signal: str = field(default=None)
```

## laboneq/dsl/experiment/experiment.py

```diff
@@ -15,14 +15,15 @@
     AcquisitionType,
     AveragingMode,
     ExecutionType,
     RepetitionMode,
 )
 from laboneq.dsl.experiment.pulse import Pulse
 
+from ..dsl_dataclass_decorator import classformatter
 from .experiment_signal import ExperimentSignal
 from .section import AcquireLoopNt, AcquireLoopRt, Case, Match, Section, Sweep
 
 if TYPE_CHECKING:
     from .. import Parameter
 
 experiment_id = 0
@@ -31,14 +32,15 @@
 def experiment_id_generator():
     global experiment_id
     retval = f"exp_{experiment_id}"
     experiment_id += 1
     return retval
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Experiment:
     """LabOne Q Experiment.
 
     Args:
         uid: UID of the experiment.
         signals: Experiment signals.
@@ -295,14 +297,18 @@
             Defaults to `None`, meaning no change is made and the phase remains continuous.
         :type increment_oscillator_phase: `float`, optional
         :param pulse_parameters: Dictionary with user pulse function parameters (re)binding.
         :type pulse_parameters: `dict`, optional
         :param marker: Dictionary with markers to play. Example: `marker={"marker1": {"enable": True}}`
         :type marker: `dict`, optional
 
+        .. note::
+
+           If markers are specified but `pulse=None`, a zero amplitude pulse as long as the end of the longest
+           marker will be automatically generated.
         """
         current_section = self._peek_section()
         current_section.play(
             signal=signal,
             pulse=pulse,
             amplitude=amplitude,
             phase=phase,
@@ -482,14 +488,15 @@
     def sweep(
         self,
         parameter,
         execution_type=None,
         uid=None,
         alignment=None,
         reset_oscillator_phase=False,
+        chunk_count=1,
     ):
         """Define a sweep section.
 
         Sections need to open a scope in the following way::
 
             with exp.sweep(...):
                 # here come the operations that shall be executed in the sweep section
@@ -505,35 +512,38 @@
                 parameters are executed in parallel in this sweep loop.
             execution_type: Defines if the sweep is executed in near time or
                 real time. Defaults to :class:`.~ExecutionType.NEAR_TIME`.
             alignment: Alignment of the operations in the section. Defaults to
                 :class:`.~SectionAlignment.LEFT`.
             reset_oscillator_phase: When True, reset all oscillators at the start of
                 each step.
+            chunk_count: The number of chunks to split the sweep into. Defaults to 1.
 
         """
         parameters = parameter if isinstance(parameter, list) else [parameter]
         return Experiment._SweepSectionContext(
             self,
             uid=uid,
             parameters=parameters,
             execution_type=execution_type,
             alignment=alignment,
             reset_oscillator_phase=reset_oscillator_phase,
+            chunk_count=chunk_count,
         )
 
     class _SweepSectionContext:
         def __init__(
             self,
             experiment,
             uid,
             parameters,
             execution_type,
             alignment,
             reset_oscillator_phase,
+            chunk_count,
         ):
             self.exp = experiment
             args = {"parameters": parameters}
             if uid is not None:
                 args["uid"] = uid
             if execution_type is not None:
                 args["execution_type"] = execution_type
@@ -550,14 +560,16 @@
 
             if alignment is not None:
                 args["alignment"] = alignment
 
             if reset_oscillator_phase is not None:
                 args["reset_oscillator_phase"] = reset_oscillator_phase
 
+            args["chunk_count"] = chunk_count
+
             self.sweep = Sweep(**args)
 
         def __enter__(self):
             self.exp._push_section(self.sweep)
             return self.sweep
 
         def __exit__(self, exc_type, exc_val, exc_tb):
```

## laboneq/dsl/experiment/experiment_signal.py

```diff
@@ -6,25 +6,27 @@
 
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
 from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.device.io_units.logical_signal import (
     LogicalSignalRef,
     resolve_logical_signal_ref,
 )
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 experiment_signal_id = 0
 
 
 def experiment_signal_id_generator():
     global experiment_signal_id
     retval = f"s{experiment_signal_id}"
     experiment_signal_id += 1
     return retval
 
 
+@classformatter
 @dataclass(init=False, repr=True, order=True)
 class ExperimentSignal:
     """Class representing a signal within an experiment. Experiment signals are connected to logical signals."""
 
     uid: str
     calibration: Optional[SignalCalibration]
     mapped_logical_signal_path: Optional[str]
```

## laboneq/dsl/experiment/play_pulse.py

```diff
@@ -2,21 +2,23 @@
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any, Dict, Optional, Union
 
+from ..dsl_dataclass_decorator import classformatter
 from .operation import Operation
 from .pulse import Pulse
 
 if TYPE_CHECKING:
     from .. import Parameter
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class PlayPulse(Operation):
     """Operation to play a pulse."""
 
     #: Unique identifier of the signal where the pulse is played.
     signal: str = field(default=None)
     #: Pulse that is played.
```

## laboneq/dsl/experiment/pulse.py

```diff
@@ -6,14 +6,15 @@
 from dataclasses import dataclass, field
 from typing import Any, Dict, Optional
 
 import numpy as np
 from numpy.typing import ArrayLike
 
 from laboneq.core.exceptions import LabOneQException
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 
 pulse_id = 0
 
 
 def pulse_id_generator():
     global pulse_id
     retval = f"p{pulse_id}"
@@ -33,14 +34,15 @@
 
 class Pulse:
     # TODO this should be checked on the pulse itself.
     def is_complex(self):
         return False
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class PulseSampledReal(Pulse):
     """Pulse based on a list of real-valued samples."""
 
     #: List of real values.
     samples: ArrayLike
     #: Unique identifier of the pulse.
@@ -61,14 +63,15 @@
     def __eq__(self, other):
         if self is other:
             return True
         return self.uid == other.uid and _compare_nested(self.samples, other.samples)
 
 
 # TODO: PulseSampledReal and PulseSampledComplex should be the same function taking a single dimensional np.ndarray.
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class PulseSampledComplex(Pulse):
     """Pulse base on a list of complex-valued samples."""
 
     #: Complex-valued data.
     samples: ArrayLike
     #: Unique identifier of the pulse.
@@ -91,14 +94,15 @@
 
     def __eq__(self, other):
         if self is other:
             return True
         return self.uid == other.uid and _compare_nested(self.samples, other.samples)
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class PulseFunctional(Pulse):
     """Pulse based on a function."""
 
     #: Key for the function used for sampling the pulse.
     function: str
```

## laboneq/dsl/experiment/reserve.py

```diff
@@ -1,15 +1,17 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 
+from ..dsl_dataclass_decorator import classformatter
 from .operation import Operation
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Reserve(Operation):
     """Operation to reserve a signal for the active section.
     Reserving an experiment signal in a section means that if there is no
     operation defined on that signal, it is not available for other sections
     as long as the active section is scoped.
     """
```

## laboneq/dsl/experiment/section.py

```diff
@@ -14,27 +14,29 @@
     AcquisitionType,
     AveragingMode,
     ExecutionType,
     RepetitionMode,
 )
 from laboneq.dsl.experiment.pulse import Pulse
 
+from ..dsl_dataclass_decorator import classformatter
 from .acquire import Acquire
 from .call import Call
 from .delay import Delay
 from .operation import Operation
 from .play_pulse import PlayPulse
 from .reserve import Reserve
 from .set import Set
 from .utils import id_generator
 
 if TYPE_CHECKING:
     from .. import Parameter
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Section:
     """Representation of a section. A section is a logical concept that groups multiple operations into a single entity
     that can be though of a container. A section can either contain other sections or a list of operations (but not both
     at the same time). Operations within a section can be aligned in various ways (left, right). Sections can have a offset
     and/or a predefined length, and they can be specified to play after another section.
 
@@ -208,25 +210,27 @@
         Args:
             func_name (Union[str, Callable]): Function that should be called.
             kwargs: Arguments of the function call.
         """
         self._add_operation(Call(func_name=func_name, **kwargs))
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class AcquireLoopNt(Section):
     """Near time acquire loop."""
 
     #: Averaging method. One of sequential, cyclic and single_shot.
     averaging_mode: AveragingMode = field(default=AveragingMode.CYCLIC)
     #: Number of loops.
     count: int = field(default=None)
     execution_type: ExecutionType = field(default=ExecutionType.NEAR_TIME)
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class AcquireLoopRt(Section):
     """Real time acquire loop."""
 
     #: Type of the acquisition. One of integration trigger, spectroscopy, discrimination, demodulation and RAW. The default acquisition type is INTEGRATION.
     acquisition_type: AcquisitionType = field(default=AcquisitionType.INTEGRATION)
     #: Averaging method. One of sequential, cyclic and single_shot.
@@ -246,30 +250,34 @@
         if self.repetition_mode == RepetitionMode.CONSTANT:
             if self.repetition_time is None:
                 raise LabOneQException(
                     f"AcquireLoopRt with uid {self.uid} has RepetitionMode.CONSTANT but repetition_time is not set"
                 )
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Sweep(Section):
     """Sweep loops. Sweeps are used to sample through a range of parameter values."""
 
     #: Parameters that should be swept.
     parameters: List[Parameter] = field(default_factory=list)
     #: When True, reset all oscillators at the start of every step.
     reset_oscillator_phase: bool = field(default=False)
+    #: When non-zero, split the sweep into N chunks.
+    chunk_count: int = field(default=1)
 
 
 @validating_allowed_values(
     {
         "alignment": [SectionAlignment.LEFT],
         "execution_type": [ExecutionType.REAL_TIME],
     }
 )
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Match(Section):
     """Execute one of the child branches depending on feedback result."""
 
     #: Handle from which to obtain results
     handle: str = ""
 
@@ -295,14 +303,15 @@
 
 @validating_allowed_values(
     {
         "alignment": [SectionAlignment.LEFT],
         "execution_type": [ExecutionType.REAL_TIME],
     }
 )
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Case(Section):
     """Branch in a match/case statement"""
 
     state: int = 0
 
     def add(self, obj):
```

## laboneq/dsl/experiment/set.py

```diff
@@ -1,16 +1,18 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass, field
 from typing import Any
 
+from ..dsl_dataclass_decorator import classformatter
 from .operation import Operation
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Set(Operation):
 
     """Operation that sets a value at a node."""
 
     #: Path to the node whose value should be set.
     path: str = field(default=None)
```

## laboneq/dsl/quantum/qubits.py

```diff
@@ -8,14 +8,15 @@
 from dataclasses import dataclass, field
 from enum import Enum
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 from laboneq.core.exceptions import LabOneQException
 from laboneq.dsl.calibration import Calibration, Oscillator, SignalCalibration
 from laboneq.dsl.device.io_units import LogicalSignal
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
 from laboneq.dsl.experiment import ExperimentSignal
 from laboneq.dsl.serialization import Serializer
 
 
 class SignalType(Enum):
     DRIVE = "drive"
     MEASURE = "measure"
@@ -63,14 +64,15 @@
             return __o == self._items
         return super().__eq__(__o)
 
     def __repr__(self):
         return repr(self._items)
 
 
+@classformatter
 @dataclass(init=False, repr=True)
 class QuantumElement(ABC):
     """An abstract base class for quantum elements."""
 
     uid: str
     signals: Dict[str, str]
     parameters: Dict[str, Any]
@@ -175,14 +177,15 @@
                 calibration=v,
                 map_to=k,
             )
             sigs.append(sig)
         return sigs
 
 
+@classformatter
 @dataclass
 class QubitParameters:
     #: Resonance frequency of the qubit.
     res_frequency: float
     #: Local oscillator frequency.
     lo_frequency: float
     #: Readout resonance frequency of the qubit.
@@ -199,14 +202,15 @@
 
     @property
     def readout_frequency(self) -> float:
         """Readout baseband frequency."""
         return self.readout_res_frequency - self.readout_lo_frequency
 
 
+@classformatter
 @dataclass(init=False, repr=True, eq=False)
 class Qubit(QuantumElement):
     """A class for a generic Qubit."""
 
     def __init__(
         self,
         uid: str = None,
@@ -283,33 +287,43 @@
                 sig_type = SignalType.FLUX.value
             signal_map[sig_type] = cls._resolve_to_logical_signal_uid(sig)
         return cls(
             uid=uid, signals=QuantumElementSignalMap(signal_map), parameters=parameters
         )
 
     def calibration(self) -> Calibration:
-        """Generate calibration from parameters."""
+        """Generate calibration from the parameters and attached signal lines.
+
+        Returns:
+            Prefilled calibration object from Qubit parameters.
+        """
         calibs = {}
-        calibs[self.signals["drive"]] = SignalCalibration(
-            oscillator=Oscillator(
-                uid=f"{self.uid}_drive_osc", frequency=self.parameters.drive_frequency
+        if "drive" in self.signals:
+            calibs[self.signals["drive"]] = SignalCalibration(
+                oscillator=Oscillator(
+                    uid=f"{self.uid}_drive_osc",
+                    frequency=self.parameters.drive_frequency,
+                )
             )
-        )
-        calibs[self.signals["measure"]] = SignalCalibration(
-            oscillator=Oscillator(
-                uid=f"{self.uid}_measure_osc",
-                frequency=self.parameters.readout_frequency,
+        if "measure" in self.signals:
+            calibs[self.signals["measure"]] = SignalCalibration(
+                oscillator=Oscillator(
+                    uid=f"{self.uid}_measure_osc",
+                    frequency=self.parameters.readout_frequency,
+                )
             )
-        )
-        calibs[self.signals["acquire"]] = SignalCalibration(
-            oscillator=Oscillator(
-                uid=f"{self.uid}_acquire_osc",
-                frequency=self.parameters.readout_frequency,
+        if "acquire" in self.signals:
+            calibs[self.signals["acquire"]] = SignalCalibration(
+                oscillator=Oscillator(
+                    uid=f"{self.uid}_acquire_osc",
+                    frequency=self.parameters.readout_frequency,
+                )
             )
-        )
+        if "flux" in self.signals:
+            calibs[self.signals["flux"]] = SignalCalibration()
         return Calibration(calibs)
 
     def experiment_signals(
         self, with_types=False
     ) -> Union[List[ExperimentSignal], List[Tuple[SignalType, ExperimentSignal]]]:
         """Experiment signals of the quantum element.
```

## laboneq/dsl/result/acquired_result.py

```diff
@@ -5,25 +5,28 @@
 
 from dataclasses import dataclass, field
 from typing import List, Union
 
 import numpy as np
 from numpy.typing import ArrayLike
 
+from laboneq.dsl.dsl_dataclass_decorator import classformatter
+
 
 def _compare_nested(a, b):
     if isinstance(a, list) or isinstance(a, np.ndarray):
         if not (isinstance(b, list) or isinstance(b, np.ndarray)):
             return False
         if not len(a) == len(b):
             return False
         return all(map(lambda x: _compare_nested(x[0], x[1]), zip(a, b)))
     return a == b
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class AcquiredResult:
     """
     This class represents the results acquired for an 'acquire' event.
 
     The acquired result is a triple consisting of actual data, axis name(s)
     and one or more axes
```

## laboneq/dsl/result/results.py

```diff
@@ -5,25 +5,27 @@
 
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any
 
 from laboneq.core.exceptions import LabOneQException
 
 from ..calibration import Calibration
+from ..dsl_dataclass_decorator import classformatter
 from ..serialization import Serializer
 from .acquired_result import AcquiredResult
 
 if TYPE_CHECKING:
     from numpy.typing import ArrayLike
 
     from laboneq.core.types import CompiledExperiment
     from laboneq.dsl.device.device_setup import DeviceSetup
     from laboneq.dsl.experiment import Experiment
 
 
+@classformatter
 @dataclass(init=True, repr=True, order=True)
 class Results:
     #: The source experiment
     experiment: Experiment = field(default=None)
 
     #: The device setup on which the experiment was run.
     device_setup: DeviceSetup = field(default=None)
```

## laboneq/executor/execution_from_experiment.py

```diff
@@ -1,24 +1,30 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List, Union
 
+from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.enums import ExecutionType
 from laboneq.executor import executor
 
 if TYPE_CHECKING:
     from laboneq.dsl import SweepParameter
     from laboneq.dsl.experiment import Experiment, Operation, Section, Sweep
 
 
 class ExecutionFactoryFromExperiment(executor.ExecutionFactory):
+    def __init__(self):
+        super().__init__()
+        self._chunked_sweep = None
+
     def make(self, experiment: Experiment) -> executor.Statement:
+        self._chunked_sweep = self.analyze_pipeline(experiment)
         self._handle_children(experiment.sections, experiment.uid)
         return self._root_sequence
 
     def _handle_children(
         self, children: List[Union[Operation, Section]], parent_uid: str
     ):
         from laboneq.dsl.experiment import (
@@ -34,38 +40,43 @@
                     self._statement_from_operation(child, parent_uid)
                 )
             elif isinstance(child, AcquireLoopNt):
                 loop_body = self._sub_scope(
                     self._handle_children, child.children, child.uid
                 )
                 self._append_statement(
-                    executor.ForLoop(child.count, loop_body, executor.LoopType.AVERAGE)
+                    executor.ForLoop(child.count, loop_body, executor.LoopFlags.AVERAGE)
                 )
             elif isinstance(child, AcquireLoopRt):
                 loop_body = self._sub_scope(
                     self._handle_children, child.children, child.uid
                 )
-                self._append_statement(
-                    executor.ExecRT(
-                        count=child.count,
-                        body=loop_body,
-                        uid=child.uid,
-                        averaging_mode=child.averaging_mode,
-                        acquisition_type=child.acquisition_type,
-                    )
-                )
+                loop = executor.ExecRT(
+                    count=child.count,
+                    body=loop_body,
+                    uid=child.uid,
+                    averaging_mode=child.averaging_mode,
+                    acquisition_type=child.acquisition_type,
+                )
+                if self._chunked_sweep is not None:
+                    # add 'fake' pipeline loop
+                    loop = self._make_pipelined(loop)
+                self._append_statement(loop)
             elif isinstance(child, Sweep):
                 count = len(child.parameters[0].values)
                 loop_body = self._sub_scope(self._handle_sweep, child)
                 loop_type = (
-                    executor.LoopType.HARDWARE
+                    executor.LoopFlags.HARDWARE
                     if child.execution_type == ExecutionType.REAL_TIME
-                    else executor.LoopType.SWEEP
+                    else executor.LoopFlags.SWEEP
+                )
+                chunk_count = child.chunk_count
+                self._append_statement(
+                    executor.ForLoop(count, loop_body, loop_type, chunk_count)
                 )
-                self._append_statement(executor.ForLoop(count, loop_body, loop_type))
             else:
                 sub_sequence = self._sub_scope(
                     self._handle_children, child.children, child.uid
                 )
                 self._append_statement(sub_sequence)
 
     def _handle_sweep(self, sweep: Sweep):
@@ -90,7 +101,55 @@
         if isinstance(operation, Delay):
             return executor.Nop()
         if isinstance(operation, Reserve):
             return executor.Nop()
         if isinstance(operation, Acquire):
             return executor.ExecAcquire(operation.handle, operation.signal, parent_uid)
         return executor.Nop()
+
+    def _make_pipelined(self, averaging_loop: executor.Statement):
+        return executor.ForLoop(
+            self._chunked_sweep.chunk_count,
+            executor.Sequence(
+                [
+                    executor.SetSoftwareParamLinear(
+                        "__pipeline_index", 0, 1, "pipeline_index"
+                    ),
+                    averaging_loop,
+                ]
+            ),
+            executor.LoopFlags.PIPELINE,
+            1,
+        )
+
+    @staticmethod
+    def analyze_pipeline(experiment: Experiment):
+        from laboneq.dsl.experiment import AcquireLoopRt, Section, Sweep
+
+        rt_averaging_loop = None
+        chunked_sweep = None
+
+        def visit(section: Section, inside_rt=False):
+            nonlocal rt_averaging_loop, chunked_sweep
+            if isinstance(section, AcquireLoopRt):
+                if rt_averaging_loop is not None:
+                    raise LabOneQException("Found multiple RT averaging loops")
+                rt_averaging_loop = section
+                inside_rt = True
+            if isinstance(section, Sweep):
+                if section.chunk_count > 1:
+                    if chunked_sweep is not None:
+                        raise LabOneQException("Found multiple chunked sweeps")
+                    if not inside_rt:
+                        raise LabOneQException(
+                            "Chunking of sweeps is only supported for real-time execution"
+                        )
+                    chunked_sweep = section
+            for child in section.children:
+                if isinstance(child, Section):
+                    visit(child, inside_rt)
+
+        for c in experiment.sections:
+            # depth-first search
+            visit(c)
+
+        return chunked_sweep
```

## laboneq/executor/executor.py

```diff
@@ -1,28 +1,33 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
-from enum import Enum, auto
+from contextlib import contextmanager
+from enum import Enum, Flag, auto
 from typing import Any, Dict, Iterator, List
 
 import numpy.typing as npt
 
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 
 
-class LoopType(Enum):
-    SWEEP = auto()
+class LoopFlags(Flag):
+    NONE = 0
     AVERAGE = auto()
-    RT_AVERAGE = auto()
     HARDWARE = auto()
+    PIPELINE = auto()
+
+    # convenience aliases
+    SWEEP = NONE  # !AVERAGE
+    RT_AVERAGE = AVERAGE | HARDWARE
 
 
 class LoopingMode(Enum):
     EXECUTE = auto()
     ONCE = auto()
 
 
@@ -56,41 +61,45 @@
 
 class Statement(ABC):
     @abstractmethod
     def run(self, scope: ExecutionScope):
         pass
 
 
-class NoOperation(Statement):
-    def run(self, scope: ExecutionScope):
-        pass
-
-
 class Sequence(Statement):
-    def __init__(self):
-        self._sequence: List[Statement] = []
+    def __init__(self, sequence=None):
+        self._sequence: List[Statement] = sequence or []
 
     def append_statement(self, statement: Statement):
         self._sequence.append(statement)
 
     def run(self, scope: ExecutionScope):
         for statement in self._sequence:
             statement.run(scope)
 
+    def __repr__(self):
+        return f"Sequence({self._sequence})"
+
 
 class Nop(Statement):
     def run(self, scope: ExecutionScope):
         pass
 
+    def __repr__(self):
+        return "Nop()"
+
 
 class ExecSet(Statement):
     def __init__(self, path, val):
         self._path = path
         self._val = val
 
+    def __repr__(self):
+        return f"ExecSet({repr(self._path)}, {repr(self._val)})"
+
     def run(self, scope: ExecutionScope):
         val = scope.resolve_variable(self._val) if type(self._val) is str else self._val
         scope.root.set_handler(self._path, val)
 
 
 class ExecUserCall(Statement):
     def __init__(self, func_name: str, args: Dict[str, Any]):
@@ -101,38 +110,47 @@
         resolved_args = {}
         for name, val in self._args.items():
             resolved_args[name] = (
                 scope.resolve_variable(val) if type(val) is str else val
             )
         scope.root.user_func_handler(self._func_name, resolved_args)
 
+    def __repr__(self):
+        return f"ExecUserCall({repr(self._func_name)}, {repr(self._args)})"
+
 
 class ExecAcquire(Statement):
     def __init__(self, handle: str, signal: str, parent_uid: str):
         self._handle = handle
         self._signal = signal
         self._parent_uid = parent_uid
 
     def run(self, scope: ExecutionScope):
         scope.root.acquire_handler(self._handle, self._signal, self._parent_uid)
 
+    def __repr__(self):
+        return f"ExecAcquire({repr(self._handle)}, {repr(self._signal)}, {repr(self._parent_uid)})"
+
 
 class SetSoftwareParamLinear(Statement):
     def __init__(self, name: str, start: float, step: float, axis_name: str = None):
         self._name = name
         self._start = start
         self._step = step
         self._axis_name = axis_name
 
     def run(self, scope: ExecutionScope):
         index = scope.resolve_variable(LOOP_INDEX)
         value = self._start + self._step * index
         scope.set_variable(self._name, value)
         scope.root.set_sw_param_handler(self._name, index, value, self._axis_name, None)
 
+    def __repr__(self):
+        return f"SetSoftwareParamLinear({self._name}, {self._start}, {self._step}, {repr(self._axis_name)})"
+
 
 class SetSoftwareParam(Statement):
     def __init__(self, name: str, values: npt.ArrayLike, axis_name: str = None):
         self._name = name
         self._values = values
         self._axis_name = axis_name
 
@@ -140,69 +158,83 @@
         index = max(0, min(scope.resolve_variable(LOOP_INDEX), len(self._values) - 1))
         value = self._values[index]
         scope.set_variable(self._name, value)
         scope.root.set_sw_param_handler(
             self._name, index, value, self._axis_name, self._values
         )
 
+    def __repr__(self):
+        return f"SetSoftwareParam({repr(self._name)}, {repr(self._values)}, {repr(self._axis_name)})"
+
 
 class ForLoop(Statement):
     def __init__(
-        self, count: int, body: Sequence, loop_type: LoopType = LoopType.SWEEP
+        self,
+        count: int,
+        body: Sequence,
+        loop_flags: LoopFlags = LoopFlags.SWEEP,
+        chunk_count=1,
     ):
         self._count = count
         self._body = body
-        self._loop_type = loop_type
+        self._loop_flags = loop_flags
+        self._chunk_count = chunk_count
 
     def _loop_iterator(self, scope: ExecutionScope) -> Iterator[int]:
         if scope.root.looping_mode == LoopingMode.EXECUTE:
-            if self._loop_type == LoopType.HARDWARE:
+            if self._loop_flags & LoopFlags.HARDWARE:
                 yield 0
             else:
                 for i in range(self._count):
                     yield i
         elif scope.root.looping_mode == LoopingMode.ONCE:
             yield 0
         else:
             raise LabOneQException(f"Unknown looping mode '{scope.root.looping_mode}'")
 
     def run(self, scope: ExecutionScope):
         sub_scope = scope.make_sub_scope()
         for i in self._loop_iterator(scope):
-            scope.root.for_loop_handler(self._count, i, self._loop_type, True)
-            sub_scope.set_variable(LOOP_INDEX, i)
-            self._body.run(sub_scope)
-            scope.root.for_loop_handler(None, None, None, False)
+            with scope.root.for_loop_handler(self._count, i, self._loop_flags):
+                sub_scope.set_variable(LOOP_INDEX, i)
+                self._body.run(sub_scope)
+
+    def __repr__(self):
+        return f"ForLoop({self._count}, {self._body}, {self._loop_flags})"
 
 
 class ExecRT(ForLoop):
     def __init__(
         self,
         count: int,
         body: Sequence,
         uid: str,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
     ):
-        super().__init__(count, body, LoopType.RT_AVERAGE)
+        super().__init__(count, body, LoopFlags.RT_AVERAGE)
         self._uid = uid
         self._averaging_mode = averaging_mode
         self._acquisition_type = acquisition_type
 
     def run(self, scope: ExecutionScope):
-        scope.root.rt_handler(
-            self._count, self._uid, self._averaging_mode, self._acquisition_type, True
-        )
-        if scope.root.looping_mode == LoopingMode.EXECUTE:
-            pass
-        elif scope.root.looping_mode == LoopingMode.ONCE:
-            super().run(scope)
-        else:
-            raise LabOneQException(f"Unknown looping mode '{scope.root.looping_mode}'")
-        scope.root.rt_handler(None, None, None, None, False)
+        with scope.root.rt_handler(
+            self._count, self._uid, self._averaging_mode, self._acquisition_type
+        ):
+            if scope.root.looping_mode == LoopingMode.EXECUTE:
+                pass
+            elif scope.root.looping_mode == LoopingMode.ONCE:
+                super().run(scope)
+            else:
+                raise LabOneQException(
+                    f"Unknown looping mode '{scope.root.looping_mode}'"
+                )
+
+    def __repr__(self):
+        return f"ExecRT({self._count}, {self._body}, {repr(self._uid)}, {self._averaging_mode}, {self._acquisition_type})"
 
 
 class ExecutorBase:
     """Base class for the concrete executor.
 
     Subclass this base class into a concrete executor. Override the necessary
     `*_handler(self, ...)` methods, and implement the desired execution behavior.
@@ -233,26 +265,25 @@
         pass
 
     def set_sw_param_handler(
         self, name: str, index: int, value: float, axis_name: str, values: npt.ArrayLike
     ):
         pass
 
-    def for_loop_handler(
-        self, count: int, index: int, loop_type: LoopType, enter: bool
-    ):
+    @contextmanager
+    def for_loop_handler(self, count: int, index: int, loop_flags: LoopFlags):
         pass
 
+    @contextmanager
     def rt_handler(
         self,
         count: int,
         uid: str,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-        enter: bool,
     ):
         pass
 
     def run(self, root_sequence: Statement):
         """Start execution of the provided sequence."""
         scope = ExecutionScope(None, self)
         root_sequence.run(scope)
```

## laboneq/implementation/legacy_adapters/converters_calibration/__init__.py

```diff
@@ -1,16 +1,12 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-# converter functions for data type package 'calibration'
-#  AUTOGENERATED, DO NOT EDIT
+
 from laboneq.core.types.enums.carrier_type import CarrierType as CarrierTypeDSL
-from laboneq.core.types.enums.high_pass_compensation_clearing import (
-    HighPassCompensationClearing as HighPassCompensationClearingDSL,
-)
 from laboneq.core.types.enums.modulation_type import ModulationType as ModulationTypeDSL
 from laboneq.data.calibration import BounceCompensation as BounceCompensationDATA
 from laboneq.data.calibration import Calibration as CalibrationDATA
 from laboneq.data.calibration import CarrierType as CarrierTypeDATA
 from laboneq.data.calibration import (
     ExponentialCompensation as ExponentialCompensationDATA,
 )
@@ -40,14 +36,16 @@
     HighPassCompensation as HighPassCompensationDSL,
 )
 from laboneq.dsl.calibration.precompensation import (
     Precompensation as PrecompensationDSL,
 )
 from laboneq.implementation.legacy_adapters.dynamic_converter import convert_dynamic
 
+# converter functions for data type package 'calibration'
+#  AUTOGENERATED, DO NOT EDIT
 from .post_process_calibration import post_process
 
 
 def get_converter_function_calibration(orig):
     converter_function_directory = {
         BounceCompensationDSL: convert_BounceCompensation,
         CalibrationDSL: convert_Calibration,
@@ -142,22 +140,22 @@
     )
 
 
 def convert_MixerCalibration(orig: MixerCalibrationDSL):
     if orig is None:
         return None
     retval = MixerCalibrationDATA()
-    retval.uid = orig.uid
     retval.correction_matrix = convert_dynamic(
         orig.correction_matrix,
         source_type_string="List[List[float]]",
         target_type_string="List[List[float]]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_calibration,
     )
+    retval.uid = orig.uid
     retval.voltage_offsets = convert_dynamic(
         orig.voltage_offsets,
         source_type_string="List[float]",
         target_type_string="List[float]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_calibration,
     )
@@ -166,44 +164,44 @@
     )
 
 
 def convert_Oscillator(orig: OscillatorDSL):
     if orig is None:
         return None
     retval = OscillatorDATA()
-    retval.uid = orig.uid
     retval.carrier_type = convert_CarrierType(orig.carrier_type)
     retval.frequency = convert_dynamic(
         orig.frequency,
-        source_type_string="Union[float, Parameter]",
-        target_type_string="Parameter",
-        orig_is_collection=False,
+        source_type_string="float | Parameter | None",
+        target_type_string="Any",
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_calibration,
     )
     retval.modulation_type = convert_ModulationType(orig.modulation_type)
+    retval.uid = orig.uid
     return post_process(
         orig, retval, conversion_function_lookup=get_converter_function_calibration
     )
 
 
 def convert_Precompensation(orig: PrecompensationDSL):
     if orig is None:
         return None
     retval = PrecompensationDATA()
-    retval.bounce = convert_BounceCompensation(orig.bounce)
-    retval.high_pass = convert_HighPassCompensation(orig.high_pass)
-    retval.uid = orig.uid
     retval.FIR = convert_FIRCompensation(orig.FIR)
+    retval.bounce = convert_BounceCompensation(orig.bounce)
     retval.exponential = convert_dynamic(
         orig.exponential,
         source_type_string="List[ExponentialCompensation]",
         target_type_string="List[ExponentialCompensation]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_calibration,
     )
+    retval.high_pass = convert_HighPassCompensation(orig.high_pass)
+    retval.uid = orig.uid
     return post_process(
         orig, retval, conversion_function_lookup=get_converter_function_calibration
     )
 
 
 def convert_Signal(orig: SignalDSL):
     if orig is None:
```

## laboneq/implementation/legacy_adapters/converters_experiment_description/__init__.py

```diff
@@ -1,12 +1,11 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-# converter functions for data type package 'experiment_description'
-#  AUTOGENERATED, DO NOT EDIT
+
 from typing import Any as AnyDSL
 
 from laboneq.core.types.enums.acquisition_type import (
     AcquisitionType as AcquisitionTypeDSL,
 )
 from laboneq.core.types.enums.averaging_mode import AveragingMode as AveragingModeDSL
 from laboneq.core.types.enums.execution_type import ExecutionType as ExecutionTypeDSL
@@ -75,14 +74,16 @@
 from laboneq.dsl.experiment.section import Sweep as SweepDSL
 from laboneq.dsl.experiment.set import Set as SetDSL
 from laboneq.dsl.parameter import LinearSweepParameter as LinearSweepParameterDSL
 from laboneq.dsl.parameter import Parameter as ParameterDSL
 from laboneq.dsl.parameter import SweepParameter as SweepParameterDSL
 from laboneq.implementation.legacy_adapters.dynamic_converter import convert_dynamic
 
+# converter functions for data type package 'experiment_description'
+#  AUTOGENERATED, DO NOT EDIT
 from .post_process_experiment_description import post_process
 
 
 def get_converter_function_experiment_description(orig):
     converter_function_directory = {
         AcquireDSL: convert_Acquire,
         AcquireLoopNtDSL: convert_AcquireLoopNt,
@@ -114,139 +115,139 @@
     return (
         next(e for e in AcquisitionTypeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_RepetitionMode(orig: RepetitionModeDSL):
+def convert_AveragingMode(orig: AveragingModeDSL):
     return (
-        next(e for e in RepetitionModeDATA if e.name == orig.name)
+        next(e for e in AveragingModeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_SectionAlignment(orig: SectionAlignmentDSL):
+def convert_ExecutionType(orig: ExecutionTypeDSL):
     return (
-        next(e for e in SectionAlignmentDATA if e.name == orig.name)
+        next(e for e in ExecutionTypeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_ExecutionType(orig: ExecutionTypeDSL):
+def convert_RepetitionMode(orig: RepetitionModeDSL):
     return (
-        next(e for e in ExecutionTypeDATA if e.name == orig.name)
+        next(e for e in RepetitionModeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_AveragingMode(orig: AveragingModeDSL):
+def convert_SectionAlignment(orig: SectionAlignmentDSL):
     return (
-        next(e for e in AveragingModeDATA if e.name == orig.name)
+        next(e for e in SectionAlignmentDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
 def convert_Acquire(orig: AcquireDSL):
     if orig is None:
         return None
     retval = AcquireDATA()
-    retval.length = orig.length
-    retval.signal = orig.signal
     retval.handle = orig.handle
-    retval.pulse_parameters = convert_dynamic(
-        orig.pulse_parameters,
-        source_type_string="Dict",
-        target_type_string="Any",
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_experiment_description,
-    )
     retval.kernel = convert_dynamic(
         orig.kernel,
         source_type_hint=PulseDSL,
         target_type_hint=PulseDATA,
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.length = orig.length
+    retval.pulse_parameters = convert_dynamic(
+        orig.pulse_parameters,
+        source_type_string="Dict",
+        target_type_string="Any",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.signal = orig.signal
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_AcquireLoopNt(orig: AcquireLoopNtDSL):
     if orig is None:
         return None
     retval = AcquireLoopNtDATA()
-    retval.uid = orig.uid
-    retval.execution_type = convert_ExecutionType(orig.execution_type)
     retval.averaging_mode = convert_AveragingMode(orig.averaging_mode)
     retval.count = orig.count
+    retval.execution_type = convert_ExecutionType(orig.execution_type)
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_AcquireLoopRt(orig: AcquireLoopRtDSL):
     if orig is None:
         return None
     retval = AcquireLoopRtDATA()
-    retval.repetition_time = orig.repetition_time
-    retval.execution_type = convert_ExecutionType(orig.execution_type)
-    retval.count = orig.count
-    retval.uid = orig.uid
     retval.acquisition_type = convert_AcquisitionType(orig.acquisition_type)
     retval.averaging_mode = convert_AveragingMode(orig.averaging_mode)
+    retval.count = orig.count
+    retval.execution_type = convert_ExecutionType(orig.execution_type)
     retval.repetition_mode = convert_RepetitionMode(orig.repetition_mode)
+    retval.repetition_time = orig.repetition_time
     retval.reset_oscillator_phase = orig.reset_oscillator_phase
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_Call(orig: CallDSL):
     if orig is None:
         return None
     retval = CallDATA()
-    retval.func_name = convert_dynamic(
-        orig.func_name,
-        source_type_hint=AnyDSL,
-        target_type_hint=AnyDATA,
-        orig_is_collection=False,
-        conversion_function_lookup=get_converter_function_experiment_description,
-    )
     retval.args = convert_dynamic(
         orig.args,
         source_type_string="Dict",
         target_type_string="Dict",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.func_name = convert_dynamic(
+        orig.func_name,
+        source_type_hint=AnyDSL,
+        target_type_hint=AnyDATA,
+        orig_is_collection=False,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_Case(orig: CaseDSL):
     if orig is None:
         return None
     retval = CaseDATA()
-    retval.uid = orig.uid
     retval.state = orig.state
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
@@ -270,14 +271,22 @@
     )
 
 
 def convert_Experiment(orig: ExperimentDSL):
     if orig is None:
         return None
     retval = ExperimentDATA()
+    retval._section_stack = convert_dynamic(
+        orig._section_stack,
+        source_type_hint=SectionDSL,
+        target_type_hint=SectionDATA,
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.epsilon = orig.epsilon
     retval.sections = convert_dynamic(
         orig.sections,
         source_type_hint=SectionDSL,
         target_type_hint=SectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
@@ -285,65 +294,57 @@
         orig.signals,
         source_type_string="Union[Dict[str, ExperimentSignal], List[ExperimentSignal]]",
         target_type_string="Union[Dict[str, ExperimentSignal], List[ExperimentSignal]]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.uid = orig.uid
-    retval.epsilon = orig.epsilon
-    retval._section_stack = convert_dynamic(
-        orig._section_stack,
-        source_type_hint=SectionDSL,
-        target_type_hint=SectionDATA,
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_experiment_description,
-    )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_ExperimentSignal(orig: ExperimentSignalDSL):
     if orig is None:
         return None
     retval = ExperimentSignalDATA()
-    retval.uid = orig.uid
     retval.calibration = convert_SignalCalibration(orig.calibration)
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_LinearSweepParameter(orig: LinearSweepParameterDSL):
     if orig is None:
         return None
     retval = LinearSweepParameterDATA()
     retval.axis_name = orig.axis_name
+    retval.count = orig.count
     retval.start = orig.start
     retval.stop = orig.stop
-    retval.count = orig.count
     retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_Match(orig: MatchDSL):
     if orig is None:
         return None
     retval = MatchDATA()
-    retval.uid = orig.uid
     retval.handle = orig.handle
     retval.local = orig.local
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
@@ -377,112 +378,112 @@
     retval.amplitude = convert_dynamic(
         orig.amplitude,
         source_type_string="Union[float, complex, Parameter]",
         target_type_string="Union[float, complex, Parameter]",
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.precompensation_clear = orig.precompensation_clear
-    retval.phase = orig.phase
+    retval.increment_oscillator_phase = convert_dynamic(
+        orig.increment_oscillator_phase,
+        source_type_string="Union[float, Parameter]",
+        target_type_string="Parameter",
+        orig_is_collection=False,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
     retval.length = convert_dynamic(
         orig.length,
         source_type_string="Union[float, Parameter]",
         target_type_string="Parameter",
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.marker = convert_dynamic(
+        orig.marker,
+        source_type_string="Dict",
+        target_type_string="Dict",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.phase = orig.phase
+    retval.precompensation_clear = orig.precompensation_clear
     retval.pulse = convert_dynamic(
         orig.pulse,
         source_type_hint=PulseDSL,
         target_type_hint=PulseDATA,
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.pulse_parameters = convert_dynamic(
         orig.pulse_parameters,
         source_type_hint=AnyDSL,
         target_type_hint=OptionalDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.increment_oscillator_phase = convert_dynamic(
-        orig.increment_oscillator_phase,
-        source_type_string="Union[float, Parameter]",
-        target_type_string="Parameter",
-        orig_is_collection=False,
-        conversion_function_lookup=get_converter_function_experiment_description,
-    )
-    retval.marker = convert_dynamic(
-        orig.marker,
-        source_type_string="Dict",
-        target_type_string="Dict",
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_experiment_description,
-    )
     retval.set_oscillator_phase = orig.set_oscillator_phase
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_PulseFunctional(orig: PulseFunctionalDSL):
     if orig is None:
         return None
     retval = PulseFunctionalDATA()
     retval.amplitude = orig.amplitude
+    retval.function = orig.function
     retval.length = orig.length
     retval.pulse_parameters = convert_dynamic(
         orig.pulse_parameters,
         source_type_hint=AnyDSL,
         target_type_hint=OptionalDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.uid = orig.uid
-    retval.function = orig.function
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_PulseSampledComplex(orig: PulseSampledComplexDSL):
     if orig is None:
         return None
     retval = PulseSampledComplexDATA()
-    retval.uid = orig.uid
     retval.samples = convert_dynamic(
         orig.samples,
         source_type_string="ArrayLike",
         target_type_string="ArrayLike",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_PulseSampledReal(orig: PulseSampledRealDSL):
     if orig is None:
         return None
     retval = PulseSampledRealDATA()
-    retval.uid = orig.uid
     retval.samples = convert_dynamic(
         orig.samples,
         source_type_string="ArrayLike",
         target_type_string="ArrayLike",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
@@ -498,157 +499,187 @@
     )
 
 
 def convert_Section(orig: SectionDSL):
     if orig is None:
         return None
     retval = SectionDATA()
-    retval.execution_type = convert_ExecutionType(orig.execution_type)
-    retval.length = orig.length
-    retval.on_system_grid = orig.on_system_grid
+    retval.alignment = convert_SectionAlignment(orig.alignment)
     retval.children = convert_dynamic(
         orig.children,
         source_type_hint=OperationDSL,
         target_type_hint=OperationDATA,
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.alignment = convert_SectionAlignment(orig.alignment)
-    retval.uid = orig.uid
+    retval.execution_type = convert_ExecutionType(orig.execution_type)
+    retval.length = orig.length
+    retval.on_system_grid = orig.on_system_grid
     retval.play_after = convert_dynamic(
         orig.play_after,
         source_type_string="Union[str, List[str]]",
         target_type_string="List[str]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.trigger = convert_dynamic(
         orig.trigger,
         source_type_string="Dict[str, Dict]",
         target_type_string="Dict",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_Set(orig: SetDSL):
     if orig is None:
         return None
     retval = SetDATA()
+    retval.key = orig.key
+    retval.path = orig.path
     retval.value = convert_dynamic(
         orig.value,
         source_type_hint=AnyDSL,
         target_type_hint=AnyDATA,
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.path = orig.path
-    retval.key = orig.key
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_SignalCalibration(orig: SignalCalibrationDSL):
     if orig is None:
         return None
     retval = SignalCalibrationDATA()
-    retval.local_oscillator = orig.local_oscillator
     retval.amplitude = convert_dynamic(
         orig.amplitude,
-        source_type_string="float",
+        source_type_string="float | Parameter | None",
         target_type_string="Any",
-        orig_is_collection=False,
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.oscillator = orig.oscillator
-    retval.precompensation = orig.precompensation
     retval.delay_signal = convert_dynamic(
         orig.delay_signal,
-        source_type_string="float",
+        source_type_string="float | None",
         target_type_string="Any",
-        orig_is_collection=False,
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.mixer_calibration = orig.mixer_calibration
-    retval.voltage_offset = convert_dynamic(
-        orig.voltage_offset,
-        source_type_string="float",
+    retval.local_oscillator = convert_dynamic(
+        orig.local_oscillator,
+        source_type_string="Oscillator | None",
         target_type_string="Any",
-        orig_is_collection=False,
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.range = convert_dynamic(
-        orig.range,
-        source_type_hint=AnyDSL,
-        target_type_hint=AnyDATA,
-        orig_is_collection=False,
+    retval.mixer_calibration = convert_dynamic(
+        orig.mixer_calibration,
+        source_type_string="MixerCalibration | None",
+        target_type_string="Any",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.oscillator = convert_dynamic(
+        orig.oscillator,
+        source_type_string="Oscillator | None",
+        target_type_string="Any",
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.port_delay = convert_dynamic(
         orig.port_delay,
-        source_type_string="float",
+        source_type_string="float | Parameter | None",
         target_type_string="Any",
-        orig_is_collection=False,
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.port_mode = convert_dynamic(
+        orig.port_mode,
+        source_type_string="PortMode | None",
+        target_type_string="Any",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.precompensation = convert_dynamic(
+        orig.precompensation,
+        source_type_string="Precompensation | None",
+        target_type_string="Any",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.range = convert_dynamic(
+        orig.range,
+        source_type_string="int | float | None",
+        target_type_string="Any",
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
     retval.threshold = convert_dynamic(
         orig.threshold,
-        source_type_string="float",
+        source_type_string="float | None",
         target_type_string="Any",
-        orig_is_collection=False,
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_description,
+    )
+    retval.voltage_offset = convert_dynamic(
+        orig.voltage_offset,
+        source_type_string="float | None",
+        target_type_string="Any",
+        orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.port_mode = orig.port_mode
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_Sweep(orig: SweepDSL):
     if orig is None:
         return None
     retval = SweepDATA()
+    retval.execution_type = convert_ExecutionType(orig.execution_type)
     retval.parameters = convert_dynamic(
         orig.parameters,
         source_type_hint=ParameterDSL,
         target_type_hint=ParameterDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.uid = orig.uid
-    retval.execution_type = convert_ExecutionType(orig.execution_type)
     retval.reset_oscillator_phase = orig.reset_oscillator_phase
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
 
 
 def convert_SweepParameter(orig: SweepParameterDSL):
     if orig is None:
         return None
     retval = SweepParameterDATA()
+    retval.axis_name = orig.axis_name
+    retval.uid = orig.uid
     retval.values = convert_dynamic(
         orig.values,
         source_type_string="ArrayLike",
         target_type_string="ArrayLike",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
-    retval.axis_name = orig.axis_name
-    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_description,
     )
```

## laboneq/implementation/legacy_adapters/converters_experiment_results/__init__.py

```diff
@@ -1,34 +1,35 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-# converter functions for data type package 'experiment_results'
-#  AUTOGENERATED, DO NOT EDIT
+
 from laboneq.data.experiment_results import AcquiredResult as AcquiredResultDATA
 from laboneq.dsl.result.acquired_result import AcquiredResult as AcquiredResultDSL
 from laboneq.implementation.legacy_adapters.dynamic_converter import convert_dynamic
 
+# converter functions for data type package 'experiment_results'
+#  AUTOGENERATED, DO NOT EDIT
 from .post_process_experiment_results import post_process
 
 
 def get_converter_function_experiment_results(orig):
     converter_function_directory = {
         AcquiredResultDSL: convert_AcquiredResult,
     }
     return converter_function_directory.get(orig)
 
 
 def convert_AcquiredResult(orig: AcquiredResultDSL):
     if orig is None:
         return None
     retval = AcquiredResultDATA()
-    retval.last_nt_step = convert_dynamic(
-        orig.last_nt_step,
-        source_type_string="List[int]",
-        target_type_string="List[int]",
+    retval.axis = convert_dynamic(
+        orig.axis,
+        source_type_string="List[Union[ArrayLike, List[ArrayLike]]]",
+        target_type_string="Any",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_results,
     )
     retval.axis_name = convert_dynamic(
         orig.axis_name,
         source_type_string="List[Union[str, List[str]]]",
         target_type_string="List",
@@ -38,12 +39,19 @@
     retval.data = convert_dynamic(
         orig.data,
         source_type_string="ArrayLike",
         target_type_string="ArrayLike",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_experiment_results,
     )
+    retval.last_nt_step = convert_dynamic(
+        orig.last_nt_step,
+        source_type_string="List[int]",
+        target_type_string="List[int]",
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_experiment_results,
+    )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_experiment_results,
     )
```

## laboneq/implementation/legacy_adapters/converters_scheduled_experiment/__init__.py

```diff
@@ -1,27 +1,25 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-# converter functions for data type package 'scheduled_experiment'
-#  AUTOGENERATED, DO NOT EDIT
-from typing import Any as AnyDSL
 
 from laboneq.core.types.compiled_experiment import PulseInstance as PulseInstanceDSL
 from laboneq.core.types.compiled_experiment import PulseMapEntry as PulseMapEntryDSL
 from laboneq.core.types.compiled_experiment import (
     PulseWaveformMap as PulseWaveformMapDSL,
 )
 from laboneq.core.types.enums.mixer_type import MixerType as MixerTypeDSL
 from laboneq.data.scheduled_experiment import MixerType as MixerTypeDATA
-from laboneq.data.scheduled_experiment import Optional as OptionalDATA
 from laboneq.data.scheduled_experiment import PulseInstance as PulseInstanceDATA
 from laboneq.data.scheduled_experiment import PulseMapEntry as PulseMapEntryDATA
 from laboneq.data.scheduled_experiment import PulseWaveformMap as PulseWaveformMapDATA
 from laboneq.implementation.legacy_adapters.dynamic_converter import convert_dynamic
 
+# converter functions for data type package 'scheduled_experiment'
+#  AUTOGENERATED, DO NOT EDIT
 from .post_process_scheduled_experiment import post_process
 
 
 def get_converter_function_scheduled_experiment(orig):
     converter_function_directory = {
         PulseInstanceDSL: convert_PulseInstance,
         PulseMapEntryDSL: convert_PulseMapEntry,
@@ -39,42 +37,42 @@
 
 
 def convert_PulseInstance(orig: PulseInstanceDSL):
     if orig is None:
         return None
     retval = PulseInstanceDATA()
     retval.amplitude = orig.amplitude
-    retval.modulation_phase = orig.modulation_phase
-    retval.pulse_pulse_parameters = convert_dynamic(
-        orig.pulse_pulse_parameters,
-        source_type_hint=AnyDSL,
-        target_type_hint=OptionalDATA,
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_scheduled_experiment,
-    )
-    retval.length = orig.length
-    retval.has_marker2 = orig.has_marker2
     retval.channel = orig.channel
     retval.has_marker1 = orig.has_marker1
-    retval.needs_conjugate = orig.needs_conjugate
-    retval.modulation_frequency = orig.modulation_frequency
+    retval.has_marker2 = orig.has_marker2
     retval.iq_phase = orig.iq_phase
+    retval.length = orig.length
+    retval.modulation_frequency = orig.modulation_frequency
+    retval.modulation_phase = orig.modulation_phase
+    retval.needs_conjugate = orig.needs_conjugate
+    retval.offset_samples = orig.offset_samples
     retval.overlaps = convert_dynamic(
         orig.overlaps,
-        source_type_string="List[str]",
+        source_type_string="list[str]",
         target_type_string="List[str]",
-        orig_is_collection=True,
+        orig_is_collection=False,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
-    retval.offset_samples = orig.offset_samples
     retval.play_pulse_parameters = convert_dynamic(
         orig.play_pulse_parameters,
-        source_type_hint=AnyDSL,
-        target_type_hint=OptionalDATA,
-        orig_is_collection=True,
+        source_type_string="dict[str, Any]",
+        target_type_string="Dict",
+        orig_is_collection=False,
+        conversion_function_lookup=get_converter_function_scheduled_experiment,
+    )
+    retval.pulse_pulse_parameters = convert_dynamic(
+        orig.pulse_pulse_parameters,
+        source_type_string="dict[str, Any]",
+        target_type_string="Dict",
+        orig_is_collection=False,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
@@ -82,39 +80,45 @@
 
 def convert_PulseMapEntry(orig: PulseMapEntryDSL):
     if orig is None:
         return None
     retval = PulseMapEntryDATA()
     retval.waveforms = convert_dynamic(
         orig.waveforms,
-        source_type_hint=PulseWaveformMapDSL,
-        target_type_hint=PulseWaveformMapDATA,
-        orig_is_collection=True,
+        source_type_string="dict[str, PulseWaveformMap]",
+        target_type_string="Dict[str, PulseWaveformMap]",
+        orig_is_collection=False,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
 
 
 def convert_PulseWaveformMap(orig: PulseWaveformMapDSL):
     if orig is None:
         return None
     retval = PulseWaveformMapDATA()
-    retval.sampling_rate = orig.sampling_rate
-    retval.length_samples = orig.length_samples
     retval.instances = convert_dynamic(
         orig.instances,
-        source_type_hint=PulseInstanceDSL,
-        target_type_hint=PulseInstanceDATA,
+        source_type_string="list[PulseInstance]",
+        target_type_string="List[PulseInstance]",
+        orig_is_collection=False,
+        conversion_function_lookup=get_converter_function_scheduled_experiment,
+    )
+    retval.length_samples = orig.length_samples
+    retval.mixer_type = convert_dynamic(
+        orig.mixer_type,
+        source_type_string="MixerType | None",
+        target_type_string="MixerType",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
+    retval.sampling_rate = orig.sampling_rate
     retval.signal_type = orig.signal_type
-    retval.mixer_type = convert_MixerType(orig.mixer_type)
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_scheduled_experiment,
     )
```

## laboneq/implementation/legacy_adapters/converters_setup_description/__init__.py

```diff
@@ -1,12 +1,11 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-# converter functions for data type package 'setup_description'
-#  AUTOGENERATED, DO NOT EDIT
+
 from typing import Any as AnyDSL
 
 from laboneq.core.types.enums.io_direction import IODirection as IODirectionDSL
 from laboneq.core.types.enums.io_signal_type import IOSignalType as IOSignalTypeDSL
 from laboneq.core.types.enums.port_mode import PortMode as PortModeDSL
 from laboneq.core.types.enums.reference_clock_source import (
     ReferenceClockSource as ReferenceClockSourceDSL,
@@ -58,14 +57,16 @@
 from laboneq.dsl.device.ports import Port as PortDSL
 from laboneq.dsl.device.server import Server as ServerDSL
 from laboneq.dsl.device.servers.data_server import DataServer as DataServerDSL
 from laboneq.dsl.quantum.qubits import QuantumElement as QuantumElementDSL
 from laboneq.dsl.quantum.qubits import Qubit as QubitDSL
 from laboneq.implementation.legacy_adapters.dynamic_converter import convert_dynamic
 
+# converter functions for data type package 'setup_description'
+#  AUTOGENERATED, DO NOT EDIT
 from .post_process_setup_description import post_process
 
 
 def get_converter_function_setup_description(orig):
     converter_function_directory = {
         ConnectionDSL: convert_Connection,
         DataServerDSL: convert_DataServer,
@@ -83,49 +84,49 @@
         SHFSGDSL: convert_SHFSG,
         ServerDSL: convert_Server,
         UHFQADSL: convert_UHFQA,
     }
     return converter_function_directory.get(orig)
 
 
-def convert_IOSignalType(orig: IOSignalTypeDSL):
+def convert_IODirection(orig: IODirectionDSL):
     return (
-        next(e for e in IOSignalTypeDATA if e.name == orig.name)
+        next(e for e in IODirectionDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_PortMode(orig: PortModeDSL):
+def convert_IOSignalType(orig: IOSignalTypeDSL):
     return (
-        next(e for e in PortModeDATA if e.name == orig.name)
+        next(e for e in IOSignalTypeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
 def convert_PhysicalChannelType(orig: PhysicalChannelTypeDSL):
     return (
         next(e for e in PhysicalChannelTypeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_ReferenceClockSource(orig: ReferenceClockSourceDSL):
+def convert_PortMode(orig: PortModeDSL):
     return (
-        next(e for e in ReferenceClockSourceDATA if e.name == orig.name)
+        next(e for e in PortModeDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
-def convert_IODirection(orig: IODirectionDSL):
+def convert_ReferenceClockSource(orig: ReferenceClockSourceDSL):
     return (
-        next(e for e in IODirectionDATA if e.name == orig.name)
+        next(e for e in ReferenceClockSourceDATA if e.name == orig.name)
         if orig is not None
         else None
     )
 
 
 def convert_Connection(orig: ConnectionDSL):
     if orig is None:
@@ -139,49 +140,49 @@
 
 
 def convert_DataServer(orig: DataServerDSL):
     if orig is None:
         return None
     retval = DataServerDATA()
     retval.api_level = orig.api_level
+    retval.host = orig.host
+    retval.leader_uid = orig.leader_uid
     retval.port = convert_dynamic(
         orig.port,
         source_type_hint=AnyDSL,
         target_type_hint=AnyDATA,
         orig_is_collection=False,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.host = orig.host
     retval.uid = orig.uid
-    retval.leader_uid = orig.leader_uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_DeviceSetup(orig: DeviceSetupDSL):
     if orig is None:
         return None
     retval = DeviceSetupDATA()
-    retval.logical_signal_groups = convert_dynamic(
-        orig.logical_signal_groups,
-        source_type_hint=LogicalSignalGroupDSL,
-        target_type_hint=LogicalSignalGroupDATA,
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_setup_description,
-    )
     retval.instruments = convert_dynamic(
         orig.instruments,
         source_type_hint=InstrumentDSL,
         target_type_hint=InstrumentDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
+    retval.logical_signal_groups = convert_dynamic(
+        orig.logical_signal_groups,
+        source_type_hint=LogicalSignalGroupDSL,
+        target_type_hint=LogicalSignalGroupDATA,
+        orig_is_collection=True,
+        conversion_function_lookup=get_converter_function_setup_description,
+    )
     retval.servers = convert_dynamic(
         orig.servers,
         source_type_hint=DataServerDSL,
         target_type_hint=ServerDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
@@ -193,112 +194,112 @@
     )
 
 
 def convert_HDAWG(orig: HDAWGDSL):
     if orig is None:
         return None
     retval = HDAWGDATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
+    retval.address = orig.address
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.address = orig.address
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_Instrument(orig: InstrumentDSL):
     if orig is None:
         return None
     retval = InstrumentDATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_LogicalSignal(orig: LogicalSignalDSL):
     if orig is None:
         return None
     retval = LogicalSignalDATA()
-    retval.uid = orig.uid
+    retval.direction = convert_IODirection(orig.direction)
     retval.name = orig.name
     retval.path = orig.path
-    retval.direction = convert_IODirection(orig.direction)
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_LogicalSignalGroup(orig: LogicalSignalGroupDSL):
     if orig is None:
         return None
     retval = LogicalSignalGroupDATA()
-    retval.uid = orig.uid
     retval.logical_signals = convert_dynamic(
         orig.logical_signals,
         source_type_string="Dict",
         target_type_string="Dict[str,LogicalSignal]",
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_PQSC(orig: PQSCDSL):
     if orig is None:
         return None
     retval = PQSCDATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
+    retval.address = orig.address
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.address = orig.address
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_PhysicalChannel(orig: PhysicalChannelDSL):
     if orig is None:
         return None
     retval = PhysicalChannelDATA()
-    retval.uid = orig.uid
     retval.type = convert_PhysicalChannelType(orig.type)
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
@@ -313,29 +314,17 @@
     )
 
 
 def convert_QuantumElement(orig: QuantumElementDSL):
     if orig is None:
         return None
     retval = QuantumElementDATA()
-    retval.parameters = convert_dynamic(
-        orig.parameters,
-        source_type_string="Dict",
-        target_type_string="List",
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_setup_description,
-    )
+    retval.parameters = orig.parameters
+    retval.signals = orig.signals
     retval.uid = orig.uid
-    retval.signals = convert_dynamic(
-        orig.signals,
-        source_type_string="Dict",
-        target_type_string="List[LogicalSignal]",
-        orig_is_collection=True,
-        conversion_function_lookup=get_converter_function_setup_description,
-    )
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
@@ -350,45 +339,45 @@
     )
 
 
 def convert_SHFQA(orig: SHFQADSL):
     if orig is None:
         return None
     retval = SHFQADATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
+    retval.address = orig.address
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.address = orig.address
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
 def convert_SHFSG(orig: SHFSGDSL):
     if orig is None:
         return None
     retval = SHFSGDATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
+    retval.address = orig.address
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.address = orig.address
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
 
 
@@ -404,22 +393,22 @@
     )
 
 
 def convert_UHFQA(orig: UHFQADSL):
     if orig is None:
         return None
     retval = UHFQADATA()
-    retval.uid = orig.uid
-    retval.interface = orig.interface
+    retval.address = orig.address
     retval.connections = convert_dynamic(
         orig.connections,
         source_type_hint=ConnectionDSL,
         target_type_hint=ConnectionDATA,
         orig_is_collection=True,
         conversion_function_lookup=get_converter_function_setup_description,
     )
-    retval.address = orig.address
+    retval.interface = orig.interface
+    retval.uid = orig.uid
     return post_process(
         orig,
         retval,
         conversion_function_lookup=get_converter_function_setup_description,
     )
```

## laboneq/implementation/runner/runner_legacy.py

```diff
@@ -327,17 +327,17 @@
     ExecutionPayloadHelper,
 )
 from laboneq.executor import executor
 
 
 def convert_loop_type(loop_type: LoopType):
     return {
-        LoopType.AVERAGE: executor.LoopType.AVERAGE,
-        LoopType.SWEEP: executor.LoopType.SWEEP,
-        LoopType.HARDWARE: executor.LoopType.HARDWARE,
+        LoopType.AVERAGE: executor.LoopFlags.AVERAGE,
+        LoopType.SWEEP: executor.LoopFlags.SWEEP,
+        LoopType.HARDWARE: executor.LoopFlags.HARDWARE,
     }[loop_type]
 
 
 def convert(near_time_program: NearTimeProgram):
     root_marker = "____ROOT___"
     context = {"nodes_by_parent": {}}
```

## laboneq/openqasm3/gate_store.py

```diff
@@ -19,31 +19,40 @@
         kwargs = kwargs or {}
         return self.gates[(self.gate_map.get(name, name), qubits)](*args, **kwargs)
 
     def map_gate(self, qasm_name: str, l1q_name: str):
         """Define mapping from qasm gate name to L1Q gate name."""
         self.gate_map[qasm_name] = l1q_name
 
-    def register_gate_section(self, name, qubits, section_factory):
+    def register_gate_section(self, name: str, qubit_names: list[str], section_factory):
         """Register a LabOne Q section factory as a gate."""
-        self.gates[(name, qubits)] = section_factory
+        self.gates[(name, qubit_names)] = section_factory
 
     @staticmethod
-    def _gate_pulse(qubit: str, pulse, phase, gate_id):
+    def _gate_pulse(qubit_uid, signal, pulse, phase, gate_id):
         def impl():
-            gate = Section(uid=id_generator(f"{qubit}_{gate_id}_pulse"))
+            gate = Section(uid=id_generator(f"{qubit_uid}_{gate_id}_pulse"))
             gate.play(
-                signal=f"{qubit}_drive",
+                signal=signal,
                 pulse=pulse,
                 increment_oscillator_phase=phase,
             )
             return gate
 
         return impl
 
+    # TODO: cleaner interface & rename to register_drive_gate?
     def register_gate(
-        self, name: str, qubit: str, pulse: Optional[Pulse], phase=None, id=None
+        self,
+        name: str,
+        qubit_name: str,
+        pulse: Optional[Pulse],
+        signal: str,
+        phase=None,
+        id=None,
     ):
         """Register a pulse as a single-qubit gate."""
         self.register_gate_section(
-            name, (qubit,), self._gate_pulse(qubit, pulse, phase, id)
+            name,
+            (qubit_name,),
+            self._gate_pulse(qubit_name, signal, pulse, phase, id),
         )
```

## laboneq/openqasm3/openqasm3_importer.py

```diff
@@ -7,21 +7,22 @@
 from contextlib import contextmanager
 from typing import Any, Optional, TextIO, Union
 
 import openpulse
 from openpulse import ast
 
 import openqasm3.visitor
-from laboneq.dsl.experiment import Section
+from laboneq.core.exceptions import LabOneQException
+from laboneq.dsl.experiment import Experiment, Section
 from laboneq.dsl.experiment.utils import id_generator
+from laboneq.dsl.quantum.qubits import Qubit, SignalType
 from laboneq.openqasm3.expression import eval_expression, eval_lvalue
 from laboneq.openqasm3.gate_store import GateStore
 from laboneq.openqasm3.namespace import ClassicalRef, NamespaceNest, QubitRef
 from laboneq.openqasm3.openqasm_error import OpenQasmException
-from laboneq.openqasm3.signal_store import SignalLineType, SignalStore
 
 ALLOWED_NODE_TYPES = {
     # quantum logic
     ast.Box,
     ast.DelayInstruction,
     ast.QuantumBarrier,
     ast.QuantumGate,
@@ -74,20 +75,20 @@
             msg = f"Node type {type(node)} not yet supported"
             raise OpenQasmException(msg, mark=node.span)
         super().generic_visit(node, context)
 
 
 class OpenQasm3Importer:
     def __init__(
-        self, gate_store: GateStore, signal_store: Optional[SignalStore] = None
+        self,
+        gate_store: GateStore,
+        qubits: dict[str, Qubit] = None,
     ):
         self.gate_store = gate_store
-        self.signal_store = (
-            signal_store if signal_store is not None else SignalStore({})
-        )
+        self.dsl_qubits = qubits
         self.scope = NamespaceNest()
 
     def __call__(
         self,
         text: Optional[str] = None,
         file: Optional[TextIO] = None,
         filename: Optional[str] = None,
@@ -111,15 +112,14 @@
         assert isinstance(tree, ast.Program)
         _AllowedNodeTypesVisitor().visit(tree, None)
         try:
             root = self.transpile(tree, uid_hint="root")
         except OpenQasmException as e:
             e.source = text
             raise
-        self.signal_store.leftover_raise()
         return root
 
     @contextmanager
     def _new_scope(self):
         self.scope.open()
         yield
         self.scope.close()
@@ -265,39 +265,43 @@
             except AttributeError as e:
                 msg = f"Qubit expected, got '{type(qubit).__name__}'"
                 raise OpenQasmException(msg, mark=q.span) from e
         qubit_names = tuple(qubit_names)
         try:
             return self.gate_store.lookup_gate(name, qubit_names, args=args)
         except KeyError as e:
-            msg = f"Gate '{name}' for qubit(s) {qubit_names} not found."
+            gates = ", ".join(
+                f"{gate[0]} for {gate[1]}" for gate in self.gate_store.gates
+            )
+            msg = f"Gate '{name}' for qubit(s) {qubit_names} not found.\nAvailable gates: {gates}"
             raise OpenQasmException(msg, mark=statement.span) from e
 
     def _handle_box(self, statement: ast.Box):
         if statement.duration:
             raise ValueError("Box duration not yet supported.")
         with self._new_scope():
             return self.transpile(statement, uid_hint="box")
 
     def _handle_barrier(self, statement: ast.QuantumBarrier):
         sect = Section(uid=id_generator("barrier"), length=0)
+
         reserved_qubits = [
-            eval_expression(qubit, namespace=self.scope).canonical_name
+            self.dsl_qubits[eval_expression(qubit, namespace=self.scope).canonical_name]
             for qubit in statement.qubits
         ]
+        if not reserved_qubits:
+            reserved_qubits = self.dsl_qubits.values()  # reserve all qubits
+
         reserved_signals = set()
-        if not reserved_qubits:  # get all signals
-            for each_qubit_signals in self.signal_store.user_map.values():
-                for signal in each_qubit_signals:
-                    reserved_signals.add(signal.exp_signal)
-        for qubit in reserved_qubits:  # get only selected signals
-            for signal in self.signal_store.user_map[qubit]:
-                reserved_signals.add(signal.exp_signal)
-        for exp_signal in reserved_signals:
-            sect.reserve(exp_signal)
+        for qubit in reserved_qubits:
+            for exp_signal in qubit.experiment_signals():
+                reserved_signals.add(exp_signal.mapped_logical_signal_path)
+        for signal in reserved_signals:
+            sect.reserve(signal)
+
         return sect
 
     def _handle_include(self, statement: ast.Include) -> None:
         if statement.filename != "stdgates.inc":
             msg = f"Only 'stdgates.inc' is supported for include, found '{statement.filename}'."
             raise OpenQasmException(msg, mark=statement.span)
 
@@ -309,18 +313,25 @@
             for qubit in qubits
         ]
         qubits_str = "_".join(qubit_names)
         delay_section = Section(
             uid=id_generator(f"{qubits_str}_delay_{duration * 1e9:.0f}ns")
         )
         for qubit in qubit_names:
-            for signal in self.signal_store.user_map[qubit]:
-                if signal.signal_type != SignalLineType.DRIVE:
+            dsl_qubit = self.dsl_qubits[qubit]
+            for role, sig in dsl_qubit.experiment_signals(with_types=True):
+                if role != SignalType.DRIVE:
                     continue
-                delay_section.delay(signal.exp_signal, time=duration)
+                delay_section.delay(sig.mapped_logical_signal_path, time=duration)
+        if not delay_section.children:
+            msg = (
+                f"Unable to apply delay to {qubit_names} due to missing drive signals."
+            )
+            raise OpenQasmException(msg, mark=statement.span)
+
         return delay_section
 
     def _handle_assignment(self, statement: ast.ClassicalAssignment):
         lvalue = eval_lvalue(statement.lvalue, namespace=self.scope)
         if isinstance(lvalue, QubitRef):
             msg = f"Cannot assign to qubit '{lvalue.canonical_name}'"
             raise OpenQasmException(msg)
@@ -390,7 +401,35 @@
             statement.qubits, namespace=self.scope
         ).canonical_name
         try:
             return self.gate_store.lookup_gate("reset", (qubit_name,))
         except KeyError as e:
             msg = f"Reset gate for qubit '{qubit_name}' not found."
             raise OpenQasmException(msg, mark=statement.span) from e
+
+
+def exp_from_qasm(program: str, qubits: dict[str, Qubit], gate_store: GateStore):
+    """Create an experiment from an OpenQASM program.
+
+    Args:
+    -----
+        program (str):             OpenQASM program
+        qubits (dict[str, Qubit]): map from OpenQASM qubit names to LabOne Q DSL Qubit objects
+        gate_store (GateStore):    map from OpenQASM gate names to LabOne Q DSL Gate objects
+    """
+    importer = OpenQasm3Importer(qubits=qubits, gate_store=gate_store)
+    qasm_section = importer(text=program)
+
+    signals = []
+    for qubit in qubits.values():
+        for exp_signal in qubit.experiment_signals():
+            if exp_signal in signals:
+                msg = f"Signal with id {exp_signal.uid} already assigned."
+                raise LabOneQException(msg)
+            signals.append(exp_signal)
+
+    # TODO: feed qubits directly to experiment when feature is implemented
+    exp = Experiment(signals=signals)
+    with exp.acquire_loop_rt(count=1) as loop:
+        loop.add(qasm_section)
+
+    return exp
```

## laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py

```diff
@@ -1,12 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import datetime
 import json
 import logging
 import os
 import textwrap
 from pathlib import Path
 
 _logger = logging.getLogger(__name__)
@@ -77,23 +78,21 @@
     The resulting file name is <name>_<timestamp>.html
 
     Args:
         name: Name of the created html file, without suffix (\\*.html)
         compiled_experiment: The compiled experiment to show.
 
     Returns:
-        A link to the html file.
+        A link to the HTML output if `IPython` is installed, otherwise
+        returns the output filename as a string.
     """
-    import datetime
-
-    try:
-        import IPython.display as ipd
-    except ImportError:
-        raise ImportError(
-            "showing pulse sheet requires ipython to be installed, use 'pip install ipython'"
-        )
     timestamp = datetime.datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
     filename = f"{name}_{timestamp}.html"
     PulseSheetViewer.generate_viewer_html_file(
         compiled_experiment.schedule, name, filename
     )
-    return ipd.FileLink(filename)
+    try:
+        import IPython.display as ipd
+
+        return ipd.FileLink(filename)
+    except ImportError:
+        return filename
```

## laboneq/simulator/output_simulator.py

```diff
@@ -26,52 +26,70 @@
 
 @dataclass
 class _AWG_ID:
     is_out: bool
     prog: str
     channels: List[int]
 
-    def __init__(self, device_setup: DeviceSetup, ch: PhysicalChannel):
+    def __init__(
+        self, device_setup: DeviceSetup, ch: PhysicalChannel, realtime_inits: list
+    ):
         self._device_setup = device_setup
         [self._dev_uid, pch] = ch.uid.split("/")
         ch_attrs = pch.split("_")
         {
             "sigouts": self._decode_sigouts,
             "qas": self._decode_qas,
             "qachannels": self._decode_qachannels,
             "sgchannels": self._decode_sgchannels,
-        }[ch_attrs[0]](ch_attrs[1:])
+        }[ch_attrs[0]](ch_attrs[1:], realtime_inits)
+
+    def find_seqc(self, device_name: str, awg_no: int, realtime_inits):
+        self.prog = next(
+            iter(
+                sorted(
+                    (
+                        rt_init
+                        for rt_init in realtime_inits
+                        if rt_init["awg_id"] == awg_no
+                        and rt_init["device_id"] == device_name
+                    ),
+                    key=lambda rt_init: rt_init["nt_step"]["indices"],
+                )
+            )
+        )["seqc_ref"]
 
-    def _decode_sigouts(self, chs: List[str]):
+    def _decode_sigouts(self, chs: List[str], realtime_inits):
         self.is_out = True
         self.channels = [int(ch) for ch in chs]
         awg_no = self.channels[0] // 2
-        self.prog = f"seq_{self._dev_uid}_{awg_no}.seqc"
+        self.find_seqc(self._dev_uid, awg_no, realtime_inits)
 
-    def _decode_qas(self, chs: List[str]):
+    def _decode_qas(self, chs: List[str], realtime_inits):
         self.is_out = False
         self.channels = [int(ch) for ch in chs]
-        self.prog = f"seq_{self._dev_uid}_0.seqc"
+        self.find_seqc(self._dev_uid, 0, realtime_inits)
 
     def _is_qc(self):
         dev = self._device_setup.instrument_by_uid(self._dev_uid)
         return dev.calc_driver() == "SHFQA" and dev.is_qc
 
-    def _decode_qachannels(self, chs: List[str]):
+    def _decode_qachannels(self, chs: List[str], realtime_inits):
         self.is_out = chs[1] == "output"
         self.channels = [0]
-        self.prog = f"seq_{self._dev_uid}_{chs[0]}.seqc"
+        self.find_seqc(self._dev_uid, int(chs[0]), realtime_inits)
+
+    def _decode_sgchannels(self, chs: List[str], realtime_inits):
+        internal_device_name = (
+            self._dev_uid if not self._is_qc() else f"{self._dev_uid}_sg"
+        )
 
-    def _decode_sgchannels(self, chs: List[str]):
         self.is_out = True
         self.channels = [0, 1]
-        if self._is_qc():
-            self.prog = f"seq_{self._dev_uid}_sg_{chs[0]}.seqc"
-        else:
-            self.prog = f"seq_{self._dev_uid}_{chs[0]}.seqc"
+        self.find_seqc(internal_device_name, int(chs[0]), realtime_inits)
 
 
 class OutputSimulator:
     """Interface to the output simulator.
 
     .. highlight:: python
     .. code-block:: python
@@ -150,15 +168,19 @@
         get_frequency: bool = False,
     ) -> OutputData:
         channel = (
             physical_channel
             if isinstance(physical_channel, PhysicalChannel)
             else self._uid_to_channel(physical_channel)
         )
-        awg_id = _AWG_ID(self._compiled_experiment.device_setup, channel)
+        awg_id = _AWG_ID(
+            self._compiled_experiment.device_setup,
+            channel,
+            self._compiled_experiment.recipe["experiment"]["realtime_execution_init"],
+        )
 
         sim = self._simulations[awg_id.prog]
         sim_targets = SimTarget.NONE
         if get_wave and awg_id.is_out:
             sim_targets |= SimTarget.PLAY
         if get_wave and not awg_id.is_out:
             sim_targets |= SimTarget.ACQUIRE
```

## laboneq/simulator/seqc_parser.py

```diff
@@ -7,15 +7,15 @@
 from dataclasses import dataclass, field
 from enum import Enum, auto
 from functools import lru_cache
 from types import SimpleNamespace
 
 # Note: The simulator may be used as a testing tool, so it must be independent of the production code
 # Do not add dependencies to the code being tested here (such as compiler, DSL asf.)
-from typing import TYPE_CHECKING, Any
+from typing import TYPE_CHECKING, Any, Dict, List
 
 import numpy as np
 from numpy import typing as npt
 from pycparser.c_ast import (
     ID,
     Assignment,
     BinaryOp,
@@ -290,17 +290,18 @@
     awg_index: int
     measurement_delay_samples: int
     startup_delay: float
     sample_multiple: int
     sampling_rate: float
     output_port_delay: float
     source: str = None
-    channels: list[int] = None
-    wave_index: dict[Any, Any] = None
-    command_table: list[Any] = None
+    channels: List[int] = None
+    wave_index: Dict[Any, Any] = None
+    command_table: List[Any] = None
+    acquisition_type: str = None
 
 
 class Operation(Enum):
     PLAY_ZERO = auto()
     PLAY_WAVE = auto()
     START_QA = auto()
     SET_OSC_FREQ = auto()
@@ -389,14 +390,15 @@
 class SeqCSimulation:
     events: list[SeqCEvent] = field(default_factory=list)
     device_type: str = ""
     waves: list[Any] = field(default_factory=list)
     sampling_rate: float = field(default=2.0e9)
     startup_delay: float = field(default=0.0)
     output_port_delay: float = field(default=0.0)
+    acquisition_type: str = field(default="")
 
 
 class SimpleRuntime:
     def __init__(
         self,
         descriptor: SeqCDescriptor,
         waves,
@@ -461,14 +463,15 @@
             "setPrecompClear": self.setPrecompClear,
             "waitWave": self.waitWave,
             "waitDIOTrigger": self.waitDIOTrigger,
             "waitZSyncTrigger": self.waitZSyncTrigger,
         }
         self.variables = {}
         self.seqc_simulation = SeqCSimulation()
+        self.seqc_simulation.acquisition_type = descriptor.acquisition_type
         self.times = {}
         self.times_at_port = {}
         self.descriptor = descriptor
         self.waves = waves
         self.source = preprocess_source(descriptor.source)
         self.wave_lookup_by_args: dict[Any, WaveRefInfo] = {}
         self.wave_names_by_index: dict[int, list[str]] = {}
@@ -748,27 +751,38 @@
         if generators_mask is None:
             generators_mask = self.resolve("QA_GEN_ALL")
         if integrators_mask is None:
             generators_mask = self.resolve("QA_INT_ALL")
 
         wave_data_idx = []
         event_length = 0
-        for gen_index in range(16):
-            if (generators_mask & (1 << gen_index)) != 0:
-                wave_key = self._args2key(["gen", gen_index])
-                known_wave = self.wave_lookup_by_args.get(wave_key)
-                if known_wave is None:
-                    known_wave = WaveRefInfo()
-                    self.wave_lookup_by_args[wave_key] = known_wave
-                wave = self.descriptor.wave_index[gen_index]
-                wave_names = [wave["wave_name"] + ".wave"]
-                wave_length_samples = len(self.waves[wave_names[0]])
-                event_length = max(event_length, wave_length_samples)
-                self._update_wave_refs(wave_names, known_wave)
-                wave_data_idx = known_wave.wave_data_idx
+
+        def add_wave(gen_index, wave_data_idx, event_length):
+            wave_key = self._args2key(["gen", gen_index])
+            known_wave = self.wave_lookup_by_args.get(wave_key)
+            if known_wave is None:
+                known_wave = WaveRefInfo()
+                self.wave_lookup_by_args[wave_key] = known_wave
+            wave = self.descriptor.wave_index[gen_index]
+            wave_names = [wave["wave_name"] + ".wave"]
+            wave_length_samples = len(self.waves[wave_names[0]])
+            event_length = max(event_length, wave_length_samples)
+            self._update_wave_refs(wave_names, known_wave)
+            wave_data_idx.append(known_wave.wave_data_idx)
+            return wave_data_idx, event_length
+
+        if "spectroscopy" in self.descriptor.acquisition_type:
+            assert generators_mask == self.predefined_consts["QA_GEN_NONE"]
+            wave_data_idx, event_length = add_wave(0, wave_data_idx, event_length)
+        else:
+            for gen_index in range(16):
+                if (generators_mask & (1 << gen_index)) != 0:
+                    wave_data_idx, event_length = add_wave(
+                        gen_index, wave_data_idx, event_length
+                    )
 
         start_samples, insert_at = self._last_play_start_samples()
         self.seqc_simulation.events.insert(
             insert_at,
             SeqCEvent(
                 start_samples=start_samples,
                 length_samples=event_length,
@@ -971,19 +985,17 @@
         }
 
         awg_index = 0
         if "awgs" in init:
             for awg in init["awgs"]:
                 awg_nr = awg["awg"]
                 rt_exec_step = next(
-                    iter(
-                        r
-                        for r in recipe["experiment"]["realtime_execution_init"]
-                        if r["device_id"] == device_uid and r["awg_id"] == awg_nr
-                    )
+                    r
+                    for r in recipe["experiment"]["realtime_execution_init"]
+                    if r["device_id"] == device_uid and r["awg_id"] == awg_nr
                 )
                 seqc = rt_exec_step["seqc_ref"]
                 if device_type == "SHFSG" or device_type == "SHFQA":
                     input_channel = awg_nr
                     output_channels = [awg_nr]
                 else:
                     input_channel = 2 * awg_nr
@@ -1046,14 +1058,15 @@
             (table["ct"] for table in command_tables if table["seqc"] == name), {}
         )
         seqc_descriptor = seqc_descriptors_from_recipe[name]
         seqc_descriptor.source = src["text"]
         seqc_descriptor.channels = outputs[name]
         seqc_descriptor.wave_index = seq_c_wave_indices.get(name, {})
         seqc_descriptor.command_table = command_table
+        seqc_descriptor.acquisition_type = recipe["experiment"]["acquisition_type"]
         seqc_descriptors.append(seqc_descriptor)
     return seqc_descriptors
 
 
 def run_single_source(descriptor: SeqCDescriptor, waves, max_time) -> SeqCSimulation:
     runtime = SimpleRuntime(
         descriptor=descriptor,
```

## laboneq/simulator/wave_scroller.py

```diff
@@ -145,14 +145,15 @@
         sim_targets: SimTarget,
         sim: SeqCSimulation,
     ):
         self.ch = ch
         self.sim = sim
 
         self.is_shfqa = sim.device_type == "SHFQA"
+        self.acquisition_type = sim.acquisition_type
 
         self.sim_targets = sim_targets
 
         self.wave_snippet = None
         self.marker_snippet = None
         self.acquire_snippet = None
         self.trigger_snippet = None
@@ -314,17 +315,50 @@
 
     def _process_shfqa_gen(self, event: SeqCEvent, snippet_start_samples: int):
         generator_mask: int = event.args[0]
         if self.ch[0] < 0:
             # The old_output_simulator sets ChannelInfo("QAResult", -1, SimTarget.ACQUIRE) to
             # skip producing the SHFQA acquire play pulse, so we support that here too.
             return
-        if (generator_mask & (1 << self.ch[0])) != 0:
-            wave = 1j * self.sim.waves[event.args[4][1]]
-            wave += self.sim.waves[event.args[4][0]]
+
+        def retrieve_wave(real_idx, imag_idx):
+            wave = 1j * self.sim.waves[imag_idx]
+            wave += self.sim.waves[real_idx]
+            return wave
+
+        wave_indices = event.args[4]
+
+        if "spectroscopy" in self.acquisition_type:
+            spectroscopy_mask = 0
+            assert generator_mask == spectroscopy_mask
+            wave = retrieve_wave(
+                wave_indices[spectroscopy_mask][0], wave_indices[spectroscopy_mask][1]
+            )
+            _slice_copy(
+                self.wave_snippet,
+                snippet_start_samples,
+                wave,
+                event.start_samples,
+                event.length_samples,
+            )
+            self.last_played_value = wave[event.length_samples - 1]
+        else:
+            wave_iter = 0
+            wave = None
+            for gen_index in range(16):
+                if (generator_mask & (1 << gen_index)) != 0:
+                    if wave is None:
+                        wave = retrieve_wave(
+                            wave_indices[wave_iter][0], wave_indices[wave_iter][1]
+                        )
+                    else:
+                        wave += retrieve_wave(
+                            wave_indices[wave_iter][0], wave_indices[wave_iter][1]
+                        )
+                    wave_iter = wave_iter + 1
             _slice_copy(
                 self.wave_snippet,
                 snippet_start_samples,
                 wave,
                 event.start_samples,
                 event.length_samples,
             )
```

## Comparing `laboneq-2.8.0.dist-info/LICENSE` & `laboneq-2.9.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `laboneq-2.8.0.dist-info/METADATA` & `laboneq-2.9.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: laboneq
-Version: 2.8.0
+Version: 2.9.0
 Summary: Zurich Instruments LabOne Q software framework for quantum computing control
 Author-email: Zurich Instruments Development Team <info@zhinst.com>
 License: Apache 2.0
 Project-URL: Homepage, https://github.com/zhinst/laboneq
 Keywords: quantum,sdk,zhinst
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
@@ -41,14 +41,15 @@
 Requires-Dist: requests
 Requires-Dist: rich
 Requires-Dist: rustworkx
 Requires-Dist: scipy
 Requires-Dist: sqlitedict
 Requires-Dist: sortedcollections
 Requires-Dist: lagom
+Requires-Dist: attrs
 Requires-Dist: zhinst-core (==23.2.42414)
 Requires-Dist: zhinst-toolkit (~=0.5.0)
 Requires-Dist: zhinst-utils (~=0.3.0)
 
 ![LabOne Q logo](https://github.com/zhinst/laboneq/raw/main/docs/images/Logo_LabOneQ.png)
```

## Comparing `laboneq-2.8.0.dist-info/RECORD` & `laboneq-2.9.0.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,99 +1,102 @@
-laboneq/VERSION.txt,sha256=op_rvxnmr4MCu4de1UkQY6h1VcwBx-VceZAvgEHqxC8,5
+laboneq/VERSION.txt,sha256=YYRkNjC4qAdbDGLeba8nMjmjiTNuzdW35BBwZo8MgeA,5
 laboneq/__init__.py,sha256=OrHAykevakOnwEAHajG2qdB1PxEirEowKhDX2V5cHKA,239
-laboneq/_token.py,sha256=D2wS1TbZ6-CzF73l5kd6Wilcm18IPyymygB6VakHyRc,2829
+laboneq/_token.py,sha256=-7XxWP4nokW9wsNrP253LfQl2M00ct1BnjQoeCM5BjU,457
 laboneq/_utils.py,sha256=4TRw9Hv192vqcPwcPDBsqXcdAGhIOvH_D24mZdyfZok,928
 laboneq/_version.py,sha256=zaxeCShR641vx5bH27_dVdirv71bA2i9ciFcH4A2krE,238
-laboneq/simple.py,sha256=PA8D5jqJYnNvSWb0LBZGWah4nNEA85Li0tWmZHbmwSY,1565
+laboneq/simple.py,sha256=6ueOT63Wnc6QB972M7iAwa6w9yemNp5xU1Udk0lG5K8,1628
 laboneq/_observability/__init__.py,sha256=rcsPn8d52W6G9ZGkI8TPrEtwSJ2WbQN_Urc2DiIaUDg,184
 laboneq/_observability/tracing/__init__.py,sha256=rEFK2BFplAYa8ZHwQpiaVKv9EaSDrUWKHBplg-AmzGE,538
 laboneq/_observability/tracing/_noop_tracer.py,sha256=z7yhOOaTwCbWTQVQJ3i0SPCYsvd2wdbngf7ygoPJVCE,893
 laboneq/_observability/tracing/_tracer.py,sha256=vqgWJiy17tpzSMIOFXgkXHg9oQotbM8Jd-cWjNyVvk0,2309
 laboneq/application_management/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/application_management/application_manager.py,sha256=H8j88An67TfPUcyDwfj3IrLaxbYqwho5bL_yYuGXuaU,2658
 laboneq/compiler/__init__.py,sha256=PQOZ0TyWFSH0U7NJZnaYtO62iQW7DGgEV5KQD0lyKVw,444
 laboneq/compiler/fastlogging.py,sha256=SCJykQ5V_qvRPvWkkDZOqFexmazzhW-fbP2jkglOUkA,204
 laboneq/compiler/qccs-schema_2_5_0.json,sha256=YauxP1Z39AGXi5lUB7eKRLsRxsllayxNlzeyHQBGOSY,22524
 laboneq/compiler/remote.py,sha256=Fyb1RaWU-JBudPSv3LN56yQhYndduOchiai2brTE1WA,666
 laboneq/compiler/code_generator/__init__.py,sha256=s8ihwbuWxGpCAMjnsBXQ0kdoXGqT-B8doSsk850gQA0,654
 laboneq/compiler/code_generator/analyze_events.py,sha256=Ohg_gOZul-azPbaK1XVXDffSDEaLzj5i-EZ2SAYiVWg,18669
 laboneq/compiler/code_generator/analyze_playback.py,sha256=F7H8nLlO2LsNFsedP5-j-afsem6II5cUrF8qtH-RUoI,26669
-laboneq/compiler/code_generator/code_generator.py,sha256=yVE7FT4BDItQZsY_P3j4ziNo1saqRuEMxIgNeN0_X_4,71964
+laboneq/compiler/code_generator/code_generator.py,sha256=S2PGlwUZru_OvVW2kzSSYXAZOwQKOxDxNv_RYpEzTp0,72969
 laboneq/compiler/code_generator/command_table_tracker.py,sha256=jXD4Ep8SMIgS_DNqgdfnGujma-oRhRZcvFcIa-AkAXc,4026
 laboneq/compiler/code_generator/compressor.py,sha256=sIbtla_ju0NM1FL1oWGV7SMyxpZoNKwMzHKvbyb3Ut8,2880
 laboneq/compiler/code_generator/feedback_register_allocator.py,sha256=iXuwHFa9g5YQriNqLHXoHIzkBanyR8XnD9C0mw6sPQU,1414
 laboneq/compiler/code_generator/interval_calculator.py,sha256=7dyk02iUdPHyzS4DU6JvkTKn36yWpUE2lhvUynY0aYQ,10355
-laboneq/compiler/code_generator/measurement_calculator.py,sha256=w15OoQt0yXR4k3V2nvJT2CoNGtrPDeCiPoQazk5TZFc,17825
-laboneq/compiler/code_generator/sampled_event_handler.py,sha256=f5GlIAKgVDSST-nS7MpR93im0LvlbjpOYPOlZa0tLzA,30380
+laboneq/compiler/code_generator/measurement_calculator.py,sha256=RO0z6TqdbxykEtTnTGgeNNc3Gf7tT4JVYrYvrIMZydE,18174
+laboneq/compiler/code_generator/sampled_event_handler.py,sha256=W3jEBhecSbyqIbXg35EzQtP0jgtTcIhuyCJpJAuJRMc,30752
 laboneq/compiler/code_generator/seq_c_generator.py,sha256=cdaWiqI6rgg-xR_oY5qYNVW5AVfgaCk7Zawk7jFr-BE,18722
 laboneq/compiler/code_generator/seqc_tracker.py,sha256=bZPvLecbCXYH02TlTL7KkhOv6NXoMHOmS_kLZE9WzO8,6333
 laboneq/compiler/code_generator/signatures.py,sha256=fQWI4maz7IPPMexBPWLsU0dhhQqlVvnQhupGUG9w0Ns,10031
 laboneq/compiler/code_generator/utils.py,sha256=KJtRJg6wE8FPALrG4B8H7GRZa_7WqOrXroWW8kgSdBA,3500
 laboneq/compiler/code_generator/wave_compressor.py,sha256=Wfg7pB_YsjeSPBso8C1kExSUSES82Y2VCDjbOMTyVA0,9102
 laboneq/compiler/code_generator/wave_index_tracker.py,sha256=700LQq60nX9Btcn9bj2SDn674qRmsxy_Nz6yy0qx1Y0,1476
 laboneq/compiler/common/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/common/awg_info.py,sha256=djhjq5t8JruHRi9hKk4rtBVH4KfMWRkuamcypmhP6WA,1093
+laboneq/compiler/common/awg_info.py,sha256=wiiaZ6H60kWRxvvqZKhTpnPhXq_Ed-dWh_Psapxqlcw,1079
 laboneq/compiler/common/awg_sampled_event.py,sha256=Sz21qx__YTdkpeBAhpfyVgT4ED1zUR4OiIn6GTnNVvw,1926
 laboneq/compiler/common/awg_signal_type.py,sha256=aXiZ_K-yaG1pPPUMh5IpOXn2rQJngQnTzwqP1LExtT8,480
 laboneq/compiler/common/compiler_settings.py,sha256=1Rr42CsHTmKtykUgOQuu0H56jCV4cGHAgoMb0nVuPFM,4015
 laboneq/compiler/common/device_type.py,sha256=QK48fFIH9-bcO25j6l4d-WrG1kpyapoTEZvHLzzsffI,6058
 laboneq/compiler/common/event_type.py,sha256=uFnpVFeUU9m-dEBgNzmo3Sj8SSoLwFOj9i_Wk37Kk2M,1624
 laboneq/compiler/common/play_wave_type.py,sha256=9olrAuZqSSq-3fDpUCwbH2IC2F1mYaZ64H_NG0J6eXM,229
 laboneq/compiler/common/pulse_parameters.py,sha256=zhIljy4MHaBGSFYR-28ksDetM39C5p006e8flU21ZWE,580
 laboneq/compiler/common/signal_obj.py,sha256=87PUbOLhI4vdpDdRTUYWNJK275tkozTPM0BPShROlNU,2541
 laboneq/compiler/common/trigger_mode.py,sha256=PfV_HskFUlk99bsngdjYz-b137e2qA6e1TNqA0Bjvbs,400
 laboneq/compiler/experiment_access/__init__.py,sha256=mb9ULouZiKIforKo2d458L6pvf0LmV4PXhmKhPBUj7g,154
 laboneq/compiler/experiment_access/acquire_info.py,sha256=bQrMObuyxABUpGTc0ubuUvOs15KzKJzos1dPw4B_PYs,222
 laboneq/compiler/experiment_access/device_info.py,sha256=HQBj1WpSt8TwHX5G_kE-1m5ulJ06-j_hdIIVamxHQDI,349
-laboneq/compiler/experiment_access/dsl_loader.py,sha256=qakMUQYeSGZaH9NqN1bDSkDNvlnfnYoQ-oGS0S2QLU8,45124
+laboneq/compiler/experiment_access/dsl_loader.py,sha256=at95uNRGgwolYz_WH44jpsVJ2t_PlJbzAkmhkid1qMU,45626
 laboneq/compiler/experiment_access/experiment_dao.py,sha256=qJhN9vRGl0GYsIfBc8xuBxM4aR4-4jFYIkAOvFhsCmU,16726
 laboneq/compiler/experiment_access/json_dumper.py,sha256=jjVvU-2PPdF9avWQGkkK4IrhFmT20FojgbURa9EfQ5Q,14122
-laboneq/compiler/experiment_access/json_loader.py,sha256=XY7srlHpGcByKLJ8Btn3GRQr9Wx16i4dBVjPWUAa6EQ,20825
-laboneq/compiler/experiment_access/loader_base.py,sha256=YU27dCvNy3JRApvbtqmL6x4w36cZzJZjwyjg4dJwP2Y,6256
+laboneq/compiler/experiment_access/json_loader.py,sha256=r1FeW8s6r_zgCRF5i_aIsBLOaDvaoHO2rSIZEfgnui0,20860
+laboneq/compiler/experiment_access/loader_base.py,sha256=5DsMv9Y-0iot1ndQkkzKPcHftKrCGNsuRUKeuTqcF5k,6253
 laboneq/compiler/experiment_access/marker.py,sha256=2Okj9Q_Ukk02B-Z7_WDM6nHN-nuXw3qFjUNaw8LUMsI,270
 laboneq/compiler/experiment_access/oscillator_info.py,sha256=VvEyOttSTDd7-oxpbim4xmPJUwYEzjrsDXup9xLwI0k,286
 laboneq/compiler/experiment_access/param_ref.py,sha256=wqyyzAiSIEu2GVeNdZc-MtvdhdSDp1Quch8qBVIPppw,197
 laboneq/compiler/experiment_access/pulse_def.py,sha256=wC192cXc_oxtxj-xJS2tY2dHkDr_CAYrtIkcp45gj6E,1311
-laboneq/compiler/experiment_access/section_info.py,sha256=4QCszplfb3FiWWqQZWLMkvc1yythBkpqu_6HdA0Sw0c,817
+laboneq/compiler/experiment_access/section_info.py,sha256=bjpGPj1BeeZlFclL2wMgGSaBLjGFstxmyqiP-lq9npY,838
 laboneq/compiler/experiment_access/section_signal_pulse.py,sha256=ZGgbvNW3v-qIgyvcW34Lk31hyhFeNb_UjE6uIUXd8os,1069
 laboneq/compiler/experiment_access/signal_info.py,sha256=HLkN-Kq2vZrh5tg92RA3ZSSYaiRXXQecw01-NtXGR_Q,387
 laboneq/compiler/scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/scheduler/case_schedule.py,sha256=HwzkOLBBYQip5bDBxNApQnGITb5cgyLVsYezwhxCdCQ,3265
 laboneq/compiler/scheduler/interval_schedule.py,sha256=tp4CauVPr-hOXxtzvUQYZrmXcqJBY7UqQDPlDDo1S_0,7439
 laboneq/compiler/scheduler/loop_iteration_schedule.py,sha256=5RKVr5tmtYqcGx8DY_kichm2rjeHtXbMrthFzwzFE9U,3327
 laboneq/compiler/scheduler/loop_schedule.py,sha256=RUFiK0sMisFwB1NVL1fAphcxKGMjB1f0ZpMPAf5-_fk,8576
-laboneq/compiler/scheduler/match_schedule.py,sha256=U67d7l60-qetl9v7BEaX3rbQvlzzfMLNYZ7fZAYC3rQ,10468
+laboneq/compiler/scheduler/match_schedule.py,sha256=xATr4GcEfxLkIYKnYn7dY_dSRzmLEMjo3aFeqlM5yFA,11090
 laboneq/compiler/scheduler/oscillator_schedule.py,sha256=Iykf3E3wT7xXuH-hVk9_MwTHM7eWQFmhR3JzzQTd1eM,2248
+laboneq/compiler/scheduler/parameter_store.py,sha256=x4IKUSFPq0RpKSXjdL3sJcd-47CTTNlreI5Fr0lGUFk,2574
 laboneq/compiler/scheduler/phase_reset_schedule.py,sha256=yLyoKe5S57LGcPMcgFxsBDyKjPROgCUdASTSPU-fQog,1761
 laboneq/compiler/scheduler/preorder_map.py,sha256=luqooLzAEbK2b0j8TIDcHsE3riHA_GFyhcSRerHUFUk,1808
 laboneq/compiler/scheduler/pulse_phase.py,sha256=poXl-PKFIO7X_xN3Qjqo-NWC-svaom3dWjetfKEsw8c,3821
 laboneq/compiler/scheduler/pulse_schedule.py,sha256=im2DdPgi2Q4pQq4Q-YnApyZyi04888iSOq03BRrzNds,6958
 laboneq/compiler/scheduler/reserve_schedule.py,sha256=WM-fLfdDnViVwB5U0TrrkiDKB0s3DSw3yUFLC5vyvQU,621
 laboneq/compiler/scheduler/root_schedule.py,sha256=2ErHbKUaD8f6xp42UdoCSaQ5AeZc5n4PNHaluspKRcE,1367
 laboneq/compiler/scheduler/sampling_rate_tracker.py,sha256=taR4AdTTaYNXfaEgM5hZNhL2VbcGnJCkx9gt4xAJg9E,1949
 laboneq/compiler/scheduler/schedule_data.py,sha256=f1m_AVtgmeOJ5nYgFw91OeCWauqB28MyewEovnNHkdw,1115
-laboneq/compiler/scheduler/scheduler.py,sha256=rbrWG2msZJ-wigS4uvDSatqsUT_UOB2JnA_pdTrZjNs,41072
+laboneq/compiler/scheduler/scheduler.py,sha256=mmrq2C5nCpvXxKwjGSdHNnZ6U0TZLXx69PZcGGBaKhA,41574
 laboneq/compiler/scheduler/section_schedule.py,sha256=UruX04LNrMUUAUoJ3RooT3zSquPW5Atfa18ds6n8sWw,13191
 laboneq/compiler/scheduler/utils.py,sha256=buFGd2oxNFr3hfGc8fx_dyMCbxTwimiSOuxCqeqSDRk,757
 laboneq/compiler/workflow/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/workflow/compiler.py,sha256=RnTQKjJ7Et5MhjwjXz5v2Soqf5fqrl4-MGFhXLavHnA,47515
+laboneq/compiler/workflow/compiler.py,sha256=Ic3vWBHXq72cwbbqvzUhZjsUmxolZHd-g87_oW5vPRg,49079
+laboneq/compiler/workflow/neartime_execution.py,sha256=YmhpGlIq0fTz6JIWHc_Z0FFEuc25ilN6jBlo2Q7NiLI,5657
 laboneq/compiler/workflow/precompensation_helpers.py,sha256=dpRw6dGJcsDAv0uI48cfzso75IYHNVfP1NUkRhD-giI,12424
-laboneq/compiler/workflow/realtime_compiler.py,sha256=6Qjl4z2xkbmnbRZY2MeMB6-CSGuWrhZOd0SJeJyMd0g,6847
-laboneq/compiler/workflow/recipe_generator.py,sha256=g9CzZEkX5Vfctu5j0iSr5K1_ZbxviumqLnVrqrsU0Qo,12441
+laboneq/compiler/workflow/realtime_compiler.py,sha256=AqU3TADVSoUgOFXDwYqsXHYryVgFUiIuhOeat0szAUY,6979
+laboneq/compiler/workflow/recipe_generator.py,sha256=pXli9HYLOqv2rwTlB-LDeBFWRHSxbJRibumj-K_i3HU,13073
+laboneq/compiler/workflow/rt_linker.py,sha256=LqWZN2dFm13NtPNHbf6kemc1cgIZCNtTqJtLGXfvqTE,7061
 laboneq/contrib/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py,sha256=dII-ZVAa3HumwKfHYGiARVBDCjaqJhGFy55XAjOPiaM,4511
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py,sha256=3RjtFb3sxYokBP92COK53gCmBrCk9ubs8_xOb75fem4,3379
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/bloch_simulator.py,sha256=VzPR_c7CCIf80jMKiYSVXYZH_BIDv3KYipLaDPqGSxw,2833
 laboneq/contrib/example_helpers/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/example_notebook_helper.py,sha256=ufTkf4Uygm1ajgv2-feNBwj2HR2ewas730S9FuddKOs,6272
-laboneq/contrib/example_helpers/feedback_helper.py,sha256=pqth_zVGWqEJz7DBdv3EUryfWbqOWCmneF6PyRNLQV0,4116
+laboneq/contrib/example_helpers/feedback_helper.py,sha256=Lajqo7ySkLlIvF1DvB8AqpmHqHaCSR_X5IkS-qRKWYk,4112
 laboneq/contrib/example_helpers/qubit_helper.py,sha256=Eh2UVnSrGlBy7nmxRcCWpQL2GG2fCrA1A6582UbYWqg,3581
 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py,sha256=JKYF-5BXJJ3aBc4fEOOGnbheh9LPX4wir-xZCMrrzTs,8830
 laboneq/contrib/example_helpers/data_analysis/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/data_analysis/data_analysis.py,sha256=8eNR-b89_rs0odyNcWmH0DlTZ9zZHYI1wjIRCy8buSs,6670
 laboneq/contrib/example_helpers/descriptors/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/descriptors/hdawg.py,sha256=Q8Asxnt3x1Jl84nrTahjOgx-Ao_TWYdbIFf4WZdAkCU,502
 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py,sha256=CzjRnXjw4v_WMtSvY5xZbmLztyEHfAQlzMbgvZ8cAmE,956
@@ -103,53 +106,53 @@
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py,sha256=cH9gx4th7Gh_oC72Fs0U3XQL1DUW3ownAv3BYsJ4PnA,2160
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py,sha256=PIPiyvyyMv9wwcKBf81xFhF1Pflol2WrS5fkfb21EKU,2708
 laboneq/contrib/example_helpers/plotting/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=yYgexGfC12FehKFFDro_uuAjKuEaKz_zvZRJFTAOcIY,12182
 laboneq/controller/__init__.py,sha256=gPuU9BwcRA-VFMRLtIzd9Y-KvLQhYv0czaGuo-uimjc,308
 laboneq/controller/attribute_value_tracker.py,sha256=Q-PznOOJHYue9gCwxM8bktkZse4FSGJcNrJINBqjItM,3380
 laboneq/controller/cache.py,sha256=sI4qtTQurYPWzMp7iW1oKwQp_GVftQX9isDkTNZ-bDE,1479
-laboneq/controller/communication.py,sha256=K-9sn7UABcGb9hGLM_8tLYtKWbNeSvUqcoubnBUTcvk,13604
-laboneq/controller/controller.py,sha256=UatTQTmZqF66kgNraEvp0QlLoSKMhTj1fnSALgkMasQ,30852
+laboneq/controller/communication.py,sha256=mykR0IB26QKTJ9rwrmx3aHgA4omqLwQHv_Hhq7d2r2Q,13484
+laboneq/controller/controller.py,sha256=91iecHJCNVxXpmnj2sPAvqH_5diR1-Et324i3NOOITQ,30444
 laboneq/controller/laboneq_logging.py,sha256=9S7qvoF2MzOvw-BQLpHi7sLSe0v-xoAo0P0I_mbCPLU,4892
-laboneq/controller/near_time_runner.py,sha256=0RsFuXKbOShRpPInWW3BfscGEYZdFX8-qb3znqu0YpA,4671
+laboneq/controller/near_time_runner.py,sha256=6-hx8K526N3ocXA4U4veeWxLEB8tMIwQHtuxLp2QxEs,4472
 laboneq/controller/protected_session.py,sha256=v4T5NsQxE57E22hJltIumOnLAoBms0D7ZTtUYjGHGGM,337
-laboneq/controller/recipe_1_4_0.py,sha256=csiCQdbuH-buQVpjJlmsqnRqfRrAT3VH7jU8UerUoII,12301
-laboneq/controller/recipe_enums.py,sha256=Tzp88VZKEmOUe5j9Z3Sq5FXRQhOhrdEa4lZwsmHFNbQ,529
-laboneq/controller/recipe_processor.py,sha256=HtOwKlubHuzzYJnvx4CefNTawjMFcJg9LQby3-GDpv0,21441
+laboneq/controller/recipe_1_4_0.py,sha256=_wf3ZNWNZp5t7Ub9f8uK_P_qeWSLjvX5qwOS5aMZw2Y,13105
+laboneq/controller/recipe_enums.py,sha256=-KdcmU97_TSIgcqoODpCfXY4yu1gTl4cEqqhaYEq2KU,776
+laboneq/controller/recipe_processor.py,sha256=dNGrfu6JxQmBYxq76F0p2yn0uER7De9eooZOBoylqD0,21227
 laboneq/controller/results.py,sha256=S3eZ2xrXt2tly2M9TCrOstazN9oWNwB9xf0wDJJ-7go,1902
 laboneq/controller/toolkit_adapter.py,sha256=moZzwjnRUUbyT-7JL31EBtBh39VD3USx1SRolFS8v-g,1594
 laboneq/controller/util.py,sha256=fi5_nCRrmORASGaFlge4TN6gXAWZIiS0pinr9-DVjnA,1178
 laboneq/controller/versioning.py,sha256=IcmXytxA6OtbudyM2aK8gCgWLcuLbweru5wIafolpnU,281
 laboneq/controller/devices/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/controller/devices/device_collection.py,sha256=w6jA90eMIXZDcXXp85y12ekc3DoQwzclPSmaYWszRD0,15692
+laboneq/controller/devices/device_collection.py,sha256=hdadLkD98FmUrAFwCjOv5RGIaw38RjaNx7QUP92h6io,15911
 laboneq/controller/devices/device_factory.py,sha256=CQmdrldqyhI7wCFw2aObszp9g3XhPaJZv9Y8U_VAdMY,1275
 laboneq/controller/devices/device_hdawg.py,sha256=H04dHZgNIsQBBp6XWKJSU9sBmDE4LFV2AyLTDUtGfP0,24400
 laboneq/controller/devices/device_nonqc.py,sha256=m1rpD0XgwgNChmIkzdOBFiyg4bbPWY-1b0ysrMLqLNs,491
-laboneq/controller/devices/device_pqsc.py,sha256=6HVcljbJvEpspB19rzzsbcXTXJRlbzYSNfNqWLa_R2E,7898
+laboneq/controller/devices/device_pqsc.py,sha256=N68v94-CEH-P-fNf5e03JyUUBp-vnVKgANkaAcKsEo8,7901
 laboneq/controller/devices/device_setup_dao.py,sha256=9XsGUnPALiOyg9T2ZB9TvTpA-VsdkMqkhoXbX3Yv-kc,4441
 laboneq/controller/devices/device_shf_base.py,sha256=V3dMo8SU2i3_MWDKNunQs0T1YI_jkX5Gs3xYcw1b2SE,2064
 laboneq/controller/devices/device_shfppc.py,sha256=nYaF3Q4DDGBdr0V2-jV1qqLHviVZ4OFbzg-6xcjn9_g,4408
-laboneq/controller/devices/device_shfqa.py,sha256=gS4UVg9kchX3pWK3lXozaDkkH2EcNxmDJAAZ0mFOJ3M,41523
+laboneq/controller/devices/device_shfqa.py,sha256=cI50N1QFw6BT1JP0p2sawRIiKm7B92Ut7QYAOUfgRng,42675
 laboneq/controller/devices/device_shfsg.py,sha256=XRhQf9auynSLRtuHdLX38XttcpYsPw0bZZ_a5n6hiG8,20499
-laboneq/controller/devices/device_uhfqa.py,sha256=rS3FKel5Jby3ckwpgiAG0xbIsM_xuYxeHchWh_BvWYo,29497
-laboneq/controller/devices/device_zi.py,sha256=0T7obImVmWhI0g5IU2K_w3K2CMzoG817s8iNE8tl6JY,32396
+laboneq/controller/devices/device_uhfqa.py,sha256=YX8QgVGGf3FleeoYZ8wxh0mVy-gm5DqpD1kNU30iWTY,29590
+laboneq/controller/devices/device_zi.py,sha256=9h2m7ntURUE554rn-FBgAiPTZVYc2tMAAORg7aDN7dg,32470
 laboneq/controller/devices/zi_emulator.py,sha256=9zaa72zvCrHnCwFFV7JwklmB9d2QiuIs2VO8cUcvkho,29980
 laboneq/controller/devices/zi_node_monitor.py,sha256=2N2Q79sP-USY9-ovk5DHOXiO6Sov9QSzBGqdsyAPnuA,10358
 laboneq/core/__init__.py,sha256=nx0-aqsC4hdoO7jIj0Ut7yNTQbe5dme7jodU9wkd4N4,97
 laboneq/core/path.py,sha256=ZDMafOg44r5I3T-sW-iY6j7xrjYMbx12UsLoqbhg3Vw,2015
 laboneq/core/validators.py,sha256=pmtl8RdlBr-49CkxJseW1VrDtJU2gqLVBWSZdLrRpWc,1338
 laboneq/core/exceptions/__init__.py,sha256=8ZaME3lWkRJ7BZw1qVWGbt91jaklPd67iyIZ-zXoBpE,126
 laboneq/core/exceptions/laboneq_exception.py,sha256=bWRVbnLJiBszdNeEglRFp-z1Q3bb-irTIzf2vgTaBK0,123
 laboneq/core/serialization/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/core/serialization/simple_serialization.py,sha256=03qj5sZYadGGsqmd7qyCGmDizeRr8d91edo2Er6FT1Y,19090
 laboneq/core/types/__init__.py,sha256=fvF9SQu_JVfxc3et0G1RWE-FZvliRnYc_m6Ym6oavto,161
 laboneq/core/types/compiled_experiment.py,sha256=lozDc0EIOQX1iUuFSIyHPAdnjYj4izPnuSNtwLjbEHA,5075
 laboneq/core/types/uid.py,sha256=bly72s6lGrQLYLJ3sk-vjJgzGhbLLYuQ87HMR9BOG9I,1473
 laboneq/core/types/enums/__init__.py,sha256=RfmSFJUHNxbqCeYHZWeg9Vl5wAA9u8k-_LDMTOTBbmM,660
-laboneq/core/types/enums/acquisition_type.py,sha256=PpK4El9Gvmt7ojw6tCcTSkfrDkJxmpvZyE2wbkPooLg,934
+laboneq/core/types/enums/acquisition_type.py,sha256=qKxm-3Ex8bN4ttgeDxscVRUz9_VcVnsATRssDywmMLI,1579
 laboneq/core/types/enums/averaging_mode.py,sha256=skosaedPnNxrW_UGRpksM1uiT7tCRLNx-9I3SuvdlMY,213
 laboneq/core/types/enums/carrier_type.py,sha256=PEbKKDkeBlQuUJCF-TFytQHjZf_enLJUDOvImdwVBH8,188
 laboneq/core/types/enums/dsl_version.py,sha256=Ba_d-Bw4wPQOb7Nv6Uy1S5XFCvDBXkNWzOoiPokiVxs,227
 laboneq/core/types/enums/execution_type.py,sha256=5AndgsShuhqkXr64g3IOuXal_TvhCrVMl7PkblOrZ1U,185
 laboneq/core/types/enums/high_pass_compensation_clearing.py,sha256=x0F2mYFI5rT1-hEYylTZQRP31kas2PX0fsxkZ42oUaQ,333
 laboneq/core/types/enums/io_direction.py,sha256=RwJfnTnkhC6GyuoQ-SbdpySgeSkDreMpWkWlNGWwwY0,157
 laboneq/core/types/enums/io_signal_type.py,sha256=eZbqdP51PHnH77vn6MUup7igCrS3pnx-15x8MO50MAo,268
@@ -161,121 +164,123 @@
 laboneq/core/types/enums/section_alignment.py,sha256=nYuTh1r0PL35aQoLUgeOGTnZoAb6XhGPgVY4a70UMgc,170
 laboneq/core/utilities/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/core/utilities/compressed_formatter.py,sha256=PsOA_xZVu0cX4uAk33ax5ZPjCEJ1Dv2UspvjGCj6Si8,1813
 laboneq/core/utilities/pulse_sampler.py,sha256=eKdg1IcTwjoVmp7mKSSAu6eV80mYPgHaMUUr9AIWkZ4,8039
 laboneq/core/utilities/replace_pulse.py,sha256=v5sA6qtAUU0cP1RMeYjiGVOEtZsCDQILcQA0IRmoPPE,9873
 laboneq/data/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/data/data_helper.py,sha256=ca5jUyF_lkiaRMPfPNyBmXumb5_TrHmoEW4NQkPIisg,3627
-laboneq/data/calibration/__init__.py,sha256=CUauhqJddoXpivkMrzIFsfQKXPSeN3YnKiY1p4tvtRg,1738
-laboneq/data/compilation_job/__init__.py,sha256=Y_JYiwAkCH1UN-Jek6NGNKmVvBK8DTJzFrY6wj3Y2RU,3199
+laboneq/data/calibration/__init__.py,sha256=suIn5jJlzbv_Dy0PWZmtoYzs7x3lhXYeI_dUZQTrKtw,1748
+laboneq/data/compilation_job/__init__.py,sha256=3-pn-ewVeQPWowfBLLdJES2tZPbSduRtTeVKOx0pfDQ,3227
 laboneq/data/execution_payload/__init__.py,sha256=GoYwGV2AUjqI8DxffEfaZ_Xe8vZsjATqnVz8--61NzY,3887
 laboneq/data/execution_payload/execution_payload_helper.py,sha256=pqwt_HmL67VTv6HTYSdOVs4j9MsOt99MbFcqkVptqJg,842
-laboneq/data/experiment_description/__init__.py,sha256=IyLHHANr1OMIl49rS-CWSkrAw4eYoUNm7BQtJuRqWL4,5188
+laboneq/data/experiment_description/__init__.py,sha256=4tHU1Hf5LqK6KkHeFsb38EOzHl0yjtOEavQu8oFAh3k,5198
 laboneq/data/experiment_description/experiment_helper.py,sha256=XekNd06WnP4oe51h90szF7VjHyoSw9JvBdqljNSzyxo,583
-laboneq/data/experiment_results/__init__.py,sha256=WPq3zHfdbaxiAUcLYf23cgaIVJ1VkMSrGpY1YkI-258,950
+laboneq/data/experiment_results/__init__.py,sha256=QEOQZZUz6A45CRq-IjreahlnMvgJqMJpH_ibG7keEjo,909
 laboneq/data/experiment_schedule/__init__.py,sha256=MiqtMp3ml2V4wwfTkQlzm1KYSaHSjr8J8f_051d34Uw,761
 laboneq/data/scheduled_experiment/__init__.py,sha256=vWDzi2fhnH9DNyfq3KBNjLNCG7RxMKe09tLAiwptnbU,1782
 laboneq/data/setup_description/__init__.py,sha256=L5L_rh81LvYqQcIKKJPhEp99A1ujx-S0txfkQLRU6So,3367
 laboneq/data/setup_description/setup_helper.py,sha256=vVlRJxe_Bt3XCnNbDj0-FvP3raYMjj4Xn7JGK_4Tdg8,2845
-laboneq/dsl/__init__.py,sha256=gsR9dv88edpbJLrwc_X2jj147IfVWpnTT10td01fPkY,178
+laboneq/dsl/__init__.py,sha256=pE5CEAweoY61TCMFkP28c8cEzbU3Z08jFVsOdvHRvjQ,220
+laboneq/dsl/_inspect.py,sha256=SA-ysomNjPU4XtOXPuYYTlnBtXMj3j8L_kaqbZ4Ahng,1965
+laboneq/dsl/dsl_dataclass_decorator.py,sha256=OF-v1LEuycxUXOasPn7t84y_0VyqDLDs30U_rtwxAn8,844
 laboneq/dsl/laboneq_facade.py,sha256=uk6A352TiRfbFkOZgw7E23mjRCBPYnTIzsdwENfN6Yo,2947
-laboneq/dsl/parameter.py,sha256=AbR78048B3-jyYvq_A5rmBqaeg4v0C601f9EGFJzRN0,2552
+laboneq/dsl/parameter.py,sha256=dQ7aOVHB2LhIJoqX-ljzfbus--Iy-feZr6Kd5Sw9Haw,2989
 laboneq/dsl/session.py,sha256=P-mOhpv3-u5stl3oeRSjTn97b4Nm4M42gxw24HYzsT4,25670
 laboneq/dsl/utils.py,sha256=v0qlt2XA2CXiGK3Rpi_PC45YZGeQriRz-ShovaTXMBE,2296
 laboneq/dsl/calibration/__init__.py,sha256=3becZcLdza9jTczHmfBgbbaH238UfP9uPakbhe5kwto,529
-laboneq/dsl/calibration/amplifier_pump.py,sha256=H1L-uYlCL3sXTMXIbBFcWS9ln1mFiz5lCr6NnLUKODk,946
+laboneq/dsl/calibration/amplifier_pump.py,sha256=COhpEOFINilNnMnJPdK5KWav72tUl7MbUkcrssfVKpU,1025
 laboneq/dsl/calibration/calibratable.py,sha256=DEx55rhplLTxoaf8-bGnmZqyO4eZdIyMptiLAGKEp7M,545
-laboneq/dsl/calibration/calibration.py,sha256=3t6v9XjyhsT8ZtZM5kIRIgfUy99OWk85JvcMFtDc-Ok,2313
+laboneq/dsl/calibration/calibration.py,sha256=sD9ZqXCCx6tWkZWSwx8Tj82Ov2FgHXO_3aEqOHYXuXA,2392
 laboneq/dsl/calibration/calibration_item.py,sha256=JlPu54zS2NfivokgD4ICOhrw5e3Rhs5DO7pB0iDazpY,111
-laboneq/dsl/calibration/mixer_calibration.py,sha256=_ivXcsDgELxaC8zZ7E5caMhE-HZYSuuDyR5odaVImKw,992
+laboneq/dsl/calibration/mixer_calibration.py,sha256=NN9Vb69dDGcStADYGYepCARw-aHo4fLaqVsv5ZyTN4c,1071
 laboneq/dsl/calibration/observable.py,sha256=5zf7HE7e4MnrnHcgwAWMKkejOiVTZs4UCtlRiVn8OVw,3403
-laboneq/dsl/calibration/oscillator.py,sha256=3e_X5v9PSCOwLcr7nb-zUWj1OGjqIvsfxZWMFB_VDKE,2134
-laboneq/dsl/calibration/precompensation.py,sha256=tDZHSsoZh_DSJH1BpZWcUiZMvkaZE9rhSI5czRtyh3M,3140
-laboneq/dsl/calibration/signal_calibration.py,sha256=798sV3mEz0ssBI4GYjNoNTIAuzBTf2rknvdMZBohQR0,5614
-laboneq/dsl/calibration/units.py,sha256=9W7YXV75G2VgNGSNserL_rsnEdjQugCuzg1gQmkvutU,553
+laboneq/dsl/calibration/oscillator.py,sha256=LJC0xgW3MwFlbxjMilrw_bWMr2VCF4zFZAno1Vj9g6w,2213
+laboneq/dsl/calibration/precompensation.py,sha256=GX0nZdilwa_rFg1F_L2EAauDQFkq6Lq2_v9r_LBWVtk,3283
+laboneq/dsl/calibration/signal_calibration.py,sha256=L1aAsLkfmfRiRHllZA9udcD43Gpauc3d9y5_ayW20fM,5693
+laboneq/dsl/calibration/units.py,sha256=NiSGoMsrGF0C3s6T2vHpMrKSZQFzoOii5rm5kcxKnhw,633
 laboneq/dsl/device/__init__.py,sha256=uqx0Rho0xQ0vHzcP4no8R0OfjkK2ZdPllpVsZoAuH6Y,363
 laboneq/dsl/device/_device_setup_generator.py,sha256=sA2j1IKi3pId3yg5Ct4sp_tvkd4aZ7o8FX7fDdpKIgg,45826
-laboneq/dsl/device/connection.py,sha256=e_uMDO-7YrMKJkZEbizlTQZITsXU1--ceOYOZ0m40Xc,601
-laboneq/dsl/device/device_setup.py,sha256=hDYGDooO-rFxHsC7i1HD5kyzPvXzNSjrXBWkCTg0dMk,13663
+laboneq/dsl/device/connection.py,sha256=pDtXRJJbVKG-khYGMsnmMBitzk8L2VPtPtBOZF81bV0,680
+laboneq/dsl/device/device_setup.py,sha256=EHNkMSZS2kFn7rum3NS6LYLjgiv_Uyw-7Bs7VObgZO8,13732
 laboneq/dsl/device/device_setup_helper.py,sha256=KRaya8xtzjqzdn1SZ_NMCU7p_V-76Aj_S0evSzuey7c,2551
-laboneq/dsl/device/instrument.py,sha256=XjaPAcpKdPQx1z-QpAFwHLFERoK65-Rgb7SjIyW_zy8,1362
-laboneq/dsl/device/logical_signal_group.py,sha256=i12USV4K1ij8y_3SOYStnZE_z3Bo6G0-f03RtuBjO-w,1893
-laboneq/dsl/device/physical_channel_group.py,sha256=1u4c9TyfC5WZWkgQGTpDcbIc6hXcgKuNdE8AJcxbaRk,1729
-laboneq/dsl/device/ports.py,sha256=-jVPCUfRq1e2PHpPBrcHuUQcrrfv7kylzDUF9rZWTnQ,538
-laboneq/dsl/device/server.py,sha256=JOM2xKKWMwFWYPcAjoCoFIuF_4ZC73_fMiZXUhNSZPk,215
+laboneq/dsl/device/instrument.py,sha256=k07sAS-ecOpR5Ne-USMBhXfd-9PFhZ1x3jmskZdGwbc,1431
+laboneq/dsl/device/logical_signal_group.py,sha256=9whT5uYUjmv1Z0Y0VnMVlieMg3-41e6VlQjofaZ5KIQ,1962
+laboneq/dsl/device/physical_channel_group.py,sha256=FdvulCQ158Dx3bw2zvTpg3GIMXec0h_K1tC0QSlJBt8,1808
+laboneq/dsl/device/ports.py,sha256=vnQ3COT9CdNPUtT_dyWzj2VCUMKVZB8d0tUYJriMWA8,617
+laboneq/dsl/device/server.py,sha256=Mryh6V2AJuiwJ1-o3AETrBFAk265po7GBrFzID-sgKU,295
 laboneq/dsl/device/instruments/__init__.py,sha256=sl302P7-HQO6Y8NXCcN2-r5mfbGastN7Ugs6PfRA1wg,328
-laboneq/dsl/device/instruments/hdawg.py,sha256=xLmo7LJhGC61PDkv_ZYn37VD0bnRxC1Ag54ET_KRLE4,1778
-laboneq/dsl/device/instruments/nonqc.py,sha256=j6jLNrFifaKe1QDcQJcTVWMdQR7eBI345V7S-iWqhts,466
-laboneq/dsl/device/instruments/pqsc.py,sha256=JQrg31Gj6HRjUOYjDyG5m2A9ngrQOFcX0mHw_2BwsGk,948
-laboneq/dsl/device/instruments/shfppc.py,sha256=E_-2fesNBJ0E-qrrwSA5MK1TdL0Daht9OX2U0BeBtkg,927
-laboneq/dsl/device/instruments/shfqa.py,sha256=C6yaZvxr1xZwUegOILTNC8_B7a28O_GqsIYag-dCvYo,2248
-laboneq/dsl/device/instruments/shfsg.py,sha256=MCJkySVlx7ls33IPHrf2ZmKBRuBXQDPGwVw7o_JXfmk,1659
-laboneq/dsl/device/instruments/uhfqa.py,sha256=sHidPdFcZHTOXXSFJFcCD__K90IkEogpZPiai5dt8Us,2312
-laboneq/dsl/device/instruments/zi_standard_instrument.py,sha256=IcDKOIMU_Yi9niyZlq9aw1xKXVLGd2VO0mO9qRW8lDI,888
+laboneq/dsl/device/instruments/hdawg.py,sha256=FuxEtoR50NFFGy6K0XAAaeEtAl9mwG7gAtxok8J53Zo,1848
+laboneq/dsl/device/instruments/nonqc.py,sha256=umBVXqegA4R1Z8RzsrDuYjH3dQ1M_ymMHetPQ1r2ua8,536
+laboneq/dsl/device/instruments/pqsc.py,sha256=fIqzKa9TtQlQ_HEKZfkngLh0SB3h6_z98Ibi_LEQb6Q,1018
+laboneq/dsl/device/instruments/shfppc.py,sha256=0tHM6y22rEu6tZThpIUgw4iWvoI7griRdFxG2C6X3XE,997
+laboneq/dsl/device/instruments/shfqa.py,sha256=qTDWyJaMdGVymtZSmlft7Pq_cf7oXPhd3J3OieM5m_0,2318
+laboneq/dsl/device/instruments/shfsg.py,sha256=DYTlHv0psrUbJp6HKczYgvC-XU7wKYlzZdOneV5X3H4,1729
+laboneq/dsl/device/instruments/uhfqa.py,sha256=MdD4ILk5Uy8jeEzCj9OMlI0Ybr7BiDlyYMzb1w9Gc3E,2382
+laboneq/dsl/device/instruments/zi_standard_instrument.py,sha256=6eXsgD3ciF4w4y1550EbP6ziVfLUoAUfuncSEesNZ1A,958
 laboneq/dsl/device/io_units/__init__.py,sha256=UOI3L_V5_3lji95HUdB3KvWoAQkja0pR8bGBshRnRr4,187
-laboneq/dsl/device/io_units/logical_signal.py,sha256=Q1TH8nwOfUJFI6XnnnHtUMXEDNrTsv_BEyJZvfwH8wQ,12750
-laboneq/dsl/device/io_units/physical_channel.py,sha256=xQBy_FTGq6nXRK0NsFpn1ZicGm1U0ywcyr2DoROpdXc,3828
+laboneq/dsl/device/io_units/logical_signal.py,sha256=U4blEgtxN0j6yS1ZXCPBhgZV6V3u1q8uscPsyVLSiaY,12952
+laboneq/dsl/device/io_units/physical_channel.py,sha256=k8o8CM3SNNbPvhXtb4wKE_7cJXA20urzuj6nXkMIOcE,4095
 laboneq/dsl/device/servers/__init__.py,sha256=ZeYikalTjZXb_HDjfdGe6YHUuZAlDv0qqHZ0d1JLOE8,114
-laboneq/dsl/device/servers/data_server.py,sha256=URgMXwwmzNAPF3PrQBTE11dU7QLxGaJa0tIdi8F2BiQ,704
+laboneq/dsl/device/servers/data_server.py,sha256=veSyu9OrfzEajSXxadIhfsxCRcqOu2DxGLP53X2Qk-I,774
 laboneq/dsl/enums/__init__.py,sha256=GeDXWBzskaPr4MxVoeJp6kj-X5kVZA1yrbUw7wcV2F0,718
 laboneq/dsl/experiment/__init__.py,sha256=N159QRiB6rNL_RH6vzZwYqi4B91GTlX-JmmysAoQgMM,508
-laboneq/dsl/experiment/acquire.py,sha256=g4Pvm6T0qu8tH8LRTHhCZ1wb2K4Drc1rawNeNTRkS_E,972
-laboneq/dsl/experiment/call.py,sha256=eATarAz81C0QC5Ih-Uuh9PrS0g4rEF_vbQsrav_-I6Q,814
-laboneq/dsl/experiment/delay.py,sha256=98P3AePai3fqH1csDnWSxUN3EGJchuysX_2qnkCF2-Y,780
-laboneq/dsl/experiment/experiment.py,sha256=eUkndC0frKHtbbx5jsUFOUrg47Mr2yTjCsn8N1zjymk,40011
-laboneq/dsl/experiment/experiment_signal.py,sha256=eHDHAu7Hv9xTSF-f9-YsJ1suZmZfaevS9anyLaBiOPY,8216
+laboneq/dsl/experiment/acquire.py,sha256=3i1nlaySteKgpNlGxJ_dg9Enu-WUZfrVuJpCupe-mO8,1041
+laboneq/dsl/experiment/call.py,sha256=Rd0y87_jEPEsSc_EffIxt0ilAMwPpHL_TPLLJrYecMQ,883
+laboneq/dsl/experiment/delay.py,sha256=9kVDfWiChR7IsFztYbU_Cjf5hjS7irZXmcIW0v5YPwI,859
+laboneq/dsl/experiment/experiment.py,sha256=d8zpKpP25LUlscX6naoCvHcip9uboTOLeUBgA6RFXyM,40479
+laboneq/dsl/experiment/experiment_signal.py,sha256=HkFwBsXewNEjBm05faZtxRLZv6-pgrtSQmX6cJCHn0I,8295
 laboneq/dsl/experiment/operation.py,sha256=kJPLIjNTFf_lJkVsOmASPi7GZVJ9CCZySdA2YDCmswU,401
-laboneq/dsl/experiment/play_pulse.py,sha256=yGd_-jzkuOK_i4A65mfoPfeG1IRKK8ZaDQE-E627Idw,1647
-laboneq/dsl/experiment/pulse.py,sha256=cdmMmMo1yGygx_5EkyemW6xO-8-FuIErugjN1PHiKrE,3953
+laboneq/dsl/experiment/play_pulse.py,sha256=0qfSTTDN0UTMZZfXqQGQd_j8B3v8Fwppa6E9BGeExT4,1716
+laboneq/dsl/experiment/pulse.py,sha256=Lqgd-zLb8-lMoyLsq3GIemO5NcuvZlXh1FSWjgdRmAM,4064
 laboneq/dsl/experiment/pulse_library.py,sha256=kmvFKXNGXIVCnjFMsFqAdiUM5bk8u-grY4ZeuKWHJ8M,8194
-laboneq/dsl/experiment/reserve.py,sha256=tn1YEkW6E7BbBuG4SKveCmiAXrsYm2IeMUI2iDnwazs,890
-laboneq/dsl/experiment/section.py,sha256=0gg3PscVUPEoTEhYaE4bsX8qsTvxgXQ4RyKb_gop5q8,11431
-laboneq/dsl/experiment/set.py,sha256=4hEgxT9iYWNgDEEAFDS4D1GlgTsInRK3regArR4cnaU,640
+laboneq/dsl/experiment/reserve.py,sha256=mFcPQ_YhjX06ZGzrF25GtUmD9vF9b3AUlUO1b7Fx8_4,959
+laboneq/dsl/experiment/section.py,sha256=azWLLBlZ0woBbfR2KfhkVNeS3EnvHNDoVPq2fiO_VJI,11673
+laboneq/dsl/experiment/set.py,sha256=MNm1efnQk-Mqk3GaV-pXSr5UW-BIeddBwIcr-xQlR5o,709
 laboneq/dsl/experiment/utils.py,sha256=TiO1tKG5F8Zqx1lUz1rUPc3lNVE6UMPnniuLNoyMql8,323
 laboneq/dsl/quantum/__init__.py,sha256=NvineMWpjeAgy-1KhEkE0Ei9INuDe3AmsPsdbQe0Khk,224
 laboneq/dsl/quantum/quantum_operations.py,sha256=kb9rZDSllCSSflTZCcNHteZa7goD-Hilg9g0w32gRg0,3423
-laboneq/dsl/quantum/qubits.py,sha256=HZSaOHG-OI2Q5BrRmpHewZhmTSgw5CptG7hnGUSd_HM,10892
+laboneq/dsl/quantum/qubits.py,sha256=_EqtnJv-mPn2O66zSWJLLzZqgbHGSittU--3Nyj3nZE,11423
 laboneq/dsl/result/__init__.py,sha256=XAUfjo82SDzPK0s8ZZSJPTVRIF8b4smFBWhI5rwqBAQ,151
-laboneq/dsl/result/acquired_result.py,sha256=yNCpd1C8BnKeWbMCJHSVFOQzcYoy00-eLdLwjAEcFQk,1766
-laboneq/dsl/result/results.py,sha256=Loyay67WyhDB_fDCJ0zjPN2k18tvAOwCKXcIchhKLQE,7189
+laboneq/dsl/result/acquired_result.py,sha256=bg7vWfV-0oGuaecJgugYKYEnCz32eFZOKdfL_kNahbc,1846
+laboneq/dsl/result/results.py,sha256=a3rE0m1WDxlSMuDJJcwhXJFDTYdlyLPRgZX6CofyDx0,7258
 laboneq/dsl/serialization/__init__.py,sha256=XVKLzoqNC9_psuftSgRNbbNmrcvTeJmWW5bIa-bmwRU,113
 laboneq/dsl/serialization/serializer.py,sha256=2V6hFMW5TevU4m6T5GJZdsha2okNvE0KCNYvElsg2AA,5394
 laboneq/executor/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/executor/execution_from_experiment.py,sha256=eE1lzSHYQqZZqlM2TAyjm0ibP3ifeeNTIOazin9z96M,3819
-laboneq/executor/executor.py,sha256=xvJwDB-9hlPjD4dTPqfxN2uNVB_2o8ZoKLNWPQBgpQc,8152
+laboneq/executor/execution_from_experiment.py,sha256=o8kmk9SpliBXLgrw4aBRVTt8nzRzMau42ZiDzjc9pXA,6010
+laboneq/executor/executor.py,sha256=mrrZ7RYftBaBSjJIrSU0n4bvutJ0dm7REZ7cmZD9rMQ,9198
 laboneq/implementation/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/compilation_service/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/compilation_service/compilation_service.py,sha256=bkthiJj5OpDDy2E7-5cXApuuuvsdEepx1AGOHu0q54k,1156
 laboneq/implementation/compilation_service/compilation_service_legacy.py,sha256=bgtE-Nzt6epqUkivxT9aNE8v8dxeg3lZZFh7dJbGizs,7894
 laboneq/implementation/data_storage/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/data_storage/l1q_database_wrapper.py,sha256=XIewgC1Gin2djDdSlz_DFQjaQ1s_dl6W_YnRABvx3K0,916
 laboneq/implementation/data_storage_service/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/data_storage_service/data_storage_service_sqlite_dict.py,sha256=CemktSIKDUVl2EHResIyU3aAJ_Ve70AJvHxSzMwkXEU,6103
 laboneq/implementation/experiment_workflow/__init__.py,sha256=AaKiWtIt7DgkOBZaLj_oOxrFACk6bWNIxqPdQd4UwOo,130
 laboneq/implementation/experiment_workflow/device_setup_generator.py,sha256=BtyCTvkijW2gr7CUaRXFxuVwDGSPXJBAKfoaDB-gaHI,16908
 laboneq/implementation/experiment_workflow/experiment_workflow.py,sha256=NC5eTQnDhae5rQRnooUBrnfL_LT8wtRoYAnlVhX-vhM,6106
 laboneq/implementation/legacy_adapters/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/legacy_adapters/dynamic_converter.py,sha256=sWsjce-ZD9uz0gKgaIicXe1NlHO0iTlmkFbi6q5Aqz0,3084
 laboneq/implementation/legacy_adapters/simple2.py,sha256=-Ye3LkRzavwAhi_bl3YbETkfWvrY_cPrdUz69Hg-G1I,950
-laboneq/implementation/legacy_adapters/converters_calibration/__init__.py,sha256=0RcULl5jNqdwM2Gqoo12x2XAQKygf8EEoWZ1PJZbCeI,7740
+laboneq/implementation/legacy_adapters/converters_calibration/__init__.py,sha256=pKo1eKFqajQJyyoO92dXOQL1bZ1KRLiyi_KzwV0Up0U,7593
 laboneq/implementation/legacy_adapters/converters_calibration/post_process_calibration.py,sha256=vsxRzSBL2VJi5I3kJbUgnM4GOHoemTAvzVmijzWttzY,131
-laboneq/implementation/legacy_adapters/converters_experiment_description/__init__.py,sha256=6dQQFLZvFtASRTsZDfxi1Yr1B6BidoCPGc3ITwj6l4M,22847
+laboneq/implementation/legacy_adapters/converters_experiment_description/__init__.py,sha256=Q4ryiAyExY7H8Kq8GwqF31rV51F99ZPGlsxvMkYoqf8,24071
 laboneq/implementation/legacy_adapters/converters_experiment_description/post_process_experiment_description.py,sha256=t1FQOO5S2w4iteG35Ryip6jlOtUPBJ-tEqA5fOBc_PE,1659
-laboneq/implementation/legacy_adapters/converters_experiment_results/__init__.py,sha256=MWmnjAIUheNFiIStmlVxUfO2Q22MqgFlKGqocqvG58g,1741
+laboneq/implementation/legacy_adapters/converters_experiment_results/__init__.py,sha256=mM5vqmQ3qKlXuLwfKO0vg9QWuaR8X2-hf1oO3vf14gA,2017
 laboneq/implementation/legacy_adapters/converters_experiment_results/post_process_experiment_results.py,sha256=vsxRzSBL2VJi5I3kJbUgnM4GOHoemTAvzVmijzWttzY,131
-laboneq/implementation/legacy_adapters/converters_scheduled_experiment/__init__.py,sha256=9ybevrSPbuLmJZjszERmB3i1T7JI-8DvCBCHcgDLD90,4376
+laboneq/implementation/legacy_adapters/converters_scheduled_experiment/__init__.py,sha256=B_qs8qXOiBF2Z7UoZOYshbqy1RoqoW2L-oiXQo-XN5I,4542
 laboneq/implementation/legacy_adapters/converters_scheduled_experiment/post_process_scheduled_experiment.py,sha256=vsxRzSBL2VJi5I3kJbUgnM4GOHoemTAvzVmijzWttzY,131
-laboneq/implementation/legacy_adapters/converters_setup_description/__init__.py,sha256=xic3V54zuLyltVv1TPEpdSGp0UxTTho-uqboAhOn4H0,13804
+laboneq/implementation/legacy_adapters/converters_setup_description/__init__.py,sha256=7CS50Wk5CRaIIH1UEtegUPaacohF90GHSspYQHxLgDA,13366
 laboneq/implementation/legacy_adapters/converters_setup_description/post_process_setup_description.py,sha256=7PlpmIH1wcQpmbaZZNwmpCKGmjrjV7wCBiQ8l5bHpvE,5165
 laboneq/implementation/legacy_adapters/legacy_dsl_adapters/__init__.py,sha256=VqQQH_MyRUWwxW-pdkJSYkLk7mYvg8I_1IQ3Pyaa9fQ,9204
 laboneq/implementation/payload_builder/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/implementation/payload_builder/payload_builder.py,sha256=vuMCu2tH9bI50MTQ5SigiPGBo88osFfW0gSAhOimYkw,25577
 laboneq/implementation/runner/__init__.py,sha256=kbDoa0zD-iLYmGvh3f9ER9rSUW9UJxHzmdheeH4kxyg,105
 laboneq/implementation/runner/runner.py,sha256=Bqai465siIHt0SwsU6H94hek6sHpCnbsE85YZPqqfPQ,2293
-laboneq/implementation/runner/runner_legacy.py,sha256=PBgNcDC9DL4Duf8wUXqYKRdrYAvU9vjxmX9sNUDvFAc,14574
+laboneq/implementation/runner/runner_legacy.py,sha256=D_IHU5vXjHg0aEiRNSPEg3E2ytScKt6XTWKUAZo91SI,14577
 laboneq/interfaces/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/interfaces/application_management/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/interfaces/application_management/laboneq_settings.py,sha256=AveKgiI8kTXggUoVS8BsCPDZF3STTSwNkOsSkWN21QA,384
 laboneq/interfaces/compilation_service/__init__.py,sha256=zB8QZ3xKM9mTzqQHFoKEmAbCkDBYhatxv3IZzqA7-KY,137
 laboneq/interfaces/compilation_service/compilation_service_api.py,sha256=QbYJLsbNtJt81vIz0J7SSJSNNCGQD3L3SO0xxB-fElQ,779
 laboneq/interfaces/data_storage/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/interfaces/data_storage/data_storage_api.py,sha256=4A3po4mvtpcYIJy1pKeUKIamknJ2-7SVQRwE3utEw9Y,2272
@@ -284,28 +289,27 @@
 laboneq/interfaces/payload_builder/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/interfaces/payload_builder/payload_builder_api.py,sha256=jliezqh7gJdH5Nw7qIMP0HHJxLopQa2hDp6vmUv9ygQ,892
 laboneq/interfaces/runner/__init__.py,sha256=3eHhVd6jL1C_XKdm6Uos7u8P7T_4MP6cnw2JMgXvqQE,77
 laboneq/interfaces/runner/runner_api.py,sha256=eHfo0TO_yZYchBQarIrALjUCmzNAxoHMeo-3oiUO4q4,766
 laboneq/interfaces/runner/runner_control_api.py,sha256=P53Yw82od4k6P8oceca9QbLLoa4Has3RiPoEeDdni54,793
 laboneq/openqasm3/__init__.py,sha256=zIfFQa39Ko4nUcnnLBmRilnUVJ9eeg022QoLpodiv2o,145
 laboneq/openqasm3/expression.py,sha256=DKk9nMo1cABcEb4kPJ3dOAKlsafr5O-rNh5TfbUHGkw,8903
-laboneq/openqasm3/gate_store.py,sha256=rF8qUBL6avuZYcGKAYVU85Xb3wwCFN69qYJEtwtZbTg,1671
+laboneq/openqasm3/gate_store.py,sha256=jOEvCe56ysNjouTBr6xp8U9072k2JYRziL3SuFVMM9g,1871
 laboneq/openqasm3/namespace.py,sha256=c_rpWEw9MZALiu1ulKntBOaSSXQudd8HieQ2r-fU3qs,2593
-laboneq/openqasm3/openqasm3_importer.py,sha256=jZc4TQ9FXP9cYtptw5lbkopk3soUhOPXE5C-7s4ol8w,15459
+laboneq/openqasm3/openqasm3_importer.py,sha256=Zcilo5F0P-NYnHU8j5QKnvjCDZFD9GjhHqpYVQzNBks,16724
 laboneq/openqasm3/openqasm_error.py,sha256=rgkp6fT1tNrhVX8eCV-q1PLJUfGxkmT4gXEErJcSB-8,1732
 laboneq/openqasm3/reset_gate_factory.py,sha256=WnWPrS0E0NXXy1pbSryMw8KgswOoGm7IW71vhynXhKA,4850
 laboneq/openqasm3/signal_store.py,sha256=SJ3lvM5iWGi2HS7t64E2TbIsBZGS5JHdhJN0gX6bE8w,1517
 laboneq/pulse_sheet_viewer/__init__.py,sha256=F_gdqvR3iTbFH2-iGtGWPp2v2XpMu0c4SXEPEIJyQb0,127
-laboneq/pulse_sheet_viewer/event_graph_viewer.py,sha256=hKBUzFzimfz9YAFUYNYwrhwMscXHa-4M3BNa6id6SHE,2059
 laboneq/pulse_sheet_viewer/interactive_psv.py,sha256=D7pEX9C8mP9EZofE5L3aAAkX3lNFaEoHwBc_l2AHyec,2692
-laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py,sha256=_O53T2cm8KWDhbUKoONuRb_9JOKyKvOqEMtQgrwlQPI,3288
+laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py,sha256=E3yX0M-s-zxGm8AjZTT9a-Y0ZHSJKY3JZBZLUMe3lsI,3268
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html,sha256=TsX3r0W8qf_PKAw1pYreXQEcexRfzgL_FmbvOAFh06s,1443040
 laboneq/simulator/__init__.py,sha256=BuPOsR4Dwi6tSLAsG0lBeHzpOZFnCsNn93ohr-v9mZ8,152
-laboneq/simulator/output_simulator.py,sha256=4_jPSN8jYT3A3pW1_g5_1YnLnkPnTdfEu0249GApzu4,6090
-laboneq/simulator/seqc_parser.py,sha256=mZjEX7opXKvxjimhlIHHDNhikip0uWu_GJS9r7kB8Zc,41644
-laboneq/simulator/wave_scroller.py,sha256=9_xRKYi1deA8je4OAmJJsKmMpNEo9pGO-qJKEpf_3FY,17091
-laboneq-2.8.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
-laboneq-2.8.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-laboneq-2.8.0.dist-info/METADATA,sha256=6QwBpj22m8DME8VbiSgEiu0LHgLA8FR9VtjRg3ra1-w,3255
-laboneq-2.8.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-laboneq-2.8.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
-laboneq-2.8.0.dist-info/RECORD,,
+laboneq/simulator/output_simulator.py,sha256=h54gv9K396qgs0PKyji_gmI-Y3oQvXlTCF7riPRu-AA,6893
+laboneq/simulator/seqc_parser.py,sha256=NjSGzwvHsWv_fSC1EnGQGUPJwaLW3ZVUFFZ4qQiykEE,42297
+laboneq/simulator/wave_scroller.py,sha256=9w7VjKePt3ixjngOPAzmksdqn4tWNfbNBLVUqBZJ7OM,18324
+laboneq-2.9.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
+laboneq-2.9.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+laboneq-2.9.0.dist-info/METADATA,sha256=sbPsP_gfkWB-S8Ztmgg9E623k2mOLFAwXG-Trv4ZKqk,3276
+laboneq-2.9.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+laboneq-2.9.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
+laboneq-2.9.0.dist-info/RECORD,,
```

