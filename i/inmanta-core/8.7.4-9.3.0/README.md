# Comparing `tmp/inmanta-core-8.7.4.tar.gz` & `tmp/inmanta-core-9.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "inmanta-core-8.7.4.tar", last modified: Fri Mar 29 14:30:59 2024, max compression
+gzip compressed data, was "inmanta-core-9.3.0.tar", last modified: Tue Jul  4 11:30:06 2023, max compression
```

## Comparing `inmanta-core-8.7.4.tar` & `inmanta-core-9.3.0.tar`

### file list

```diff
@@ -1,270 +1,258 @@
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.341372 inmanta-core-8.7.4/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    10174 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/LICENSE
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      311 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/MANIFEST.in
--rw-r--r--   0 jenkins    (989) jenkins    (986)     4353 2024-03-29 14:30:59.341372 inmanta-core-8.7.4/PKG-INFO
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2238 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/README.md
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.305370 inmanta-core-8.7.4/misc/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)       31 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/extensions.cfg
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      402 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta-agent.service
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      333 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta-server.service
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8762 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta-workon-register.sh
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2885 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta.cfg
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12162 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta.lang
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1256 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/inmanta.vim
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      141 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/misc/logrotation_config
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1484 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/pyproject.toml
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      918 2024-03-29 14:30:59.342372 inmanta-core-8.7.4/setup.cfg
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3647 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/setup.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.303370 inmanta-core-8.7.4/src/
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.309370 inmanta-core-8.7.4/src/inmanta/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1121 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/__init__.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.310370 inmanta-core-8.7.4/src/inmanta/agent/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      738 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    66353 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/agent.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    10068 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/cache.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6254 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/config.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    43463 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/handler.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.310370 inmanta-core-8.7.4/src/inmanta/agent/io/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2795 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/io/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    20119 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/io/local.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6335 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/io/remote.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3375 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/agent/reporting.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    36280 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/app.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.311370 inmanta-core-8.7.4/src/inmanta/ast/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    33527 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7086 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/attribute.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6363 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/blocks.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.312370 inmanta-core-8.7.4/src/inmanta/ast/constraint/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/constraint/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    17846 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/constraint/expression.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    19627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/entity.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2783 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/export.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.313370 inmanta-core-8.7.4/src/inmanta/ast/statements/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    24929 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/statements/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    25210 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/statements/assign.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12235 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/statements/call.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    25102 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/statements/define.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    57185 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/statements/generator.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    24059 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/type.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12864 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/ast/variables.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3354 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/command.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.313370 inmanta-core-8.7.4/src/inmanta/compiler/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    14492 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1963 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/config.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1086 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/data.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.313370 inmanta-core-8.7.4/src/inmanta/compiler/help/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/help/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8310 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/help/explainer.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.314370 inmanta-core-8.7.4/src/inmanta/compiler/help/templates/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      235 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/help/templates/index_collision.j2
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3604 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/help/templates/modified_after_freeze.j2
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      733 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/compiler/help/templates/module_v2_in_v1_path.j2
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    21473 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/config.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9451 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/const.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.315370 inmanta-core-8.7.4/src/inmanta/data/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)   261835 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/data/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    50642 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/data/dataview.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    22156 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/data/model.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12179 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/data/schema.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.315370 inmanta-core-8.7.4/src/inmanta/db/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    10675 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/util.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.322371 inmanta-core-8.7.4/src/inmanta/db/versions/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12123 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v1.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1737 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v17.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1393 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v2.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2413 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202105170.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      915 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202106080.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1247 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202106210.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1826 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202109100.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      979 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202111260.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1581 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202203140.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2200 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202203160.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      910 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202205250.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      979 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202206290.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      948 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202208180.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1881 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202208190.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      976 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202209090.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3957 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202209130.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      861 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202209160.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2919 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202211230.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1430 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202212010.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1494 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301100.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      924 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301110.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      977 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301120.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      929 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301160.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      896 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301170.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1313 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202301190.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      860 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202302200.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1036 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202302270.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      825 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202303070.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1936 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202303071.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1027 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202304070.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1434 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202306060.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1782 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202308010.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      971 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202308020.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1862 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202308100.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      909 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202309130.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1123 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202310040.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1337 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202310090.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      949 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202310180.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1550 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202402130.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1017 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202403120.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      973 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v202403220.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1471 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v3.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3556 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v4.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1529 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v5.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1043 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v6.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1558 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/db/versions/v7.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    17121 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/deploy.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2688 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/docstring_parser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    58346 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/env.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.322371 inmanta-core-8.7.4/src/inmanta/execute/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/__init__.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.323371 inmanta-core-8.7.4/src/inmanta/execute/dataflow/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    41003 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/dataflow/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9509 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/dataflow/datatrace.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7411 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/dataflow/graphic.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7071 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/dataflow/root_cause.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8429 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/proxy.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    51951 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/runtime.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    30719 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/scheduler.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1799 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/tracking.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1434 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/execute/util.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    27085 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/export.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5449 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/file_parser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    24709 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/loader.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    15731 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/logging.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    35294 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/main.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9060 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/model.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)   143758 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/module.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    84432 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/moduletool.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.325371 inmanta-core-8.7.4/src/inmanta/parser/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2934 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/parser/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5797 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/parser/cache.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)   581091 2024-03-29 14:30:49.000000 inmanta-core-8.7.4/src/inmanta/parser/parser.out
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    73768 2024-03-29 14:30:49.000000 inmanta-core-8.7.4/src/inmanta/parser/parsetab.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1556 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/parser/pickle.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8302 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/parser/plyInmantaLex.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    43183 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/parser/plyInmantaParser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    31426 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/plugins.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5487 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/postgresproc.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      734 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/profile_mem.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.326371 inmanta-core-8.7.4/src/inmanta/protocol/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3131 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    42368 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/common.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9031 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/decorators.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    18533 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/endpoints.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4449 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/exceptions.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    37640 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/methods.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    64414 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/methods_v2.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.327371 inmanta-core-8.7.4/src/inmanta/protocol/openapi/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/openapi/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    20535 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/openapi/converter.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9064 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/openapi/model.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.327371 inmanta-core-8.7.4/src/inmanta/protocol/rest/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    23588 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/rest/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6369 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/rest/client.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    14035 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/rest/server.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2179 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/protocol/return_value_meta.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/py.typed
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6284 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/reporter.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    23675 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/resources.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.329371 inmanta-core-8.7.4/src/inmanta/server/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1363 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    56287 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/agentmanager.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    10054 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/bootloader.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      688 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/compilerservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    10843 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/config.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7297 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/diff.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7660 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/extensions.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    28515 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/protocol.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7933 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/server.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.331371 inmanta-core-8.7.4/src/inmanta/server/services/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5673 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/codeservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    42766 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/compilerservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5757 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/databaseservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    11598 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/dryrunservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    27474 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/environment_metrics_service.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    31177 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/environmentservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6560 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/fileservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4531 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/metricservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7960 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/notificationservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    69014 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/orchestrationservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    13862 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/paramservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6254 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/projectservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    57328 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/resourceservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4852 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/services/userservice.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    11647 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/server/validate_filter.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      886 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/stable_api.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2921 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/types.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6908 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/user_setup.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.332371 inmanta-core-8.7.4/src/inmanta/util/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    29673 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/util/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2381 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/util/db.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    34630 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/util/dict_path.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3273 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/validation_type.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6484 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta/warnings.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.340371 inmanta-core-8.7.4/src/inmanta_core.egg-info/
--rw-r--r--   0 jenkins    (989) jenkins    (986)     4353 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/PKG-INFO
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7468 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/SOURCES.txt
--rw-rw-r--   0 jenkins    (989) jenkins    (986)        1 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/dependency_links.txt
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      129 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/entry_points.txt
--rw-rw-r--   0 jenkins    (989) jenkins    (986)        1 2024-03-29 14:30:39.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/not-zip-safe
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      621 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/requires.txt
--rw-rw-r--   0 jenkins    (989) jenkins    (986)       36 2024-03-29 14:30:59.000000 inmanta-core-8.7.4/src/inmanta_core.egg-info/top_level.txt
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.303370 inmanta-core-8.7.4/src/inmanta_ext/
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.333371 inmanta-core-8.7.4/src/inmanta_ext/core/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta_ext/core/__init__.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2238 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta_ext/core/extension.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.303370 inmanta-core-8.7.4/src/inmanta_plugins/
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.333371 inmanta-core-8.7.4/src/inmanta_plugins/1/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      627 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/src/inmanta_plugins/1/__init__.py
-drwxrwxr-x   0 jenkins    (989) jenkins    (986)        0 2024-03-29 14:30:59.340371 inmanta-core-8.7.4/tests/
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8452 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_2way_protocol.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     7497 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_agent.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    58340 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_agent_manager.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    21375 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_app.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    17367 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_app_cli.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    12767 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_cache.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    18747 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_cli.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4628 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_compilation.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9797 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_compiler_entrypoints.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    11546 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_config.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     1300 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_const.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)   130122 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_data.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9224 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_data_concurrency.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3426 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_data_model.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4346 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_deploy.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5151 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_docs_snippets.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3047 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_docstring_parser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    30723 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_env.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    24490 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_export.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     9432 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_extension_loading.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2765 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_file_parser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     6567 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_handler.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     4295 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_import_entry_points.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5950 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_influxdbreporting.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8558 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_io.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5352 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_jwt.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    18501 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_loader.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8682 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_logging.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    58122 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_module_loader.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    18981 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_modules.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    33415 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_openapi.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)      988 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_param.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    63731 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_parser.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     8327 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_postgres.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2110 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_postgres_proc.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    25600 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_project.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3799 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_projectmetadata.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    79233 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_protocol.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3038 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_proxy.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    11162 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_resource.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)    70569 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_server.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     3597 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_type.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     5665 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_usersetup.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2628 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tests/test_validation_type.py
--rw-rw-r--   0 jenkins    (989) jenkins    (986)     2025 2024-03-29 14:26:48.000000 inmanta-core-8.7.4/tox.ini
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.147137 inmanta-core-9.3.0/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    10174 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/LICENSE
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      311 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/MANIFEST.in
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3195 2023-07-04 11:30:06.147137 inmanta-core-9.3.0/PKG-INFO
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2238 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/README.md
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.114136 inmanta-core-9.3.0/misc/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)       31 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/extensions.cfg
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      402 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta-agent.service
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      333 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta-server.service
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8762 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta-workon-register.sh
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2906 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta.cfg
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12162 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta.lang
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1256 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/inmanta.vim
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      141 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/misc/logrotation_config
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1432 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/pyproject.toml
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      918 2023-07-04 11:30:06.148137 inmanta-core-9.3.0/setup.cfg
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3416 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/setup.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.112136 inmanta-core-9.3.0/src/
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.118136 inmanta-core-9.3.0/src/inmanta/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      914 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/__init__.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.119136 inmanta-core-9.3.0/src/inmanta/agent/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      738 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    59119 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/agent.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    10115 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/cache.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5149 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/config.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    43297 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/handler.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.119136 inmanta-core-9.3.0/src/inmanta/agent/io/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2815 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/io/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    19884 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/io/local.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6362 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/io/remote.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3395 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/agent/reporting.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    28443 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/app.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.120136 inmanta-core-9.3.0/src/inmanta/ast/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    32500 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7103 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/attribute.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6354 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/blocks.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.120136 inmanta-core-9.3.0/src/inmanta/ast/constraint/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/constraint/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    17182 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/constraint/expression.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    19266 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/entity.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2783 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/export.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.121136 inmanta-core-9.3.0/src/inmanta/ast/statements/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    23361 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/statements/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    23834 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/statements/assign.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12314 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/statements/call.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    24146 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/statements/define.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    55960 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/statements/generator.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    20775 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/type.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12524 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/ast/variables.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3400 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/command.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.121136 inmanta-core-9.3.0/src/inmanta/compiler/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    14509 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1963 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/config.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1110 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/data.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.122136 inmanta-core-9.3.0/src/inmanta/compiler/help/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/help/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8327 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/help/explainer.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.122136 inmanta-core-9.3.0/src/inmanta/compiler/help/templates/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      235 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/help/templates/index_collision.j2
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3604 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/help/templates/modified_after_freeze.j2
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      733 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/compiler/help/templates/module_v2_in_v1_path.j2
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    20756 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/config.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9233 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/const.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.123136 inmanta-core-9.3.0/src/inmanta/data/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)   242866 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/data/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    46598 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/data/dataview.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    21742 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/data/model.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12206 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/data/schema.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.123136 inmanta-core-9.3.0/src/inmanta/db/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8702 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/util.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.127137 inmanta-core-9.3.0/src/inmanta/db/versions/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12123 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v1.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1737 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v17.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1393 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v2.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2443 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202105170.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      915 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202106080.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1247 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202106210.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1826 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202109100.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      979 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202111260.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1581 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202203140.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2200 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202203160.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      910 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202205250.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      979 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202206290.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      948 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202208180.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1881 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202208190.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      976 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202209090.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3957 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202209130.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      861 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202209160.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2919 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202211230.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1430 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202212010.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1494 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301100.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      924 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301110.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      977 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301120.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      929 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301160.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      896 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301170.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1313 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202301190.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      860 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202302200.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1036 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202302270.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      825 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202303070.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1936 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202303071.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      989 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202304060.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1027 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202304070.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1434 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v202306060.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1471 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v3.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3556 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v4.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1529 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v5.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1043 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v6.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1558 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/db/versions/v7.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    16471 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/deploy.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2694 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/docstring_parser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    57882 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/env.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.128136 inmanta-core-9.3.0/src/inmanta/execute/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/__init__.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.128136 inmanta-core-9.3.0/src/inmanta/execute/dataflow/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    41029 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/dataflow/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9488 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/dataflow/datatrace.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7405 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/dataflow/graphic.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7152 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/dataflow/root_cause.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8478 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/proxy.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    50130 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/runtime.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    30598 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/scheduler.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1807 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/tracking.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1451 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/execute/util.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    25819 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/export.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5488 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/file_parser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    24386 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/loader.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    11292 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/logging.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    35363 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/main.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9144 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/model.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)   143695 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/module.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    83933 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/moduletool.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.130137 inmanta-core-9.3.0/src/inmanta/parser/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2934 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/parser/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5803 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/parser/cache.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)   549509 2023-07-04 11:29:55.000000 inmanta-core-9.3.0/src/inmanta/parser/parser.out
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    71238 2023-07-04 11:29:55.000000 inmanta-core-9.3.0/src/inmanta/parser/parsetab.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1563 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/parser/pickle.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8245 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/parser/plyInmantaLex.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    41546 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/parser/plyInmantaParser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    23793 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/plugins.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5509 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/postgresproc.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      734 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/profile_mem.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.132137 inmanta-core-9.3.0/src/inmanta/protocol/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3131 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    42088 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/common.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9024 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/decorators.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    17283 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/endpoints.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     4455 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/exceptions.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    32616 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/methods.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    63705 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/methods_v2.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.132137 inmanta-core-9.3.0/src/inmanta/protocol/openapi/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/openapi/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    20514 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/openapi/converter.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9049 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/openapi/model.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.133137 inmanta-core-9.3.0/src/inmanta/protocol/rest/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    23049 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/rest/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6064 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/rest/client.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    13955 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/rest/server.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2158 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/protocol/return_value_meta.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/py.typed
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6396 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/reporter.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    23670 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/resources.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.135137 inmanta-core-9.3.0/src/inmanta/server/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1363 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    56173 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/agentmanager.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9866 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/bootloader.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      688 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/compilerservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    10223 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/config.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7314 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/diff.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7672 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/extensions.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    27983 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/protocol.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7705 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/server.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.138137 inmanta-core-9.3.0/src/inmanta/server/services/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5702 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/codeservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    42567 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/compilerservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5790 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/databaseservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    11640 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/dryrunservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    25390 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/environment_metrics_service.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    27899 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/environmentservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6420 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/fileservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     4551 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/metricservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7970 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/notificationservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    59626 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/orchestrationservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    13898 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/paramservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6280 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/projectservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    48277 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/resourceservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     4852 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/services/userservice.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    11714 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/server/validate_filter.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      865 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/stable_api.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2927 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/types.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6908 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/user_setup.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    27310 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/util.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6487 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta/warnings.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.139137 inmanta-core-9.3.0/src/inmanta_core.egg-info/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3195 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/PKG-INFO
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7057 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/SOURCES.txt
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)        1 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/dependency_links.txt
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      129 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/entry_points.txt
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)        1 2023-07-04 11:29:45.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/not-zip-safe
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      586 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/requires.txt
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)       36 2023-07-04 11:30:06.000000 inmanta-core-9.3.0/src/inmanta_core.egg-info/top_level.txt
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.112136 inmanta-core-9.3.0/src/inmanta_ext/
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.139137 inmanta-core-9.3.0/src/inmanta_ext/core/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta_ext/core/__init__.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2238 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta_ext/core/extension.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.112136 inmanta-core-9.3.0/src/inmanta_plugins/
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.139137 inmanta-core-9.3.0/src/inmanta_plugins/1/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      627 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/src/inmanta_plugins/1/__init__.py
+drwxrwxr-x   0 jenkins    (989) jenkins    (987)        0 2023-07-04 11:30:06.147137 inmanta-core-9.3.0/tests/
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7829 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_2way_protocol.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8023 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_agent.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    54739 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_agent_manager.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    18854 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_app.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12682 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_app_cli.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    12791 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_cache.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    18791 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_cli.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     4624 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_compilation.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     7682 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_compiler_entrypoints.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    11564 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_config.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1300 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_const.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)   123032 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_data.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8212 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_data_concurrency.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3426 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_data_model.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3912 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_deploy.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8058 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_discovered_resources.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5151 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_docs_snippets.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3047 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_docstring_parser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    27584 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_env.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    22013 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_export.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     9400 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_extension_loading.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2789 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_file_parser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6573 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_handler.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     4111 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_import_entry_points.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5982 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_influxdbreporting.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8541 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_io.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5352 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_jwt.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    18512 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_loader.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     8697 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_logging.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    58413 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_module_loader.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    18976 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_modules.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    33059 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_openapi.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)      988 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_param.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    62820 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_parser.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     6367 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_postgres.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     2110 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_postgres_proc.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    24277 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_project.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5585 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_projectmetadata.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    78909 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_protocol.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3038 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_proxy.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    11162 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_resource.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    62143 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_server.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     3664 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_type.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     5678 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_usersetup.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)    17775 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tests/test_util.py
+-rw-rw-r--   0 jenkins    (989) jenkins    (987)     1924 2023-07-04 11:27:43.000000 inmanta-core-9.3.0/tox.ini
```

### Comparing `inmanta-core-8.7.4/LICENSE` & `inmanta-core-9.3.0/LICENSE`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/README.md` & `inmanta-core-9.3.0/README.md`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/misc/inmanta-workon-register.sh` & `inmanta-core-9.3.0/misc/inmanta-workon-register.sh`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/misc/inmanta.cfg` & `inmanta-core-9.3.0/misc/inmanta.cfg`

 * *Files 5% similar despite different names*

```diff
@@ -2,14 +2,16 @@
 # The directory where the server stores its state
 state-dir=/var/lib/inmanta
 
 # The directory where the server stores log file. Currently this is only for the output of
 # embedded agents.
 log-dir=/var/log/inmanta
 
+fact-expire = 3600
+
 # Force the hostname of this machine to a specific value
 #node-name =
 
 # Names of the agents this instance should deploy configuration for
 agent-names = $node-name
 
 # The deploy interval of the agent
@@ -61,15 +63,15 @@
 bind-port = 8888
 
 # The public ip address of the server. This is required for example to inject the inmanta agent in
 # virtual machines at boot time.
 #server_address=localhost
 
 # After how many seconds will discovered facts/parameters expire
-fact-expire = 3600
+#fact-expire = 3600
 
 # After how many seconds will discovered facts/parameters be renewed? This value needs to be lower
 # than fact-expire
 #fact-renew = 1200
 
 # On boot and at regular intervals the server will purge versions that have not been deployed. This
 # is the number of most recent undeployed versions to keep available.
```

### Comparing `inmanta-core-8.7.4/misc/inmanta.lang` & `inmanta-core-9.3.0/misc/inmanta.lang`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/misc/inmanta.vim` & `inmanta-core-9.3.0/misc/inmanta.vim`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/pyproject.toml` & `inmanta-core-9.3.0/pyproject.toml`

 * *Files 8% similar despite different names*

```diff
@@ -58,11 +58,7 @@
 markers = [
     "slowtest",
     "link_check",
     "parametrize_any: only execute one of the parameterized cases when in fast mode (see documentation in conftest.py)",
     "db_restore_dump(dump): mark the db dump to restore. To be used in conjunction with the `migrate_db_from` fixture."
 ]
 log_format = "%(asctime)s.%(msecs)03d %(levelname)s %(message)s"
-
-[tool.coverage.run]
-parallel = true
-branch = false
```

### Comparing `inmanta-core-8.7.4/setup.cfg` & `inmanta-core-9.3.0/setup.cfg`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/setup.py` & `inmanta-core-9.3.0/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,59 +1,55 @@
 from setuptools import setup, find_namespace_packages
 from os import path
 
 requires = [
-    "asyncpg~=0.25",
-    "build~=1.0",
+    "asyncpg~=0.25,<0.28",
     "click-plugins~=1.0",
     # click has been known to publish non-backwards compatible minors in the past (removed deprecated code in 8.1.0)
     "click>=8.0,<8.2",
     "colorlog~=6.4",
     "cookiecutter>=1,<3",
     "crontab>=0.23,<2.0",
     "cryptography>=36,<42",
     # docstring-parser has been known to publish non-backwards compatible minors in the past
     "docstring-parser>=0.10,<0.16",
     "email-validator>=1,<3",
-    "execnet>=1,<2",
-    "importlib_metadata>=4,<8",
+    "execnet~=1.0",
+    "importlib_metadata>=4,<7",
     "jinja2~=3.0",
-    "more-itertools>=8,<11",
+    "more-itertools>=8,<10",
     "netifaces~=0.11",
     # leave upper bound floating for fast-moving and extremely stable packaging
     "packaging>=21.3",
     # pip>=21.3 required for editable pyproject.toml + setup.cfg based install support
     "pip>=21.3",
     "ply~=3.0",
     # lower bound because of pydantic/pydantic#5821
     "pydantic>=1.10.8,<2",
     "pyformance~=0.4",
     "PyJWT~=2.0",
     "pynacl~=1.5",
     "python-dateutil~=2.0",
     "pyyaml~=6.0",
-    "setuptools",
     "texttable~=1.0",
     "tornado~=6.0",
-    "typing-extensions>=4.8,<4.10",
     # lower bound because of ilevkivskyi/typing_inspect#100
     "typing_inspect~=0.9",
+    "build~=0.7",
     "ruamel.yaml~=0.17",
     "toml~=0.10 ",
 ]
 
 
 # read the contents of your README file
 this_directory = path.abspath(path.dirname(__file__))
 with open(path.join(this_directory, "README.md"), encoding="utf-8") as f:
     long_description = f.read()
 
-# This version is managed by bumpversion. Should you ever update it manually, make sure to consistently update it everywhere
-# (See the bumpversion.cfg file for relevant locations).
-version = "8.7.4"
+version = "9.3.0"
 
 setup(
     version=version,
     python_requires=">=3.9",  # also update classifiers
     # Meta data
     name="inmanta-core",
     description="Inmanta deployment tool",
```

### Comparing `inmanta-core-8.7.4/src/inmanta/__init__.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202209160.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2017 Inmanta
+    Copyright 2022 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -12,22 +12,16 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-COMPILER_VERSION = "2023.5.2"
-# This version is managed by bumpversion. Should you ever update it manually, make sure to consistently update it everywhere
-# (See the bumpversion.cfg file for relevant locations).
-__version__ = "8.7.4"
+from asyncpg import Connection
 
-RUNNING_TESTS = False
-"""
-    This is enabled/disabled by the test suite when tests are run.
-    This variable is used to disable certain features that shouldn't run during tests.
-"""
-
-if __name__ == "__main__":
-    import inmanta.app
 
-    inmanta.app.app()
+async def update(connection: Connection) -> None:
+    schema = """
+    ALTER TABLE public.compile
+        ADD COLUMN exporter_plugin varchar DEFAULT NULL;
+    """
+    await connection.execute(schema)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/__init__.py` & `inmanta-core-9.3.0/src/inmanta/agent/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/agent.py` & `inmanta-core-9.3.0/src/inmanta/agent/agent.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,57 +13,45 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import abc
 import asyncio
-import dataclasses
 import datetime
-import enum
 import logging
 import os
 import random
 import time
 import uuid
 from asyncio import Lock
 from collections import defaultdict
-from collections.abc import Awaitable, Callable, Iterable, Sequence
 from concurrent.futures.thread import ThreadPoolExecutor
 from logging import Logger
-from typing import Any, Dict, Optional, Union, cast
+from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Tuple, cast
 
 from inmanta import const, data, env, protocol
 from inmanta.agent import config as cfg
 from inmanta.agent import handler
 from inmanta.agent.cache import AgentCache
 from inmanta.agent.handler import ResourceHandler, SkipResource
 from inmanta.agent.io.remote import ChannelClosedException
 from inmanta.agent.reporting import collect_report
 from inmanta.const import ParameterSource, ResourceState
 from inmanta.data.model import AttributeStateChange, ResourceIdStr, ResourceVersionIdStr
 from inmanta.loader import CodeLoader, ModuleSource
 from inmanta.protocol import SessionEndpoint, SyncClient, methods, methods_v2
 from inmanta.resources import Id, Resource
 from inmanta.types import Apireturn, JsonType
-from inmanta.util import (
-    CronSchedule,
-    IntervalSchedule,
-    NamedLock,
-    ScheduledTask,
-    TaskMethod,
-    TaskSchedule,
-    add_future,
-    join_threadpools,
-)
+from inmanta.util import IntervalSchedule, NamedLock, ScheduledTask, TaskMethod, add_future, join_threadpools
 
 LOGGER = logging.getLogger(__name__)
 
 
-class ResourceActionResult:
+class ResourceActionResult(object):
     def __init__(self, cancel: bool) -> None:
         self.cancel = cancel
 
     def __add__(self, other: "ResourceActionResult") -> "ResourceActionResult":
         return ResourceActionResult(self.cancel or other.cancel)
 
     def __str__(self) -> str:
@@ -74,17 +62,17 @@
 
 
 class ResourceActionBase(abc.ABC):
     """Base class for Local and Remote resource actions"""
 
     resource_id: Id
     future: ResourceActionResultFuture
-    dependencies: list["ResourceActionBase"]
+    dependencies: List["ResourceActionBase"]
     # resourceid -> attribute -> {current: , desired:}
-    changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]]
+    changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]]
 
     def __init__(self, scheduler: "ResourceScheduler", resource_id: Id, gid: uuid.UUID, reason: str) -> None:
         """
         :param gid: A unique identifier to identify a deploy. This is local to this agent.
         """
         self.scheduler: "ResourceScheduler" = scheduler
         self.resource_id: Id = resource_id
@@ -108,55 +96,55 @@
         return self.running
 
     def is_done(self) -> bool:
         return self.future.done()
 
     def cancel(self) -> None:
         if not self.is_running() and not self.is_done():
-            self.logger.info("Cancelled deploy of %s %s %s", self.__class__.__name__, self.gid, self.resource_id)
+            LOGGER.info("Cancelled deploy of %s %s", self.gid, self.resource_id)
             self.future.set_result(ResourceActionResult(cancel=True))
 
     def long_string(self) -> str:
-        return "{} awaits {}".format(self.resource_id.resource_str(), " ".join([str(aw) for aw in self.dependencies]))
+        return "%s awaits %s" % (self.resource_id.resource_str(), " ".join([str(aw) for aw in self.dependencies]))
 
     def __str__(self) -> str:
         status = ""
         if self.is_done():
             status = " Done"
         elif self.is_running():
             status = " Running"
 
         return self.resource_id.resource_str() + status
 
 
 class DummyResourceAction(ResourceActionBase):
     def __init__(self, scheduler: "ResourceScheduler", gid: uuid.UUID, reason: str) -> None:
         dummy_id = Id("agent::Dummy", scheduler.name, "type", "dummy")
-        super().__init__(scheduler, dummy_id, gid, reason)
+        super(DummyResourceAction, self).__init__(scheduler, dummy_id, gid, reason)
 
 
 class ResourceAction(ResourceActionBase):
     def __init__(self, scheduler: "ResourceScheduler", resource: Resource, gid: uuid.UUID, reason: str) -> None:
         """
         :param gid: A unique identifier to identify a deploy. This is local to this agent.
         """
-        super().__init__(scheduler, resource.id, gid, reason)
+        super(ResourceAction, self).__init__(scheduler, resource.id, gid, reason)
         self.resource: Resource = resource
 
-    async def send_in_progress(self, action_id: uuid.UUID) -> dict[ResourceIdStr, const.ResourceState]:
+    async def send_in_progress(self, action_id: uuid.UUID) -> Dict[ResourceIdStr, const.ResourceState]:
         result = await self.scheduler.get_client().resource_deploy_start(
             tid=self.scheduler._env_id,
             rvid=self.resource.id.resource_version_str(),
             action_id=action_id,
         )
         if result.code != 200 or result.result is None:
             raise Exception("Failed to report the start of the deployment to the server")
         return {Id.parse_id(key).resource_str(): const.ResourceState[value] for key, value in result.result["data"].items()}
 
-    async def _execute(self, ctx: handler.HandlerContext, requires: dict[ResourceIdStr, const.ResourceState]) -> None:
+    async def _execute(self, ctx: handler.HandlerContext, requires: Dict[ResourceIdStr, const.ResourceState]) -> None:
         """
         :param ctx: The context to use during execution of this deploy
         :param requires: A dictionary that maps each dependency of the resource to be deployed, to its latest resource
                          state that was not `deploying'.
         """
         ctx.debug("Start deploy %(deploy_id)s of resource %(resource_id)s", deploy_id=self.gid, resource_id=self.resource_id)
 
@@ -206,35 +194,15 @@
     ) -> None:
         self.logger.log(const.LogLevel.TRACE.to_int, "Entering %s %s", self.gid, self.resource)
         with cache.manager(self.resource.id.get_version()):
             self.dependencies = [generation[x.resource_str()] for x in self.resource.requires]
             waiters = [x.future for x in self.dependencies]
             waiters.append(dummy.future)
             # Explicit cast is required because mypy has issues with * and generics
-            results: list[ResourceActionResult] = cast(list[ResourceActionResult], await asyncio.gather(*waiters))
-
-            if self.undeployable:
-                self.running = True
-                try:
-                    if self.is_done():
-                        # Action is cancelled
-                        self.logger.log(const.LogLevel.TRACE.to_int, f"{self.gid} {self.resource} is no longer active")
-                        return
-                    result = sum(results, ResourceActionResult(cancel=False))
-                    if result.cancel:
-                        # self.running will be set to false when self.cancel is called
-                        # Only happens when global cancel has not cancelled us but our predecessors have already been cancelled
-                        return
-                    self.status = self.undeployable
-                    self.change = const.Change.nochange
-                    self.changes = {}
-                    self.future.set_result(ResourceActionResult(cancel=False))
-                    return
-                finally:
-                    self.running = False
+            results: List[ResourceActionResult] = cast(List[ResourceActionResult], await asyncio.gather(*waiters))
 
             async with self.scheduler.ratelimiter:
                 ctx = handler.HandlerContext(self.resource, logger=self.logger)
 
                 ctx.debug(
                     "Start run for resource %(resource)s because %(reason)s",
                     resource=str(self.resource.id),
@@ -243,39 +211,42 @@
                     reason=self.reason,
                 )
 
                 self.running = True
                 try:
                     if self.is_done():
                         # Action is cancelled
-                        self.logger.log(const.LogLevel.TRACE.to_int, f"{self.gid} {self.resource} is no longer active")
+                        self.logger.log(const.LogLevel.TRACE.to_int, "%s %s is no longer active" % (self.gid, self.resource))
                         return
 
                     result = sum(results, ResourceActionResult(cancel=False))
 
                     if result.cancel:
                         # self.running will be set to false when self.cancel is called
                         # Only happens when global cancel has not cancelled us but our predecessors have already been cancelled
                         return
 
                     try:
-                        requires: dict[ResourceIdStr, const.ResourceState] = await self.send_in_progress(ctx.action_id)
+                        requires: Dict[ResourceIdStr, const.ResourceState] = await self.send_in_progress(ctx.action_id)
                     except Exception:
                         ctx.set_status(const.ResourceState.failed)
                         ctx.exception("Failed to report the start of the deployment to the server")
                     else:
-                        await self._execute(ctx=ctx, requires=requires)
+                        if self.undeployable is not None:
+                            ctx.set_status(self.undeployable)
+                        else:
+                            await self._execute(ctx=ctx, requires=requires)
 
                     ctx.debug(
                         "End run for resource %(resource)s in deploy %(deploy_id)s",
                         resource=str(self.resource.id),
                         deploy_id=self.gid,
                     )
 
-                    changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]] = {
+                    changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]] = {
                         self.resource.id.resource_version_str(): ctx.changes
                     }
 
                     if ctx.facts:
                         ctx.debug("Sending facts to the server")
                         set_fact_response = await self.scheduler.get_client().set_parameters(
                             tid=self.scheduler._env_id, parameters=ctx.facts
@@ -302,279 +273,186 @@
                     self.future.set_result(ResourceActionResult(cancel=False))
                 finally:
                     self.running = False
 
 
 class RemoteResourceAction(ResourceActionBase):
     def __init__(self, scheduler: "ResourceScheduler", resource_id: Id, gid: uuid.UUID, reason: str) -> None:
-        super().__init__(scheduler, resource_id, gid, reason)
+        super(RemoteResourceAction, self).__init__(scheduler, resource_id, gid, reason)
 
     async def execute(
         self, dummy: "ResourceActionBase", generation: "Dict[ResourceIdStr, ResourceActionBase]", cache: AgentCache
     ) -> None:
         await dummy.future
-        async with self.scheduler.agent.process.cad_ratelimiter:
-            try:
-                # got event or cancel first
-                if self.is_done():
-                    return
-
-                result = await self.scheduler.get_client().get_resource(
-                    self.scheduler.agent._env_id,
-                    self.resource_id.resource_version_str(),
-                    logs=True,
-                    log_action=const.ResourceAction.deploy,
-                    log_limit=1,
-                )
-                if result.code != 200 or result.result is None:
-                    LOGGER.error("Failed to get the status for remote resource %s (%s)", str(self.resource_id), result.result)
-                    return
-
-                status = const.ResourceState[result.result["resource"]["status"]]
-
-                self.running = True
+        try:
+            result = await self.scheduler.get_client().get_resource(
+                self.scheduler.agent._env_id,
+                self.resource_id.resource_version_str(),
+                logs=True,
+                log_action=const.ResourceAction.deploy,
+                log_limit=1,
+            )
+            if result.code != 200 or result.result is None:
+                LOGGER.error("Failed to get the status for remote resource %s (%s)", str(self.resource_id), result.result)
+                return
 
-                if status in const.TRANSIENT_STATES or self.future.done():
-                    # wait for event
-                    pass
-                else:
-                    if "logs" in result.result and len(result.result["logs"]) > 0:
-                        log = result.result["logs"][0]
+            status = const.ResourceState[result.result["resource"]["status"]]
+            self.running = True
+            if status in const.TRANSIENT_STATES or self.future.done():
+                # wait for event
+                pass
+            else:
+                if "logs" in result.result and len(result.result["logs"]) > 0:
+                    log = result.result["logs"][0]
 
-                        if "change" in log and log["change"] is not None:
-                            self.change = const.Change[log["change"]]
-                        else:
-                            self.change = const.Change.nochange
+                    if "change" in log and log["change"] is not None:
+                        self.change = const.Change[log["change"]]
+                    else:
+                        self.change = const.Change.nochange
 
-                        if "changes" in log and log["changes"] is not None and str(self.resource_id) in log["changes"]:
-                            self.changes = log["changes"]
-                        else:
-                            self.changes = {}
-                        self.status = status
+                    if "changes" in log and log["changes"] is not None and str(self.resource_id) in log["changes"]:
+                        self.changes = log["changes"]
+                    else:
+                        self.changes = {}
+                    self.status = status
 
-                    self.future.set_result(ResourceActionResult(cancel=False))
-            except Exception:
-                LOGGER.exception("could not get status for remote resource")
-            finally:
-                self.running = False
+                self.future.set_result(ResourceActionResult(cancel=False))
+        except Exception:
+            LOGGER.exception("could not get status for remote resource")
+        finally:
+            self.running = False
 
     def notify(
         self,
         status: const.ResourceState,
         change: const.Change,
-        changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]],
+        changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]],
     ) -> None:
         if not self.future.done():
             self.status = status
             self.change = change
             self.changes = changes
             self.future.set_result(ResourceActionResult(cancel=False))
 
 
-@dataclasses.dataclass
-class DeployRequest:
-    """
-    A request to perform a deploy
-
-    :param is_full_deploy: is this a full deploy or incremental deploy?
-    :param is_periodic: is this deploy triggered by a timer?
-    :param reason: textual description of the deployment
-    """
-
-    is_full_deploy: bool
-    is_periodic: bool
-    reason: str
-
-    def interrupt(self, other: "DeployRequest") -> "DeployRequest":
-        """Interrupt this deploy for the other and produce a new request for future rescheduling of this deploy"""
-        return DeployRequest(
-            self.is_full_deploy, self.is_periodic, f"Restarting run '{self.reason}', interrupted for '{other.reason}'"
-        )
-
-
-class DeployRequestAction(str, enum.Enum):
-    """
-    When a deploy is running and a new request arrives, we can take the following actions
-    """
-
-    ignore = "ignore"
-    """ ignore the new request, continue with the exiting deploy """
-    terminate = "terminate"
-    """ terminate the current deploy, start the new one """
-    defer = "defer"
-    """ defer the new request,  continue with the exiting deploy, start the new one when the current deploy is done"""
-    interrupt = "interrupt"
-    """ interrupt the current deploy: cancel it, start the new one and restart the current deploy when the new one is done"""
-
-
-# Two letter abbreviations to make table line up
-# N normal
-# P periodic
-# F full
-# I incremental
-NF = (True, False)
-NI = (False, False)
-PF = (True, True)
-PI = (False, True)
-# shorten table
-ignore = DeployRequestAction.ignore
-terminate = DeployRequestAction.terminate
-defer = DeployRequestAction.defer
-interrupt = DeployRequestAction.interrupt
-
-# This matrix describes what do when a new DeployRequest enters before the old one is done
-# Format is (old_is_repair, old_is_periodic), (new_is_repair, new_is_periodic)
-# The underlying idea is that
-# 1. periodic deploys have no time pressure, they can be delayed
-# 2. non-periodic deploy should run as soon as possible
-# 3. non-periodic incremental deploys take precedence over repairs (as they are smaller)
-# 4. Periodic repairs should not interrupt each other to prevent restart loops
-# 5. Periodic repairs take precedence over periodic incremental deploys.
-# These rules do not full specify the matrix! They are the rules we have to follow.
-# A subtle detail is that when we do defer or interrupt, we only over keep one.
-# So if a previous deferred run exists, it will be silently dropped
-# But, we only defer or interrupt full deploys
-# As such, we will always execute a full deploy
-# (it may oscillate between periodic and not, but it will execute)
-
-deploy_response_matrix = {
-    # ((old_is_repair, old_is_periodic), (new_is_repair, new_is_periodic))
-    # Periodic restart loops: Full periodic is never interrupted by periodic
-    (PF, PF): ignore,  # Full periodic ignores full periodic to prevent restart loops
-    (NF, PF): ignore,  # Full ignores full periodic to avoid restart loops
-    (PF, PI): ignore,  # Full periodic ignores periodic increment to prevent restart loops
-    (PI, PF): terminate,  # Incremental periodic terminated by full periodic: upgrade to full
-    (PI, NF): terminate,  # Incremental periodic terminated by full: upgrade to full
-    # Same terminates same: focus on the new one
-    (PF, NF): terminate,  # Full periodic terminated by Full
-    (NF, NF): terminate,  # Full terminated by Full
-    # Increment * terminates Increment *
-    (PI, PI): terminate,
-    (PI, NI): terminate,
-    (NI, PI): terminate,
-    (NI, NI): terminate,
-    (NI, PF): defer,  # Incremental defers full periodic
-    (NI, NF): defer,  # Incremental defers full
-    # Non-periodic is always executed asap
-    (PF, NI): interrupt,  # periodic full interrupted by increment
-    (NF, NI): interrupt,  # full interrupted by increment
-    # Prefer the normal full over PI
-    (NF, PI): ignore,  # full ignores periodic increment
-}
-
-
-class ResourceScheduler:
+class ResourceScheduler(object):
     """Class responsible for managing sequencing of actions performed by the agent.
 
     State of the last run is not removed after the run but remains.
 
     By not removing e.g. the generation,
     1 - the class is always in a valid state
     2 - we don't need to figure out exactly when a run is done
     """
 
     def __init__(self, agent: "AgentInstance", env_id: uuid.UUID, name: str, cache: AgentCache) -> None:
-        self.generation: dict[ResourceIdStr, ResourceActionBase] = {}
-        self.cad: dict[str, RemoteResourceAction] = {}
+        self.generation: Dict[ResourceIdStr, ResourceActionBase] = {}
+        self.cad: Dict[str, RemoteResourceAction] = {}
         self._env_id = env_id
         self.agent = agent
         self.cache = cache
         self.name = name
         self.ratelimiter = agent.ratelimiter
         self.version: int = 0
-
-        self.running: Optional[DeployRequest] = None
-        self.deferred: Optional[DeployRequest] = None
-
+        # the reason the last run was started
+        self.reason: str = ""
+        # was the last run a repair run?
+        self.is_repair: bool = False
+        # if this value is not None, a new repair run will be started after the current run is done
+        # this field is both flag and value, to ensure consistency
+        self._resume_reason: Optional[str] = None
         self.logger: Logger = agent.logger
 
-    def get_scheduled_resource_actions(self) -> list[ResourceActionBase]:
+    def get_scheduled_resource_actions(self) -> List[ResourceActionBase]:
         return list(self.generation.values())
 
     def finished(self) -> bool:
         for resource_action in self.generation.values():
             if not resource_action.is_done():
                 return False
         return True
 
+    def is_normal_deploy_running(self) -> bool:
+        return not self.finished() and not self.is_repair
+
     def cancel(self) -> None:
         """
         Cancel all scheduled deployments.
         """
         for ra in self.generation.values():
             ra.cancel()
         self.generation = {}
         self.cad = {}
 
     def reload(
         self,
-        resources: list[Resource],
-        undeployable: dict[ResourceVersionIdStr, ResourceState],
-        new_request: DeployRequest,
+        resources: List[Resource],
+        undeployable: Dict[ResourceVersionIdStr, ResourceState] = {},
+        reason: str = "RELOAD",
+        is_repair: bool = False,
     ) -> None:
         """
         Schedule a new set of resources for execution.
 
         :param resources: The set of resource should be closed, the scheduler assumes that all resource referenced are in the
                           set or on another agent.
 
         **This method should only be called under critical_ratelimiter lock!**
         """
+
         # First determined if we should start and if the current run should be resumed
         if not self.finished():
             # we are still running
-            assert self.running is not None
-            # Get correct action
-            response = deploy_response_matrix[
-                ((self.running.is_full_deploy, self.running.is_periodic), (new_request.is_full_deploy, new_request.is_periodic))
-            ]
-            # Execute action
-            if response == DeployRequestAction.terminate:
-                self.logger.info("Terminating run '%s' for '%s'", self.running.reason, new_request.reason)
-            elif response == DeployRequestAction.defer:
-                self.logger.info("Deferring run '%s' for '%s'", new_request.reason, self.running.reason)
-                self.deferred = new_request
-                return
-            elif response == DeployRequestAction.ignore:
-                self.logger.info("Ignoring new run '%s' in favor of current '%s'", new_request.reason, self.running.reason)
-                return
-            elif response == DeployRequestAction.interrupt:
-                self.logger.info("Interrupting run '%s' for '%s'", self.running.reason, new_request.reason)
-                # Can overwrite, acceptable
-                self.deferred = self.running.interrupt(new_request)
+            if self.is_repair:
+                # now running repair
+                if is_repair:
+                    # repair restarts repair
+                    self.logger.info("Terminating run '%s' for '%s'", self.reason, reason)
+                else:
+                    # increment interrupts repair
+                    self.logger.info("Interrupting run '%s' for '%s'", self.reason, reason)
+                    self._resume_reason = "Restarting run '%s', interrupted for '%s'" % (self.reason, reason)
             else:
-                assert False, f"Unexpected DeployRequestAction {response}"
-
+                # now running increment
+                if is_repair:
+                    # repair is delayed
+                    self.logger.info("Deferring run '%s' for '%s'", reason, self.reason)
+                    self._resume_reason = reason
+                    return
+                else:
+                    # increment overrules increment
+                    self.logger.info("Terminating run '%s' for '%s'", self.reason, reason)
             # cancel old run
             self.cancel()
 
         # start new run
-        self.running = new_request
+        self.reason = reason
+        self.is_repair = is_repair
         self.version = resources[0].id.get_version()
         gid = uuid.uuid4()
-        self.logger.info(f"Running {gid} for reason: {self.running.reason}")
+        self.logger.info("Running %s for reason: %s" % (gid, reason))
 
         # re-generate generation
-        self.generation = {r.id.resource_str(): ResourceAction(self, r, gid, self.running.reason) for r in resources}
+        self.generation = {r.id.resource_str(): ResourceAction(self, r, gid, reason) for r in resources}
 
         # mark undeployable
         for key, res in self.generation.items():
             vid = res.resource_id.resource_version_str()
             if vid in undeployable:
                 self.generation[key].undeployable = undeployable[vid]
 
         # hook up Cross Agent Dependencies
         cross_agent_dependencies = [q for r in resources for q in r.requires if q.get_agent_name() != self.name]
         for cad in cross_agent_dependencies:
-            ra = RemoteResourceAction(self, cad, gid, self.running.reason)
+            ra = RemoteResourceAction(self, cad, gid, reason)
             self.cad[str(cad)] = ra
             self.generation[cad.resource_str()] = ra
 
         # Create dummy to give start signal
-        dummy = DummyResourceAction(self, gid, self.running.reason)
+        dummy = DummyResourceAction(self, gid, reason)
         # Dispatch all actions
         # Will block on dependencies and dummy
         for r in self.generation.values():
             add_future(r.execute(dummy, self.generation, self.cache))
 
         # Listen for completion
         self.agent.process.add_background_task(self.mark_deployment_as_finished(self.generation.values()))
@@ -587,25 +465,29 @@
         # Because the asyncio.gather() call propagates cancellation, we shield the ResourceActionBase.future.
         # Cancellation of these futures is handled by the ResourceActionBase.cancel() method. Not shielding them
         # would cause the result of the future to be set twice, which results in an undesired InvalidStateError.
         await asyncio.gather(*[asyncio.shield(resource_action.future) for resource_action in resource_actions])
         async with self.agent.critical_ratelimiter:
             if not self.finished():
                 return
-            if self.deferred is not None:
-                self.logger.info("Resuming run '%s'", self.deferred.reason)
-                self.agent.process.add_background_task(self.agent.get_latest_version_for_agent(self.deferred))
-                self.deferred = None
+            if self._resume_reason is not None:
+                self.logger.info("Resuming run '%s'", self._resume_reason)
+                self.agent.process.add_background_task(
+                    self.agent.get_latest_version_for_agent(
+                        reason=self._resume_reason, incremental_deploy=False, is_repair_run=True
+                    )
+                )
+                self._resume_reason = None
 
     def notify_ready(
         self,
         resourceid: ResourceVersionIdStr,
         state: const.ResourceState,
         change: const.Change,
-        changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]],
+        changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]],
     ) -> None:
         if resourceid not in self.cad:
             # received CAD notification for which no resource are waiting, so return
             return
         self.cad[resourceid].notify(state, change, changes)
 
     def dump(self) -> None:
@@ -613,19 +495,19 @@
         for r in self.generation.values():
             print(r.long_string())
 
     def get_client(self) -> protocol.Client:
         return self.agent.get_client()
 
 
-class AgentInstance:
+class AgentInstance(object):
     _get_resource_timeout: float
     _get_resource_duration: float
 
-    def __init__(self, process: "Agent", name: str, uri: str, *, ensure_deploy_on_start: bool = False) -> None:
+    def __init__(self, process: "Agent", name: str, uri: str) -> None:
         self.process = process
         self.name = name
         self._uri = uri
 
         self.logger: Logger = LOGGER.getChild(self.name)
 
         # the lock for changing the current ongoing deployment
@@ -645,46 +527,41 @@
 
         self._env_id: uuid.UUID = process.environment
         self.sessionid: uuid.UUID = process.sessionid
 
         # init
         self._cache = AgentCache(self)
         self._nq = ResourceScheduler(self, self._env_id, name, self._cache)
-        self._time_triggered_actions: set[ScheduledTask] = set()
+        self._time_triggered_actions: Set[ScheduledTask] = set()
         self._enabled = False
         self._stopped = False
 
         # do regular deploys
         self._deploy_interval = cfg.agent_deploy_interval.get()
         deploy_splay_time = cfg.agent_deploy_splay_time.get()
         self._deploy_splay_value = random.randint(0, deploy_splay_time)
 
         # do regular repair runs
-        self._repair_interval: Union[int, str] = cfg.agent_repair_interval.get()
+        self._repair_interval = cfg.agent_repair_interval.get()
         repair_splay_time = cfg.agent_repair_splay_time.get()
         self._repair_splay_value = random.randint(0, repair_splay_time)
 
         self._getting_resources = False
         self._get_resource_timeout = 0
 
-        # If this instance has no deploy timer set, deploy anyway
-        # This is used for agents that are started via the agentmap
-        # To give smooth deploy experience, we want these agents to start immediately.
-        self.ensure_deploy_on_start = ensure_deploy_on_start
-
     async def stop(self) -> None:
         self._stopped = True
         self._enabled = False
         self._disable_time_triggers()
         self._nq.cancel()
         self._cache.close()
         self.provider_thread_pool.shutdown(wait=False)
         self.thread_pool.shutdown(wait=False)
 
-    def join(self, thread_pool_finalizer: list[ThreadPoolExecutor]) -> None:
+    def join(self, thread_pool_finalizer: List[ThreadPoolExecutor]) -> None:
         """
         Called after stop to ensure complete shutdown
 
         :param thread_pool_finalizer: all threadpools that should be joined should be added here.
         """
         assert self._stopped
         thread_pool_finalizer.append(self.provider_thread_pool)
@@ -734,89 +611,61 @@
 
         return 200, "paused"
 
     def _enable_time_triggers(self) -> None:
         async def deploy_action() -> None:
             now = datetime.datetime.now().astimezone()
             await self.get_latest_version_for_agent(
-                DeployRequest(
-                    reason="Periodic deploy started at %s" % (now.strftime(const.TIME_LOGFMT)),
-                    is_full_deploy=False,
-                    is_periodic=True,
-                )
+                reason="Periodic deploy started at %s" % (now.strftime(const.TIME_LOGFMT)),
+                incremental_deploy=True,
+                is_repair_run=False,
             )
 
         async def repair_action() -> None:
             now = datetime.datetime.now().astimezone()
             await self.get_latest_version_for_agent(
-                DeployRequest(
-                    reason="Repair run started at %s" % (now.strftime(const.TIME_LOGFMT)),
-                    is_full_deploy=True,
-                    is_periodic=True,
-                )
+                reason="Repair run started at %s" % (now.strftime(const.TIME_LOGFMT)),
+                incremental_deploy=False,
+                is_repair_run=True,
             )
 
-        def periodic_schedule(
-            kind: str,
-            action: Callable[[], Awaitable[object]],
-            interval: Union[int, str],
-            splay_value: int,
-            initial_time: datetime.datetime,
-        ) -> bool:
-            if isinstance(interval, int) and interval > 0:
-                self.logger.info(
-                    "Scheduling periodic %s with interval %d and splay %d (first run at %s)",
-                    kind,
-                    interval,
-                    splay_value,
-                    (initial_time + datetime.timedelta(seconds=splay_value)).strftime(const.TIME_LOGFMT),
-                )
-                interval_schedule: IntervalSchedule = IntervalSchedule(
-                    interval=float(interval), initial_delay=float(splay_value)
-                )
-                self._enable_time_trigger(action, interval_schedule)
-                return True
-
-            if isinstance(interval, str):
-                self.logger.info("Scheduling periodic %s with cron expression '%s'", kind, interval)
-                cron_schedule = CronSchedule(cron=interval)
-                self._enable_time_trigger(action, cron_schedule)
-                return True
-            return False
-
         now = datetime.datetime.now().astimezone()
-        if self.ensure_deploy_on_start:
-            self.process.add_background_task(
-                self.get_latest_version_for_agent(
-                    DeployRequest(
-                        reason="Initial deploy started at %s" % (now.strftime(const.TIME_LOGFMT)),
-                        is_full_deploy=False,
-                        is_periodic=False,
-                    )
-                )
+        if self._deploy_interval > 0:
+            self.logger.info(
+                "Scheduling periodic deploy with interval %d and splay %d (first run at %s)",
+                self._deploy_interval,
+                self._deploy_splay_value,
+                (now + datetime.timedelta(seconds=self._deploy_splay_value)).strftime(const.TIME_LOGFMT),
             )
-            self.ensure_deploy_on_start = False
-        periodic_schedule("deploy", deploy_action, self._deploy_interval, self._deploy_splay_value, now)
-        periodic_schedule("repair", repair_action, self._repair_interval, self._repair_splay_value, now)
+            self._enable_time_trigger(deploy_action, self._deploy_interval, self._deploy_splay_value)
+        if self._repair_interval > 0:
+            self.logger.info(
+                "Scheduling repair with interval %d and splay %d (first run at %s)",
+                self._repair_interval,
+                self._repair_splay_value,
+                (now + datetime.timedelta(seconds=self._repair_splay_value)).strftime(const.TIME_LOGFMT),
+            )
+            self._enable_time_trigger(repair_action, self._repair_interval, self._repair_splay_value)
 
-    def _enable_time_trigger(self, action: TaskMethod, schedule: TaskSchedule) -> None:
+    def _enable_time_trigger(self, action: TaskMethod, interval: int, splay: int) -> None:
+        schedule: IntervalSchedule = IntervalSchedule(interval=float(interval), initial_delay=float(splay))
         self.process._sched.add_action(action, schedule)
         self._time_triggered_actions.add(ScheduledTask(action=action, schedule=schedule))
 
     def _disable_time_triggers(self) -> None:
         for task in self._time_triggered_actions:
             self.process._sched.remove(task)
         self._time_triggered_actions.clear()
 
     def notify_ready(
         self,
         resourceid: ResourceVersionIdStr,
         state: const.ResourceState,
         change: const.Change,
-        changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]],
+        changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]],
     ) -> None:
         self._nq.notify_ready(resourceid, state, change, changes)
 
     def _can_get_resources(self) -> bool:
         if self._getting_resources:
             self.logger.info("Attempting to get resource while get is in progress")
             return False
@@ -833,58 +682,57 @@
         provider = await asyncio.get_running_loop().run_in_executor(
             self.provider_thread_pool, handler.Commander.get_provider, self._cache, self, resource
         )
         provider.set_cache(self._cache)
         return provider
 
     async def get_latest_version_for_agent(
-        self,
-        deploy_request: DeployRequest,
+        self, reason: str = "Unknown", incremental_deploy: bool = False, is_repair_run: bool = False
     ) -> None:
         """
         Get the latest version for the given agent (this is also how we are notified)
 
         :param reason: the reason this deploy was started
         """
         if not self._can_get_resources():
-            self.logger.warning("%s aborted by rate limiter", deploy_request.reason)
+            self.logger.warning("%s aborted by rate limiter", reason)
             return
 
         async with self.critical_ratelimiter:
             if not self._can_get_resources():
-                self.logger.warning("%s aborted by rate limiter", deploy_request.reason)
+                self.logger.warning("%s aborted by rate limiter", reason)
                 return
 
-            self.logger.debug("Getting latest resources for %s", deploy_request.reason)
+            self.logger.debug("Getting latest resources for %s", reason)
             self._getting_resources = True
             start = time.time()
             try:
                 result = await self.get_client().get_resources_for_agent(
-                    tid=self._env_id, agent=self.name, incremental_deploy=not deploy_request.is_full_deploy
+                    tid=self._env_id, agent=self.name, incremental_deploy=incremental_deploy
                 )
             finally:
                 self._getting_resources = False
             end = time.time()
             self._get_resource_duration = end - start
             self._get_resource_timeout = cfg.agent_get_resource_backoff.get() * self._get_resource_duration + end
             if result.code == 404:
-                self.logger.info("No released configuration model version available for %s", deploy_request.reason)
+                self.logger.info("No released configuration model version available for %s", reason)
             elif result.code == 409:
-                self.logger.warning("We are not currently primary during %s: %s", deploy_request.reason, result.result)
+                self.logger.warning("We are not currently primary during %s: %s", reason, result.result)
             elif result.code != 200 or result.result is None:
-                self.logger.warning("Got an error while pulling resources for %s. %s", deploy_request.reason, result.result)
+                self.logger.warning("Got an error while pulling resources for %s. %s", reason, result.result)
 
             else:
                 undeployable, resources = await self.load_resources(
                     result.result["version"], const.ResourceAction.deploy, result.result["resources"]
                 )
-                self.logger.debug("Pulled %d resources because %s", len(resources), deploy_request.reason)
+                self.logger.debug("Pulled %d resources because %s", len(resources), reason)
 
                 if len(resources) > 0:
-                    self._nq.reload(resources, undeployable, deploy_request)
+                    self._nq.reload(resources, undeployable, reason=reason, is_repair=is_repair_run)
 
     async def dryrun(self, dry_run_id: uuid.UUID, version: int) -> Apireturn:
         self.process.add_background_task(self.do_run_dryrun(version, dry_run_id))
         return 200
 
     async def do_run_dryrun(self, version: int, dry_run_id: uuid.UUID) -> None:
         async with self.dryrunlock:
@@ -1046,26 +894,26 @@
                 return 500
             finally:
                 if provider is not None:
                     provider.close()
             return 200
 
     async def load_resources(
-        self, version: int, action: const.ResourceAction, resources: list[JsonType]
-    ) -> tuple[dict[ResourceVersionIdStr, const.ResourceState], list[Resource]]:
+        self, version: int, action: const.ResourceAction, resources: List[JsonType]
+    ) -> Tuple[Dict[ResourceVersionIdStr, const.ResourceState], List[Resource]]:
         """Deserialize all resources and load all handler code. When the code for this type fails to load, the resource
         is marked as failed
         """
         started = datetime.datetime.now().astimezone()
         failed_resource_types = await self.process.ensure_code(
             self._env_id, version, [res["resource_type"] for res in resources]
         )
-        loaded_resources: list[Resource] = []
-        failed_resources: list[ResourceVersionIdStr] = []
-        undeployable: dict[ResourceVersionIdStr, const.ResourceState] = {}
+        loaded_resources: List[Resource] = []
+        failed_resources: List[ResourceVersionIdStr] = []
+        undeployable: Dict[ResourceVersionIdStr, const.ResourceState] = {}
 
         for res in resources:
             try:
                 res["attributes"]["id"] = res["id"]
                 if res["resource_type"] not in failed_resource_types:
                     resource = Resource.deserialize(res["attributes"])
                     loaded_resources.append(resource)
@@ -1075,15 +923,15 @@
                         undeployable[res["id"]] = state
                 else:
                     failed_resources.append(res["id"])
                     undeployable[res["id"]] = const.ResourceState.unavailable
                     resource = Resource.deserialize(res["attributes"], use_generic=True)
                     loaded_resources.append(resource)
 
-            except Exception:
+            except TypeError:
                 failed_resources.append(res["id"])
                 undeployable[res["id"]] = const.ResourceState.unavailable
                 resource = Resource.deserialize(res["attributes"], use_generic=True)
                 loaded_resources.append(resource)
 
         if len(failed_resources) > 0:
             log = data.LogLine.log(
@@ -1116,62 +964,51 @@
     # cache reference to THIS ioloop for handlers to push requests on it
     # defer to start, just to be sure
     _io_loop: asyncio.AbstractEventLoop
 
     def __init__(
         self,
         hostname: Optional[str] = None,
-        agent_map: Optional[dict[str, str]] = None,
+        agent_map: Optional[Dict[str, str]] = None,
         code_loader: bool = True,
         environment: Optional[uuid.UUID] = None,
         poolsize: int = 1,
     ):
-        """
-        :param hostname: this used to indicate the hostname of the agent,
-        but it is now mostly used by testcases to prevent endpoint to be loaded from the config singleton
-           see _init_endpoint_names
-        :param agent_map: the agent map for this agent to use
-        :param code_loader: do we enable the code loader (used for testing)
-        :param environment: environment id
-        :param poolsize: level of parallelism per agent instance, in practice, always 1
-        """
         super().__init__("agent", timeout=cfg.server_timeout.get(), reconnect_delay=cfg.agent_reconnect_delay.get())
 
         self.hostname = hostname
         self.poolsize = poolsize
         self.ratelimiter = asyncio.Semaphore(poolsize)
-        # Number of in flight requests for resolving CAD's
-        self.cad_ratelimiter = asyncio.Semaphore(3)
         self.thread_pool = ThreadPoolExecutor(poolsize, thread_name_prefix="mainpool")
 
         self._storage = self.check_storage()
 
         if environment is None:
             environment = cfg.environment.get()
             if environment is None:
                 raise Exception("The agent requires an environment to be set.")
         self.set_environment(environment)
 
-        self._instances: dict[str, AgentInstance] = {}
+        self._instances: Dict[str, AgentInstance] = {}
         self._instances_lock = asyncio.Lock()
 
         self._loader: Optional[CodeLoader] = None
         self._env: Optional[env.VirtualEnv] = None
         if code_loader:
             self._env = env.VirtualEnv(self._storage["env"])
             self._env.use_virtual_env()
             self._loader = CodeLoader(self._storage["code"])
             # Lock to ensure only one actual install runs at a time
             self._loader_lock = Lock()
             # Cache to prevent re-loading the same resource-version
-            self._last_loaded: dict[str, int] = defaultdict(lambda: -1)
+            self._last_loaded: Dict[str, int] = defaultdict(lambda: -1)
             # Per-resource lock to serialize all actions per resource
             self._resource_loader_lock = NamedLock()
 
-        self.agent_map: Optional[dict[str, str]] = agent_map
+        self.agent_map: Optional[Dict[str, str]] = agent_map
 
     async def _init_agent_map(self) -> None:
         if cfg.use_autostart_agent_map.get():
             LOGGER.info("Using the autostart_agent_map configured on the server")
             env_id = self.get_environment()
             assert env_id is not None
             result = await self._client.environment_setting_get(env_id, data.AUTOSTART_AGENT_MAP)
@@ -1192,15 +1029,15 @@
             if agent_names is not None:
                 for name in agent_names:
                     if "$" in name:
                         name = name.replace("$node-name", self.node_name)
                     await self.add_end_point_name(name)
 
     async def stop(self) -> None:
-        await super().stop()
+        await super(Agent, self).stop()
         self.thread_pool.shutdown(wait=False)
         threadpools_to_join = [self.thread_pool]
         for instance in self._instances.values():
             await instance.stop()
             instance.join(threadpools_to_join)
         await join_threadpools(threadpools_to_join)
 
@@ -1218,63 +1055,63 @@
             except CouldNotConnectToServer:
                 await asyncio.sleep(1)
         await self._init_endpoint_names()
 
     async def start(self) -> None:
         # cache reference to THIS ioloop for handlers to push requests on it
         self._io_loop = asyncio.get_running_loop()
-        await super().start()
+        await super(Agent, self).start()
 
     async def add_end_point_name(self, name: str) -> None:
         async with self._instances_lock:
             await self._add_end_point_name(name)
 
-    async def _add_end_point_name(self, name: str, *, ensure_deploy_on_start: bool = False) -> None:
+    async def _add_end_point_name(self, name: str) -> None:
         """
         Note: always call under _instances_lock
         """
         LOGGER.info("Adding endpoint %s", name)
-        await super().add_end_point_name(name)
+        await super(Agent, self).add_end_point_name(name)
 
         # Make mypy happy
         assert self.agent_map is not None
 
         hostname = "local:"
         if name in self.agent_map:
             hostname = self.agent_map[name]
 
-        self._instances[name] = AgentInstance(self, name, hostname, ensure_deploy_on_start=ensure_deploy_on_start)
+        self._instances[name] = AgentInstance(self, name, hostname)
 
     async def remove_end_point_name(self, name: str) -> None:
         async with self._instances_lock:
             await self._remove_end_point_name(name)
 
     async def _remove_end_point_name(self, name: str) -> None:
         """
         Note: always call under _instances_lock
         """
         LOGGER.info("Removing endpoint %s", name)
-        await super().remove_end_point_name(name)
+        await super(Agent, self).remove_end_point_name(name)
 
         agent_instance = self._instances[name]
         del self._instances[name]
         await agent_instance.stop()
 
     @protocol.handle(methods_v2.update_agent_map)
-    async def update_agent_map(self, agent_map: dict[str, str]) -> None:
+    async def update_agent_map(self, agent_map: Dict[str, str]) -> None:
         if not cfg.use_autostart_agent_map.get():
             LOGGER.warning(
                 "Agent received an update_agent_map() trigger, but agent is not running with "
                 "the use_autostart_agent_map option."
             )
         else:
             LOGGER.debug("Received update_agent_map() trigger with agent_map %s", agent_map)
             await self._update_agent_map(agent_map)
 
-    async def _update_agent_map(self, agent_map: dict[str, str]) -> None:
+    async def _update_agent_map(self, agent_map: Dict[str, str]) -> None:
         async with self._instances_lock:
             self.agent_map = agent_map
             # Add missing agents
             agents_to_add = [agent_name for agent_name in self.agent_map.keys() if agent_name not in self._instances]
             # Remove agents which are not present in agent-map anymore
             agents_to_remove = [agent_name for agent_name in self._instances.keys() if agent_name not in self.agent_map]
             # URI was updated
@@ -1287,21 +1124,19 @@
                     LOGGER.info("Updating the URI of the endpoint %s from %s to %s", agent_name, current_uri, uri)
                     update_uri_agents.append(agent_name)
 
             updated_uri_agents_to_enable = [
                 agent_name for agent_name in update_uri_agents if self._instances[agent_name].is_enabled()
             ]
 
-            to_be_gathered = [self._add_end_point_name(agent_name, ensure_deploy_on_start=True) for agent_name in agents_to_add]
+            to_be_gathered = [self._add_end_point_name(agent_name) for agent_name in agents_to_add]
             to_be_gathered += [self._remove_end_point_name(agent_name) for agent_name in agents_to_remove + update_uri_agents]
             await asyncio.gather(*to_be_gathered)
             # Re-add agents with updated URI
-            await asyncio.gather(
-                *[self._add_end_point_name(agent_name, ensure_deploy_on_start=True) for agent_name in update_uri_agents]
-            )
+            await asyncio.gather(*[self._add_end_point_name(agent_name) for agent_name in update_uri_agents])
             # Enable agents with updated URI that were enabled before
             for agent_to_enable in updated_uri_agents_to_enable:
                 self.unpause(agent_to_enable)
 
     def unpause(self, name: str) -> Apireturn:
         instance = self._instances.get(name)
         if not instance:
@@ -1346,20 +1181,24 @@
                 LOGGER.warning("could not get state from the server")
 
     async def on_disconnect(self) -> None:
         LOGGER.warning("Connection to server lost, taking agents offline")
         for agent_instance in self._instances.values():
             agent_instance.pause("Connection to server lost")
 
-    async def ensure_code(self, environment: uuid.UUID, version: int, resource_types: Sequence[str]) -> set[str]:
+    async def get_latest_version(self) -> None:
         """
-        Ensure that the code for the given environment and version is loaded.
-        Return a list of all the ``resource_types`` that it failed to load.
+        Get the latest version of managed resources for all agents
         """
-        failed_to_load: set[str] = set()
+        for agent in self._instances.values():
+            await agent.get_latest_version_for_agent(reason="call to get_latest_version on agent")
+
+    async def ensure_code(self, environment: uuid.UUID, version: int, resource_types: Sequence[str]) -> Set[str]:
+        """Ensure that the code for the given environment and version is loaded"""
+        failed_to_load: Set[str] = set()
         if self._loader is None:
             return failed_to_load
 
         for rt in set(resource_types):
             # only one logical thread can load a particular resource type at any time
             async with self._resource_loader_lock.get(rt):
                 # stop if the last successful load was this one
@@ -1373,30 +1212,27 @@
                 result: protocol.Result = await self._client.get_source_code(environment, version, rt)
                 if result.code == 200 and result.result is not None:
                     try:
                         sync_client = SyncClient(client=self._client, ioloop=self._io_loop)
                         LOGGER.debug("Installing handler %s version=%d", rt, version)
                         requirements = set()
                         sources = []
-                        # Encapsulate source code details in ``ModuleSource`` objects
                         for source in result.result["data"]:
                             sources.append(
                                 ModuleSource(
                                     name=source["module_name"],
                                     is_byte_code=source["is_byte_code"],
                                     hash_value=source["hash"],
                                     _client=sync_client,
                                 )
                             )
                             requirements.update(source["requirements"])
 
                         await self._install(sources, list(requirements))
                         LOGGER.debug("Installed handler %s version=%d", rt, version)
-                        # Update the ``_last_loaded`` cache to indicate that the given resource type's code
-                        # was loaded successfully at the specified version.
                         self._last_loaded[rt] = version
                     except Exception:
                         LOGGER.exception("Failed to install handler %s version=%d", rt, version)
                         failed_to_load.add(rt)
 
         return failed_to_load
 
@@ -1420,34 +1256,28 @@
             return 200
 
         if not instance.is_enabled():
             return 500, "Agent is not _enabled"
 
         LOGGER.info("Agent %s got a trigger to update in environment %s", agent, env)
         self.add_background_task(
-            instance.get_latest_version_for_agent(
-                DeployRequest(
-                    is_full_deploy=not incremental_deploy,
-                    is_periodic=False,
-                    reason="call to trigger_update",
-                )
-            )
+            instance.get_latest_version_for_agent(reason="call to trigger_update", incremental_deploy=incremental_deploy)
         )
         return 200
 
     @protocol.handle(methods.resource_event, env="tid", agent="id")
     async def resource_event(
         self,
         env: uuid.UUID,
         agent: str,
         resource: ResourceVersionIdStr,
         send_events: bool,
         state: const.ResourceState,
         change: const.Change,
-        changes: dict[ResourceVersionIdStr, dict[str, AttributeStateChange]],
+        changes: Dict[ResourceVersionIdStr, Dict[str, AttributeStateChange]],
     ) -> Apireturn:
         if env != self._env_id:
             LOGGER.error(
                 "The agent process for the environment %s has received a cross agent dependency event that was intended for "
                 "another environment %s. It originated from the resource: %s, that is in state: %s",
                 self._env_id,
                 env,
@@ -1486,15 +1316,15 @@
         if not instance:
             return 200
 
         LOGGER.info("Agent %s got a trigger to run dryrun %s for version %s in environment %s", agent, dry_run_id, version, env)
 
         return await instance.dryrun(dry_run_id, version)
 
-    def check_storage(self) -> dict[str, str]:
+    def check_storage(self) -> Dict[str, str]:
         """
         Check if the server storage is configured and ready to use.
         """
 
         state_dir = cfg.state_dir.get()
 
         if not os.path.exists(state_dir):
@@ -1516,15 +1346,15 @@
         dir_map["env"] = env_dir
         if not os.path.exists(env_dir):
             os.mkdir(env_dir)
 
         return dir_map
 
     @protocol.handle(methods.get_parameter, env="tid")
-    async def get_facts(self, env: uuid.UUID, agent: str, resource: dict[str, Any]) -> Apireturn:
+    async def get_facts(self, env: uuid.UUID, agent: str, resource: Dict[str, Any]) -> Apireturn:
         instance = self._instances.get(agent)
         if not instance:
             return 200
 
         return await instance.get_facts(resource)
 
     @protocol.handle(methods.get_status)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/cache.py` & `inmanta-core-9.3.0/src/inmanta/agent/cache.py`

 * *Files 8% similar despite different names*

```diff
@@ -18,32 +18,32 @@
 
 import bisect
 import contextlib
 import logging
 import sys
 import time
 from threading import Lock
-from typing import TYPE_CHECKING, Any, Callable, Optional
+from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Set
 
 from inmanta.resources import Resource
 from inmanta.stable_api import stable_api
 
 if TYPE_CHECKING:
     from inmanta.agent.agent import AgentInstance
 
 LOGGER = logging.getLogger()
 
 
-class Scope:
+class Scope(object):
     def __init__(self, timeout: int = 24 * 3600, version: int = 0) -> None:
         self.timeout = timeout
         self.version = version
 
 
-class CacheItem:
+class CacheItem(object):
     def __init__(self, key: str, scope: Scope, value: Any, call_on_delete: Optional[Callable[[Any], None]]) -> None:
         self.key = key
         self.scope = scope
         self.value = value
         self.time: float = time.time() + scope.timeout
         self.call_on_delete = call_on_delete
 
@@ -73,15 +73,15 @@
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self.cache.close_version(self.version)
         return None
 
 
 @stable_api
-class AgentCache:
+class AgentCache(object):
     """
     Caching system for the agent:
 
     cache items can expire based on:
     1. time
     2. version
 
@@ -90,21 +90,21 @@
     """
 
     def __init__(self, agent_instance: Optional["AgentInstance"] = None) -> None:
         """
         :param agent_instance: The AgentInstance that is using the cache. The value is None when the cache
                                is used from pytest-inmanta.
         """
-        self.cache: dict[str, Any] = {}
-        self.counterforVersion: dict[int, int] = {}
-        self.keysforVersion: dict[int, set[str]] = {}
-        self.timerqueue: list[CacheItem] = []
+        self.cache: Dict[str, Any] = {}
+        self.counterforVersion: Dict[int, int] = {}
+        self.keysforVersion: Dict[int, Set[str]] = {}
+        self.timerqueue: List[CacheItem] = []
         self.nextAction: float = sys.maxsize
         self.addLock = Lock()
-        self.addLocks: dict[str, Lock] = {}
+        self.addLocks: Dict[str, Lock] = {}
         self._agent_instance = agent_instance
 
     def close(self) -> None:
         """
         Cleanly terminate the cache
         """
         for version in list(self.counterforVersion.keys()):
@@ -247,15 +247,15 @@
 
     def get_or_else(
         self,
         key: str,
         function: Callable[..., Any],
         for_version: bool = True,
         timeout: int = 5000,
-        ignore: set[str] = set(),
+        ignore: Set[str] = set(),
         cache_none: bool = True,
         call_on_delete: Optional[Callable[[Any], None]] = None,
         **kwargs,
     ) -> object:
         """
         Attempt to find a value in the cache.
 
@@ -272,15 +272,15 @@
         """
         acceptable = {"resource"}
         if for_version:
             acceptable.add("version")
         args = {k: v for k, v in kwargs.items() if k in acceptable and k not in ignore}
         others = sorted([k for k in kwargs.keys() if k not in acceptable and k not in ignore])
         for k in others:
-            key = f"{k},{repr(kwargs[k])}" + key
+            key = "%s,%s" % (k, repr(kwargs[k])) + key
         try:
             return self.find(key, **args)
         except KeyError:
             with self.addLock:
                 if key in self.addLocks:
                     lock = self.addLocks[key]
                 else:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/config.py` & `inmanta-core-9.3.0/src/inmanta/agent/config.py`

 * *Files 27% similar despite different names*

```diff
@@ -91,22 +91,16 @@
     is_time,
 )
 
 agent_deploy_interval = Option(
     "config",
     "agent-deploy-interval",
     0,
-    "Either the number of seconds between two (incremental) deployment runs of the agent or a cron-like expression."
-    " If a cron-like expression is specified, a deploy will be run following a cron-like time-to-run specification,"
-    " interpreted in UTC. The expected format is `[sec] min hour dom month dow [year]` ( If only 6 values are provided, they"
-    " are interpreted as `min hour dom month dow year`)."
-    " A deploy will be requested at the scheduled time. Note that if a cron"
-    " expression is used the 'agent_deploy_splay_time' setting will be ignored."
-    " Set this to 0 to disable the scheduled deploy runs.",
-    is_time_or_cron,
+    "The number of seconds between two (incremental) deployment runs of the agent. Set this to 0 to disable the scheduled deploy runs.",
+    is_time,
     predecessor_option=agent_interval,
 )
 agent_deploy_splay_time = Option(
     "config",
     "agent-deploy-splay-time",
     600,
     """The splaytime added to the agent-deploy-interval. Set this to 0 to disable the splaytime.
@@ -118,40 +112,34 @@
     predecessor_option=agent_splay,
 )
 
 agent_repair_interval = Option(
     "config",
     "agent-repair-interval",
     600,
-    "Either the number of seconds between two repair runs (full deploy) of the agent or a cron-like expression."
-    " If a cron-like expression is specified, a repair will be run following a cron-like time-to-run specification,"
-    " interpreted in UTC. The expected format is `[sec] min hour dom month dow [year]` ( If only 6 values are provided, they"
-    " are interpreted as `min hour dom month dow year`)."
-    " A repair will be requested at the scheduled time. Note that if a cron"
-    " expression is used the 'agent_repair_splay_time' setting will be ignored."
-    " Setting this to 0 to disable the scheduled repair runs.",
-    is_time_or_cron,
+    "The number of seconds between two repair runs (full deploy) of the agent. "
+    + "Set this to 0 to disable the scheduled repair runs.",
+    is_time,
 )
 agent_repair_splay_time = Option(
     "config",
     "agent-repair-splay-time",
     600,
     """The splaytime added to the agent-repair-interval. Set this to 0 to disable the splaytime.
 
 At startup the agent will choose a random number between 0 and agent-repair-splay-time.
 It will wait this number of second before performing the first repair run.
-Each subsequent repair deployment will start agent-repair-interval seconds after the previous one.
-This option is ignored and a splay of 0 is used if 'agent_repair_interval' is a cron expression""",
+Each subsequent repair deployment will start agent-repair-interval seconds after the previous one.""",
     is_time,
 )
 
 agent_get_resource_backoff = Option(
     "config",
     "agent-get-resource-backoff",
-    5,
+    3,
     "This is a load management feature. It ensures that the agent will not pull resources from the inmanta server"
     " `<agent-get-resource-backoff>*<duration-last-pull-in-seconds>` seconds after the last time the agent pulled resources"
     " from the server. Setting this option too low may result in a high load on the Inmanta server. Setting it too high"
     " may result in long deployment times.",
     is_float,
 )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/handler.py` & `inmanta-core-9.3.0/src/inmanta/agent/handler.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,17 +18,17 @@
 import base64
 import inspect
 import logging
 import traceback
 import typing
 import uuid
 from abc import ABC, abstractmethod
-from collections import abc, defaultdict
+from collections import defaultdict
 from concurrent.futures import Future
-from typing import Any, Callable, Generic, Optional, TypeVar, Union, cast, overload
+from typing import Any, Callable, Dict, Generic, List, Optional, Tuple, Type, TypeVar, Union, cast, overload
 
 from tornado import concurrent
 
 import inmanta
 from inmanta import const, data, protocol, resources
 from inmanta.agent import io
 from inmanta.agent.cache import AgentCache
@@ -47,15 +47,15 @@
 LOGGER = logging.getLogger(__name__)
 
 T = TypeVar("T")
 T_FUNC = TypeVar("T_FUNC", bound=Callable[..., Any])
 
 
 @stable_api
-class provider:  # noqa: N801
+class provider(object):  # noqa: N801
     """
     A decorator that registers a new handler.
 
     :param resource_type: The type of the resource this handler provides an implementation for.
                           For example, :inmanta:entity:`std::File`
     :param name: A name to reference this provider.
     """
@@ -93,15 +93,15 @@
     This exception is raised by the context or handler methods when an invalid operation is performed.
     """
 
 
 @stable_api
 def cache(
     func: Optional[T_FUNC] = None,
-    ignore: list[str] = [],
+    ignore: typing.List[str] = [],
     timeout: int = 5000,
     for_version: bool = True,
     cache_none: bool = True,
     # deprecated parameter kept for backwards compatibility: if set, overrides cache_none
     cacheNone: Optional[bool] = None,  # noqa: N803
     call_on_delete: Optional[Callable[[Any], None]] = None,
 ) -> Union[T_FUNC, Callable[[T_FUNC], T_FUNC]]:
@@ -209,35 +209,35 @@
         resource: resources.Resource,
         dry_run: bool = False,
         action_id: Optional[uuid.UUID] = None,
         logger: Optional[logging.Logger] = None,
     ) -> None:
         self._resource = resource
         self._dry_run = dry_run
-        self._cache: dict[str, Any] = {}
+        self._cache: Dict[str, Any] = {}
 
         self._purged = False
         self._updated = False
         self._created = False
         self._change = const.Change.nochange
 
-        self._changes: dict[str, AttributeStateChange] = {}
+        self._changes: Dict[str, AttributeStateChange] = {}
 
         if action_id is None:
             action_id = uuid.uuid4()
         self._action_id = action_id
         self._status: Optional[ResourceState] = None
-        self._logs: list[data.LogLine] = []
+        self._logs: List[data.LogLine] = []
         self.logger: logging.Logger
         if logger is None:
             self.logger = LOGGER
         else:
             self.logger = logger
 
-        self._facts: list[dict[str, Any]] = []
+        self._facts: List[Dict[str, Any]] = []
 
     def set_fact(self, fact_id: str, value: str) -> None:
         """
         Send a fact to the Inmanta server.
 
         :param fact_id: The name of the fact.
         :param value: The actual value of the fact.
@@ -248,27 +248,27 @@
             "source": ParameterSource.fact.value,
             "value": value,
             "resource_id": resource_id,
         }
         self._facts.append(fact)
 
     @property
-    def facts(self) -> list[dict[str, Any]]:
+    def facts(self) -> List[Dict[str, Any]]:
         return self._facts
 
     @property
     def action_id(self) -> uuid.UUID:
         return self._action_id
 
     @property
     def status(self) -> Optional[const.ResourceState]:
         return self._status
 
     @property
-    def logs(self) -> list[data.LogLine]:
+    def logs(self) -> List[data.LogLine]:
         return self._logs
 
     def set_status(self, status: const.ResourceState) -> None:
         """
         Set the status of the handler operation.
         """
         self._status = status
@@ -346,31 +346,31 @@
         Report that fields have been updated
         """
         for field in fields:
             if field not in self._changes:
                 self._changes[fields] = AttributeStateChange()
 
     @overload  # noqa: F811
-    def update_changes(self, changes: dict[str, AttributeStateChange]) -> None:
+    def update_changes(self, changes: Dict[str, AttributeStateChange]) -> None:
         pass
 
     @overload  # noqa: F811
-    def update_changes(self, changes: dict[str, dict[str, Optional[SimpleTypes]]]) -> None:
+    def update_changes(self, changes: Dict[str, Dict[str, Optional[SimpleTypes]]]) -> None:
         pass
 
     @overload  # noqa: F811
-    def update_changes(self, changes: dict[str, tuple[SimpleTypes, SimpleTypes]]) -> None:
+    def update_changes(self, changes: Dict[str, Tuple[SimpleTypes, SimpleTypes]]) -> None:
         pass
 
     def update_changes(  # noqa: F811
         self,
         changes: Union[
-            dict[str, AttributeStateChange],
-            dict[str, dict[str, Optional[SimpleTypes]]],
-            dict[str, tuple[SimpleTypes, SimpleTypes]],
+            Dict[str, AttributeStateChange],
+            Dict[str, Dict[str, Optional[SimpleTypes]]],
+            Dict[str, Tuple[SimpleTypes, SimpleTypes]],
         ],
     ) -> None:
         """
         Update the changes list with changes
 
         :param changes: This should be a dict with a value a dict containing "current" and "desired" keys
         """
@@ -387,21 +387,17 @@
                 self._changes[attribute] = AttributeStateChange(current=change[0], desired=change[1])
             elif isinstance(change, AttributeStateChange):
                 self._changes[attribute] = change
             else:
                 raise InvalidOperation(f"Reported changes for {attribute} not in a type that is recognized.")
 
     @property
-    def changes(self) -> dict[str, AttributeStateChange]:
+    def changes(self) -> Dict[str, AttributeStateChange]:
         return self._changes
 
-    def log_msg(self, level: int, msg: str, args: abc.Sequence[object], kwargs: abc.MutableMapping[str, object]) -> None:
-        LOGGER.warning("Direct calls to the log_msg method are being deprecated, please use the LoggerABC interface instead.")
-        self._log_msg(level, msg, *args, **kwargs)
-
     def _log_msg(self, level: int, msg: str, *args: object, exc_info: bool = False, **kwargs: object) -> None:
         if len(args) > 0:
             raise Exception("Args not supported")
         if exc_info:
             kwargs["traceback"] = traceback.format_exc()
 
         for k, v in kwargs.items():
@@ -419,15 +415,15 @@
                 raise Exception("Exception during serializing log message arguments") from e
         log = data.LogLine.log(level, msg, **kwargs)
         self.logger.log(level, "resource %s: %s", self._resource.id.resource_version_str(), log._data["msg"], exc_info=exc_info)
         self._logs.append(log)
 
 
 @stable_api
-class ResourceHandler:
+class ResourceHandler(object):
     """
     A baseclass for classes that handle resources. New handler are registered with the
     :func:`~inmanta.agent.handler.provider` decorator.
 
     The implementation of a handler should use the ``self._io`` instance to execute io operations. This io objects
     makes abstraction of local or remote operations. See :class:`~inmanta.agent.io.local.LocalIO` for the available
     operations.
@@ -519,15 +515,15 @@
         :param ctx: Context object to report changes and logs to the agent and server.
         :param resource: The resource to query facts for.
         """
 
     def close(self) -> None:
         pass
 
-    def _diff(self, current: resources.Resource, desired: resources.Resource) -> dict[str, dict[str, typing.Any]]:
+    def _diff(self, current: resources.Resource, desired: resources.Resource) -> typing.Dict[str, typing.Dict[str, typing.Any]]:
         """
         Calculate the diff between the current and desired resource state.
 
         :param current: The current state of the resource
         :param desired: The desired state of the resource
         :return: A dict with key the name of the field and value another dict with "current" and "desired" as keys for
                  fields that require changes.
@@ -551,43 +547,43 @@
         :param ctx: Context object to report changes and logs to the agent and server.
         :param resource: The resource to check the current state of.
         :return: A resource to represents the current state. Use the :func:`~inmanta.resources.Resource.clone` to create
                  clone of the given resource that can be modified.
         """
         raise NotImplementedError()
 
-    def list_changes(self, ctx: HandlerContext, resource: resources.Resource) -> dict[str, dict[str, typing.Any]]:
+    def list_changes(self, ctx: HandlerContext, resource: resources.Resource) -> typing.Dict[str, typing.Dict[str, typing.Any]]:
         """
         Returns the changes required to bring the resource on this system in the state described in the resource entry.
         This method calls :func:`~inmanta.agent.handler.ResourceHandler.check_resource`
 
         :param ctx: Context object to report changes and logs to the agent and server.
         :param resource: The resource to check the current state of.
         :return: A dict with key the name of the field and value another dict with "current" and "desired" as keys for
                  fields that require changes.
         """
         current = self.check_resource(ctx, resource)
         return self._diff(current, resource)
 
-    def do_changes(self, ctx: HandlerContext, resource: resources.Resource, changes: dict[str, dict[str, object]]) -> None:
+    def do_changes(self, ctx: HandlerContext, resource: resources.Resource, changes: Dict[str, Dict[str, object]]) -> None:
         """
         Do the changes required to bring the resource on this system in the state of the given resource.
 
         :param ctx: Context object to report changes and logs to the agent and server.
         :param resource: The resource to check the current state of.
         :param changes: The changes that need to occur as reported by
                         :func:`~inmanta.agent.handler.ResourceHandler.list_changes`
         """
         raise NotImplementedError()
 
     def deploy(
         self,
         ctx: HandlerContext,
         resource: resources.Resource,
-        requires: dict[ResourceIdStr, ResourceState],
+        requires: Dict[ResourceIdStr, ResourceState],
     ) -> None:
         """
         This method is always be called by the agent, even when one of the requires of the given resource
         failed to deploy. The default implementation of this method will deploy the given resource when all its
         requires were deployed successfully. Override this method if a different condition determines whether the
         resource should deploy.
 
@@ -610,16 +606,16 @@
 
             if result.code != 200:
                 error_msg_from_server = f": {result.result['message']}" if "message" in result.result else ""
                 raise Exception(f"Failed to determine whether resource should reload{error_msg_from_server}")
             return result.result["data"]
 
         def filter_resources_in_unexpected_state(
-            reqs: dict[ResourceIdStr, ResourceState]
-        ) -> dict[ResourceIdStr, ResourceState]:
+            reqs: Dict[ResourceIdStr, ResourceState]
+        ) -> Dict[ResourceIdStr, ResourceState]:
             """
             Return a sub-dictionary of reqs with only those resources that are in an unexpected state.
             """
             unexpected_states = {
                 const.ResourceState.available,
                 const.ResourceState.dry,
                 const.ResourceState.undefined,
@@ -690,28 +686,28 @@
             except Exception as e:
                 ctx.exception(
                     "An error occurred after deployment of %(resource_id)s (exception: %(exception)s",
                     resource_id=resource.id,
                     exception=f"{e.__class__.__name__}('{e}')",
                 )
 
-    def facts(self, ctx: HandlerContext, resource: resources.Resource) -> dict[str, object]:
+    def facts(self, ctx: HandlerContext, resource: resources.Resource) -> Dict[str, object]:
         """
         Override this method to implement fact querying. A queried fact can be reported back in two different ways:
         either via the return value of this method or by adding the fact to the HandlerContext via the
         :func:`~inmanta.agent.handler.HandlerContext.set_fact` method. :func:`~inmanta.agent.handler.ResourceHandler.pre`
         and :func:`~inmanta.agent.handler.ResourceHandler.post` are called before and after this method.
 
         :param ctx: Context object to report changes, logs and facts to the agent and server.
         :param resource: The resource to query facts for.
         :return: A dict with fact names as keys and facts values.
         """
         return {}
 
-    def check_facts(self, ctx: HandlerContext, resource: resources.Resource) -> dict[str, object]:
+    def check_facts(self, ctx: HandlerContext, resource: resources.Resource) -> Dict[str, object]:
         """
         This method is called by the agent to query for facts. It runs :func:`~inmanta.agent.handler.ResourceHandler.pre`
         and :func:`~inmanta.agent.handler.ResourceHandler.post`. This method calls
         :func:`~inmanta.agent.handler.ResourceHandler.facts` to do the actually querying.
 
         :param ctx: Context object to report changes and logs to the agent and server.
         :param resource: The resource to query facts for.
@@ -832,30 +828,30 @@
         :param ctx: Context can be used to get values discovered in the read method. For example, the id used in API
                     calls. This context should also be used to let the handler know what changes were made to the
                     resource.
         :param resource: The desired resource state.
         """
 
     def update_resource(
-        self, ctx: HandlerContext, changes: dict[str, dict[str, Any]], resource: resources.PurgeableResource
+        self, ctx: HandlerContext, changes: Dict[str, Dict[str, Any]], resource: resources.PurgeableResource
     ) -> None:
         """
         This method is called by the handler when the resource should be updated.
 
         :param ctx: Context can be used to get values discovered in the read method. For example, the id used in API
                     calls. This context should also be used to let the handler know what changes were made to the
                     resource.
         :param changes: A map of resource attributes that should be changed. Each value is a tuple with the current and the
                         desired value.
         :param resource: The desired resource state.
         """
 
     def calculate_diff(
         self, ctx: HandlerContext, current: resources.Resource, desired: resources.Resource
-    ) -> dict[str, dict[str, typing.Any]]:
+    ) -> typing.Dict[str, typing.Dict[str, typing.Any]]:
         """
         Calculate the diff between the current and desired resource state.
 
         :param ctx: Context can be used to get values discovered in the read method. For example, the id used in API
                     calls. This context should also be used to let the handler know what changes were made to the
                     resource.
         :param current: The current state of the resource
@@ -878,15 +874,15 @@
 
             # current is clone, except for purged is set to false to prevent a bug that occurs often where the desired
             # state defines purged=true but the read_resource fails to set it to false if the resource does exist
             desired = resource
             assert isinstance(desired, resources.PurgeableResource)
             current = desired.clone(purged=False)
             assert isinstance(current, resources.PurgeableResource)
-            changes: dict[str, dict[str, typing.Any]] = {}
+            changes: typing.Dict[str, typing.Dict[str, typing.Any]] = {}
             try:
                 ctx.debug("Calling read_resource")
                 self.read_resource(ctx, current)
                 changes = self.calculate_diff(ctx, current, desired)
 
             except ResourcePurged:
                 if not desired.purged:
@@ -949,48 +945,48 @@
 
     def create_resource(self, ctx: HandlerContext, resource: TPurgeableResource) -> None:
         pass
 
     def delete_resource(self, ctx: HandlerContext, resource: TPurgeableResource) -> None:
         pass
 
-    def update_resource(self, ctx: HandlerContext, changes: dict[str, dict[str, Any]], resource: TPurgeableResource) -> None:
+    def update_resource(self, ctx: HandlerContext, changes: Dict[str, Dict[str, Any]], resource: TPurgeableResource) -> None:
         pass
 
     def calculate_diff(
         self, ctx: HandlerContext, current: TPurgeableResource, desired: TPurgeableResource
-    ) -> dict[str, dict[str, typing.Any]]:
+    ) -> typing.Dict[str, typing.Dict[str, typing.Any]]:
         return super().calculate_diff(ctx, current, desired)
 
     def execute(self, ctx: HandlerContext, resource: TPurgeableResource, dry_run: bool = False) -> None:
         super().execute(ctx, resource, dry_run)
 
 
-class Commander:
+class Commander(object):
     """
     This class handles commands
     """
 
-    __command_functions: dict[str, dict[str, type[ResourceHandler]]] = defaultdict(dict)
+    __command_functions: Dict[str, Dict[str, Type[ResourceHandler]]] = defaultdict(dict)
 
     @classmethod
-    def get_handlers(cls) -> dict[str, dict[str, type[ResourceHandler]]]:
+    def get_handlers(cls) -> Dict[str, Dict[str, Type[ResourceHandler]]]:
         return cls.__command_functions
 
     @classmethod
     def reset(cls) -> None:
         cls.__command_functions = defaultdict(dict)
 
     @classmethod
     def close(cls) -> None:
         pass
 
     @classmethod
     def _get_instance(
-        cls, handler_class: type[ResourceHandler], agent: "inmanta.agent.agent.AgentInstance", io: "IOBase"
+        cls, handler_class: Type[ResourceHandler], agent: "inmanta.agent.agent.AgentInstance", io: "IOBase"
     ) -> ResourceHandler:
         new_instance = handler_class(agent, io)
         return new_instance
 
     @classmethod
     def get_provider(
         cls, cache: AgentCache, agent: "inmanta.agent.agent.AgentInstance", resource: resources.Resource
@@ -1028,36 +1024,36 @@
 
         elif len(available) == 1:
             return available[0]
 
         raise Exception("No resource handler registered for resource of type %s" % resource_type)
 
     @classmethod
-    def add_provider(cls, resource: str, name: str, provider: type["ResourceHandler"]) -> None:
+    def add_provider(cls, resource: str, name: str, provider: Type["ResourceHandler"]) -> None:
         """
         Register a new provider
 
         :param resource: the name of the resource this handler applies to
         :param name: the name of the handler itself
         :param provider: the handler function
         """
         if resource in cls.__command_functions and name in cls.__command_functions[resource]:
             del cls.__command_functions[resource][name]
 
         cls.__command_functions[resource][name] = provider
 
     @classmethod
-    def get_providers(cls) -> typing.Iterator[tuple[str, type["ResourceHandler"]]]:
+    def get_providers(cls) -> typing.Iterator[Tuple[str, typing.Type["ResourceHandler"]]]:
         """Return an iterator over resource type, handler definition"""
         for resource_type, handler_map in cls.__command_functions.items():
             for handle_name, handler_class in handler_map.items():
                 yield (resource_type, handler_class)
 
     @classmethod
-    def get_provider_class(cls, resource_type: str, name: str) -> Optional[type["ResourceHandler"]]:
+    def get_provider_class(cls, resource_type: str, name: str) -> Optional[typing.Type["ResourceHandler"]]:
         """
         Return the class of the handler for the given type and with the given name
         """
         if resource_type not in cls.__command_functions:
             return None
 
         if name not in cls.__command_functions[resource_type]:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/io/__init__.py` & `inmanta-core-9.3.0/src/inmanta/agent/io/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,36 +15,36 @@
 
     Contact: code@inmanta.com
 """
 import logging
 import re
 import typing
 import urllib
-from typing import Optional
+from typing import Dict, Optional
 
 from inmanta.agent.cache import AgentCache
 
 from . import local, remote
 
 if typing.TYPE_CHECKING:
     from inmanta.agent.io.local import IOBase
 
 
 LOGGER = logging.getLogger(__name__)
 
 
-def parse_agent_uri(uri: str) -> tuple[str, dict[str, Optional[str]]]:
+def parse_agent_uri(uri: str) -> typing.Tuple[str, Dict[str, Optional[str]]]:
     """
     Parse an agent uri and return the settings
 
     :attr uri: The uri to parse
     :return: (scheme, config)
     """
     parts = urllib.parse.urlparse(uri)
-    config: dict[str, Optional[str]] = {}
+    config: Dict[str, Optional[str]] = {}
     scheme = "local"
 
     if parts.query != "":
         items = urllib.parse.parse_qs(parts.query)
         for key, values in items.items():
             config[key] = values[0]
 
@@ -63,15 +63,15 @@
         else:
             scheme = "ssh"
             config.update({"host": parts.path, "port": None, "user": None})
 
     return scheme, config
 
 
-def _get_io_class(scheme: str) -> type[local.IOBase]:
+def _get_io_class(scheme: str) -> typing.Type[local.IOBase]:
     """
     Get an IO instance.
     """
     if scheme == "local":
         return local.LocalIO
 
     elif scheme == "ssh":
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/io/local.py` & `inmanta-core-9.3.0/src/inmanta/agent/io/local.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,18 +10,14 @@
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
-
-    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
-    !!!!!!!!!!!!!! THIS FILE MUST REMAIN PYTHON2 COMPATIBLE !!!!!!!!!!!!!!!!!
-    !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 """
 
 import hashlib
 import os
 import shutil
 import subprocess
 import sys
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/io/remote.py` & `inmanta-core-9.3.0/src/inmanta/agent/io/remote.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
     Contact: code@inmanta.com
 """
 
 import logging
 import threading
 import time
-from typing import Callable, Optional
+from typing import Callable, Dict, Optional
 
 from execnet import gateway_bootstrap, multi
 
 from inmanta import resources
 
 from . import local
 
@@ -52,16 +52,16 @@
      * retries: The number of retries before giving up. The default number of retries 10
      * retry_wait: The time to wait between retries for the remote target to become available. The default wait is 30s
     """
 
     def is_remote(self) -> bool:
         return True
 
-    def __init__(self, uri: str, config: dict[str, Optional[str]]) -> None:
-        super().__init__(uri, config)
+    def __init__(self, uri: str, config: Dict[str, Optional[str]]) -> None:
+        super(SshIO, self).__init__(uri, config)
         self._host = config["host"]
         if "port" in config and config["port"] is not None:
             self._port = int(config["port"])
         else:
             self._port = 22
 
         if "user" in config and config["user"] is not None:
@@ -121,15 +121,15 @@
         opts += " -p %d" % self._port
 
         if "python" in self.config:
             python = self.config["python"]
         else:
             python = "python"
 
-        return f"ssh={opts} {self._user}@{self._host}//python={python}"
+        return "ssh=%s %s@%s//python=%s" % (opts, self._user, self._host, python)
 
     def _execute(self, function_name: str, *args: object, **kwargs: object) -> object:
         with self._lock:
             try:
                 ch = self._gw.remote_exec(local)
             except OSError:
                 raise ChannelClosedException(
```

### Comparing `inmanta-core-8.7.4/src/inmanta/agent/reporting.py` & `inmanta-core-9.3.0/src/inmanta/agent/reporting.py`

 * *Files 14% similar despite different names*

```diff
@@ -14,31 +14,31 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
 import os
 import platform
-from typing import TYPE_CHECKING, Callable, Union
+from typing import TYPE_CHECKING, Callable, Dict, List, Union
 
 if TYPE_CHECKING:
     from inmanta.agent.agent import Agent
 
 try:
     import resource
 except ImportError:
     resource = None
 
 LOGGER = logging.getLogger(__name__)
 
-ReportReturn = Union[dict[str, list[str]], dict[str, str], dict[str, float], str]
-reports: dict[str, Callable[["Agent"], ReportReturn]] = {}
+ReportReturn = Union[Dict[str, List[str]], Dict[str, str], Dict[str, float], str]
+reports: Dict[str, Callable[["Agent"], ReportReturn]] = {}
 
 
-def collect_report(agent: "Agent") -> dict[str, ReportReturn]:
+def collect_report(agent: "Agent") -> Dict[str, ReportReturn]:
     out = {}
     for name, report in reports.items():
         try:
             out[name] = report(agent)
         except Exception:
             out[name] = "ERROR"
             LOGGER.exception("could generate report for entry: %s" % name)
@@ -66,15 +66,15 @@
 def report_hostname(agent: "Agent") -> str:
     return platform.node()
 
 
 reports["hostname"] = report_hostname
 
 
-def report_ips(agent: "Agent") -> Union[str, dict[str, list[str]]]:
+def report_ips(agent: "Agent") -> Union[str, Dict[str, List[str]]]:
     try:
         import netifaces
 
         alladdresses = [netifaces.ifaddresses(i) for i in netifaces.interfaces()]
         v4 = [str(y["addr"]) for x in alladdresses if netifaces.AF_INET in x for y in x[netifaces.AF_INET]]
         v6 = [str(y["addr"]) for x in alladdresses if netifaces.AF_INET6 in x for y in x[netifaces.AF_INET6]]
         out = {"v4": v4, "v6": v6}
@@ -85,28 +85,28 @@
         return socket.gethostbyname(socket.gethostname())
 
 
 reports["ips"] = report_ips
 
 
 def report_python(agent: "Agent") -> str:
-    return f"{platform.python_implementation()} {platform.python_version()} {platform.python_build()}"
+    return "%s %s %s" % (platform.python_implementation(), platform.python_version(), platform.python_build())
 
 
 reports["python"] = report_python
 
 
 def report_pid(agent: "Agent") -> str:
     return str(os.getpid())
 
 
 reports["pid"] = report_pid
 
 
-def report_resources(agent: "Agent") -> dict[str, float]:
+def report_resources(agent: "Agent") -> Dict[str, float]:
     if resource is None:
         return {}
 
     ru = resource.getrusage(resource.RUSAGE_SELF)
     out = {
         "utime": ru.ru_utime,
         "stime": ru.ru_stime,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/app.py` & `inmanta-core-9.3.0/src/inmanta/app.py`

 * *Files 18% similar despite different names*

```diff
@@ -27,52 +27,45 @@
 
     Entry points
     ------------
     @command annotation to register new command
 """
 import argparse
 import asyncio
-import contextlib
-import dataclasses
-import enum
 import json
 import logging
 import os
-import shutil
 import signal
 import socket
 import sys
 import threading
 import time
 import traceback
 from argparse import ArgumentParser
 from asyncio import ensure_future
 from collections import abc
-from collections.abc import Callable, Coroutine
 from configparser import ConfigParser
 from threading import Timer
 from types import FrameType
-from typing import Any, Optional
+from typing import Any, Callable, Coroutine, Dict, Optional
 
-import click
 from tornado import gen
-from tornado.httpclient import AsyncHTTPClient
 from tornado.ioloop import IOLoop
 from tornado.util import TimeoutError
 
 import inmanta.compiler as compiler
 from inmanta import const, module, moduletool, protocol, util
 from inmanta.ast import CompilerException, Namespace
 from inmanta.ast import type as inmanta_type
 from inmanta.command import CLIException, Commander, ShowUsageException, command
 from inmanta.compiler import do_compile
 from inmanta.config import Config, Option
 from inmanta.const import EXIT_START_FAILED
 from inmanta.export import cfg_env
-from inmanta.logging import InmantaLoggerConfig, LoggerMode, _is_on_tty
+from inmanta.logging import InmantaLoggerConfig, _is_on_tty
 from inmanta.server.bootloader import InmantaBootloader
 from inmanta.util import get_compiler_version
 from inmanta.warnings import WarningsManager
 
 try:
     import rpdb
 except ImportError:
@@ -117,24 +110,17 @@
         exit(EXIT_START_FAILED)
 
 
 @command("agent", help_msg="Start the inmanta agent")
 def start_agent(options: argparse.Namespace) -> None:
     from inmanta.agent import agent
 
-    # The call to configure() should be done as soon as possible.
-    # If an AsyncHTTPClient is started before this call, the max_client
-    # will not be taken into account.
-    max_clients: Optional[int] = Config.get("agent_rest_transport", "max_clients", None)
-    if max_clients:
-        AsyncHTTPClient.configure(None, max_clients=max_clients)
-
     util.ensure_event_loop()
-    a = agent.Agent()
 
+    a = agent.Agent()
     setup_signal_handlers(a.stop)
     IOLoop.current().add_callback(a.start)
     IOLoop.current().start()
     LOGGER.info("Agent Shutdown complete")
 
 
 def dump_threads() -> None:
@@ -230,15 +216,15 @@
 
 class ExperimentalFeatureFlags:
     """
     Class to expose feature flag configs as options in a uniform matter
     """
 
     def __init__(self) -> None:
-        self.metavar_to_option: dict[str, Option[bool]] = {}
+        self.metavar_to_option: Dict[str, Option[bool]] = {}
 
     def _get_name(self, option: Option[bool]) -> str:
         return f"flag_{option.name}"
 
     def add(self, option: Option[bool]) -> None:
         """Add an option to the set of feature flags"""
         self.metavar_to_option[self._get_name(option)] = option
@@ -325,80 +311,73 @@
     moduletool.add_deps_check_arguments(parser)
 
 
 @command(
     "compile", help_msg="Compile the project to a configuration model", parser_config=compiler_config, require_project=True
 )
 def compile_project(options: argparse.Namespace) -> None:
-    inmanta_logger_config = InmantaLoggerConfig.get_current_instance()
-    with inmanta_logger_config.run_in_logger_mode(LoggerMode.COMPILER):
-        if options.environment is not None:
-            Config.set("config", "environment", options.environment)
+    if options.environment is not None:
+        Config.set("config", "environment", options.environment)
 
-        if options.server is not None:
-            Config.set("compiler_rest_transport", "host", options.server)
+    if options.server is not None:
+        Config.set("compiler_rest_transport", "host", options.server)
 
-        if options.port is not None:
-            Config.set("compiler_rest_transport", "port", options.port)
+    if options.port is not None:
+        Config.set("compiler_rest_transport", "port", options.port)
 
-        if options.user is not None:
-            Config.set("compiler_rest_transport", "username", options.user)
+    if options.user is not None:
+        Config.set("compiler_rest_transport", "username", options.user)
 
-        if options.password is not None:
-            Config.set("compiler_rest_transport", "password", options.password)
+    if options.password is not None:
+        Config.set("compiler_rest_transport", "password", options.password)
 
-        if options.ssl:
-            Config.set("compiler_rest_transport", "ssl", "true")
+    if options.ssl:
+        Config.set("compiler_rest_transport", "ssl", "true")
 
-        if options.ca_cert is not None:
-            Config.set("compiler_rest_transport", "ssl-ca-cert-file", options.ca_cert)
+    if options.ca_cert is not None:
+        Config.set("compiler_rest_transport", "ssl-ca-cert-file", options.ca_cert)
 
-        if options.export_compile_data is True:
-            Config.set("compiler", "export_compile_data", "true")
+    if options.export_compile_data is True:
+        Config.set("compiler", "export_compile_data", "true")
 
-        if options.export_compile_data_file is not None:
-            Config.set("compiler", "export_compile_data_file", options.export_compile_data_file)
+    if options.export_compile_data_file is not None:
+        Config.set("compiler", "export_compile_data_file", options.export_compile_data_file)
 
-        if options.feature_compiler_cache is False:
-            Config.set("compiler", "cache", "false")
+    if options.feature_compiler_cache is False:
+        Config.set("compiler", "cache", "false")
 
-        if options.datatrace is True:
-            Config.set("compiler", "datatrace_enable", "true")
+    if options.datatrace is True:
+        Config.set("compiler", "datatrace_enable", "true")
 
-        if options.dataflow_graphic is True:
-            Config.set("compiler", "dataflow_graphic_enable", "true")
+    if options.dataflow_graphic is True:
+        Config.set("compiler", "dataflow_graphic_enable", "true")
 
-        strict_deps_check = moduletool.get_strict_deps_check(
-            no_strict_deps_check=options.no_strict_deps_check, strict_deps_check=options.strict_deps_check
-        )
-        module.Project.get(options.main_file, strict_deps_check=strict_deps_check)
+    strict_deps_check = moduletool.get_strict_deps_check(
+        no_strict_deps_check=options.no_strict_deps_check, strict_deps_check=options.strict_deps_check
+    )
+    module.Project.get(options.main_file, strict_deps_check=strict_deps_check)
 
-        summary_reporter = CompileSummaryReporter()
-        if options.profile:
-            import cProfile
-            import pstats
-
-            with summary_reporter.compiler_exception.capture():
-                cProfile.runctx("do_compile()", globals(), {}, "run.profile")
-            p = pstats.Stats("run.profile")
-            p.strip_dirs().sort_stats("time").print_stats(20)
-        else:
-            t1 = time.time()
-            with summary_reporter.compiler_exception.capture():
-                do_compile()
-            LOGGER.debug("The entire compile command took %0.03f seconds", time.time() - t1)
+    if options.profile:
+        import cProfile
+        import pstats
 
-        summary_reporter.print_summary_and_exit(show_stack_traces=options.errors)
+        cProfile.runctx("do_compile()", globals(), {}, "run.profile")
+        p = pstats.Stats("run.profile")
+        p.strip_dirs().sort_stats("time").print_stats(20)
+    else:
+        t1 = time.time()
+        do_compile()
+        LOGGER.debug("Compile time: %0.03f seconds", time.time() - t1)
 
 
 @command("list-commands", help_msg="Print out an overview of all commands", add_verbose_flag=False)
 def list_commands(options: argparse.Namespace) -> None:
     print("The following commands are available:")
     for cmd, info in Commander.commands().items():
-        print(" {}: {}".format(cmd, info["help"]))
+        print(" %s: %s" % (cmd, info["help"]))
 
 
 def help_parser_config(parser: argparse.ArgumentParser, parent_parsers: abc.Sequence[ArgumentParser]) -> None:
     parser.add_argument("subcommand", help="Output help for a particular subcommand", nargs="?", default=None)
 
 
 @command("help", help_msg="show a help message and exit", parser_config=help_parser_config, add_verbose_flag=False)
@@ -539,260 +518,108 @@
     parser.add_argument(
         "--delete-resource-set",
         dest="delete_resource_set",
         help="Remove a resource set as part of a partial compile. This option can be provided multiple times and should always "
         "be used together with the --partial option.",
         action="append",
     )
-    parser.add_argument(
-        "--soft-delete",
-        dest="soft_delete",
-        help="Use in combination with --delete-resource-set to delete these resource sets only if they are not being exported",
-        action="store_true",
-        default=False,
-    )
     moduletool.add_deps_check_arguments(parser)
 
 
 @command("export", help_msg="Export the configuration", parser_config=export_parser_config, require_project=True)
 def export(options: argparse.Namespace) -> None:
-    inmanta_logger_config = InmantaLoggerConfig.get_current_instance()
-    with inmanta_logger_config.run_in_logger_mode(LoggerMode.COMPILER):
-        if not options.partial_compile and options.delete_resource_set:
-            raise CLIException(
-                "The --delete-resource-set option should always be used together with the --partial option", exitcode=1
-            )
-        if options.environment is not None:
-            Config.set("config", "environment", options.environment)
-
-        if options.server is not None:
-            Config.set("compiler_rest_transport", "host", options.server)
-
-        if options.port is not None:
-            Config.set("compiler_rest_transport", "port", options.port)
-
-        if options.token is not None:
-            Config.set("compiler_rest_transport", "token", options.token)
-
-        if options.ssl is not None:
-            Config.set("compiler_rest_transport", "ssl", f"{options.ssl}".lower())
-
-        if options.ca_cert is not None:
-            Config.set("compiler_rest_transport", "ssl-ca-cert-file", options.ca_cert)
-
-        if options.export_compile_data is True:
-            Config.set("compiler", "export_compile_data", "true")
-
-        if options.export_compile_data_file is not None:
-            Config.set("compiler", "export_compile_data_file", options.export_compile_data_file)
-
-        if options.feature_compiler_cache is False:
-            Config.set("compiler", "cache", "false")
-
-        # try to parse the metadata as json. If a normal string, create json for it.
-        if options.metadata is not None and len(options.metadata) > 0:
-            try:
-                metadata = json.loads(options.metadata)
-            except json.decoder.JSONDecodeError:
-                metadata = {"message": options.metadata}
-        else:
-            metadata = {"message": "Manual compile on the CLI by user"}
-
-        if "cli-user" not in metadata and "USERNAME" in os.environ:
-            metadata["cli-user"] = os.environ["USERNAME"]
-
-        if "hostname" not in metadata:
-            metadata["hostname"] = socket.gethostname()
-
-        if "type" not in metadata:
-            metadata["type"] = "manual"
-
-        strict_deps_check = moduletool.get_strict_deps_check(
-            no_strict_deps_check=options.no_strict_deps_check, strict_deps_check=options.strict_deps_check
+    if not options.partial_compile and options.delete_resource_set:
+        raise CLIException(
+            "The --delete-resource-set option should always be used together with the --partial option", exitcode=1
         )
-        module.Project.get(options.main_file, strict_deps_check=strict_deps_check)
+    if options.environment is not None:
+        Config.set("config", "environment", options.environment)
 
-        from inmanta.export import Exporter  # noqa: H307
+    if options.server is not None:
+        Config.set("compiler_rest_transport", "host", options.server)
 
-        summary_reporter = CompileSummaryReporter()
+    if options.port is not None:
+        Config.set("compiler_rest_transport", "port", options.port)
 
-        types: Optional[dict[str, inmanta_type.Type]]
-        scopes: Optional[Namespace]
+    if options.token is not None:
+        Config.set("compiler_rest_transport", "token", options.token)
 
-        t1 = time.time()
-        with summary_reporter.compiler_exception.capture():
-            try:
-                (types, scopes) = do_compile()
-            except Exception:
-                types, scopes = (None, None)
-                raise
-
-    with inmanta_logger_config.run_in_logger_mode(LoggerMode.EXPORTER):
-        # Even if the compile failed we might have collected additional data such as unknowns. So
-        # continue the export
-
-        export = Exporter(options)
-        with summary_reporter.exporter_exception.capture():
-            results = export.run(
-                types,
-                scopes,
-                metadata=metadata,
-                model_export=options.model_export,
-                export_plugin=options.export_plugin,
-                partial_compile=options.partial_compile,
-                resource_sets_to_remove=options.delete_resource_set,
-            )
+    if options.ssl is not None:
+        Config.set("compiler_rest_transport", "ssl", f"{options.ssl}".lower())
 
-        if not summary_reporter.is_failure() and options.deploy:
-            version = results[0]
-            conn = protocol.SyncClient("compiler")
-            LOGGER.info("Triggering deploy for version %d" % version)
-            tid = cfg_env.get()
-            agent_trigger_method = const.AgentTriggerMethod.get_agent_trigger_method(options.full_deploy)
-            conn.release_version(tid, version, True, agent_trigger_method)
+    if options.ca_cert is not None:
+        Config.set("compiler_rest_transport", "ssl-ca-cert-file", options.ca_cert)
 
-        LOGGER.debug("The entire export command took %0.03f seconds", time.time() - t1)
-        summary_reporter.print_summary_and_exit(show_stack_traces=options.errors)
+    if options.export_compile_data is True:
+        Config.set("compiler", "export_compile_data", "true")
 
+    if options.export_compile_data_file is not None:
+        Config.set("compiler", "export_compile_data_file", options.export_compile_data_file)
 
-class Color(enum.Enum):
-    RED = "red"
-    GREEN = "green"
+    if options.feature_compiler_cache is False:
+        Config.set("compiler", "cache", "false")
 
-
-@dataclasses.dataclass
-class ExceptionCollector:
-    """
-    This class defines a context manager that captures any unhandled exception raised within the context.
-    """
-
-    exception: Optional[Exception] = None
-
-    def has_exception(self) -> bool:
-        return self.exception is not None
-
-    @contextlib.contextmanager
-    def capture(self) -> abc.Iterator["ExceptionCollector"]:
-        """
-        Record any exceptions raised within the context manager. The exception will not be re-raised.
-        """
+    # try to parse the metadata as json. If a normal string, create json for it.
+    if options.metadata is not None and len(options.metadata) > 0:
         try:
-            yield self
-        except Exception as e:
-            self.exception = e
-
-
-class CompileSummaryReporter:
-    """
-    Contains the logic to print a summary at the end of the `inmanta compile` or `inmanta export`
-    command that provides an overview on whether the command was successful or not.
-    """
+            metadata = json.loads(options.metadata)
+        except json.decoder.JSONDecodeError:
+            metadata = {"message": options.metadata}
+    else:
+        metadata = {"message": "Manual compile on the CLI by user"}
 
-    def __init__(self) -> None:
-        self.compiler_exception: ExceptionCollector = ExceptionCollector()
-        self.exporter_exception: ExceptionCollector = ExceptionCollector()
+    if "cli-user" not in metadata and "USERNAME" in os.environ:
+        metadata["cli-user"] = os.environ["USERNAME"]
 
-    def is_failure(self) -> bool:
-        """
-        Return true iff an exception has occurred during the compile or export stage.
-        """
-        return self.compiler_exception.has_exception() or self.exporter_exception.has_exception()
+    if "hostname" not in metadata:
+        metadata["hostname"] = socket.gethostname()
 
-    def _get_global_status(self) -> str:
-        """
-        Return the global status of the run.
-        """
-        if self.compiler_exception.has_exception():
-            return "COMPILATION FAILURE"
-        elif self.exporter_exception.has_exception():
-            return "EXPORT FAILURE"
-        else:
-            return "SUCCESS"
+    if "type" not in metadata:
+        metadata["type"] = "manual"
 
-    def _get_header(self, header_text: str) -> str:
-        """
-        Return a header for the summary with the given header_text.
-        """
-        terminal_width = shutil.get_terminal_size()[0]
-        minimal_header = f"= {header_text.upper()} ="
-        length_minimal_header = len(minimal_header)
-        if terminal_width <= length_minimal_header:
-            return minimal_header
-        else:
-            nr_equals_signs_to_add_each_side = int((terminal_width - length_minimal_header) / 2)
-            extra_equals_signs_each_side = "=" * nr_equals_signs_to_add_each_side
-            return f"{extra_equals_signs_each_side}{minimal_header}{extra_equals_signs_each_side}"
-
-    def _get_exception_to_report(self) -> Exception:
-        """
-        Return the exception that should be reported in the summary. Compiler exceptions take precedence
-        over exporter exceptions because they happen first.
-        """
-        assert self.is_failure()
-        if self.compiler_exception.has_exception():
-            assert self.compiler_exception.exception is not None
-            return self.compiler_exception.exception
-        else:
-            assert self.exporter_exception.exception is not None
-            return self.exporter_exception.exception
-
-    def _get_error_message(self) -> str:
-        """
-        Return the error message associated with `self._get_exception_to_report()`.
-        """
-        exc = self._get_exception_to_report()
-        if isinstance(exc, CompilerException):
-            error_message = exc.format_trace(indent="  ").strip("\n")
-            # Add explainer text if any
-            from inmanta.compiler.help.explainer import ExplainerFactory
-
-            helpmsg = ExplainerFactory().explain_and_format(exc, plain=not _is_on_tty())
-            if helpmsg is not None:
-                helpmsg = helpmsg.strip("\n")
-                return f"{error_message}\n\n{helpmsg}"
-        else:
-            error_message = str(exc).strip("\n")
-        return f"Error: {error_message}"
-
-    def _get_stack_trace(self) -> str:
-        """
-        Return the stack trace associated with `self._get_exception_to_report()`.
-        """
-        exc = self._get_exception_to_report()
-        return "".join(traceback.format_exception(None, value=exc, tb=exc.__traceback__)).strip("\n")
-
-    def _print_to_stderr(self, text: str = "", bold: bool = False, **kwargs: object) -> None:
-        """
-        Prints the given text to stderr with the given styling requirements. On a tty the text
-        is printed in green in case of success and in red in case of a failure.
-        """
-        if _is_on_tty():
-            color = Color.RED if self.is_failure() else Color.GREEN
-            text = click.style(text, fg=color.value, bold=bold)
-        print(text, file=sys.stderr, **kwargs)
+    strict_deps_check = moduletool.get_strict_deps_check(
+        no_strict_deps_check=options.no_strict_deps_check, strict_deps_check=options.strict_deps_check
+    )
+    module.Project.get(options.main_file, strict_deps_check=strict_deps_check)
 
-    def print_summary(self, show_stack_traces: bool) -> None:
-        """
-        Print the summary of the compile run.
-        """
-        self._print_to_stderr()
-        if show_stack_traces and self.is_failure():
-            self._print_to_stderr(text=self._get_header(header_text="EXCEPTION TRACE"))
-            self._print_to_stderr(text=self._get_stack_trace(), end="\n\n")
-
-        self._print_to_stderr(text=self._get_header(header_text=self._get_global_status()))
-        if self.is_failure():
-            self._print_to_stderr(text=self._get_error_message())
+    from inmanta.export import Exporter  # noqa: H307
 
-    def print_summary_and_exit(self, show_stack_traces: bool) -> None:
-        """
-        Print the compile summary and exit with a 0 status code in case of success or 1 in case of failure.
-        """
-        self.print_summary(show_stack_traces)
-        exit(1 if self.is_failure() else 0)
+    exp = None
+    types: Optional[Dict[str, inmanta_type.Type]]
+    scopes: Optional[Namespace]
+    try:
+        (types, scopes) = do_compile()
+    except Exception as e:
+        exp = e
+        types, scopes = (None, None)
+
+    # Even if the compile failed we might have collected additional data such as unknowns. So
+    # continue the export
+
+    export = Exporter(options)
+    results = export.run(
+        types,
+        scopes,
+        metadata=metadata,
+        model_export=options.model_export,
+        export_plugin=options.export_plugin,
+        partial_compile=options.partial_compile,
+        resource_sets_to_remove=options.delete_resource_set,
+    )
+    version = results[0]
+
+    if exp is not None:
+        raise exp
+
+    if options.deploy:
+        conn = protocol.SyncClient("compiler")
+        LOGGER.info("Triggering deploy for version %d" % version)
+        tid = cfg_env.get()
+        agent_trigger_method = const.AgentTriggerMethod.get_agent_trigger_method(options.full_deploy)
+        conn.release_version(tid, version, True, agent_trigger_method)
 
 
 def cmd_parser() -> argparse.ArgumentParser:
     # create the argument compiler
 
     parser = argparse.ArgumentParser()
     parser.add_argument("-p", action="store_true", dest="profile", help="Profile this run of the program")
@@ -834,21 +661,14 @@
         "--version",
         action="store_true",
         dest="inmanta_version",
         help="Show the version of the installed Inmanta product and the version of its subcomponents",
         default=False,
         required=False,
     )
-    parser.add_argument(
-        "--keep-logger-names",
-        dest="keep_logger_names",
-        help="Display the log messages using the name of the logger that created the log messages.",
-        action="store_true",
-        default=False,
-    )
 
     verbosity_parser = argparse.ArgumentParser(add_help=False)
     verbosity_parser.add_argument(
         "-v",
         "--verbose",
         action="count",
         default=argparse.SUPPRESS,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/__init__.py` & `inmanta-core-9.3.0/src/inmanta/ast/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,15 +17,14 @@
 """
 
 import traceback
 from abc import abstractmethod
 from functools import lru_cache
 from typing import Dict, List, Optional, Union
 
-from inmanta import warnings
 from inmanta.ast import export
 from inmanta.stable_api import stable_api
 from inmanta.warnings import InmantaWarning
 
 try:
     from typing import TYPE_CHECKING
 except ImportError:
@@ -38,18 +37,14 @@
     from inmanta.ast.statements.define import DefineEntity, DefineImport  # noqa: F401
     from inmanta.ast.type import NamedType, Type  # noqa: F401
     from inmanta.compiler import Compiler
     from inmanta.execute.runtime import DelayedResultVariable, ExecutionContext, Instance, ResultVariable  # noqa: F401
     from inmanta.plugins import PluginException
 
 
-class TypeDeprecationWarning(InmantaWarning):
-    pass
-
-
 class Location(export.Exportable):
     __slots__ = ("file", "lnr")
 
     def __init__(self, file: str, lnr: int) -> None:
         self.file = file
         self.lnr = lnr
 
@@ -144,15 +139,15 @@
                 and self.start_char == other.start_char
                 and self.end_lnr == other.end_lnr
                 and self.end_char == other.end_char
             )
         return False
 
 
-class AnchorTarget:
+class AnchorTarget(object):
     """AnchorTarget is used purely at the periphery of the compiler"""
 
     __slots__ = ("location", "docstring")
 
     def __init__(
         self,
         location: Location,
@@ -163,23 +158,23 @@
         :param location: the location of the target of the anchor
         :param docstring: the docstring attached to the target
         """
         self.location = location
         self.docstring = docstring
 
 
-class WithComment:
+class WithComment(object):
     """
     Mixin class for AST nodes that can have a comment attached to them.
     """
 
     comment: Optional[str] = None
 
 
-class Locatable:
+class Locatable(object):
     __slots__ = ("_location",)
 
     def __init__(self) -> None:
         self._location: Optional[Location] = None
 
     def set_location(self, location: Location) -> None:
         assert location is not None and location.lnr > 0
@@ -194,15 +189,15 @@
         Copy the location of this locatable to the given locatable
         """
         other.set_location(self.location)
 
     location = property(get_location, set_location)
 
 
-class LocatableString:
+class LocatableString(object):
     """
     A string with an attached source location.
 
     It is not a subtype of str, as str is not a normal class
     As such, it is very important to unwrap strings as this object is not an actual string.
 
     All identifiers produced by the parser are of this type.
@@ -230,15 +225,15 @@
     def get_location(self) -> Range:
         return self.location
 
     def __str__(self) -> str:
         return self.value
 
 
-class Anchor:
+class Anchor(object):
     def __init__(self, range: Range) -> None:
         self.range = range
 
     def get_range(self) -> Range:
         return self.range
 
     def get_location(self) -> Range:
@@ -260,43 +255,29 @@
         location = t.get_location()
         docstring = t.comment if isinstance(t, WithComment) else None
         if not location:
             return None
         return AnchorTarget(location=location, docstring=docstring)
 
 
-class TypeAnchor(Anchor):
-    """Reference to a resolved type"""
-
-    def __init__(self, reference: LocatableString, type: "Type") -> None:
-        """
-        :param reference: the location we are referencing from
-        :param type: the type that is being referenced
-        """
-        Anchor.__init__(self, range=reference.get_location())
-        self.type = type
-        self.type.get_location()
-
-    def resolve(self) -> Optional[AnchorTarget]:
-        t = self.type
-        location = t.get_location()
-        docstring = t.comment if isinstance(t, WithComment) else None
-        if not location:
-            return None
-        return AnchorTarget(location=location, docstring=docstring)
-
-
-class AttributeAnchor(Anchor):
-    def __init__(self, range: Range, attribute: "Attribute") -> None:
+class AttributeReferenceAnchor(Anchor):
+    def __init__(self, range: Range, namespace: "Namespace", type: LocatableString, attribute: str) -> None:
         Anchor.__init__(self, range=range)
+        self.namespace = namespace
+        self.type = type
         self.attribute = attribute
 
     def resolve(self) -> Optional[AnchorTarget]:
-        location = self.attribute.get_location()
-        docstring = self.attribute.comment if isinstance(self.attribute, WithComment) else None
+        instancetype = self.namespace.get_type(self.type)
+        # type check impossible atm due to import loop
+        # assert isinstance(instancetype, Entity)
+        entity_attribute: Optional[Attribute] = instancetype.get_attribute(self.attribute)
+        assert entity_attribute is not None
+        location = entity_attribute.get_location()
+        docstring = instancetype.comment if isinstance(instancetype, WithComment) else None
         if not location:
             return None
         return AnchorTarget(location=location, docstring=docstring)
 
 
 class Namespaced(Locatable):
     __slots__ = ()
@@ -333,15 +314,15 @@
 
     def __init__(self, name: str, parent: "Optional[Namespace]" = None) -> None:
         Namespaced.__init__(self)
         self.__name = name
         self.__parent = parent
         self.__children = {}  # type: Dict[str,Namespace]
         self.defines_types = {}  # type: Dict[str,NamedType]
-        self.visible_namespaces: dict[str, Import]
+        self.visible_namespaces: Dict[str, Import]
         if self.__parent is not None:
             self.visible_namespaces = {self.get_full_name(): MockImport(self)}
             self.__parent.add_child(self)
         else:
             self.visible_namespaces = {name: MockImport(self)}
         self.primitives = None  # type: Optional[Dict[str,Type]]
         self.scope = None  # type:  Optional[ExecutionContext]
@@ -374,15 +355,15 @@
             other = self.visible_namespaces[name]
             if not isinstance(other, MockImport):
                 raise DuplicateException(ns, self.visible_namespaces[name], "Two import statements have the same name")
         self.visible_namespaces[name] = ns
 
     def lookup_namespace(self, name: str) -> Import:
         if name not in self.visible_namespaces:
-            raise NotFoundException(None, name, f"Namespace {name} not found.\nTry importing it with `import {name}`")
+            raise NotFoundException(None, name, f"Namespace {name} not found. Try importing it with `import {name}`")
         return self.visible_namespaces[name]
 
     def lookup(self, name: str) -> "Union[Type, ResultVariable]":
         if "::" not in name:
             return self.get_scope().direct_lookup(name)
         parts = name.rsplit("::", 1)
         return self.lookup_namespace(parts[0]).target.get_scope().direct_lookup(parts[1])
@@ -395,26 +376,23 @@
             if parts[0] in self.visible_namespaces:
                 ns = self.visible_namespaces[parts[0]].target
                 if parts[1] in ns.defines_types:
                     return ns.defines_types[parts[1]]
                 else:
                     raise TypeNotFoundException(typ, ns)
             else:
-                raise MissingImportException(typ, self, parts, str(self.location.file))
+                raise TypeNotFoundException(typ, self)
         elif name in self.primitives:
-            if name == "number":
-                warnings.warn(TypeDeprecationWarning("Type 'number' is deprecated, use 'float' or 'int' instead"))
             return self.primitives[name]
         else:
             cns = self  # type: Optional[Namespace]
             while cns is not None:
                 if name in cns.defines_types:
                     return cns.defines_types[name]
                 cns = cns.get_parent()
-
             raise TypeNotFoundException(typ, self)
 
     def get_name(self) -> str:
         """
         Get the name of this namespace
         """
         return self.__name
@@ -522,31 +500,31 @@
         type name.
 
         :param fqtn: The type name
         """
         name_parts = fqtn.split("::")
         return self.get_root()._get_ns(name_parts)
 
-    def _get_ns(self, ns_parts: list[str]) -> "Optional[Namespace]":
+    def _get_ns(self, ns_parts: List[str]) -> "Optional[Namespace]":
         """
         Return the namespace indicated by the parts list. Each element of
         the array represents a level in the namespace hierarchy.
         """
         if len(ns_parts) == 0:
             return None
         elif len(ns_parts) == 1:
             return self.get_child(ns_parts[0])
         else:
             child = self.get_child(ns_parts[0])
             if child is None:
                 return None
             return child._get_ns(ns_parts[1:])
 
-    @lru_cache
-    def to_path(self) -> list[str]:
+    @lru_cache()
+    def to_path(self) -> List[str]:
         """
         Return a list with the namespace path elements in it.
         """
         if self.__parent is None or self.__parent.get_name() == "__root__":
             return [self.__name]
         else:
             return self.__parent.to_path() + [self.__name]
@@ -582,15 +560,15 @@
     def get_causes(self) -> "List[CompilerException]":
         return []
 
     def format(self) -> str:
         """Make a string representation of this particular exception"""
         location = self.get_location()
         if location is not None:
-            return f"{self.get_message()} ({location})"
+            return "%s (%s)" % (self.get_message(), location)
         else:
             return self.get_message()
 
     def format_trace(self, indent: str = "", indent_level: int = 0) -> str:
         """Make a representation of this exception and its causes"""
         out = indent * indent_level + self.format()
 
@@ -614,15 +592,15 @@
         self.root_ns = compiler.get_ns()
 
     def export(self) -> export.Error:
         location: Optional[Location] = self.get_location()
         module: Optional[str] = self.__class__.__module__
         name: str = self.__class__.__qualname__
         return export.Error(
-            type=name if module is None else f"{module}.{name}",
+            type=name if module is None else "%s.%s" % (module, name),
             message=self.get_message(),
             location=location.export() if location is not None else None,
         )
 
     def __str__(self) -> str:
         return self.format()
 
@@ -646,16 +624,16 @@
         if replace or self.stmt is None:
             self.set_location(stmt.get_location())
             self.stmt = stmt
 
     def format(self) -> str:
         """Make a string representation of this particular exception"""
         if self.stmt is not None:
-            return f"{self.get_message()} (reported in {self.stmt} ({self.get_location()}))"
-        return super().format()
+            return "%s (reported in %s (%s))" % (self.get_message(), self.stmt, self.get_location())
+        return super(RuntimeException, self).format()
 
 
 class InvalidCompilerState(RuntimeException):
     def __init__(self, stmt: "Optional[Locatable]", msg: str) -> None:
         super().__init__(stmt, "Invalid compiler state, this likely indicates a bug in the compiler. Details: %s" % msg)
 
 
@@ -685,43 +663,27 @@
         CompilerRuntimeWarning.__init__(self, stmt, msg)
 
 
 class TypeNotFoundException(RuntimeException):
     """Exception raised when a type is referenced that does not exist"""
 
     def __init__(self, type: LocatableString, ns: Namespace) -> None:
-        RuntimeException.__init__(self, stmt=None, msg=f"could not find type {type} in namespace {ns}")
+        RuntimeException.__init__(self, stmt=None, msg="could not find type %s in namespace %s" % (type, ns))
         self.type = type
         self.ns = ns
         self.set_location(type.get_location())
 
     def importantance(self) -> int:
         return 20
 
 
-class MissingImportException(TypeNotFoundException):
-    """Exception raised when a referenced type's module is missing from the namespace"""
-
-    def __init__(
-        self, type: LocatableString, ns: Namespace, parts: Optional[list[str]] = None, file: Optional[str] = None
-    ) -> None:
-        suggest_importing: str = ""
-        suggest_file = ""
-        if file:
-            suggest_file = f" in {file}"
-        if parts:
-            suggest_importing = f".\nTry importing the module with `import {parts[0]}`{suggest_file}"
-        super().__init__(type, ns)
-        self.msg += suggest_importing
-
-
 class AmbiguousTypeException(TypeNotFoundException):
     """Exception raised when a type is referenced that does not exist"""
 
-    def __init__(self, type: LocatableString, candidates: list["Entity"]) -> None:
+    def __init__(self, type: LocatableString, candidates: List["Entity"]) -> None:
         candidates = sorted(candidates, key=lambda x: x.get_full_name())
         RuntimeException.__init__(
             self,
             stmt=None,
             msg="Could not determine namespace for type %s. %d possible candidates exists: [%s]."
             " To resolve this, use the fully qualified name instead of the short name."
             % (type, len(candidates), ", ".join([x.get_full_name() for x in candidates])),
@@ -730,30 +692,30 @@
         self.type = type
         self.set_location(type.get_location())
 
 
 def stringify_exception(exn: Exception) -> str:
     if isinstance(exn, CompilerException):
         return str(exn)
-    return f"{exn.__class__.__name__}: {str(exn)}"
+    return "%s: %s" % (exn.__class__.__name__, str(exn))
 
 
 @stable_api
 class ExternalException(RuntimeException):
     """
     When a plugin call produces an exception that is not a :py:class:`RuntimeException`,
     it is wrapped in an ExternalException to make it conform to the expected interface
     """
 
     def __init__(self, stmt: Optional[Locatable], msg: str, cause: Exception) -> None:
         RuntimeException.__init__(self, stmt=stmt, msg=msg)
 
         self.__cause__ = cause
 
-    def get_causes(self) -> list[CompilerException]:
+    def get_causes(self) -> List[CompilerException]:
         return []
 
     def format_trace(self, indent: str = "", indent_level: int = 0) -> str:
         """Make a representation of this exception and its causes"""
 
         out = indent * indent_level + self.format().replace("\n", "\n" + indent * indent_level)
 
@@ -779,15 +741,15 @@
         self.__cause__: PluginException
 
     def export(self) -> export.Error:
         location: Optional[Location] = self.get_location()
         module: Optional[str] = self.__cause__.__class__.__module__
         name: str = self.__cause__.__class__.__qualname__
         return export.Error(
-            type=name if module is None else f"{module}.{name}",
+            type=name if module is None else "%s.%s" % (module, name),
             message=self.__cause__.message,
             location=location.export() if location is not None else None,
             category=export.ErrorCategory.plugin,
         )
 
     def get_message(self) -> str:
         return self.msg + "\n" + self.__cause__.message
@@ -800,40 +762,40 @@
         if stmt is None and isinstance(cause, RuntimeException):
             stmt = cause.stmt
 
         RuntimeException.__init__(self, stmt=stmt, msg=msg)
 
         self.__cause__ = cause  # type: CompilerException
 
-    def get_causes(self) -> list[CompilerException]:
+    def get_causes(self) -> List[CompilerException]:
         return [self.__cause__]
 
     def importantance(self) -> int:
         # less likely to be the cause then out child
         return self.__cause__.importantance() + 1
 
 
 @stable_api
 class AttributeException(WrappingRuntimeException):
     """Exception raise when an attribute could not be set, always wraps another exception"""
 
     def __init__(self, stmt: "Locatable", instance: "Instance", attribute: str, cause: RuntimeException) -> None:
         WrappingRuntimeException.__init__(
-            self, stmt=stmt, msg=f"Could not set attribute `{attribute}` on instance `{str(instance)}`", cause=cause
+            self, stmt=stmt, msg="Could not set attribute `%s` on instance `%s`" % (attribute, str(instance)), cause=cause
         )
         self.attribute = attribute
         self.instance = instance
 
 
 class OptionalValueException(RuntimeException):
     """Exception raised when an optional value is accessed that has no value (and is frozen)"""
 
     def __init__(self, instance: "Instance", attribute: "Attribute") -> None:
         RuntimeException.__init__(
-            self, None, f"Optional variable accessed that has no value (attribute `{attribute}` of `{instance}`)"
+            self, instance, "Optional variable accessed that has no value (attribute `%s` of `%s`)" % (attribute, instance)
         )
         self.instance = instance
         self.attribute = attribute
 
     def importantance(self) -> int:
         return 61
 
@@ -866,15 +828,15 @@
         return 70
 
 
 class CycleException(TypingException):
     """Exception raised when a type is its own parent (type cycle)"""
 
     def __init__(self, first_type: "DefineEntity", final_name: str) -> None:
-        super().__init__(first_type, "")
+        super(CycleException, self).__init__(first_type, "")
         self.types = []  # type: List[DefineEntity]
         self.complete = False
         self.final_name = final_name
 
     def add(self, element: "DefineEntity") -> None:
         """Collect parent entities while traveling up the stack"""
         if self.complete:
@@ -903,15 +865,15 @@
 class DoubleSetException(RuntimeException):
     def __init__(
         self, variable: "ResultVariable", stmt: "Optional[Statement]", newvalue: object, newlocation: Location
     ) -> None:
         self.variable: "ResultVariable" = variable
         self.newvalue = newvalue  # type: object
         self.newlocation = newlocation
-        msg = "value set twice:\n\told value: {}\n\t\tset at {}\n\tnew value: {}\n\t\tset at {}\n".format(
+        msg = "value set twice:\n\told value: %s\n\t\tset at %s\n\tnew value: %s\n\t\tset at %s\n" % (
             self.variable.value,
             self.variable.location,
             self.newvalue,
             self.newlocation,
         )
         RuntimeException.__init__(self, stmt, msg)
 
@@ -945,32 +907,32 @@
     """Exception raise when something is defined twice"""
 
     def __init__(self, stmt: Locatable, other: Locatable, msg: str) -> None:
         TypingException.__init__(self, stmt, msg)
         self.other = other
 
     def format(self) -> str:
-        return f"{self.get_message()} (original at ({self.location})) (duplicate at ({self.other.get_location()}))"
+        return "%s (original at (%s)) (duplicate at (%s))" % (self.get_message(), self.location, self.other.get_location())
 
     def importantance(self) -> int:
         return 40
 
 
 class CompilerError(Exception):
     pass
 
 
 class MultiException(CompilerException):
     """A single exception collecting multiple CompilerExceptions"""
 
-    def __init__(self, others: list[CompilerException]) -> None:
+    def __init__(self, others: List[CompilerException]) -> None:
         CompilerException.__init__(self, "")
         self.others = others
 
-    def get_causes(self) -> list[CompilerException]:
+    def get_causes(self) -> List[CompilerException]:
         def sortkey(item: CompilerException):
             location = item.get_location()
             if not location:
                 file = ""
                 line = 0
             else:
                 file = location.file
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/attribute.py` & `inmanta-core-9.3.0/src/inmanta/ast/attribute.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from typing import Optional, Tuple
+from typing import List, Optional, Set, Tuple
 
 from inmanta.ast import CompilerException, Locatable, Location, RuntimeException, TypingException
 from inmanta.ast.type import NullableType, TypedList
 from inmanta.execute import runtime
 from inmanta.execute.util import Unknown
 from inmanta.stable_api import stable_api
 
@@ -121,15 +121,15 @@
     def is_multi(self) -> bool:
         """
         Returns true iff this attribute expects a list of values of its base type.
         Deprecated but still used internally.
         """
         return self.__multi
 
-    def final(self, excns: list[CompilerException]) -> None:
+    def final(self, excns: List[CompilerException]) -> None:
         pass
 
     def has_relation_precedence_rules(self) -> bool:
         """
         Return true iff a relation precedence rule exists that defines that this Attribute should
         be frozen before another Attribute.
         """
@@ -150,18 +150,18 @@
         Attribute.__init__(self, entity, value_type, name, location)
         self.end: Optional[RelationAttribute] = None
         self.low = 1
         self.high = 1
         self.depends = False
         self.source_annotations = []
         self.target_annotations = []
-        self.freeze_dependents: set[RelationAttribute] = set()
+        self.freeze_dependents: Set[RelationAttribute] = set()
 
     def __str__(self) -> str:
-        return f"{self.get_entity().get_full_name()}.{self.name}"
+        return "%s.%s" % (self.get_entity().get_full_name(), self.name)
 
     def __repr__(self) -> str:
         return "[%d:%s] %s" % (self.low, self.high if self.high is not None else "", self.name)
 
     def set_multiplicity(self, values: "Tuple[int, Optional[int]]") -> None:
         """
         Set the multiplicity of this end
@@ -182,15 +182,15 @@
 
     def is_optional(self) -> bool:
         return self.low == 0
 
     def is_multi(self) -> bool:
         return self.high != 1
 
-    def final(self, excns: list[CompilerException]) -> None:
+    def final(self, excns: List[CompilerException]) -> None:
         for rv in self.source_annotations:
             try:
                 if isinstance(rv.get_value(), Unknown):
                     excns.append(TypingException(self, "Relation annotation can not be Unknown"))
             except RuntimeException as e:
                 excns.append(e)
         for rv in self.target_annotations:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/blocks.py` & `inmanta-core-9.3.0/src/inmanta/ast/blocks.py`

 * *Files 12% similar despite different names*

```diff
@@ -12,51 +12,50 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import warnings
-from collections.abc import Iterable, Iterator, Sequence, Set
+from collections.abc import Set
 from itertools import chain
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Dict, FrozenSet, Iterable, Iterator, List, Optional, Sequence, Tuple
 
 from inmanta.ast import Anchor, Locatable, Namespace, RuntimeException, TypeNotFoundException, VariableShadowWarning
 from inmanta.ast.statements import DefinitionStatement, DynamicStatement, Statement, StaticEagerPromise
 from inmanta.execute.runtime import QueueScheduler, Resolver
 
 if TYPE_CHECKING:
     from inmanta.execute.runtime import ExecutionContext
 
 
-class BasicBlock:
-    def __init__(self, namespace: Namespace, stmts: list[DynamicStatement] = []) -> None:
-        self.__stmts: list[DynamicStatement] = []
-        self.__definition_stmts: list[DefinitionStatement] = []
-        self.__variables: list[tuple[str, Statement]] = []
+class BasicBlock(object):
+    def __init__(self, namespace: Namespace, stmts: List[DynamicStatement] = []) -> None:
+        self.__stmts = []  # type: List[DynamicStatement]
+        self.__definition_stmts = []  # type: List[DefinitionStatement]
+        self.__variables = []  # type: List[Tuple[str, Statement]]
         self.namespace = namespace
         self.context: "ExecutionContext" = None
 
         for st in stmts:
             self.add(st)
 
-    def get_stmts(self) -> list[DynamicStatement]:
+    def get_stmts(self) -> List[DynamicStatement]:
         return self.__stmts
 
-    def get_anchors(self) -> list[Anchor]:
-        """Should only be called after normalization."""
+    def get_anchors(self) -> List[Anchor]:
         return [a for s in self.__stmts for a in s.get_anchors()]
 
     def add(self, stmt: DynamicStatement) -> None:
         self.__stmts.append(stmt)
 
     def add_definition(self, stmt: DefinitionStatement) -> None:
         self.__definition_stmts.append(stmt)
 
-    def get_variables(self) -> list[str]:
+    def get_variables(self) -> List[str]:
         """
         Returns a list of all variables declared in this block. Does not include variables declared in nested blocks.
         """
         return [var for var, _ in self.__variables]
 
     def add_var(self, name: str, stmt: Statement) -> None:
         """
@@ -67,15 +66,15 @@
     def normalize(self) -> None:
         self.__variables = [(var, stmt) for stmt in self.__stmts for var in stmt.declared_variables()]
 
         for s in self.__stmts:
             try:
                 s.normalize()
             except TypeNotFoundException as e:
-                e.set_statement(s, False)
+                e.set_statement(s)
                 raise e
         # not used yet
         # self.requires = set([require for s in self.__stmts for require in s.requires()])
 
         # self.external = self.requires - set(self.__variables)
 
         # self.external_not_global = [x for x in self.external if "::" not in x]
@@ -99,15 +98,15 @@
         ]
 
     def emit(self, resolver: Resolver, queue: QueueScheduler) -> None:
         for s in self.__stmts:
             try:
                 s.emit(resolver, queue)
             except RuntimeException as e:
-                e.set_statement(s, False)
+                e.set_statement(s)
                 raise e
 
     def warn_shadowed_variables(self) -> None:
         """
         Produces a warning for any shadowed variables in ocurring in this namespace. This namespace's scope's root block
         is used as an entrypoint for the check. If nested_block is provided, that block is interpreted as living in this
         scope and only that block is searched for shadowing with respect to the scope.
@@ -123,28 +122,28 @@
                         ",".join(str(loc.get_location()) for loc in shadowed_locs),
                     ),
                 )
             )
 
     def shadowed_variables(
         self,
-        surrounding_vars: Optional[dict[str, frozenset[Locatable]]] = None,
-    ) -> Iterator[tuple[str, frozenset[Locatable], frozenset[Locatable]]]:
+        surrounding_vars: Optional[Dict[str, FrozenSet[Locatable]]] = None,
+    ) -> Iterator[Tuple[str, FrozenSet[Locatable], FrozenSet[Locatable]]]:
         """
         Returns an iterator over variables shadowed in this block or its nested blocks.
         The elements are tuples of the variable name, a set of the shadowed locations
         and a set of the originally declared locations.
         :param surrounding_vars: an accumulator for variables declared in surrounding blocks.
         """
         if surrounding_vars is None:
             surrounding_vars = {}
         surrounding_vars = surrounding_vars.copy()
 
-        def merge_locatables(tuples: Iterable[tuple[str, Locatable]]) -> dict[str, frozenset[Locatable]]:
-            acc: dict[str, frozenset[Locatable]] = {}
+        def merge_locatables(tuples: Iterable[Tuple[str, Locatable]]) -> Dict[str, FrozenSet[Locatable]]:
+            acc: Dict[str, FrozenSet[Locatable]] = {}
             for var, loc in tuples:
                 if var not in acc:
                     acc[var] = frozenset(())
                 acc[var] = acc[var].union({loc})
             return acc
 
         for var, locs in merge_locatables(self.__variables).items():
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/constraint/__init__.py` & `inmanta-core-9.3.0/src/inmanta/ast/constraint/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/constraint/expression.py` & `inmanta-core-9.3.0/src/inmanta/ast/constraint/expression.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     Contact: code@inmanta.com
 """
 
 import re
 from abc import ABCMeta, abstractmethod
 from collections import abc
 from itertools import chain
-from typing import Optional, Type
+from typing import Dict, List, Optional, Type
 
 import inmanta.execute.dataflow as dataflow
 from inmanta import stable_api
 from inmanta.ast import LocatableString, RuntimeException, TypingException
 from inmanta.ast.statements import (
     AttributeAssignmentLHS,
     ExpressionStatement,
@@ -34,15 +34,14 @@
     StaticEagerPromise,
     VariableReferenceHook,
 )
 from inmanta.ast.type import Bool, create_function
 from inmanta.ast.variables import IsDefinedGradual, Reference
 from inmanta.execute.dataflow import DataflowGraph
 from inmanta.execute.runtime import ExecutionUnit, HangUnit, QueueScheduler, Resolver, ResultVariable, VariableABC
-from inmanta.execute.util import Unknown
 
 
 class InvalidNumberOfArgumentsException(Exception):
     """
     This exception is raised if an invalid amount of arguments is passed
     to an operator.
     """
@@ -68,31 +67,31 @@
     only makes sense for subclasses of the Operator class.
     """
 
     def __init__(self, name, bases, attr_dict) -> None:
         attribute = "_%s__op" % name
         if attribute in attr_dict:
             Operator.register_operator(attr_dict[attribute], self)
-        super().__init__(name, bases, attr_dict)
+        super(OpMetaClass, self).__init__(name, bases, attr_dict)
 
 
 class IsDefined(ReferenceStatement):
     __slots__ = ("attr", "name")
 
     def __init__(self, attr: Optional[Reference], name: LocatableString) -> None:
         if attr:
             children = [attr]
         else:
             children = []
-        super().__init__(children)
+        super(IsDefined, self).__init__(children)
         self.attr = attr
         self.name = str(name)
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
-        requires: dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
         # introduce temp variable to contain the eventual result of this stmt
         temp = ResultVariable()
         # construct waiter
         gradual_helper: IsDefinedGradual = IsDefinedGradual(owner=self, target=temp)
         hook: VariableReferenceHook = VariableReferenceHook(
             instance=self.attr,
             name=self.name,
@@ -101,41 +100,42 @@
         self.copy_location(hook)
         hook.schedule(resolver, queue)
 
         # wait for the attribute value
         requires[self] = temp
         return requires
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         # helper returned: return result
         return requires[self]
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("IsDefined.get_node() placeholder for %s" % self).reference()
 
     def pretty_print(self) -> str:
         if self.attr is not None:
-            name = f"{self.attr.pretty_print()}.{self.name}"
+            name = "%s.%s" % (self.attr.pretty_print(), self.name)
         else:
             name = self.name
         return "%s is defined" % name
 
 
 class Operator(ReferenceStatement, metaclass=OpMetaClass):
     """
     This class is an abstract base class for all operators that can be used in expressions
     """
 
     __slots__ = ("__number_arguments", "_arguments", "__name")
 
     # A hash to lookup each handler
-    __operator: dict[str, "Type[Operator]"] = {}
+    __operator: Dict[str, "Type[Operator]"] = {}
 
     @classmethod
-    def register_operator(cls, operator_string: str, operator_class: type["Operator"]) -> None:
+    def register_operator(cls, operator_string: str, operator_class: Type["Operator"]) -> None:
         """
         Register a new operator
         """
         cls.__operator[operator_string] = operator_class
 
     @classmethod
     def get_operator_class(cls, oper: str) -> "Optional[Type[Operator]]":
@@ -143,24 +143,25 @@
         Get the class that implements the given operator. Returns none of the operator does not exist
         """
         if oper in cls.__operator:
             return cls.__operator[oper]
 
         return None
 
-    def __init__(self, name: str, children: list[ExpressionStatement]) -> None:
+    def __init__(self, name: str, children: List[ExpressionStatement]) -> None:
         self.__number_arguments = len(children)
         self._arguments = children
         ReferenceStatement.__init__(self, self._arguments)
         self.__name = name
 
     def get_name(self) -> str:
         return self.__name
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         return self._op([x.execute(requires, resolver, queue) for x in self._arguments])
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         return self._op([x.execute_direct(requires) for x in self._arguments])
 
     def get_op(self) -> str:
         attribute = "_%s__op" % type(self).__name__
@@ -177,15 +178,15 @@
     def __repr__(self):
         """
         Return a representation of the op
         """
         arg_list = []
         for arg in self._arguments:
             arg_list.append(str(arg))
-        return "{}({})".format(self.__class__.__name__, ", ".join(arg_list))
+        return "%s(%s)" % (self.__class__.__name__, ", ".join(arg_list))
 
     def to_function(self):
         """
         Returns a function that represents this expression
         """
         return create_function(self)
 
@@ -206,26 +207,25 @@
     def __init__(self, name: str, op1: ExpressionStatement, op2: ExpressionStatement) -> None:
         Operator.__init__(self, name, [op1, op2])
 
     def _op(self, args):
         """
         The method that needs to be implemented for this operator
         """
-        if any(isinstance(arg, Unknown) for arg in args):
-            return Unknown(self)
+        # pylint: disable-msg=W0142
         return self._bin_op(*args)
 
     @abstractmethod
     def _bin_op(self, arg1: object, arg2: object) -> object:
         """
         The implementation of the binary op
         """
 
     def pretty_print(self) -> str:
-        return f"({self._arguments[0].pretty_print()} {self.get_op()} {self._arguments[1].pretty_print()})"
+        return "(%s %s %s)" % (self._arguments[0].pretty_print(), self.get_op(), self._arguments[1].pretty_print())
 
     def __repr__(self) -> str:
         return self.pretty_print()
 
 
 class LazyBooleanOperator(BinaryOperator, Resumer):
     """
@@ -241,42 +241,39 @@
         super().normalize()
         # lazy execution: we don't immediately emit the second operator so we need to hold its promises until we do
         self._own_eager_promises = list(self.children[1].get_all_eager_promises())
 
     def get_all_eager_promises(self) -> abc.Iterator["StaticEagerPromise"]:
         return chain(self._own_eager_promises, self.children[0].get_all_eager_promises())
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
-        requires: dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
         # introduce temp variable to contain the eventual result of this stmt
         temp: ResultVariable = ResultVariable()
         temp.set_type(Bool())
 
         # wait for the lhs
         requires.update(self.children[0].requires_emit(resolver, queue))
         HangUnit(queue, resolver, requires, temp, self)
         return {self: temp}
 
     def _validate_value(self, value: object, side: int) -> None:
         try:
             Bool().validate(value)
         except RuntimeException as e:
             e.set_statement(self)
-            e.msg = "Invalid {} hand value `{}`: `{}` expects a boolean".format(
+            e.msg = "Invalid %s hand value `%s`: `%s` expects a boolean" % (
                 "left" if side == 0 else "right",
                 value,
                 self.get_op(),
             )
             raise e
 
-    def resume(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
+    def resume(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
         result = self.children[0].execute(requires, resolver, queue)
-        if isinstance(result, Unknown):
-            target.set_value(result, self.location)
-            return
         self._validate_value(result, 0)
         assert isinstance(result, bool)
         # second operand will get emitted now or never, no need to hold its promises any longer
         self._fulfill_promises(requires)
         if self._is_final(result):
             target.set_value(result, self.location)
         else:
@@ -291,22 +288,19 @@
         if self._is_final(lhs):
             return lhs
         else:
             rhs = self.children[1].execute_direct(requires)
             self._validate_value(rhs, 1)
             return rhs
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        # no need to fulfill promises, already done in resume
         # helper returned: return result
         return requires[self]
 
-    def _fulfill_promises(self, requires: dict[object, object]) -> None:
-        # no need to fulfill promises, already done in resume
-        pass
-
     def _is_final(self, result: bool) -> bool:
         raise NotImplementedError()
 
     def _bin_op(self, arg1: object, arg2: object) -> object:
         """
         The implementation of the binary op
         """
@@ -319,31 +313,29 @@
     """
 
     __slots__ = ()
 
     def __init__(self, name: str, op1: ExpressionStatement) -> None:
         Operator.__init__(self, name, [op1])
 
-    def _op(self, args: abc.Sequence[object]) -> object:
+    def _op(self, args):
         """
         This method calls the implementation of the operator
         """
-        arg = args[0]
-        if isinstance(arg, Unknown):
-            return Unknown(self)
-        return self._un_op(arg)
+        # pylint: disable-msg=W0142
+        return self._un_op(args[0])
 
     @abstractmethod
     def _un_op(self, arg: object) -> object:
         """
         The implementation of the operator
         """
 
     def pretty_print(self) -> str:
-        return f"({self.get_op()} {self._arguments[0].pretty_print()})"
+        return "(%s %s)" % (self.get_op(), self._arguments[0].pretty_print())
 
 
 class Not(UnaryOperator):
     """
     The negation operator
     """
 
@@ -359,15 +351,15 @@
 
         @see Operator#_op
         """
         try:
             Bool().validate(arg)
         except RuntimeException as e:
             e.set_statement(self)
-            e.msg = f"Invalid value `{arg}`: `{self.get_op()}` expects a boolean"
+            e.msg = "Invalid value `%s`: `%s` expects a boolean" % (arg, self.get_op())
             raise e
         return not arg
 
 
 @stable_api.stable_api
 class Regex(BinaryOperator):
     """
@@ -382,15 +374,15 @@
 
     def _bin_op(self, arg1: object, arg2: object) -> object:
         """
         @see Operator#_op
         """
         assert arg2 == self.regex
         if not isinstance(arg1, str):
-            raise TypingException(self, f"Regex can only be match with strings. {arg1} is of type {type(arg1)}")
+            raise TypingException(self, "Regex can only be match with strings. %s is of type %s" % (arg1, type(arg1)))
 
         return self.regex.match(arg1) is not None
 
     def pretty_print(self) -> str:
         return "/%s/" % self.regex.pattern
 
 
@@ -547,31 +539,21 @@
 
     __slots__ = ()
     __op = "in"
 
     def __init__(self, op1: ExpressionStatement, op2: ExpressionStatement) -> None:
         BinaryOperator.__init__(self, "in", op1, op2)
 
-    def _op(self, args):
-        # override parent implementation to not propagate unknowns eagerly
-        return self._bin_op(*args)
-
     def _bin_op(self, arg1: object, arg2: object) -> object:
         """
         @see Operator#_op
         """
-        if isinstance(arg1, Unknown):
-            return Unknown(self)
-
         if isinstance(arg2, dict):
             return arg1 in arg2
         elif isinstance(arg2, list):
-            any_unknown: bool = False
             for arg in arg2:
                 if arg == arg1:
                     return True
-                if isinstance(arg, Unknown):
-                    any_unknown = True
-            # if we did not find arg1 in arg2 but there are unknowns we can't be sure
-            return Unknown(self) if any_unknown else False
         else:
             raise TypingException(self, "Operand two of 'in' can only be a list or dict (%s)" % arg2)
+
+        return False
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/entity.py` & `inmanta-core-9.3.0/src/inmanta/ast/entity.py`

 * *Files 5% similar despite different names*

```diff
@@ -14,30 +14,30 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 # pylint: disable-msg=R0902,R0904
 
-from typing import Any, Dict, List, Optional, Set, Tuple, Union  # noqa: F401
+from typing import Any, Dict, List, Optional, Sequence, Set, Tuple, Union  # noqa: F401
 
 from inmanta.ast import (
     CompilerException,
     DuplicateException,
     Locatable,
     Location,
     Named,
     Namespace,
     NotFoundException,
     RuntimeException,
     WithComment,
 )
 from inmanta.ast.blocks import BasicBlock
 from inmanta.ast.statements.generator import SubConstructor
-from inmanta.ast.type import Float, NamedType, Type
+from inmanta.ast.type import NamedType, Type
 from inmanta.execute.runtime import Instance, QueueScheduler, Resolver, dataflow
 from inmanta.execute.util import AnyType
 
 try:
     from typing import TYPE_CHECKING
 except ImportError:
     TYPE_CHECKING = False
@@ -120,15 +120,15 @@
         for i in self.implements:
             i.normalize()
 
         self.subc = [SubConstructor(self, i) for i in self.get_implements()]
         for sub in self.subc:
             sub.normalize()
 
-    def get_sub_constructor(self) -> list[SubConstructor]:
+    def get_sub_constructor(self) -> List[SubConstructor]:
         return self.subc
 
     def get_implements(self) -> "List[Implement]":
         if self.implements_inherits:
             return self.implements + [i for p in self.parent_entities for i in p.get_implements()]
         else:
             return self.implements
@@ -136,15 +136,15 @@
     def add_default_value(self, name: str, value: "DefineAttribute") -> None:
         """
         Add a default value for an attribute
         """
         self.__default_values[name] = value
 
     def _get_own_defaults(self) -> "Dict[str, Optional[ExpressionStatement]]":
-        return {k: v.default for k, v in self.__default_values.items() if v.default is not None or v.remove_default}
+        return dict((k, v.default) for k, v in self.__default_values.items() if v.default is not None or v.remove_default)
 
     def get_namespace(self) -> Namespace:
         """
         The namespace of this entity
         """
         return self.__namespace
 
@@ -234,19 +234,15 @@
     def add_attribute(self, attribute: "Attribute") -> None:
         """
         Add an attribute to this entity. The attribute should not exist yet.
         """
         if attribute.name not in self._attributes:
             self._attributes[attribute.name] = attribute
         else:
-            raise DuplicateException(
-                self._attributes[attribute.name],
-                attribute,
-                "attribute '%s' already exists on entity '%s'" % (attribute.name, self.name),
-            )
+            raise DuplicateException(self._attributes[attribute.name], attribute, "attribute already exists")
 
     def get_attribute(self, name: str) -> Optional["Attribute"]:
         """
         Get the attribute with the given name
         """
         if name in self._attributes:
             return self._attributes[name]
@@ -284,15 +280,15 @@
         self.add_to_index(obj)
 
         for parent in self.parent_entities:
             parent.add_instance(obj)
 
     def get_instance(
         self,
-        attributes: dict[str, object],
+        attributes: Dict[str, object],
         resolver: Resolver,
         queue: QueueScheduler,
         location: Location,
         node: Optional[dataflow.InstanceNodeReference] = None,
     ) -> "Instance":
         """
         Return an instance of the class defined in this entity.
@@ -319,19 +315,19 @@
         """
         Validate the given value
         """
         if isinstance(value, AnyType):
             return True
 
         if not isinstance(value, Instance):
-            raise RuntimeException(None, f"Invalid type for value '{value}', should be type {self}")
+            raise RuntimeException(None, "Invalid type for value '%s', should be type %s" % (value, self))
 
         value_definition = value.type
         if not (value_definition is self or self.is_subclass(value_definition)):
-            raise RuntimeException(None, f"Invalid class type for {value}, should be {self}")
+            raise RuntimeException(None, "Invalid class type for %s, should be %s" % (value, self))
 
         return True
 
     def add_implementation(self, implement: "Implementation") -> None:
         """
         Register an implementation for this entity
         """
@@ -360,46 +356,45 @@
         Override list eq method
         """
         if not isinstance(other, Entity):
             return False
 
         return self.name == other.name and self.namespace == other.namespace
 
-    def add_index(self, attributes: list[str]) -> None:
+    def add_index(self, attributes: List[str]) -> None:
         """
         Add an index over the given attributes.
         """
         # duplicate check
         for index in self._index_def:
             if len(index) == len(attributes) and all((a == b for a, b in zip(index, attributes))):
                 return
 
         self._index_def.append(sorted(attributes))
         for child in self.child_entities:
             child.add_index(attributes)
 
-    def get_indices(self) -> list[list[str]]:
+    def get_indices(self) -> List[List[str]]:
         return self._index_def
 
     def add_to_index(self, instance: Instance) -> None:
         """
         Update indexes based on the instance and the attribute that has
         been set
         """
         attributes = {k: repr(v.get_value()) for (k, v) in instance.slots.items() if v.is_ready()}
-
         # check if an index entry can be added
         for index_attributes in self.get_indices():
             index_ok = True
             key = []
             for attribute in index_attributes:
                 if attribute not in attributes:
                     index_ok = False
                 else:
-                    key.append(f"{attribute}={attributes[attribute]}")
+                    key.append("%s=%s" % (attribute, attributes[attribute]))
 
             if index_ok:
                 keys = ", ".join(key)
 
                 if keys in self._index and self._index[keys] is not instance:
                     raise DuplicateException(instance, self._index[keys], "Duplicate key in index. %s" % keys)
 
@@ -412,16 +407,16 @@
 
     def lookup_index(
         self, params: "List[Tuple[str,object]]", stmt: "Statement", target: "Optional[ResultVariable]" = None
     ) -> "Optional[Instance]":
         """
         Search an instance in the index.
         """
-        all_attributes: list[str] = [x[0] for x in params]
-        attributes: set[str] = set()
+        all_attributes: List[str] = [x[0] for x in params]
+        attributes: Set[str] = set(())
         for attr in all_attributes:
             if attr in attributes:
                 raise RuntimeException(stmt, "Attribute %s provided twice in index lookup" % attr)
             attributes.add(attr)
 
         found_index = False
         for index_attributes in self.get_indices():
@@ -429,24 +424,16 @@
                 found_index = True
 
         if not found_index:
             raise NotFoundException(
                 stmt, self.get_full_name(), "No index defined on %s for this lookup: " % self.get_full_name() + str(params)
             )
 
-        key = ", ".join(
-            [
-                "%s=%s"
-                % (
-                    k,
-                    repr(self.get_attribute(k).type.cast(v) if isinstance(self.get_attribute(k).type, Float) else v),
-                )
-                for k, v in sorted(params, key=lambda x: x[0])
-            ]
-        )
+        key = ", ".join(["%s=%s" % (k, repr(v)) for (k, v) in sorted(params, key=lambda x: x[0])])
+
         if target is None:
             if key in self._index:
                 return self._index[key]
             else:
                 return None
         elif key in self._index:
             target.set_value(self._index[key], stmt.location)
@@ -479,18 +466,20 @@
         Get a default value for a given name
         """
         defaults = self.get_default_values()
         if name not in defaults:
             raise AttributeError(name)
         return defaults[name]
 
-    def final(self, excns: list[CompilerException]) -> None:
+    def final(self, excns: List[CompilerException]) -> None:
         for key, indices in self.index_queue.items():
             for _, stmt in indices:
-                excns.append(NotFoundException(stmt, key, f"No match in index on type {self.get_full_name()} with key {key}"))
+                excns.append(
+                    NotFoundException(stmt, key, "No match in index on type %s with key %s" % (self.get_full_name(), key))
+                )
         for _, attr in self.get_attributes().items():
             attr.final(excns)
 
     def get_double_defined_exception(self, other: "Namespaced") -> "DuplicateException":
         return DuplicateException(self, other, "Entity %s is already defined" % (self.get_full_name()))
 
     def get_location(self) -> Location:
@@ -524,30 +513,27 @@
 
     def __repr__(self) -> str:
         return "Implementation(name = %s)" % self.name
 
     def normalize(self) -> None:
         try:
             self.statements.normalize()
-        except RuntimeException as e:
-            e.set_statement(self, False)
-            raise
         except CompilerException as e:
             e.set_location(self.location)
             raise
 
     def get_full_name(self) -> str:
         return self.namespace.get_full_name() + "::" + self.name
 
     def get_namespace(self) -> Namespace:
         return self.namespace
 
     def get_double_defined_exception(self, other: "Namespaced") -> "DuplicateException":
         raise DuplicateException(
-            self, other, f"Implementation {self.get_full_name()} for type {self.target_type} is already defined"
+            self, other, "Implementation %s for type %s is already defined" % (self.get_full_name(), self.target_type)
         )
 
     def get_location(self) -> Location:
         return self.location
 
 
 class Implement(Locatable):
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/export.py` & `inmanta-core-9.3.0/src/inmanta/ast/export.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/statements/__init__.py` & `inmanta-core-9.3.0/src/inmanta/ast/statements/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -12,18 +12,17 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 from collections import abc
-from collections.abc import Iterator, Sequence
 from dataclasses import dataclass
 from itertools import chain
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Dict, Iterator, List, Optional, Sequence, Tuple
 
 import inmanta.execute.dataflow as dataflow
 from inmanta.ast import (
     Anchor,
     DirectExecuteException,
     Locatable,
     Location,
@@ -61,29 +60,28 @@
     An abstract baseclass representing a statement in the configuration policy.
     """
 
     __slots__ = ("namespace", "anchors", "lexpos")
 
     def __init__(self) -> None:
         Namespaced.__init__(self)
-        self.namespace: Namespace = None
-        self.anchors: list[Anchor] = []
+        self.namespace = None  # type: Namespace
+        self.anchors = []  # type: List[Anchor]
         self.lexpos: Optional[int] = None
 
     def get_namespace(self) -> "Namespace":
         return self.namespace
 
     def pretty_print(self) -> str:
         return str(self)
 
     def get_location(self) -> Location:
         return self.location
 
-    def get_anchors(self) -> list[Anchor]:
-        """Should only be called after normalization (DynamicStatement) or evaluation (DefinitionStatement)."""
+    def get_anchors(self) -> List[Anchor]:
         return self.anchors
 
     def nested_blocks(self) -> Iterator["BasicBlock"]:
         """
         Returns an iterator over blocks contained within this statement.
         """
         return iter(())
@@ -149,47 +147,57 @@
         Emits this statement by scheduling its promises and scheduling a unit to wait on its requirements. Injects the
         scheduled promise objects in the waiter's requires in order to pass it on to the execute method.
         """
         target = ResultVariable()
         reqs = self.requires_emit(resolver, queue)
         ExecutionUnit(queue, resolver, target, reqs, self)
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC]:
         """
         Returns a dict of the result variables required for execution. Names are an opaque identifier. May emit statements to
         break execution is smaller segments.
         Additionally schedules this statement's eager promises and includes them (wrapped in a result variable) in the requires
         dict in order to pass it on to the execution phase.
         When this method is called, the caller must make sure to eventually call `execute` as well.
         """
         return self._requires_emit_promises(resolver, queue)
 
-    def _requires_emit_promises(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
+    def requires_emit_gradual(
+        self, resolver: Resolver, queue: QueueScheduler, resultcollector: ResultCollector[object]
+    ) -> Dict[object, VariableABC]:
+        """
+        Returns a dict of the result variables required for execution. Behaves like requires_emit, but additionally may attach
+        resultcollector as a listener to result variables.
+        When this method is called, the caller must make sure to eventually call `execute` as well.
+        """
+        return self.requires_emit(resolver, queue)
+
+    def _requires_emit_promises(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC]:
         """
         Acquires eager promises this statement is responsible for and returns them, wrapped in a variable, in a requires dict.
         Returns an empty dict if no promises were acquired (for performance reasons).
         """
         promises: Sequence["EagerPromise"] = self.schedule_eager_promises(resolver, queue)
         return {(self, EagerPromise): WrappedValueVariable(promises)} if promises else {}
 
     def schedule_eager_promises(self, resolver: Resolver, queue: QueueScheduler) -> Sequence["EagerPromise"]:
         """
         Schedules this statement's eager promises to be acquired in the given dynamic context.
         """
         return [promise.schedule(self, resolver, queue) for promise in self.get_own_eager_promises()]
 
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         """
         execute the statement, give the values provided in the requires dict.
         These values correspond to the values requested via requires_emit
         """
         self._fulfill_promises(requires)
         return None
 
-    def _fulfill_promises(self, requires: dict[object, object]) -> None:
+    def _fulfill_promises(self, requires: Dict[object, object]) -> None:
         """
         Given a requires dict, fulfills this statements dynamic promises
         """
         promises: Sequence["EagerPromise"]
         try:
             promises = requires[(self, EagerPromise)]
         except KeyError:
@@ -204,71 +212,37 @@
     attribute: str
     type_hint: Optional["Type"] = None
 
 
 class ExpressionStatement(RequiresEmitStatement):
     __slots__ = ()
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         """
         List of all variable names used by this statement. Artifact from the past, hardly used anymore.
         """
         raise NotImplementedError()
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         """
         Execute this statement in a static context without any scheduling, returning the expression's result.
 
         :param requires: A dictionary mapping names to values.
         """
         raise DirectExecuteException(self, f"The statement {str(self)} can not be executed in this context")
 
-    def requires_emit_gradual(
-        self, resolver: Resolver, queue: QueueScheduler, resultcollector: ResultCollector[object]
-    ) -> dict[object, VariableABC]:
-        """
-        Returns a dict of the result variables required for execution. Behaves like requires_emit, but additionally may attach
-        resultcollector as a listener to result variables.
-        When this method is called, the caller must make sure to eventually call `execute` as well.
-
-        Composite statements (e.g. conditional expression) will pass result collectors to their children rather than
-        report to them themselves.
-        """
-        return {**self.requires_emit(resolver, queue), (self, ResultCollector): WrappedValueVariable(resultcollector)}
-
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         """
         :param lhs_attribute: The left hand side attribute if this expression is a right hand side in an attribute assignment.
             If not None, that caller is responsible for making sure the reference resolves to the correct instance as soon as
             this statement enters the `requires_emit` stage. As a result, it should always be None if the instance construction
             depends on this statement.
         """
         raise NotImplementedError()
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
-        """
-        Execute the expression and return the value it resolves to without performing any of the associated steps like
-        fulfilling promises or notifying result collectors.
-        """
-        raise NotImplementedError()
-
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
-        """
-        Execute the expression and return the value it resolves to.
-        The requires dict contains the resolved values of the variables that were requested via requires_emit.
-        """
-        super().execute(requires, resolver, queue)
-        # resolve expression, then notify result collectors before returning
-        result: object = self._resolve(requires, resolver, queue)
-        resultcollector: Optional[ResultCollector] = requires.get((self, ResultCollector), None)
-        # `result is None` represents the absence of a result, not the `null` DSL value
-        if result is not None and resultcollector is not None:
-            resultcollector.receive_result_flatten(result, self.location)
-        return result
-
     def as_constant(self) -> object:
         """
         Returns this expression as a constant value, if possible. Otherwise, raise a RuntimeException.
         """
         raise RuntimeException(None, "%s is not a constant" % self)
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
@@ -281,26 +255,26 @@
 class Resumer(Locatable):
     """
     Resume on a set of requirement variables' values when they become ready (i.e. they are complete).
     """
 
     __slots__ = ()
 
-    def resume(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
+    def resume(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
         pass
 
 
 class RawResumer(Locatable):
     """
     Resume on a set of requirement variables when they become ready (i.e. they are complete).
     """
 
     __slots__ = ()
 
-    def resume(self, requires: dict[object, VariableABC], resolver: Resolver, queue: QueueScheduler) -> None:
+    def resume(self, requires: Dict[object, VariableABC], resolver: Resolver, queue: QueueScheduler) -> None:
         pass
 
 
 class VariableReferenceHook(RawResumer):
     """
     Generic helper class for adding a hook to a variable (ResultVariable) object. Supports both plain variables and instance
     attributes. Calls variable resumer with the variable object as soon as it's available. Resolves to a variable object that is
@@ -342,15 +316,15 @@
                 resolver,
                 # no need for gradual execution here because this class represents an attribute reference on self.instance,
                 # which is not allowed on multi variables (the only kind of variables that would benefit from gradual execution)
                 self.instance.requires_emit(resolver, queue, propagate_unset=self.propagate_unset),
                 self,
             )
 
-    def resume(self, requires: dict[object, VariableABC], resolver: Resolver, queue: QueueScheduler) -> None:
+    def resume(self, requires: Dict[object, VariableABC], resolver: Resolver, queue: QueueScheduler) -> None:
         """
         Fetches the variable when it's available and calls variable resumer.
         """
         variable: VariableABC[object]
         if self.instance is not None:
             # get the Instance
             instance_requires: dict[object, object] = {}
@@ -366,15 +340,17 @@
                 # propagate unset variable up the attribute reference chain
                 variable = unset
             else:
                 # all requires are present, execute instance
                 instance: object = self.instance.execute(instance_requires, resolver, queue)
 
                 if isinstance(instance, list):
-                    raise RuntimeException(self, f"can not get attribute {self.name}, {instance} is not an entity but a list")
+                    raise RuntimeException(
+                        self, "can not get attribute %s, %s is not an entity but a list" % (self.name, instance)
+                    )
                 if not isinstance(instance, Instance):
                     raise RuntimeException(
                         self,
                         "can not get attribute %s, %s is not an entity but a %s with value '%s'"
                         % (self.name, self.instance, type(instance).__name__, instance),
                     )
 
@@ -387,22 +363,22 @@
             variable = obj
 
         self.variable_resumer.variable_resume(variable, resolver, queue)
 
     def emit(self, resolver: Resolver, queue: QueueScheduler) -> None:
         raise RuntimeException(self, "%s is not an actual AST node, it should never be executed" % self.__class__.__name__)
 
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         raise RuntimeException(self, "%s is not an actual AST node, it should never be executed" % self.__class__.__name__)
 
     def __str__(self) -> str:
-        return f"{self.instance}.{self.name}"
+        return "%s.%s" % (self.instance, self.name)
 
     def __repr__(self) -> str:
-        return "{}({!r}, {}, {!r}, propagate_unset={!r})".format(
+        return "%s(%r, %s, %r, propagate_unset=%r)" % (
             self.__class__.__name__,
             self.instance,
             self.name,
             self.variable_resumer,
             self.propagate_unset,
         )
 
@@ -515,63 +491,58 @@
     """
 
     __slots__ = ("children",)
 
     def __init__(self, children: Sequence[ExpressionStatement]) -> None:
         ExpressionStatement.__init__(self)
         self.children: Sequence[ExpressionStatement] = children
+        self.anchors.extend((anchor for e in self.children for anchor in e.get_anchors()))
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
-        for child in self.children:
-            child.normalize()
-            self.anchors.extend(child.get_anchors())
+        for c in self.children:
+            c.normalize()
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(super().get_all_eager_promises(), *(subexpr.get_all_eager_promises() for subexpr in self.children))
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return [req for v in self.children for req in v.requires()]
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
-        try:
-            requires: dict[object, VariableABC] = super().requires_emit(resolver, queue)
-            requires.update({rk: rv for i in self.children for (rk, rv) in i.requires_emit(resolver, queue).items()})
-            return requires
-        except RuntimeException as e:
-            e.set_statement(self, False)
-            raise e
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = super().requires_emit(resolver, queue)
+        requires.update({rk: rv for i in self.children for (rk, rv) in i.requires_emit(resolver, queue).items()})
+        return requires
 
 
 class AssignStatement(DynamicStatement):
     """
     This class models binary sts
     """
 
     __slots__ = ("lhs", "rhs")
 
     def __init__(self, lhs: Optional["Reference"], rhs: ExpressionStatement) -> None:
         DynamicStatement.__init__(self)
         self.lhs: Optional["Reference"] = lhs
         self.rhs: ExpressionStatement = rhs
+        if lhs is not None:
+            self.anchors.extend(lhs.get_anchors())
+        self.anchors.extend(rhs.get_anchors())
 
     def normalize(self) -> None:
         self.rhs.normalize()
-        if self.lhs is not None:
-            self.lhs.normalize()
-            self.anchors.extend(self.lhs.get_anchors())
-        self.anchors.extend(self.rhs.get_anchors())
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(
             super().get_all_eager_promises(),
             (self.lhs.get_all_eager_promises() if self.lhs is not None else []),
             self.rhs.get_all_eager_promises(),
         )
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         out = self.lhs.requires() if self.lhs is not None else []  # type : List[str]
         out.extend(self.rhs.requires())  # type : List[str]
         return out
 
     def _add_to_dataflow_graph(self, graph: Optional[DataflowGraph]) -> None:
         """
         Adds this assignment to the resolver's data flow graph.
@@ -591,18 +562,19 @@
         pass
 
     def __repr__(self) -> str:
         if isinstance(self.value, bool):
             return repr(self.value).lower()
         return repr(self.value)
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return []
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         return self.value
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         return self.value
 
     def as_constant(self) -> object:
         return self.value
@@ -624,15 +596,15 @@
     def __init__(self, namespace: Namespace, name: str) -> None:
         DefinitionStatement.__init__(self)
         self.name = name
         self.namespace = namespace
         self.fullName = namespace.get_full_name() + "::" + str(name)
         self.type = None  # type: NamedType
 
-    def register_types(self) -> tuple[str, "NamedType"]:
+    def register_types(self) -> Tuple[str, "NamedType"]:
         self.namespace.define_type(self.name, self.type)
         return (self.fullName, self.type)
 
     def evaluate(self) -> None:
         pass
 
     def get_full_name(self) -> str:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/statements/assign.py` & `inmanta-core-9.3.0/src/inmanta/ast/statements/assign.py`

 * *Files 15% similar despite different names*

```diff
@@ -17,27 +17,27 @@
 """
 
 # pylint: disable-msg=W0613
 import typing
 from collections import abc
 from itertools import chain
 from string import Formatter
-from typing import Optional, TypeVar
+from typing import Dict, Optional, Tuple, TypeVar
 
 import inmanta.execute.dataflow as dataflow
 from inmanta.ast import (
     AttributeException,
     DuplicateException,
     HyphenException,
     KeyException,
     LocatableString,
     Location,
     OptionalValueException,
     RuntimeException,
-    TypeAnchor,
+    TypeReferenceAnchor,
     TypingException,
 )
 from inmanta.ast.attribute import RelationAttribute
 from inmanta.ast.statements import (
     AssignStatement,
     AttributeAssignmentLHS,
     ExpressionStatement,
@@ -78,31 +78,30 @@
 class CreateList(ReferenceStatement):
     """
     Represents a list literal statement which might contain any type of value (constants and/or instances).
     """
 
     __slots__ = ("items",)
 
-    def __init__(self, items: list[ExpressionStatement]) -> None:
+    def __init__(self, items: typing.List[ExpressionStatement]) -> None:
         ReferenceStatement.__init__(self, items)
         self.items = items
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         for item in self.items:
             # pass on lhs_attribute to children
             item.normalize(lhs_attribute=lhs_attribute)
-            self.anchors.extend(item.get_anchors())
 
     def requires_emit_gradual(
         self, resolver: Resolver, queue: QueueScheduler, resultcollector: Optional[ResultCollector]
-    ) -> dict[object, VariableABC]:
+    ) -> typing.Dict[object, VariableABC]:
         if resultcollector is None:
             return self.requires_emit(resolver, queue)
 
-        requires: dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
 
         # if we are in gradual mode, transform to a list of assignments instead of assignment of a list
         # to get more accurate gradual execution
         # temp variable is required get all heuristics right
 
         # ListVariable to hold all the stuff. Used as a proxy for gradual execution and to track promises.
         # Freezes itself once all promises have been fulfilled, at which point it represents the full list literal created by
@@ -120,18 +119,20 @@
             # empty: just close
             temp.freeze()
 
         # pass temp
         requires[self] = temp
         return requires
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         """
         Create this list
         """
+        super().execute(requires, resolver, queue)
+
         # gradual case, everything is in placeholder
         if self in requires:
             return requires[self]
 
         qlist = []
 
         for i in range(len(self.items)):
@@ -148,15 +149,15 @@
 
         for i in range(len(self.items)):
             value = self.items[i]
             qlist.append(value.execute_direct(requires))
 
         return qlist
 
-    def as_constant(self) -> list[object]:
+    def as_constant(self) -> typing.List[object]:
         return [item.as_constant() for item in self.items]
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("CreateList.get_node() placeholder for %s" % self).reference()
 
     def pretty_print(self) -> str:
         return "[%s]" % ",".join(item.pretty_print() for item in self.items)
@@ -164,15 +165,15 @@
     def __repr__(self) -> str:
         return "List()"
 
 
 class CreateDict(ReferenceStatement):
     __slots__ = ("items",)
 
-    def __init__(self, items: list[tuple[str, ReferenceStatement]]) -> None:
+    def __init__(self, items: typing.List[typing.Tuple[str, ReferenceStatement]]) -> None:
         ReferenceStatement.__init__(self, [x[1] for x in items])
         self.items = items
         seen = {}  # type: typing.Dict[str,ReferenceStatement]
         for x, v in items:
             if x in seen:
                 raise DuplicateException(v, seen[x], "duplicate key in dict %s" % x)
             seen[x] = v
@@ -182,27 +183,28 @@
 
         for i in range(len(self.items)):
             key, value = self.items[i]
             qlist[key] = value.execute_direct(requires)
 
         return qlist
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         """
         Create this list
         """
+        super().execute(requires, resolver, queue)
         qlist = {}
 
         for i in range(len(self.items)):
             key, value = self.items[i]
             qlist[key] = value.execute(requires, resolver, queue)
 
         return qlist
 
-    def as_constant(self) -> dict[str, object]:
+    def as_constant(self) -> typing.Dict[str, object]:
         return {k: v.as_constant() for k, v in self.items}
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("CreateDict.get_node() placeholder for %s" % self).reference()
 
     def __repr__(self) -> str:
         return "Dict()"
@@ -222,17 +224,14 @@
         self.value = value
         self.list_only = list_only
         self._assignment_promise: StaticEagerPromise = StaticEagerPromise(self.instance, self.attribute_name, self)
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         # register this assignment as left hand side to the value on the right hand side
         self.rhs.normalize(lhs_attribute=AttributeAssignmentLHS(self.instance, self.attribute_name))
-        self.anchors.extend(self.rhs.get_anchors())
-        if self.lhs is not None:
-            self.anchors.extend(self.lhs.get_anchors())
 
     def get_all_eager_promises(self) -> abc.Iterator["StaticEagerPromise"]:
         # propagate this attribute assignment's promise to parent blocks
         return chain(super().get_all_eager_promises(), [self._assignment_promise])
 
     def _add_to_dataflow_graph(self, graph: typing.Optional[DataflowGraph]) -> None:
         if graph is None:
@@ -242,19 +241,21 @@
 
     def emit(self, resolver: Resolver, queue: QueueScheduler) -> None:
         self._add_to_dataflow_graph(resolver.dataflow_graph)
         reqs = self.instance.requires_emit(resolver, queue)
         # This class still implements custom attribute resolution, rather than using the new VariableReferenceHook mechanism
         HangUnit(queue, resolver, reqs, ResultVariable(), self)
 
-    def resume(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
+    def resume(
+        self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable
+    ) -> None:
         instance = self.instance.execute(requires, resolver, queue)
         if not isinstance(instance, Instance):
             raise TypingException(
-                self, f"The object at {self.instance} is not an Entity but a {type(instance)} with value {instance}"
+                self, "The object at %s is not an Entity but a %s with value %s" % (self.instance, type(instance), instance)
             )
         var = instance.get_attribute(self.attribute_name)
         if self.list_only and not var.is_multi():
             raise TypingException(self, "Can not use += on relations with multiplicity 1")
 
         if var.is_multi():
             # gradual only for multi
@@ -265,18 +266,18 @@
             )
         else:
             reqs = self.value.requires_emit(resolver, queue)
 
         SetAttributeHelper(queue, resolver, var, reqs, self.value, self, instance, self.attribute_name)
 
     def pretty_print(self) -> str:
-        return f"{self.instance.pretty_print()}.{self.attribute_name} = {self.value.pretty_print()}"
+        return "%s.%s = %s" % (self.instance.pretty_print(), self.attribute_name, self.value.pretty_print())
 
     def __str__(self) -> str:
-        return f"{str(self.instance)}.{self.attribute_name} = {str(self.value)}"
+        return "%s.%s = %s" % (str(self.instance), self.attribute_name, str(self.value))
 
 
 class GradualSetAttributeHelper(ResultCollector[T]):
     """
     A result collector wrapper that ensures that exceptions that happen during assignment
     are attributed to the correct statement
     """
@@ -305,15 +306,15 @@
     __slots__ = ("stmt", "instance", "attribute_name")
 
     def __init__(
         self,
         queue_scheduler: QueueScheduler,
         resolver: Resolver,
         result: ResultVariable,
-        requires: dict[object, ResultVariable],
+        requires: typing.Dict[object, ResultVariable],
         expression: ExpressionStatement,
         stmt: Statement,
         instance: Instance,
         attribute_name: str,
     ) -> None:
         ExecutionUnit.__init__(self, queue_scheduler, resolver, result, requires, expression)
         self.stmt = stmt
@@ -373,113 +374,117 @@
     def declared_variables(self) -> abc.Iterator[str]:
         yield str(self.name)
 
     def pretty_print(self) -> str:
         return f"{self.name} = {self.value.pretty_print()}"
 
     def __repr__(self) -> str:
-        return f"Assign({self.name}, {self.value})"
+        return "Assign(%s, %s)" % (self.name, self.value)
 
     def __str__(self) -> str:
         return f"{self.name} = {self.value}"
 
 
 class MapLookup(ReferenceStatement):
     """
     Lookup a value in a dict
     """
 
     __slots__ = ("themap", "key", "location")
 
     def __init__(self, themap: ExpressionStatement, key: ExpressionStatement):
-        super().__init__([themap, key])
+        super(MapLookup, self).__init__([themap, key])
         self.themap = themap
         self.key = key
         self.location = themap.get_location().merge(key.location)
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         mapv = self.themap.execute(requires, resolver, queue)
         if isinstance(mapv, Unknown):
             return Unknown(self)
         if not isinstance(mapv, dict):
             raise TypingException(self, "dict lookup is only possible on dicts, %s is not an object" % mapv)
 
         keyv = self.key.execute(requires, resolver, queue)
         if isinstance(keyv, Unknown):
             return Unknown(self)
         if not isinstance(keyv, str):
             raise TypingException(self, "dict keys must be string, %s is not a string" % keyv)
 
         if keyv not in mapv:
-            raise KeyException(self, "key {} not found in dict, options are [{}]".format(keyv, ",".join(mapv.keys())))
+            raise KeyException(self, "key %s not found in dict, options are [%s]" % (keyv, ",".join(mapv.keys())))
 
         return mapv[keyv]
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("MapLookup.get_node() placeholder for %s" % self).reference()
 
     def __repr__(self) -> str:
-        return f"{repr(self.themap)}[{repr(self.key)}]"
+        return "%s[%s]" % (repr(self.themap), repr(self.key))
 
 
 class IndexLookup(ReferenceStatement, Resumer):
     """
     Lookup a value in a dictionary
     """
 
     __slots__ = ("index_type", "query", "wrapped_query", "type")
 
     def __init__(
         self,
         index_type: LocatableString,
-        query: list[tuple[LocatableString, ExpressionStatement]],
-        wrapped_query: list["WrappedKwargs"],
+        query: typing.List[typing.Tuple[LocatableString, ExpressionStatement]],
+        wrapped_query: typing.List["WrappedKwargs"],
     ) -> None:
         ReferenceStatement.__init__(self, list(chain((v for (_, v) in query), wrapped_query)))
         self.index_type = index_type
+        self.anchors.append(TypeReferenceAnchor(index_type.namespace, index_type))
         self.query = [(str(n), e) for n, e in query]
-        self.wrapped_query: list["WrappedKwargs"] = wrapped_query
+        self.wrapped_query: typing.List["WrappedKwargs"] = wrapped_query
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         ReferenceStatement.normalize(self)
         self.type = self.namespace.get_type(self.index_type)
-        self.anchors.append(TypeAnchor(self.index_type, self.type))
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC]:
-        requires: dict[object, VariableABC] = RequiresEmitStatement.requires_emit(self, resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> typing.Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = RequiresEmitStatement.requires_emit(self, resolver, queue)
         sub = ReferenceStatement.requires_emit(self, resolver, queue)
         temp = ResultVariable()
         temp.set_type(self.type)
         HangUnit(queue, resolver, sub, temp, self)
         requires[self] = temp
         return requires
 
-    def resume(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
+    def resume(
+        self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable
+    ) -> None:
         self.type.lookup_index(
             list(
                 chain(
                     ((k, v.execute(requires, resolver, queue)) for (k, v) in self.query),
                     ((k, v) for kwargs in self.wrapped_query for (k, v) in kwargs.execute(requires, resolver, queue)),
                 )
             ),
             self,
             target,
         )
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         return requires[self]
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("IndexLookup.get_node() placeholder for %s" % self).reference()
 
     def __repr__(self) -> str:
         """
         The representation of this statement
         """
-        return "{}[{}]".format(self.index_type, ",".join([repr(x) for x in chain([self.query], self.wrapped_query)]))
+        return "%s[%s]" % (self.index_type, ",".join([repr(x) for x in chain([self.query], self.wrapped_query)]))
 
 
 class ShortIndexLookup(IndexLookup):
     """lookup of the form
     vm = ip::Host(...)
     file = std::File(host=vm, path="/etc/motd", ...)
 
@@ -488,29 +493,31 @@
 
     __slots__ = ("rootobject", "relation", "querypart", "wrapped_querypart")
 
     def __init__(
         self,
         rootobject: ExpressionStatement,
         relation: LocatableString,
-        query: list[tuple[LocatableString, ExpressionStatement]],
-        wrapped_query: list["WrappedKwargs"],
+        query: typing.List[typing.Tuple[LocatableString, ExpressionStatement]],
+        wrapped_query: typing.List["WrappedKwargs"],
     ):
         ReferenceStatement.__init__(self, list(chain((v for (_, v) in query), [rootobject], wrapped_query)))
         self.rootobject = rootobject
         self.relation = str(relation)
-        self.querypart: list[tuple[str, ExpressionStatement]] = [(str(n), e) for n, e in query]
-        self.wrapped_querypart: list["WrappedKwargs"] = wrapped_query
+        self.querypart: typing.List[typing.Tuple[str, ExpressionStatement]] = [(str(n), e) for n, e in query]
+        self.wrapped_querypart: typing.List["WrappedKwargs"] = wrapped_query
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         ReferenceStatement.normalize(self)
         # currently there is no way to get the type of an expression prior to evaluation
         self.type = None
 
-    def resume(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable) -> None:
+    def resume(
+        self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler, target: ResultVariable
+    ) -> None:
         root_object = self.rootobject.execute(requires, resolver, queue)
 
         if not isinstance(root_object, Instance):
             raise TypingException(self, "short index lookup is only possible one objects, %s is not an object" % root_object)
 
         from_entity = root_object.get_type()
 
@@ -537,51 +544,52 @@
             target,
         )
 
     def __repr__(self) -> str:
         """
         The representation of this statement
         """
-        return "{}.{}[{}]".format(
+        return "%s.%s[%s]" % (
             self.rootobject,
             self.relation,
             ",".join(repr(part) for part in chain([self.querypart], self.wrapped_querypart)),
         )
 
 
 class FormattedString(ReferenceStatement):
     """
     This class is an abstraction around a string containing references to variables.
     """
 
-    __slots__ = ("_format_string",)
+    __slots__ = ("_format_string", "_variables")
 
     def __init__(self, format_string: str, variables: abc.Sequence["Reference"]) -> None:
         super().__init__(variables)
         self._format_string = format_string
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("StringFormat.get_node() placeholder for %s" % self).reference()
 
     def __repr__(self) -> str:
-        return "Format(%r)" % self._format_string
+        return "Format(%s)" % self._format_string
 
 
 class StringFormat(FormattedString):
     """
     Create a new string by doing a string interpolation
     """
 
-    __slots__ = ("_variables",)
+    __slots__ = ()
 
-    def __init__(self, format_string: str, variables: abc.Sequence[tuple["Reference", str]]) -> None:
+    def __init__(self, format_string: str, variables: abc.Sequence[Tuple["Reference", str]]) -> None:
         super().__init__(format_string, [k for (k, _) in variables])
         self._variables = variables
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         result_string = self._format_string
         for _var, str_id in self._variables:
             value = _var.execute(requires, resolver, queue)
             if isinstance(value, Unknown):
                 return Unknown(self)
             if isinstance(value, float) and (value - int(value)) == 0:
                 value = int(value)
@@ -591,75 +599,46 @@
         return result_string
 
 
 class FStringFormatter(Formatter):
     def __init__(self) -> None:
         Formatter.__init__(self)
 
-    def get_field(self, key: str, args: abc.Sequence[object], kwargs: abc.Mapping[str, object]) -> tuple[object, str]:
+    def get_field(self, key: str, args: abc.Sequence[object], kwds: abc.Mapping[str, object]) -> Tuple[object, str]:
         """
         Overrides Formatter.get_field. Composite variable names are expected to be resolved at this point and can be
         retrieved by their full name.
-
-        Key is the full string between '{' and '}', e.g. ' a.b.c ' in '{ a.b.c }'. We override this method rather than get_value
-        because we want to leverage the compiler to execute the reference, rather than just to execute the first component
-        ('a'), and let Python handle subsequent components through attribute lookups, as is the default Formatter behavior.
         """
-        # may raise KeyError, which has to be handled by format caller
-        return (kwargs[key], key)
+        return (kwds[key], key)
 
 
 class StringFormatV2(FormattedString):
     """
     Create a new string by using python build in formatting
-
     """
 
-    __slots__ = ("_variables",)
+    __slots__ = ()
 
-    def __init__(self, format_string: str, variables: abc.Sequence[tuple["Reference", str]]) -> None:
-        """
-        :param format_string: The string on which to perform substitution
-        :param variables: Sequence of tuples each holding a normalized reference (i.e. stripped of eventual whitespaces ) to a
-         variable to substitute in the format_string and the raw full name of this variable (i.e. including potential
-         whitespaces).
-        """
+    def __init__(self, format_string: str, variables: abc.Sequence[typing.Tuple["Reference", str]]) -> None:
         only_refs: abc.Sequence["Reference"] = [k for (k, _) in variables]
         super().__init__(format_string, only_refs)
-        self._variables: abc.Mapping[Reference, str] = {ref: full_name for (ref, full_name) in variables}
+        self._variables = only_refs
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: typing.Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         formatter: FStringFormatter = FStringFormatter()
 
         # We can't cache the formatter because it has no ability to cache the parsed string
 
         kwargs = {}
-        for _var, full_name in self._variables.items():
+        for _var in self._variables:
             value = _var.execute(requires, resolver, queue)
             if isinstance(value, Unknown):
                 return Unknown(self)
             if isinstance(value, float) and (value - int(value)) == 0:
                 value = int(value)
-            kwargs[full_name] = value
 
-        try:
-            result_string = formatter.vformat(self._format_string, args=[], kwargs=kwargs)
-        except KeyError as e:
-            key: str = str(e)
-            if key == "'0'":
-                # special-case '{}' (which is valid in Python) with a more informative error message
-                raise RuntimeException(
-                    self, "f-strings do not support positional substitutions via '{}', use variable or attribute keys instead"
-                )
-            # this is probably not reachable in practice, but it might trigger if Python ever changes the '0' key
-            # or the resolution order
-            raise RuntimeException(self, f"Invalid key in f-string: '{key}'")
-        except ValueError as e:
-            raise RuntimeException(self, f"Invalid f-string: {e}")
+            kwargs[_var.full_name] = value
 
-        return result_string
+        result_string = formatter.vformat(self._format_string, args=[], kwargs=kwargs)
 
-    def __repr__(self) -> str:
-        return "StringFormatV2(%r)" % self._format_string
-
-    def __str__(self) -> str:
-        return repr(self._format_string)
+        return result_string
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/statements/call.py` & `inmanta-core-9.3.0/src/inmanta/ast/statements/call.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
     Contact: code@inmanta.com
 """
 
 import logging
 from collections import abc
 from itertools import chain
-from typing import Optional
+from typing import Dict, List, Optional, Tuple
 
 import inmanta.ast.type as InmantaType
 import inmanta.execute.dataflow as dataflow
 from inmanta import plugins
 from inmanta.ast import (
     ExplicitPluginException,
     ExternalException,
@@ -57,55 +57,56 @@
     """
 
     __slots__ = ("name", "arguments", "wrapped_kwargs", "location", "kwargs", "function")
 
     def __init__(
         self,
         name: LocatableString,
-        arguments: list[ExpressionStatement],
-        kwargs: list[tuple[LocatableString, ExpressionStatement]],
-        wrapped_kwargs: list[WrappedKwargs],
+        arguments: List[ExpressionStatement],
+        kwargs: List[Tuple[LocatableString, ExpressionStatement]],
+        wrapped_kwargs: List[WrappedKwargs],
         location: Location,
         namespace: Namespace,
     ) -> None:
         ReferenceStatement.__init__(self, list(chain(arguments, (v for _, v in kwargs), wrapped_kwargs)))
         self.name: LocatableString = name
-        self.arguments: list[ExpressionStatement] = arguments
-        self.wrapped_kwargs: list[WrappedKwargs] = wrapped_kwargs
+        self.arguments: List[ExpressionStatement] = arguments
+        self.wrapped_kwargs: List[WrappedKwargs] = wrapped_kwargs
         self.location: Location = location
         self.namespace: Namespace = namespace
-        self.kwargs: dict[str, ExpressionStatement] = {}
+        self.anchors = [TypeReferenceAnchor(self.namespace, self.name)]
+        self.kwargs: Dict[str, ExpressionStatement] = {}
         for loc_name, expr in kwargs:
             arg_name: str = str(loc_name)
             if arg_name in self.kwargs:
-                raise RuntimeException(self, f"Keyword argument {arg_name} repeated in function call {self.name}()")
+                raise RuntimeException(self, "Keyword argument %s repeated in function call %s()" % (arg_name, self.name))
             self.kwargs[arg_name] = expr
         self.function: Optional[Function] = None
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         ReferenceStatement.normalize(self)
         func = self.namespace.get_type(self.name)
-        self.anchors = [TypeReferenceAnchor(self.namespace, self.name)]
         if isinstance(func, InmantaType.Primitive):
             self.function = Cast(self, func)
         elif isinstance(func, plugins.Plugin):
             self.function = PluginFunction(self, func)
         else:
             raise RuntimeException(self, "Can not call '%s', can only call plugin or primitive type cast" % self.name)
 
     def requires_emit(self, resolver, queue):
-        requires: dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
         sub = ReferenceStatement.requires_emit(self, resolver, queue)
         # add lazy vars
         temp = ResultVariable()
         FunctionUnit(queue, resolver, temp, sub, self)
         requires[self] = temp
         return requires
 
-    def _resolve(self, requires, resolver, queue):
+    def execute(self, requires, resolver, queue):
+        super().execute(requires, resolver, queue)
         return requires[self]
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         arguments = [a.execute_direct(requires) for a in self.arguments]
         kwargs = {k: v.execute_direct(requires) for k, v in self.kwargs.items()}
         for wrapped_kwarg_expr in self.wrapped_kwargs:
             for k, v in wrapped_kwarg_expr.execute_direct(requires):
@@ -127,32 +128,32 @@
                 kwargs[k] = v
         self.function.call_in_context(arguments, kwargs, resolver, queue, result)
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.NodeReference:
         return dataflow.NodeStub("FunctionCall.get_node() placeholder for %s" % self).reference()
 
     def __repr__(self) -> str:
-        return "{}({})".format(
+        return "%s(%s)" % (
             self.name,
             ",".join(
                 chain(
                     (repr(a) for a in self.arguments),
-                    (f"{k}={repr(v)}" for k, v in self.kwargs.items()),
+                    ("%s=%s" % (k, repr(v)) for k, v in self.kwargs.items()),
                     ("%s" % repr(kwargs) for kwargs in self.wrapped_kwargs),
                 )
             ),
         )
 
     def pretty_print(self) -> str:
-        return "{}({})".format(
+        return "%s(%s)" % (
             self.name,
             ",".join(
                 chain(
                     (a.pretty_print() for a in self.arguments),
-                    (f"{k}={v.pretty_print()}" for k, v in self.kwargs.items()),
+                    ("%s=%s" % (k, v.pretty_print()) for k, v in self.kwargs.items()),
                     ("%s" % kwargs.pretty_print() for kwargs in self.wrapped_kwargs),
                 )
             ),
         )
 
 
 class Function:
@@ -173,35 +174,35 @@
 
 
 class Cast(Function):
     def __init__(self, ast_node: FunctionCall, tp: InmantaType.Primitive) -> None:
         Function.__init__(self, ast_node)
         self.type = tp
 
-    def call_direct(self, args: list[object], kwargs: dict[str, object]) -> object:
+    def call_direct(self, args: List[object], kwargs: Dict[str, object]) -> object:
         if len(kwargs) > 0:
             raise RuntimeException(self.ast_node, "Only positional arguments allowed in type cast")
         if len(args) != 1:
             raise RuntimeException(
                 self.ast_node, "Illegal arguments %s: type cast expects exactly 1 argument" % ",".join(map(repr, args))
             )
         return self.type.cast(*args)
 
     def call_in_context(
-        self, args: list[object], kwargs: dict[str, object], resolver: Resolver, queue: QueueScheduler, result: ResultVariable
+        self, args: List[object], kwargs: Dict[str, object], resolver: Resolver, queue: QueueScheduler, result: ResultVariable
     ) -> None:
         result.set_value(self.call_direct(args, kwargs), self.ast_node.location)
 
 
 class PluginFunction(Function):
     def __init__(self, ast_node: FunctionCall, plugin: plugins.Plugin) -> None:
         Function.__init__(self, ast_node)
         self.plugin: plugins.Plugin = plugin
 
-    def call_direct(self, args: list[object], kwargs: dict[str, object]) -> object:
+    def call_direct(self, args: List[object], kwargs: Dict[str, object]) -> object:
         no_unknows = self.plugin.check_args(args, kwargs)
 
         if not no_unknows and not self.plugin.opts["allow_unknown"]:
             raise RuntimeException(self.ast_node, "Received unknown value during direct execution")
 
         if self.plugin._context != -1:
             raise RuntimeException(self.ast_node, "Context Aware functions are not allowed in direct execution")
@@ -219,15 +220,15 @@
                 raise ExplicitPluginException(
                     self.ast_node, "PluginException in direct execution for plugin %s" % self.ast_node.name, e
                 )
             except Exception as e:
                 raise ExternalException(self.ast_node, "Exception in direct execution for plugin %s" % self.ast_node.name, e)
 
     def call_in_context(
-        self, args: list[object], kwargs: dict[str, object], resolver: Resolver, queue: QueueScheduler, result: ResultVariable
+        self, args: List[object], kwargs: Dict[str, object], resolver: Resolver, queue: QueueScheduler, result: ResultVariable
     ) -> None:
         no_unknows = self.plugin.check_args(args, kwargs)
 
         if not no_unknows and not self.plugin.opts["allow_unknown"]:
             result.set_value(Unknown(self), self.ast_node.location)
             return
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/statements/define.py` & `inmanta-core-9.3.0/src/inmanta/ast/statements/define.py`

 * *Files 18% similar despite different names*

```diff
@@ -14,33 +14,31 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 # pylint: disable-msg=R0923,W0613
 
 import logging
+import typing
 import warnings
-from collections.abc import Iterator, Sequence
-from typing import Optional
+from typing import Dict, Iterator, List, Optional, Tuple
 
 from inmanta.ast import (
-    Anchor,
-    AttributeAnchor,
+    AttributeReferenceAnchor,
     CompilerException,
     CompilerRuntimeWarning,
     DuplicateException,
     HyphenException,
     Import,
     IndexException,
     LocatableString,
     Namespace,
     NotFoundException,
     Range,
     RuntimeException,
-    TypeAnchor,
     TypeNotFoundException,
     TypeReferenceAnchor,
     TypingException,
 )
 from inmanta.ast.attribute import Attribute, RelationAttribute
 from inmanta.ast.blocks import BasicBlock
 from inmanta.ast.constraint.expression import Equals
@@ -100,15 +98,15 @@
         name: LocatableString,
         default_value: Optional[ExpressionStatement] = None,
         remove_default: bool = True,
     ) -> None:
         """
         if default_value is None, this is an explicit removal of a default value
         """
-        super().__init__()
+        super(DefineAttribute, self).__init__()
         if "-" in name.value:
             raise HyphenException(name)
         self.type = attr_type
         self.name = name
         self.default = default_value
         self.remove_default = remove_default
 
@@ -124,29 +122,30 @@
     type: Entity
 
     def __init__(
         self,
         namespace: Namespace,
         lname: LocatableString,
         comment: Optional[LocatableString],
-        parents: list[LocatableString],
-        attributes: list[DefineAttribute],
+        parents: List[LocatableString],
+        attributes: List[DefineAttribute],
     ) -> None:
         name = str(lname)
         TypeDefinitionStatement.__init__(self, namespace, name)
         if "-" in name:
             raise HyphenException(lname)
 
+        self.anchors = [TypeReferenceAnchor(namespace, x) for x in parents]
+
         self.name = name
         self.attributes = attributes
         if comment is not None:
             self.comment = str(comment)
 
         self.parents = parents
-        self.anchors = [TypeReferenceAnchor(self.namespace, x) for x in self.parents]
 
         if len(self.parents) == 0 and not (self.name == "Entity" and self.namespace.name == "std"):
             dummy_location: Range = Range("__internal__", 1, 1, 1, 1)
             self.parents.append(LocatableString("std::Entity", dummy_location, -1, namespace))
 
         self.type = Entity(self.name, namespace, self.comment)
         self.type.location = lname.location
@@ -161,18 +160,18 @@
 
     def __repr__(self) -> str:
         """
         A textual representation of this entity
         """
         return "Entity(%s)" % self.name
 
-    def get_full_parent_names(self) -> list[str]:
+    def get_full_parent_names(self) -> List[str]:
         def resolve_parent(parent: LocatableString) -> str:
             ptype = self.namespace.get_type(parent)
-            assert isinstance(ptype, Entity), f"Parents of entities should be entities, but {parent} is a {type(ptype)}"
+            assert isinstance(ptype, Entity), "Parents of entities should be entities, but %s is a %s" % (parent, type(ptype))
             return ptype.get_full_name()
 
         try:
             return [resolve_parent(parent) for parent in self.parents]
         except TypeNotFoundException as e:
             e.set_statement(self)
             raise e
@@ -181,15 +180,15 @@
         """
         Evaluate this statement.
         """
         try:
             entity_type = self.type
             entity_type.comment = self.comment
 
-            add_attributes: dict[str, Attribute] = {}
+            add_attributes: Dict[str, Attribute] = {}
             attribute: DefineAttribute
             for attribute in self.attributes:
                 attr_type: Type = attribute.type.get_type(self.namespace)
                 if not isinstance(attr_type, (Type, type)):
                     raise TypingException(self, "Attributes can only be a type. Entities need to be defined as relations.")
 
                 name = str(attribute.name)
@@ -273,46 +272,39 @@
         if comment is not None:
             self.comment = str(comment)
 
         self.location = name.get_location()
 
         self.type = Implementation(str(self.name), self.block, self.namespace, str(target_type), self.comment)
         self.type.location = name.get_location()
+        self.anchors = [TypeReferenceAnchor(namespace, target_type)]
+        self.anchors.extend(statements.get_anchors())
 
     def __repr__(self) -> str:
         """
         The representation of this implementation
         """
         return "Implementation(%s)" % self.name
 
     def evaluate(self) -> None:
         """
         Evaluate this statement in the given scope
         """
         try:
             cls = self.namespace.get_type(self.entity)
-            self.anchors = [TypeAnchor(self.entity, cls)]
             if not isinstance(cls, Entity):
-                raise TypingException(self, f"Implementation can only be define for an Entity, but {self.entity} is a {cls}")
+                raise TypingException(
+                    self, "Implementation can only be define for an Entity, but %s is a %s" % (self.entity, cls)
+                )
             self.type.set_type(cls)
             self.copy_location(self.type)
         except TypeNotFoundException as e:
             e.set_statement(self)
             raise e
 
-    def get_anchors(self) -> list[Anchor]:
-        """
-        This method overrides the default get_anchors() to accommodate the two-stage normalization process.
-        DefineImplementations register anchors for their blocks. However, these anchors only come into existence
-        after the type normalization phase.
-        This implementation ensures that anchors are correctly gathered from both the type statements and
-        the block itself.
-        """
-        return [*self.type.statements.get_anchors(), *self.anchors]
-
     def nested_blocks(self) -> Iterator["BasicBlock"]:
         """
         Returns an iterator over blocks contained within this statement.
         """
         yield self.block
 
 
@@ -327,57 +319,51 @@
     """
 
     comment: Optional[str] = None
 
     def __init__(
         self,
         entity_name: LocatableString,
-        implementations: list[LocatableString],
+        implementations: List[LocatableString],
         select: ExpressionStatement,
         inherit: bool = False,
         comment: Optional[LocatableString] = None,
     ) -> None:
         DefinitionStatement.__init__(self)
         self.entity = entity_name
         self.entity_location = entity_name.get_location()
         self.implementations = implementations
+        self.anchors = [TypeReferenceAnchor(x.namespace, x) for x in implementations]
+        self.anchors.append(TypeReferenceAnchor(entity_name.namespace, entity_name))
+        self.anchors.extend(select.get_anchors())
         self.location = entity_name.get_location()
         if inherit and (not isinstance(select, Literal) or select.value is not True):
             raise RuntimeException(self, "Conditional implementation with parents not allowed")
         self.select = select
         self.inherit: bool = inherit
         if comment is not None:
             self.comment = str(comment)
 
     def __repr__(self) -> str:
         """
         Returns a representation of this class
         """
         return "Implement(%s)" % (self.entity)
 
-    def get_anchors(self) -> list[Anchor]:
-        """
-        This method overrides the default get_anchors() to accommodate the two-stage normalization process.
-        DefineImplement should register anchors for an ExpressionStatement. This one is not yet normalized during
-        evaluation and so its anchors come into existence only after the type normalization phase.
-        This implementation ensures that anchors are also correctly gathered from the type statement.
-        """
-        return [*self.anchors, *self.select.get_anchors()]
-
     def evaluate(self) -> None:
         """
         Evaluate this statement.
         """
         try:
             entity_type = self.namespace.get_type(self.entity)
+
             if not isinstance(entity_type, Entity):
                 raise TypingException(
-                    self, f"Implementation can only be define for an Entity, but {self.entity} is a {entity_type}"
+                    self, "Implementation can only be define for an Entity, but %s is a %s" % (self.entity, entity_type)
                 )
-            self.anchors.append(TypeAnchor(self.entity, entity_type))
 
             # If one implements statement has parent declared, set to true
             entity_type.implements_inherits |= self.inherit
 
             implement = Implement()
             implement.comment = self.comment
             implement.constraint = self.select
@@ -397,15 +383,14 @@
                     raise TypingException(
                         self,
                         "Type mismatch: cannot use %s as implementation for "
                         " %s because its implementing type is %s" % (impl_obj.name, entity_type, impl_obj.entity),
                     )
 
                 # add it
-                self.anchors.append(TypeAnchor(_impl, impl_obj))
                 implement.implementations.append(impl_obj)
 
             entity_type.add_implement(implement)
         except TypeNotFoundException as e:
             e.set_statement(self)
             raise e
 
@@ -424,14 +409,16 @@
 
     def __init__(
         self, namespace: Namespace, name: LocatableString, basetype: LocatableString, expression: ExpressionStatement
     ) -> None:
         TypeDefinitionStatement.__init__(self, namespace, str(name))
         self.set_location(name.get_location())
         self.basetype = basetype
+        self.anchors.append(TypeReferenceAnchor(namespace, basetype))
+        self.anchors.extend(expression.get_anchors())
         self.set_expression(expression)
         self.type = ConstraintType(self.namespace, str(name))
         self.type.location = name.get_location()
         if self.name in TYPES:
             warnings.warn(CompilerRuntimeWarning(self, "Trying to override a built-in type: %s" % self.name))
         if "-" in self.name:
             raise HyphenException(name)
@@ -472,57 +459,59 @@
         return "Type(%s)" % self.name
 
     def evaluate(self) -> None:
         """
         Evaluate this statement.
         """
         basetype = self.namespace.get_type(self.basetype)
-        self.anchors.append(TypeAnchor(self.basetype, basetype))
 
         constraint_type = self.type
 
         constraint_type.comment = self.comment
         constraint_type.basetype = basetype
         constraint_type.constraint = self.expression
         self.expression.normalize()
-        self.anchors.extend(self.expression.get_anchors())
 
 
-Relationside = tuple[LocatableString, Optional[LocatableString], Optional[tuple[int, Optional[int]]]]
+Relationside = Tuple[LocatableString, Optional[LocatableString], Optional[Tuple[int, Optional[int]]]]
 
 
 class DefineRelation(BiStatement):
     """
     Define a relation
     """
 
-    annotation_expression: list[tuple[ResultVariable, ExpressionStatement]]
+    annotation_expression: List[Tuple[ResultVariable, ExpressionStatement]]
 
-    def __init__(self, left: Relationside, right: Relationside, annotations: list[ExpressionStatement] = []) -> None:
+    def __init__(self, left: Relationside, right: Relationside, annotations: List[ExpressionStatement] = []) -> None:
         DefinitionStatement.__init__(self)
         if "-" in str(right[1]):
             raise HyphenException(right[1])
 
         if "-" in str(left[1]):
             raise HyphenException(left[1])
         # for later evaluation
         self.annotation_expression = [(ResultVariable(), exp) for exp in annotations]
         # for access to results
         self.annotations = [exp[0] for exp in self.annotation_expression]
 
+        self.anchors.extend((y for x in annotations for y in x.get_anchors()))
+        self.anchors.append(TypeReferenceAnchor(left[0].namespace, left[0]))
+        self.anchors.append(TypeReferenceAnchor(right[0].namespace, right[0]))
+
         self.left: Relationside = left
         self.right: Relationside = right
 
         self.comment = None
 
     def __repr__(self) -> str:
         """
         The represenation of this relation
         """
-        return f"Relation({self.left[0]}, {self.right[0]})"
+        return "Relation(%s, %s)" % (self.left[0], self.right[0])
 
     def evaluate(self) -> None:
         """
         Add this relation to the participating ends
         """
         try:
             left = self.namespace.get_type(self.left[0])
@@ -575,81 +564,74 @@
         for rv, exp in self.annotation_expression:
             reqs = exp.requires_emit(resolver, queue)
             ExecutionUnit(queue, resolver, rv, reqs, exp)
 
     def normalize(self) -> None:
         for _, exp in self.annotation_expression:
             exp.normalize()
-            self.anchors.extend(exp.get_anchors())
-
-        self.anchors.append(TypeReferenceAnchor(self.left[0].namespace, self.left[0]))
-        self.anchors.append(TypeReferenceAnchor(self.right[0].namespace, self.right[0]))
 
 
 class DefineIndex(DefinitionStatement):
     """
     This defines an index over attributes in an entity
     """
 
-    def __init__(self, entity_type: LocatableString, attributes: list[LocatableString]):
+    def __init__(self, entity_type: LocatableString, attributes: List[LocatableString]):
         DefinitionStatement.__init__(self)
         self.type = entity_type
-        self.attributes: Sequence[LocatableString] = attributes
+        self.attributes = [str(a) for a in attributes]
+        self.anchors.append(TypeReferenceAnchor(entity_type.namespace, entity_type))
+        self.anchors.extend(
+            [AttributeReferenceAnchor(x.get_location(), entity_type.namespace, entity_type, str(x)) for x in attributes]
+        )
 
-    def types(self, recursive: bool = False) -> list[tuple[str, LocatableString]]:
+    def types(self, recursive: bool = False) -> List[Tuple[str, LocatableString]]:
         """
         @see Statement#types
         """
         return [("type", self.type)]
 
     def __repr__(self) -> str:
-        return "index {}({})".format(self.type, ", ".join([str(a) for a in self.attributes]))
+        return "index %s(%s)" % (self.type, ", ".join(self.attributes))
 
     def evaluate(self) -> None:
         """
         Add the index to the entity
         """
         entity_type = self.namespace.get_type(self.type)
         assert isinstance(entity_type, Entity), "%s is not an entity" % entity_type
-        self.anchors.append(TypeAnchor(self.type, entity_type))
 
         allattributes = entity_type.get_all_attribute_names()
         for attribute in self.attributes:
-            str_attribute = str(attribute)
-            if str_attribute not in allattributes:
+            if attribute not in allattributes:
                 raise NotFoundException(
-                    self,
-                    str_attribute,
-                    f"Attribute '{str_attribute}' referenced in index is not defined in entity {entity_type}",
+                    self, attribute, "Attribute '%s' referenced in index is not defined in entity %s" % (attribute, entity_type)
                 )
             else:
-                rattribute = entity_type.get_attribute(str_attribute)
-                self.anchors.append(AttributeAnchor(attribute.get_location(), rattribute))
+                rattribute = entity_type.get_attribute(attribute)
                 assert rattribute is not None  # Make mypy happy
                 if rattribute.is_optional():
                     raise IndexException(
                         self,
-                        "Index can not contain optional attributes, Attribute ' %s.%s' is optional"
-                        % (str_attribute, entity_type),
+                        "Index can not contain optional attributes, Attribute ' %s.%s' is optional" % (attribute, entity_type),
                     )
                 if rattribute.is_multi():
                     raise IndexException(
-                        self,
-                        f"Index can not contain list attributes, Attribute ' {str_attribute}.{entity_type}' is a list",
+                        self, "Index can not contain list attributes, Attribute ' %s.%s' is a list" % (attribute, entity_type)
                     )
 
-        entity_type.add_index([str(a) for a in self.attributes])
+        entity_type.add_index(self.attributes)
 
 
 class PluginStatement(TypeDefinitionStatement):
     """
     This statement defines a plugin function
     """
 
-    def __init__(self, namespace: Namespace, name: str, function_class: type[Plugin]) -> None:
+    def __init__(self, namespace: Namespace, name: str, function_class: typing.Type[Plugin]) -> None:
         TypeDefinitionStatement.__init__(self, namespace, name)
         self._name = name
         self._function_class = function_class
         self.type = self._function_class(namespace)
 
     def __repr__(self) -> str:
         """
@@ -657,14 +639,15 @@
         """
         return "Function(%s)" % self._name
 
     def evaluate(self) -> None:
         """
         Evaluate this plugin
         """
+        pass
 
 
 class DefineImport(TypeDefinitionStatement, Import):
     def __init__(self, name: LocatableString, toname: LocatableString) -> None:
         DefinitionStatement.__init__(self)
         self.name = str(name)
         if "-" in self.name:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/statements/generator.py` & `inmanta-core-9.3.0/src/inmanta/ast/statements/generator.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,35 +18,34 @@
 
 # pylint: disable-msg=W0613,R0201
 
 import itertools
 import logging
 import uuid
 from collections import abc
-from collections.abc import Iterator
 from itertools import chain
-from typing import Optional, Union
+from typing import Dict, Iterator, List, Optional, Tuple, Union
 
 import inmanta.ast.entity
 import inmanta.ast.type as inmanta_type
 import inmanta.execute.dataflow as dataflow
 from inmanta.ast import (
     AmbiguousTypeException,
-    AttributeAnchor,
+    AttributeReferenceAnchor,
     DuplicateException,
     InvalidCompilerState,
     Locatable,
     LocatableString,
     Location,
     Namespace,
     NotFoundException,
     Range,
     RuntimeException,
-    TypeAnchor,
     TypeNotFoundException,
+    TypeReferenceAnchor,
     TypingException,
 )
 from inmanta.ast.attribute import Attribute, RelationAttribute
 from inmanta.ast.blocks import BasicBlock
 from inmanta.ast.statements import (
     AttributeAssignmentLHS,
     ExpressionStatement,
@@ -83,15 +82,15 @@
 
 if TYPE_CHECKING:
     from inmanta.ast.entity import Entity, Implement  # noqa: F401
 
 LOGGER = logging.getLogger(__name__)
 
 
-class SubConstructor(RequiresEmitStatement):
+class SubConstructor(ExpressionStatement):
     """
     This statement selects an implementation for a given object and
     imports the statements
 
     :ivar type: The specific entity type of an instance this subconstructor applies to, i.e. the actual instance type, not a
         supertype.
     """
@@ -116,37 +115,38 @@
         #     # the boundary we translate references so that they are resolved correctly in any context wrapping the constructor
         #     dataclasses.replace(promise, instance=promise.instance.fully_qualified())
         #     for implementation in self.implements.implementations
         #     for promise in implementation.statements.get_eager_promises()
         #     if promise.get_root_variable() not in injected_variables
         # ]
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC[object]]:
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
         try:
             resv = resolver.for_namespace(self.implements.constraint.namespace)
             requires.update(self.implements.constraint.requires_emit(resv, queue))
             return requires
         except NotFoundException as e:
             e.set_statement(self.implements)
             raise e
 
-    def execute(self, requires: dict[object, object], instance: Instance, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], instance: Instance, queue: QueueScheduler) -> object:
         """
         Evaluate this statement
         """
         LOGGER.log(LOG_LEVEL_TRACE, "executing subconstructor for %s implement %s", self.type, self.implements.location)
         super().execute(requires, instance, queue)
         # this assertion is because the typing of this method is not correct
         # it should logically always hold, but we can't express this as types yet
         assert isinstance(instance, Instance)
         condition = self.implements.constraint.execute(requires, instance, queue)
         try:
             inmanta_type.Bool().validate(condition)
         except RuntimeException as e:
+            e.set_statement(self.implements)
             e.msg = (
                 "Invalid value `%s`: the condition for a conditional implementation can only be a boolean expression"
                 % condition
             )
             raise e
         if not condition:
             return None
@@ -160,15 +160,15 @@
                 # generate a subscope/namespace for each loop
                 xc = ExecutionContext(impl.statements, instance.for_namespace(impl.statements.namespace))
                 xc.emit(myqueue)
 
         return None
 
     def pretty_print(self) -> str:
-        return "implement {} using {} when {}".format(
+        return "implement %s using %s when %s" % (
             self.type,
             ",".join(i.name for i in self.implements.implementations),
             self.implements.constraint.pretty_print(),
         )
 
     def __str__(self) -> str:
         return self.pretty_print()
@@ -183,17 +183,14 @@
     def __init__(self, stmt: "For", resolver: Resolver, queue: QueueScheduler) -> None:
         self.resolver = resolver
         self.queue = queue
         self.stmt = stmt
         self.seen: set[int] = set()
 
     def receive_result(self, value: object, location: Location) -> bool:
-        if isinstance(value, Unknown):
-            # skip unknowns
-            return False
         if id(value) in self.seen:
             return False
         self.seen.add(id(value))
 
         xc = ExecutionContext(self.stmt.module, self.resolver.for_namespace(self.stmt.module.namespace))
         loopvar = xc.lookup(self.stmt.loop_var)
         # this assertion is because the typing of this method is not correct
@@ -213,57 +210,61 @@
 
     def __init__(self, variable: ExpressionStatement, loop_var: LocatableString, module: BasicBlock) -> None:
         super().__init__()
         self.base: ExpressionStatement = variable
         self.loop_var = str(loop_var)
         self.loop_var_loc = loop_var.get_location()
         self.module = module
+        self.anchors.extend(module.get_anchors())
+        self.anchors.extend(variable.get_anchors())
 
     def __repr__(self) -> str:
         return "For(%s)" % self.loop_var
 
     def normalize(self) -> None:
         self.base.normalize()
         # self.loop_var.normalize(resolver)
         self.module.normalize()
-        self.anchors.extend(self.base.get_anchors())
-        self.anchors.extend(self.module.get_anchors())
         self.module.add_var(self.loop_var, self)
         self._own_eager_promises = self.module.get_eager_promises()
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(super().get_all_eager_promises(), self.base.get_all_eager_promises())
 
     def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
 
         # pass context via requires!
         helper = GradualFor(self, resolver, queue)
         requires[self] = WrappedValueVariable(helper)
 
         requires.update(self.base.requires_emit_gradual(resolver, queue, helper))
 
         return requires
 
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         """
         Evaluate this statement.
         """
         super().execute(requires, resolver, queue)
         var = self.base.execute(requires, resolver, queue)
 
-        if not isinstance(var, (list, Unknown)):
-            msg = "A for loop can only be applied to lists and relations."
-            if isinstance(self.base, Reference):
-                msg += " Hint: '%s' resolves to '%s'." % (self.base, str(var))
-            else:
-                msg += " Hint: '%s' is not a list." % str(var)
-            raise TypingException(self, msg)
+        if isinstance(var, Unknown):
+            return None
+
+        if not isinstance(var, list):
+            raise TypingException(self, "A for loop can only be applied to lists and relations")
+
+        helper = requires[self]
+        assert isinstance(helper, GradualFor)
+
+        for loop_var in var:
+            # generate a subscope/namespace for each loop
+            helper.receive_result(loop_var, self.location)
 
-        # we're done here: base's execute has reported results to helper
         return None
 
     def nested_blocks(self) -> Iterator["BasicBlock"]:
         yield self.module
 
 
 class ListComprehension(RawResumer, ExpressionStatement):
@@ -281,28 +282,28 @@
         guard: Optional[ExpressionStatement] = None,
     ) -> None:
         super().__init__()
         self.value_expression: ExpressionStatement = value_expression
         self.loop_var: LocatableString = loop_var
         self.iterable: ExpressionStatement = iterable
         self.guard: Optional[ExpressionStatement] = guard
-
-    def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
-        self.value_expression.normalize(lhs_attribute=lhs_attribute)
-        self.iterable.normalize()
-        if self.guard is not None:
-            self.guard.normalize()
         self.anchors.extend(
             itertools.chain(
                 self.value_expression.get_anchors(),
                 self.iterable.get_anchors(),
                 (self.guard.get_anchors() if self.guard is not None else ()),
             )
         )
 
+    def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
+        self.value_expression.normalize(lhs_attribute=lhs_attribute)
+        self.iterable.normalize()
+        if self.guard is not None:
+            self.guard.normalize()
+
     def requires(self) -> list[str]:
         # exclude loop var, unless it shadows an occurrence in iterable
         return list(set(self.value_expression.requires()) - {str(self.loop_var)} | set(self.iterable.requires()))
 
     def requires_emit(
         self, resolver: Resolver, queue: QueueScheduler, *, lhs: Optional[ResultCollector[object]] = None
     ) -> dict[object, VariableABC[object]]:
@@ -368,15 +369,16 @@
         elif not isinstance(iterable, list):
             raise TypingException(
                 self, f"A list comprehension can only be applied to lists and relations, got {type(iterable).__name__}"
             )
         else:
             collector_helper.complete(iterable, resolver, queue)
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         # at this point the resumer signalled the helper we were done and the helper waited for all value expressions
         # => just fetch the result
         return requires[self]
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> Union[list[object], Unknown]:
         iterable: object = self.iterable.execute_direct(requires)
         if isinstance(iterable, Unknown):
@@ -413,57 +415,38 @@
                 guard_passed = guard_value
 
             return self.value_expression.execute_direct(extended_requires) if guard_passed else None
 
         return [result for element in iterable if (result := process(element)) is not None]
 
     def pretty_print(self) -> str:
-        return "[{} for {} in {}{}]".format(
+        return "[%s for %s in %s%s]" % (
             self.value_expression.pretty_print(),
             self.loop_var,
             self.iterable.pretty_print(),
             f" if {self.guard.pretty_print()}" if self.guard is not None else "",
         )
 
     def __str__(self) -> str:
         return self.pretty_print()
 
     def __repr__(self) -> str:
-        return "ListComprehension(value_expression={}, loop_var={}, iterable={}, guard={})".format(
+        return "ListComprehension(value_expression=%s, loop_var=%s, iterable=%s, guard=%s)" % (
             repr(self.value_expression),
             repr(self.loop_var),
             repr(self.iterable),
             repr(self.guard),
         )
 
 
-class ListComprehensionGuard(Literal):
-    """
-    Representation of the else expression for a list comprehension guard. This statement is an expression in the sense that
-    it behaves like one but its return value represents that a subexpression should be filtered out rather than an actual
-    DSL-compatible value. This special value must always be caught by the statement that creates the guard. This expression
-    must never be exposed directly in the DSL.
-    """
-
-    __slots__ = ()
-
-    GUARD = object()
-    """
-    Artificial value used in the else branch of the list comprehension guard's conditional expression. Indicates that the value
-    expression for an element should not be executed because the element was filtered by the guard.
-    """
-
-    def __init__(self) -> None:
-        super().__init__(self.GUARD)
-
-    def requires_emit_gradual(
-        self, resolver: Resolver, queue: QueueScheduler, resultcollector: ResultCollector[object]
-    ) -> dict[object, VariableABC[object]]:
-        # this statement represents the absence of a result => don't pass on resultcollector
-        return self.requires_emit(resolver, queue)
+LIST_COMPREHENSION_GUARDED = object()
+"""
+Artificial value used in the else branch of the list comprehension guard's conditional expression. Indicates that the value
+expression for an element should not be executed because the element was filtered by the guard.
+"""
 
 
 class ListComprehensionCollector(RawResumer, ResultCollector[object]):
     """
     Result collector (gradual or otherwise) for the list comprehension statement. When it receives a
     result, it sets up appropriate (gradual or otherwise) execution for the value expression, with the lhs as final result
     collector. Finally, it collects all final results in its own result variable for non-gradual execution.
@@ -514,32 +497,24 @@
             name=str(self.statement.loop_var),
             variable=value_wrapper,
         )
 
         result_variable: ResultVariable[object] = ResultVariable()
         self._results.append(result_variable)
 
-        # propagate unknowns without executing value expression while still allowing to filter them out with the guard
-        value_expression: ExpressionStatement
-        if isinstance(value, Unknown):
-            value_expression = Literal(value)
-            self.statement.copy_location(value_expression)
-        else:
-            value_expression = self.statement.value_expression
-
         # execute the value expression and the guard
         guarded_expression: ExpressionStatement
         if self.statement.guard is None:
-            guarded_expression = value_expression
+            guarded_expression = self.statement.value_expression
         else:
-            else_expression: ExpressionStatement = ListComprehensionGuard()
+            else_expression: ExpressionStatement = Literal(LIST_COMPREHENSION_GUARDED)
             guarded_expression = ConditionalExpression(
                 condition=self.statement.guard,
-                if_expression=value_expression,
-                else_expression=else_expression,
+                if_expression=self.statement.value_expression,
+                else_expression=Literal(LIST_COMPREHENSION_GUARDED),
             )
             self.statement.copy_location(else_expression)
             self.statement.copy_location(guarded_expression)
 
         requires: dict[object, VariableABC[object]] = (
             guarded_expression.requires_emit(value_resolver, self.queue)
             if self.lhs is None
@@ -556,42 +531,41 @@
         return False
 
     def set_unknown(self) -> None:
         """
         Set the final result to be an unknown. No elements should be gradually received in this case.
         Mutually exclusive with `complete`.
         """
-        if self._results and not all(isinstance(result, Unknown) for result in self._results):
+        if self._results:
             raise InvalidCompilerState(
                 self, "list comprehension helper got set_unknown after some (known) elements where received"
             )
         self.final_result.set_value(Unknown(self.statement), self.statement.location)
 
     def complete(self, all_values: abc.Sequence[object], resolver: Resolver, queue: QueueScheduler) -> None:
         """
         Indicate that all results have been received. No further calls to `receive_result` should be done after this.
         Mutually exclusive with `set_unknown`.
         """
         if self._results:
+            # We should only have received previous results in gradual mode, if the
             if self.lhs is None:
-                # We should only have received previous results in gradual mode, if any gradual results were received in
-                # non-gradual mode, this indicates a bug in the compiler, likely in this class
                 raise InvalidCompilerState(self, "list comprehension helper received gradual results in non-gradual mode")
             if len(self._results) != len(all_values):
                 raise InvalidCompilerState(self, "list comprehension helper received some but not all values gradually")
         else:
             for value in all_values:
                 self.receive_result(value, location=self.statement.location)
 
         RawUnit(queue, resolver, dict(enumerate(self._results)), resumer=self)
 
     def resume(self, requires: dict[object, VariableABC[object]], resolver: Resolver, queue: QueueScheduler) -> None:
         def get(variable: VariableABC[object]) -> Optional[abc.Sequence[object]]:
             value: object = variable.get_value()
-            return None if value is ListComprehensionGuard.GUARD else value if isinstance(value, list) else [value]
+            return None if value is LIST_COMPREHENSION_GUARDED else value if isinstance(value, list) else [value]
 
         # collect all element value expressions' results and write them to the final result variable
         self.final_result.set_value(
             list(
                 itertools.chain.from_iterable(value for variable in requires.values() if (value := get(variable)) is not None)
             ),
             self.statement.location,
@@ -606,36 +580,36 @@
     __slots__ = ("condition", "if_branch", "else_branch")
 
     def __init__(self, condition: ExpressionStatement, if_branch: BasicBlock, else_branch: BasicBlock) -> None:
         super().__init__()
         self.condition: ExpressionStatement = condition
         self.if_branch: BasicBlock = if_branch
         self.else_branch: BasicBlock = else_branch
+        self.anchors.extend(condition.get_anchors())
+        self.anchors.extend(if_branch.get_anchors())
+        self.anchors.extend(else_branch.get_anchors())
 
     def __repr__(self) -> str:
         return "If"
 
     def normalize(self) -> None:
         self.condition.normalize()
         self.if_branch.normalize()
         self.else_branch.normalize()
-        self.anchors.extend(self.condition.get_anchors())
-        self.anchors.extend(self.if_branch.get_anchors())
-        self.anchors.extend(self.else_branch.get_anchors())
         self._own_eager_promises = [*self.if_branch.get_eager_promises(), *self.else_branch.get_eager_promises()]
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(super().get_all_eager_promises(), self.condition.get_all_eager_promises())
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC[object]]:
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
         requires.update(self.condition.requires_emit(resolver, queue))
         return requires
 
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         """
         Evaluate this statement.
         """
         super().execute(requires, resolver, queue)
         cond: object = self.condition.execute(requires, resolver, queue)
         if isinstance(cond, Unknown):
             return None
@@ -666,106 +640,104 @@
     def __init__(
         self, condition: ExpressionStatement, if_expression: ExpressionStatement, else_expression: ExpressionStatement
     ) -> None:
         super().__init__()
         self.condition: ExpressionStatement = condition
         self.if_expression: ExpressionStatement = if_expression
         self.else_expression: ExpressionStatement = else_expression
+        self.anchors.extend(condition.get_anchors())
+        self.anchors.extend(if_expression.get_anchors())
+        self.anchors.extend(else_expression.get_anchors())
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         self.condition.normalize()
         # pass on lhs_attribute to branches
         self.if_expression.normalize(lhs_attribute=lhs_attribute)
         self.else_expression.normalize(lhs_attribute=lhs_attribute)
-        self.anchors.extend(self.condition.get_anchors())
-        self.anchors.extend(self.if_expression.get_anchors())
-        self.anchors.extend(self.else_expression.get_anchors())
         self._own_eager_promises = [
             *self.if_expression.get_all_eager_promises(),
             *self.else_expression.get_all_eager_promises(),
         ]
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(super().get_all_eager_promises(), self.condition.get_all_eager_promises())
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return list(chain.from_iterable(sub.requires() for sub in [self.condition, self.if_expression, self.else_expression]))
 
     def requires_emit(
         self, resolver: Resolver, queue: QueueScheduler, *, lhs: Optional[ResultCollector[object]] = None
     ) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
 
         # This ResultVariable will receive the result of this expression
         result: ResultVariable[object] = ResultVariable()
 
         # Schedule execution to resume when the condition can be executed
         resumer: RawResumer = ConditionalExpressionResumer(self, result, lhs=lhs)
         self.copy_location(resumer)
-        RawUnit(queue, resolver, self.condition.requires_emit(resolver, queue), resumer, override_exception_location=False)
+        RawUnit(queue, resolver, self.condition.requires_emit(resolver, queue), resumer)
 
         # Wait for the result variable to be populated
         requires[self] = result
         return requires
 
     def requires_emit_gradual(
         self, resolver: Resolver, queue: QueueScheduler, resultcollector: ResultCollector[object]
     ) -> dict[object, VariableABC[object]]:
         return self.requires_emit(resolver, queue, lhs=resultcollector)
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         return requires[self]
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         condition_value: object = self.condition.execute_direct(requires)
         if isinstance(condition_value, Unknown):
             return Unknown(self)
         if not isinstance(condition_value, bool):
             raise RuntimeException(
-                self,
-                "Invalid value `%s`: the condition for a conditional expression must be a boolean expression" % condition_value,
+                self, "Invalid value `%s`: the condition for a conditional expression must be a boolean expression"
             )
         return (self.if_expression if condition_value else self.else_expression).execute_direct(requires)
 
     def pretty_print(self) -> str:
-        return "{} ? {} : {}".format(
+        return "%s ? %s : %s" % (
             self.condition.pretty_print(),
             self.if_expression.pretty_print(),
             self.else_expression.pretty_print(),
         )
 
     def __repr__(self) -> str:
-        return f"{self.condition} ? {self.if_expression} : {self.else_expression}"
+        return "%s ? %s : %s" % (self.condition, self.if_expression, self.else_expression)
 
 
 class ConditionalExpressionResumer(RawResumer):
     __slots__ = ("expression", "condition_value", "result", "lhs")
 
     def __init__(
         self, expression: ConditionalExpression, result: ResultVariable, *, lhs: Optional[ResultCollector[object]] = None
     ) -> None:
         super().__init__()
         self.expression: ConditionalExpression = expression
         self.condition_value: Optional[bool] = None
         self.result: ResultVariable = result
         self.lhs: Optional[ResultCollector[object]] = lhs
 
-    def resume(self, requires: dict[object, VariableABC[object]], resolver: Resolver, queue: QueueScheduler) -> None:
+    def resume(self, requires: Dict[object, VariableABC[object]], resolver: Resolver, queue: QueueScheduler) -> None:
         if self.condition_value is None:
             condition_value: object = self.expression.condition.execute(
                 {k: v.get_value() for k, v in requires.items()}, resolver, queue
             )
             if isinstance(condition_value, Unknown):
                 self.result.set_value(Unknown(self), self.location)
                 return
             if not isinstance(condition_value, bool):
                 raise RuntimeException(
-                    self.expression,
-                    "Invalid value `%s`: the condition for a conditional expression must be a boolean expression"
-                    % condition_value,
+                    self, "Invalid value `%s`: the condition for a conditional expression must be a boolean expression"
                 )
             self.condition_value = condition_value
 
             # Schedule execution of appropriate subexpression
             subexpression: ExpressionStatement = (
                 self.expression.if_expression if self.condition_value else self.expression.else_expression
             )
@@ -792,15 +764,15 @@
     Raised when an index attribute was not set in the constructor call for an entity.
     """
 
     def __init__(self, stmt: Optional[Locatable], entity: "Entity", unset_attributes: abc.Sequence[str]):
         if not unset_attributes:
             raise Exception("Argument `unset_attributes` should contain at least one element")
         error_message = self._get_error_message(entity, unset_attributes)
-        super().__init__(stmt, error_message)
+        super(IndexAttributeMissingInConstructorException, self).__init__(stmt, error_message)
 
     def _get_error_message(self, entity: "Entity", unset_attributes: abc.Sequence[str]) -> str:
         exc_message = "Invalid Constructor call:"
         for attribute_name in unset_attributes:
             attribute: Optional[Attribute] = entity.get_attribute(attribute_name)
             assert attribute is not None  # Make mypy happy
             attribute_kind = "relation" if isinstance(attribute, RelationAttribute) else "attribute"
@@ -832,70 +804,70 @@
         "_direct_attributes",
         "_indirect_attributes",
     )
 
     def __init__(
         self,
         class_type: LocatableString,
-        attributes: list[tuple[LocatableString, ExpressionStatement]],
-        wrapped_kwargs: list["WrappedKwargs"],
+        attributes: List[Tuple[LocatableString, ExpressionStatement]],
+        wrapped_kwargs: List["WrappedKwargs"],
         location: Location,
         namespace: Namespace,
     ) -> None:
         super().__init__()
         self.class_type = class_type
-        self.__attributes: dict[str, ExpressionStatement] = {}
-        self.__attribute_locations: dict[str, LocatableString] = {}
-        self.__wrapped_kwarg_attributes: list[WrappedKwargs] = wrapped_kwargs
+        self.__attributes = {}  # type: Dict[str,ExpressionStatement]
+        self.__attribute_locations: Dict[str, LocatableString] = {}
+        self.__wrapped_kwarg_attributes: List[WrappedKwargs] = wrapped_kwargs
         self.location = location
         self.namespace = namespace
+        self.anchors.append(TypeReferenceAnchor(namespace, class_type))
         for a in attributes:
             self.add_attribute(a[0], a[1])
         self.type: Optional["Entity"] = None
         self._self_ref: "Reference" = Reference(
             LocatableString(str(uuid.uuid4()), Range("__internal__", 1, 1, 1, 1), -1, self.namespace)
         )
         self._lhs_attribute: Optional[AttributeAssignmentLHS] = None
         self._required_dynamic_args: list[str] = []  # index attributes required from kwargs or lhs_attribute
 
-        self._direct_attributes: dict[str, ExpressionStatement] = {}
-        self._indirect_attributes: dict[str, ExpressionStatement] = {}
+        self._direct_attributes = {}  # type: Dict[str,ExpressionStatement]
+        self._indirect_attributes = {}  # type: Dict[str,ExpressionStatement]
 
     def pretty_print(self) -> str:
-        return "{}({})".format(
+        return "%s(%s)" % (
             self.class_type,
             ",".join(
                 chain(
-                    (f"{k}={v.pretty_print()}" for k, v in self.attributes.items()),
+                    ("%s=%s" % (k, v.pretty_print()) for k, v in self.attributes.items()),
                     ("**%s" % kwargs.pretty_print() for kwargs in self.wrapped_kwargs),
                 )
             ),
         )
 
     def _normalize_rhs(self, index_attributes: abc.Set[str]) -> None:
         assert self.type is not None  # Make mypy happy
         for k, v in self.__attributes.items():
             attr = self.type.get_attribute(k)
             if attr is None:
-                raise TypingException(self.__attribute_locations[k], f"no attribute {k} on type {self.type.get_full_name()}")
+                raise TypingException(
+                    self.__attribute_locations[k], "no attribute %s on type %s" % (k, self.type.get_full_name())
+                )
             type_hint = attr.get_type().get_base_type()
             # don't notify the rhs for index attributes because it won't be able to resolve the reference
             # (index attributes need to be resolved before the instance can be constructed)
             v.normalize(
                 lhs_attribute=AttributeAssignmentLHS(self._self_ref, k, type_hint) if k not in index_attributes else None
             )
-            self.anchors.extend(v.get_anchors())
-            self.anchors.append(AttributeAnchor(self.__attribute_locations[k].get_location(), attr))
-
         for wrapped_kwargs in self.wrapped_kwargs:
             wrapped_kwargs.normalize()
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         self.type = self._resolve_type(lhs_attribute)
-        self.anchors.append(TypeAnchor(self.class_type, self.type))
+
         inindex: abc.MutableSet[str] = set()
 
         all_attributes = dict(self.type.get_default_values())
         all_attributes.update(self.__attributes)
 
         # now check that all variables that have indexes on them, are already
         # defined and add the instance to the index
@@ -917,15 +889,17 @@
                 raise IndexAttributeMissingInConstructorException(self, self.type, self._required_dynamic_args)
 
         self._normalize_rhs(inindex)
 
         for k, v in all_attributes.items():
             attribute = self.type.get_attribute(k)
             if attribute is None:
-                raise TypingException(self.__attribute_locations[k], f"no attribute {k} on type {self.type.get_full_name()}")
+                raise TypingException(
+                    self.__attribute_locations[k], "no attribute %s on type %s" % (k, self.type.get_full_name())
+                )
             if k not in inindex:
                 self._indirect_attributes[k] = v
             else:
                 self._direct_attributes[k] = v
 
         self._own_eager_promises = list(
             chain.from_iterable(subconstructor.get_all_eager_promises() for subconstructor in self.type.get_sub_constructor())
@@ -991,22 +965,22 @@
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(
             super().get_all_eager_promises(),
             *(subexpr.get_all_eager_promises() for subexpr in chain(self.attributes.values(), self.wrapped_kwargs)),
         )
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         out = [req for (k, v) in self.__attributes.items() for req in v.requires()]
         out.extend(req for kwargs in self.__wrapped_kwarg_attributes for req in kwargs.requires())
         out.extend(req for (k, v) in self.get_default_values().items() for req in v.requires())
         return out
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC[object]]:
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
         # direct
         direct = [x for x in self._direct_attributes.items()]
 
         direct_requires = {rk: rv for (k, v) in direct for (rk, rv) in v.requires_emit(resolver, queue).items()}
         direct_requires.update(
             {rk: rv for kwargs in self.__wrapped_kwarg_attributes for (rk, rv) in kwargs.requires_emit(resolver, queue).items()}
         )
@@ -1026,34 +1000,34 @@
             # TODO: also add wrapped_kwargs
             for k, v in chain(self._direct_attributes.items(), self._indirect_attributes.items()):
                 node.assign_attribute(k, v.get_dataflow_node(graph), self, graph)
 
         return requires
 
     def _collect_required_dynamic_arguments(
-        self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler
+        self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler
     ) -> abc.Mapping[str, object]:
         """
         Part of the execute flow: returns values for kwargs and the inverse relation derived from the lhs for which this
         constructor is the rhs, if appliccable.
         """
         type_class = self.type
         assert type_class
 
         # kwargs
         kwarg_attrs: dict[str, object] = {}
         for kwargs in self.wrapped_kwargs:
             for k, v in kwargs.execute(requires, resolver, queue):
                 if k in self.attributes or k in kwarg_attrs:
                     raise RuntimeException(
-                        self, f"The attribute {k} is set twice in the constructor call of {self.class_type}."
+                        self, "The attribute %s is set twice in the constructor call of %s." % (k, self.class_type)
                     )
                 attribute = type_class.get_attribute(k)
                 if attribute is None:
-                    raise TypingException(self, f"no attribute {k} on type {type_class.get_full_name()}")
+                    raise TypingException(self, "no attribute %s on type %s" % (k, type_class.get_full_name()))
                 kwarg_attrs[k] = v
 
         lhs_inverse_assignment: Optional[tuple[str, object]] = None
         # add inverse relation if it is part of an index
         if self._lhs_attribute is not None:
             lhs_instance: object = self._lhs_attribute.instance.execute(requires, resolver, queue)
             if not isinstance(lhs_instance, Instance):
@@ -1083,42 +1057,43 @@
 
         late_args = {**dict([lhs_inverse_assignment] if lhs_inverse_assignment is not None else []), **kwarg_attrs}
         missing_attrs: abc.Sequence[str] = [attr for attr in self._required_dynamic_args if attr not in late_args]
         if missing_attrs:
             raise IndexAttributeMissingInConstructorException(self, type_class, missing_attrs)
         return late_args
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> Instance:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> Instance:
         """
         Evaluate this statement.
         """
         LOGGER.log(LOG_LEVEL_TRACE, "executing constructor for %s at %s", self.class_type, self.location)
+        super().execute(requires, resolver, queue)
 
         # the type to construct
         type_class = self.type
         assert type_class
 
         # kwargs and implicit inverse from lhs
         late_args: abc.Mapping[str, object] = self._collect_required_dynamic_arguments(requires, resolver, queue)
 
         # Schedule all direct attributes for direct execution. The kwarg keys and the direct_attributes keys are disjoint
         # because a RuntimeException is raised above when they are not.
-        direct_attributes: dict[str, object] = {
+        direct_attributes: Dict[str, object] = {
             k: v.execute(requires, resolver, queue) for (k, v) in self._direct_attributes.items()
         }
         direct_attributes.update(late_args)
 
         # Override defaults with kwargs. The kwarg keys and the indirect_attributes keys are disjoint because a RuntimeException
         # is raised above when they are not.
-        indirect_attributes: dict[str, ExpressionStatement] = {
+        indirect_attributes: Dict[str, ExpressionStatement] = {
             k: v for k, v in self._indirect_attributes.items() if k not in late_args
         }
 
         # check if the instance already exists in the index (if there is one)
-        instances: list[Instance] = []
+        instances: List[Instance] = []
         # register any potential index collision
         collisions: abc.MutableMapping[tuple[str, ...], Instance] = {}
         for index in type_class.get_indices():
             params = []
             for attr in index:
                 params.append((attr, direct_attributes[attr]))
 
@@ -1191,24 +1166,28 @@
         """
         Add an attribute to this constructor call
         """
         name = str(lname)
         if name not in self.__attributes:
             self.__attributes[name] = value
             self.__attribute_locations[name] = lname
+            self.anchors.append(AttributeReferenceAnchor(lname.get_location(), lname.namespace, self.class_type, name))
+            self.anchors.extend(value.get_anchors())
         else:
-            raise RuntimeException(self, f"The attribute {name} in the constructor call of {self.class_type} is already set.")
+            raise RuntimeException(
+                self, "The attribute %s in the constructor call of %s is already set." % (name, self.class_type)
+            )
 
-    def get_attributes(self) -> dict[str, ExpressionStatement]:
+    def get_attributes(self) -> Dict[str, ExpressionStatement]:
         """
         Get the attribtues that are set for this constructor call
         """
         return self.__attributes
 
-    def get_wrapped_kwargs(self) -> list["WrappedKwargs"]:
+    def get_wrapped_kwargs(self) -> List["WrappedKwargs"]:
         """
         Get the wrapped kwargs that are set for this constructor call
         """
         return self.__wrapped_kwarg_attributes
 
     attributes = property(get_attributes)
     wrapped_kwargs = property(get_wrapped_kwargs)
@@ -1253,25 +1232,26 @@
 
     def normalize(self, *, lhs_attribute: Optional[AttributeAssignmentLHS] = None) -> None:
         self.dictionary.normalize()
 
     def get_all_eager_promises(self) -> Iterator["StaticEagerPromise"]:
         return chain(super().get_all_eager_promises(), self.dictionary.get_all_eager_promises())
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return self.dictionary.requires()
 
-    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> dict[object, VariableABC[object]]:
-        requires: dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
+    def requires_emit(self, resolver: Resolver, queue: QueueScheduler) -> Dict[object, VariableABC[object]]:
+        requires: Dict[object, VariableABC[object]] = super().requires_emit(resolver, queue)
         requires.update(self.dictionary.requires_emit(resolver, queue))
         return requires
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> list[tuple[str, object]]:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> List[Tuple[str, object]]:
+        super().execute(requires, resolver, queue)
         dct: object = self.dictionary.execute(requires, resolver, queue)
-        if not isinstance(dct, dict):
+        if not isinstance(dct, Dict):
             raise TypingException(self, "The ** operator can only be applied to dictionaries")
         return list(dct.items())
 
 
 class IndexCollisionException(RuntimeException):
     """Exception raised when an index collision is detected"""
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/type.py` & `inmanta-core-9.3.0/src/inmanta/ast/type.py`

 * *Files 11% similar despite different names*

```diff
@@ -12,26 +12,23 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-import copy
-import functools
 import numbers
-from collections.abc import Sequence
+import typing
 from typing import Callable
 from typing import List as PythonList
-from typing import Optional
+from typing import Optional, Sequence
 
 from inmanta.ast import (
     DuplicateException,
     Locatable,
-    LocatableString,
     Named,
     Namespace,
     NotFoundException,
     RuntimeException,
     TypeNotFoundException,
 )
 from inmanta.execute.util import AnyType, NoneValue, Unknown
@@ -42,15 +39,15 @@
 except ImportError:
     TYPE_CHECKING = False
 
 if TYPE_CHECKING:
     from inmanta.ast.statements import ExpressionStatement
 
 
-class BasicResolver:
+class BasicResolver(object):
     def __init__(self, types):
         self.types = types
 
     def get_type(self, namespace, name):
         if not isinstance(name, str):
             raise Exception("Should Not Occur, bad AST construction")
         if "::" in name:
@@ -59,22 +56,22 @@
             else:
                 raise TypeNotFoundException(name, namespace)
         elif name in TYPES:
             return self.types[name]
         else:
             cns = namespace
             while cns is not None:
-                full_name = f"{cns.get_full_name()}::{name}"
+                full_name = "%s::%s" % (cns.get_full_name(), name)
                 if full_name in self.types:
                     return self.types[full_name]
                 cns = cns.get_parent()
                 raise TypeNotFoundException(name, namespace)
 
 
-class NameSpacedResolver:
+class NameSpacedResolver(object):
     def __init__(self, ns):
         self.ns = ns
 
     def get_type(self, name):
         return self.ns.get_type(name)
 
     def get_resolver_for(self, namespace: Namespace):
@@ -201,15 +198,15 @@
         Type.__init__(self)
         self.try_cast_functions: Sequence[Callable[[Optional[object]], object]] = []
 
     def cast(self, value: Optional[object]) -> object:
         """
         Cast a value to this type. If the value can not be cast, raises a :py:class:`inmanta.ast.RuntimeException`.
         """
-        exception: RuntimeException = RuntimeException(None, f"Failed to cast '{value}' to {self}")
+        exception: RuntimeException = RuntimeException(None, "Failed to cast '%s' to %s" % (value, self))
 
         if isinstance(value, Unknown):
             # propagate unknowns
             return value
 
         for cast in self.try_cast_functions:
             try:
@@ -228,40 +225,34 @@
             return NotImplemented
         return True
 
 
 @stable_api
 class Number(Primitive):
     """
-    This class represents an integer or a float in the configuration model.
+    This class represents an integer or float in the configuration model. On
+    these numbers the following operations are supported:
+
+    +, -, /, *
     """
 
     def __init__(self) -> None:
         Primitive.__init__(self)
-        self.try_cast_functions: Sequence[Callable[[Optional[object]], numbers.Number]] = [float]
-
-    def cast(self, value: Optional[object]) -> object:
-        """
-        Attempts to cast a given value to an int or a float.
-        """
-        # Keep precision: cast to an int only if it already is an int
-        if isinstance(value, int):
-            return int(value)
-        return super().cast(value)
+        self.try_cast_functions: Sequence[Callable[[Optional[object]], numbers.Number]] = [int, float]
 
     def validate(self, value: Optional[object]) -> bool:
         """
         Validate the given value to check if it satisfies the constraints
         associated with this type
         """
         if isinstance(value, AnyType):
             return True
 
         if not isinstance(value, numbers.Number):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
+            raise RuntimeException(None, "Invalid value '%s', expected Number" % value)
 
         return True  # allow this function to be called from a lambda function
 
     def is_primitive(self) -> bool:
         return True
 
     def get_location(self) -> None:
@@ -271,70 +262,29 @@
         return "number"
 
     def type_string_internal(self) -> str:
         return self.type_string()
 
 
 @stable_api
-class Float(Primitive):
-    """
-    This class is an alias for the Number class and represents a float in
-    the configuration model.
-    """
-
-    def __init__(self) -> None:
-        Primitive.__init__(self)
-        self.try_cast_functions: Sequence[Callable[[Optional[object]], object]] = [float]
-
-    def validate(self, value: Optional[object]) -> bool:
-        """
-        Validate the given value to check if it satisfies the constraints
-        associated with this type
-        """
-        if isinstance(value, AnyType):
-            return True
-
-        if not isinstance(value, float):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
-        return True  # allow this function to be called from a lambda function
-
-    def is_primitive(self) -> bool:
-        return True
-
-    def get_location(self) -> None:
-        return None
-
-    def type_string(self) -> str:
-        return "float"
-
-    def type_string_internal(self) -> str:
-        return self.type_string()
-
-
-@stable_api
 class Integer(Number):
     """
     An instance of this class represents the int type in the configuration model.
     """
 
     def __init__(self) -> None:
         Number.__init__(self)
         self.try_cast_functions: Sequence[Callable[[Optional[object]], object]] = [int]
 
     def validate(self, value: Optional[object]) -> bool:
-        """
-        Validate the given value to check if it satisfies the constraints
-        associated with this type
-        """
-        if isinstance(value, AnyType):
-            return True
-
+        if not super().validate(value):
+            return False
         if not isinstance(value, numbers.Integral):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
-        return True  # allow this function to be called from a lambda function
+            raise RuntimeException(None, "Invalid value '%s', expected %s" % (value, self.type_string()))
+        return True
 
     def type_string(self) -> str:
         return "int"
 
 
 @stable_api
 class Bool(Primitive):
@@ -351,15 +301,15 @@
         Validate the given value to check if it satisfies the constraints
         associated with this type
         """
         if isinstance(value, AnyType):
             return True
         if isinstance(value, bool):
             return True
-        raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
+        raise RuntimeException(None, "Invalid value '%s', expected Bool" % value)
 
     def cast(self, value: Optional[object]) -> object:
         return super().cast(value if not isinstance(value, NoneValue) else None)
 
     def type_string(self) -> str:
         return "bool"
 
@@ -387,15 +337,15 @@
         """
         Validate the given value to check if it satisfies the constraints
         associated with this type
         """
         if isinstance(value, AnyType):
             return True
         if not isinstance(value, str):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
+            raise RuntimeException(None, "Invalid value '%s', expected String" % value)
 
         return True
 
     def cast(self, value: Optional[object]) -> object:
         if value is True:
             return "true"
         if value is False:
@@ -415,36 +365,31 @@
         return None
 
 
 @stable_api
 class List(Type):
     """
     Instances of this class represent a list type containing any types of values.
-    This class refers to the list type used in plugin annotations. For the list type in the Inmanta DSL, see `LiteralList`.
     """
 
     def __init__(self):
         Type.__init__(self)
 
     def validate(self, value: Optional[object]) -> bool:
         if value is None:
             return True
 
         if isinstance(value, AnyType):
             return True
 
         if not isinstance(value, list):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
+            raise RuntimeException(None, "Invalid value '%s', expected %s" % (value, self.type_string()))
 
         return True
 
-    def type_string(self) -> str:
-        # This is not a type in the model, but it is used in plugin annotations, which are also part of the DSL.
-        return "list"
-
     def type_string_internal(self) -> str:
         return "List"
 
     def get_location(self) -> None:
         return None
 
 
@@ -541,15 +486,15 @@
         if isinstance(value, AnyType):
             return True
 
         if value is None:
             return True
 
         if not isinstance(value, dict):
-            raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
+            raise RuntimeException(None, "Invalid value '%s', expected dict" % value)
 
         return True
 
     def type_string_internal(self) -> str:
         return "Dict"
 
     def type_string(self) -> str:
@@ -621,29 +566,29 @@
     def validate(self, value: object) -> bool:
         for typ in self.types:
             try:
                 if typ.validate(value):
                     return True
             except RuntimeException:
                 pass
-        raise RuntimeException(None, f"Invalid value '{value}', expected {self}")
+        raise RuntimeException(None, "Invalid value '%s', expected %s" % (value, self))
 
     def type_string_internal(self) -> str:
-        return "Union[%s]" % ",".join(t.type_string_internal() for t in self.types)
+        return "Union[%s]" % ",".join((t.type_string_internal() for t in self.types))
 
 
 @stable_api
 class Literal(Union):
     """
     Instances of this class represent a literal in the configuration model. A literal is a primitive or a list or dict
     where all values are literals themselves.
     """
 
     def __init__(self) -> None:
-        Union.__init__(self, [NullableType(Float()), Number(), Bool(), String(), TypedList(self), TypedDict(self)])
+        Union.__init__(self, [NullableType(Number()), Bool(), String(), TypedList(self), TypedDict(self)])
 
     def type_string_internal(self) -> str:
         return "Literal"
 
 
 @stable_api
 class ConstraintType(NamedType):
@@ -693,21 +638,21 @@
 
         assert self.basetype is not None
         self.basetype.validate(value)
 
         assert self._constraint is not None
         if not self._constraint(value):
             raise RuntimeException(
-                self, f"Invalid value {repr(value)}, does not match constraint `{self.expression.pretty_print()}`"
+                self, "Invalid value %s, does not match constraint `%s`" % (repr(value), self.expression.pretty_print())
             )
 
         return True
 
     def type_string(self) -> str:
-        return f"{self.namespace}::{self.name}"
+        return "%s::%s" % (self.namespace, self.name)
 
     def type_string_internal(self) -> str:
         return self.type_string()
 
     def get_full_name(self) -> str:
         return self.namespace.get_full_name() + "::" + self.name
 
@@ -737,56 +682,19 @@
         except NotFoundException as e:
             e.msg = "Unable to resolve `%s`: a type constraint can not reference variables." % e.stmt.name
             raise e
 
     return function
 
 
-TYPES: dict[str, Type] = {  # Part of the stable API
+TYPES: typing.Dict[str, Type] = {  # Part of the stable API
     "string": String(),
-    "float": Float(),
     "number": Number(),
     "int": Integer(),
     "bool": Bool(),
     "list": LiteralList(),
     "dict": LiteralDict(),
 }
 """
     Maps Inmanta :term:`DSL` types to their internal representation. For each key, value pair, `value.type_string()` is
     guaranteed to return key.
 """
-
-
-@stable_api
-def resolve_type(locatable_type: LocatableString, resolver: Namespace) -> Type:
-    """
-    Convert a locatable type string, into a real inmanta type, that can be used for validation.
-
-    :param locatable_type: An object pointing to the type expression.
-    :param resolver: The namespace that can be used to resolve the type expression
-    """
-    # quickfix issue #1774
-    allowed_element_type: Type = Type()
-    if locatable_type.value == "list":
-        return List()
-    if locatable_type.value == "dict":
-        return TypedDict(allowed_element_type)
-
-    # stack of transformations to be applied to the base inmanta_type.Type
-    # transformations will be applied right to left
-    transformation_stack: List[Callable[[Type], Type]] = []
-
-    if locatable_type.value.endswith("?"):
-        # We don't want to modify the object we received as argument
-        locatable_type = copy.copy(locatable_type)
-        locatable_type.value = locatable_type.value[0:-1]
-        transformation_stack.append(NullableType)
-
-    if locatable_type.value.endswith("[]"):
-        # We don't want to modify the object we received as argument
-        locatable_type = copy.copy(locatable_type)
-        locatable_type.value = locatable_type.value[0:-2]
-        transformation_stack.append(TypedList)
-
-    return functools.reduce(
-        lambda acc, transform: transform(acc), reversed(transformation_stack), resolver.get_type(locatable_type)
-    )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/ast/variables.py` & `inmanta-core-9.3.0/src/inmanta/ast/variables.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import logging
 from collections import abc
-from typing import Generic, Optional, TypeVar, Union
+from typing import Dict, Generic, List, Optional, TypeVar
 
 import inmanta.execute.dataflow as dataflow
 from inmanta.ast import LocatableString, Location, NotFoundException, OptionalValueException, Range, RuntimeException
 from inmanta.ast.statements import (
     AssignStatement,
     AttributeAssignmentLHS,
     ExpressionStatement,
@@ -37,17 +37,16 @@
     QueueScheduler,
     RawUnit,
     Resolver,
     ResultCollector,
     ResultVariable,
     ResultVariableProxy,
     VariableABC,
-    WrappedValueVariable,
 )
-from inmanta.execute.util import NoneValue, Unknown
+from inmanta.execute.util import NoneValue
 from inmanta.parser import ParserException
 from inmanta.stable_api import stable_api
 
 LOGGER = logging.getLogger(__name__)
 
 
 R = TypeVar("R", bound="Reference")
@@ -75,38 +74,36 @@
             # fail-fast if namespace does not exist
             try:
                 self.namespace.lookup_namespace(split[0])
             except NotFoundException as e:
                 e.set_statement(self)
                 raise
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return [self.full_name]
 
     def requires_emit(
         self, resolver: Resolver, queue: QueueScheduler, *, propagate_unset: bool = False
-    ) -> dict[object, VariableABC]:
-        requires: dict[object, VariableABC] = super().requires_emit(resolver, queue)
+    ) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = super().requires_emit(resolver, queue)
         # FIXME: may be done more efficient?
         requires[self.name] = resolver.lookup(self.full_name)
         return requires
 
     def requires_emit_gradual(
         self, resolver: Resolver, queue: QueueScheduler, resultcollector: ResultCollector, *, propagate_unset: bool = False
-    ) -> dict[object, VariableABC]:
-        result: dict[object, VariableABC] = self.requires_emit(resolver, queue, propagate_unset=propagate_unset)
-        var: VariableABC = result[self.name]
-        assert isinstance(var, ResultVariable)
-        listener_registered: bool = var.listener(resultcollector, self.location)
-        if not listener_registered:
-            # pass on resultcollector for explicit reporting in execute
-            result[(self, ResultCollector)] = WrappedValueVariable(resultcollector)
-        return result
+    ) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+        var: ResultVariable = resolver.lookup(self.full_name)
+        var.listener(resultcollector, self.location)
+        requires[self.name] = var
+        return requires
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        super().execute(requires, resolver, queue)
         return requires[self.name]
 
     def execute_direct(self, requires: abc.Mapping[str, object]) -> object:
         if self.name not in requires:
             raise NotFoundException(self, "Could not resolve the value %s in this static context" % self.name)
         return requires[self.name]
 
@@ -163,26 +160,30 @@
 
 class VariableReader(VariableResumer, Generic[T]):
     """
     Resumes execution on a variable when it becomes avaiable, then connects the target proxy variable to it.
     Optionally subscribes a result collector to intermediate values.
     """
 
-    __slots__ = ("target",)
+    __slots__ = ("owner", "target", "resultcollector")
 
-    def __init__(self, target: ResultVariableProxy[T]) -> None:
+    def __init__(self, owner: Statement, target: ResultVariableProxy[T], resultcollector: Optional[ResultCollector[T]]) -> None:
         super().__init__()
+        self.owner: Statement = owner
         self.target: ResultVariableProxy[T] = target
+        self.resultcollector: Optional[ResultCollector[T]] = resultcollector
 
     def variable_resume(
         self,
         variable: VariableABC[T],
         resolver: Resolver,
         queue_scheduler: QueueScheduler,
     ) -> None:
+        if self.resultcollector:
+            variable.listener(self.resultcollector, self.owner.location)
         self.target.connect(variable)
 
 
 class IsDefinedGradual(VariableResumer, RawResumer, ResultCollector[object]):
     """
     Fill target variable with is defined result as soon as it gets known.
     """
@@ -199,17 +200,14 @@
         return False
 
     def receive_result(self, value: object, location: Location) -> bool:
         """
         Gradually receive an assignment to the referenced variable. Sets the target variable to True because to receive a single
         value implies that the variable is defined.
         """
-        if isinstance(value, Unknown):
-            # value may or may not be defined, nothing can be decided yet
-            return False
         self.target.set_value(True, self.owner.location)
         return True
 
     def variable_resume(
         self,
         variable: VariableABC[object],
         resolver: Resolver,
@@ -219,42 +217,35 @@
             self.target.set_value(self._target_value(variable), self.owner.location)
         else:
             # gradual execution: as soon as a value comes in, the result is known
             variable.listener(self, self.owner.location)
             # wait for variable completeness in case no value comes in at all
             RawUnit(queue_scheduler, resolver, {self: variable}, self, override_exception_location=False)
 
-    def resume(self, requires: dict[object, VariableABC], resolver: Resolver, queue_scheduler: QueueScheduler) -> None:
+    def resume(self, requires: Dict[object, VariableABC], resolver: Resolver, queue_scheduler: QueueScheduler) -> None:
         self.target.set_value(self._target_value(requires[self]), self.owner.location)
 
-    def _target_value(self, variable: VariableABC[object]) -> Union[bool, Unknown]:
+    def _target_value(self, variable: VariableABC[object]) -> bool:
         """
         Returns the target value based on the attribute variable's value or absence of a value.
         """
         try:
             value = variable.get_value()
-            if isinstance(value, Unknown):
-                return Unknown(self)
             if isinstance(value, list):
-                if len(value) == 0:
-                    return False
-                elif all(isinstance(v, Unknown) for v in value):
-                    return Unknown(self)
-                else:
-                    return True
+                return len(value) != 0
             elif isinstance(value, NoneValue):
                 return False
             return True
         except OptionalValueException:
             return False
 
     def emit(self, resolver: Resolver, queue: QueueScheduler) -> None:
         raise RuntimeException(self, "%s is not an actual AST node, it should never be executed" % self.__class__.__name__)
 
-    def execute(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
         raise RuntimeException(self, "%s is not an actual AST node, it should never be executed" % self.__class__.__name__)
 
 
 class AttributeReference(Reference):
     """
     This variable refers to an attribute. This is mostly used to refer to
     attributes of a class or class instance.
@@ -267,62 +258,61 @@
             instance.locatable_name.location.file,
             instance.locatable_name.lnr,
             instance.locatable_name.start,
             attribute.elnr,
             attribute.end,
         )
         reference: LocatableString = LocatableString(
-            f"{instance.full_name}.{attribute}", range, instance.locatable_name.lexpos, instance.namespace
+            "%s.%s" % (instance.full_name, attribute), range, instance.locatable_name.lexpos, instance.namespace
         )
         Reference.__init__(self, reference)
         self.attribute = attribute
 
         # a reference to the instance
         self.instance = instance
 
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         return self.instance.requires()
 
     def requires_emit(
         self, resolver: Resolver, queue: QueueScheduler, *, propagate_unset: bool = False
-    ) -> dict[object, VariableABC]:
+    ) -> Dict[object, VariableABC]:
         return self.requires_emit_gradual(resolver, queue, None, propagate_unset=propagate_unset)
 
     def requires_emit_gradual(
         self,
         resolver: Resolver,
         queue: QueueScheduler,
         resultcollector: Optional[ResultCollector],
         *,
         propagate_unset: bool = False,
-    ) -> dict[object, VariableABC]:
-        requires: dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
+    ) -> Dict[object, VariableABC]:
+        requires: Dict[object, VariableABC] = self._requires_emit_promises(resolver, queue)
 
         # The tricky one!
 
-        # introduce proxy variable to point to the eventual result of this stmt
-        proxy: ResultVariableProxy[object] = ResultVariableProxy(
-            listener=(resultcollector, self.location) if resultcollector is not None else None,
-        )
+        # introduce temp variable to contain the eventual result of this stmt
+        temp = ResultVariableProxy()
         # construct waiter
-        reader: VariableReader = VariableReader(target=proxy)
+        reader: VariableReader = VariableReader(owner=self, target=temp, resultcollector=resultcollector)
         hook: VariableReferenceHook = VariableReferenceHook(
             self.instance,
             str(self.attribute),
             variable_resumer=reader,
             propagate_unset=propagate_unset,
         )
         self.copy_location(hook)
         hook.schedule(resolver, queue)
         # wait for the attribute value
-        requires[self] = proxy
+        requires[self] = temp
 
         return requires
 
-    def _resolve(self, requires: dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+    def execute(self, requires: Dict[object, object], resolver: Resolver, queue: QueueScheduler) -> object:
+        ExpressionStatement.execute(self, requires, resolver, queue)
         # helper returned: return result
         return requires[self]
 
     def get_root_variable(self) -> "Reference":
         """
         Returns the root reference node. e.g. for a.b.c.d, returns the reference for a.
         """
@@ -337,8 +327,8 @@
         return out
 
     def get_dataflow_node(self, graph: DataflowGraph) -> dataflow.AttributeNodeReference:
         assert self.instance is not None
         return dataflow.AttributeNodeReference(self.instance.get_dataflow_node(graph), str(self.attribute))
 
     def __repr__(self) -> str:
-        return f"{repr(self.instance)}.{str(self.attribute)}"
+        return "%s.%s" % (repr(self.instance), str(self.attribute))
```

### Comparing `inmanta-core-8.7.4/src/inmanta/command.py` & `inmanta-core-9.3.0/src/inmanta/command.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,48 +15,48 @@
 
     Contact: code@inmanta.com
 """
 
 
 import argparse
 from collections import abc
-from typing import Callable, Optional
+from typing import Callable, Dict, List, Optional
 
 FunctionType = Callable[[argparse.Namespace], None]
 ParserConfigType = Callable[[argparse.ArgumentParser, abc.Sequence[argparse.ArgumentParser]], None]
 
 
 class CLIException(Exception):
     def __init__(self, *args: str, exitcode: int) -> None:
         self.exitcode = exitcode
-        super().__init__(*args)
+        super(CLIException, self).__init__(*args)
 
 
 class ShowUsageException(Exception):
     """
     Raise this exception to show the usage message of the given level
     """
 
 
-class Commander:
+class Commander(object):
     """
     This class handles commands
     """
 
-    __command_functions: dict[str, dict[str, object]] = {}
+    __command_functions: Dict[str, Dict[str, object]] = {}
 
     @classmethod
     def add(
         cls,
         name: str,
         function: FunctionType,
         help_msg: str,
         parser_config: Optional[ParserConfigType],
         require_project: bool = False,
-        aliases: list[str] = [],
+        aliases: List[str] = [],
         add_verbose_flag: bool = True,
     ) -> None:
         """
         Add a new export function
         """
         if name in cls.__command_functions:
             raise Exception("Command %s already registered" % name)
@@ -76,35 +76,35 @@
     def reset(cls) -> None:
         """
         Return a list of commands
         """
         cls.__command_functions = {}
 
     @classmethod
-    def commands(cls) -> dict[str, dict[str, object]]:
+    def commands(cls) -> Dict[str, Dict[str, object]]:
         """
         Return a list of commands
         """
         return cls.__command_functions
 
 
-class command:  # noqa: N801
+class command(object):  # noqa: N801
     """
     A decorator that registers an export function
 
     :param add_verbose_flag: Set this to false to prevent automatically adding the verbose option to the registered command.
     """
 
     def __init__(
         self,
         name: str,
         help_msg: str,
         parser_config: Optional[ParserConfigType] = None,
         require_project: bool = False,
-        aliases: list[str] = [],
+        aliases: List[str] = [],
         add_verbose_flag: bool = True,
     ) -> None:
         self.name = name
         self.help = help_msg
         self.require_project = require_project
         self.parser_config = parser_config
         self.aliases = aliases
```

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/__init__.py` & `inmanta-core-9.3.0/src/inmanta/compiler/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,17 +14,16 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
 import sys
 from collections import abc
-from collections.abc import Sequence
 from itertools import chain
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Dict, List, Optional, Sequence, Set, Tuple
 
 import inmanta.ast.type as inmanta_type
 import inmanta.execute.dataflow as dataflow
 from inmanta import const, module
 from inmanta.ast import (
     AnchorTarget,
     AttributeException,
@@ -93,28 +92,28 @@
         show_dataflow_graphic(sched, compiler)
     return (sched.get_types(), compiler.get_ns())
 
 
 def show_dataflow_graphic(scheduler: scheduler.Scheduler, compiler: "Compiler") -> None:
     from inmanta.execute.dataflow.graphic import GraphicRenderer
 
-    types: dict[str, inmanta_type.Type] = scheduler.get_types()
+    types: Dict[str, inmanta_type.Type] = scheduler.get_types()
     ns: Namespace = compiler.get_ns()
     config_ns: Namespace = ns.get_child("__config__")
     GraphicRenderer.view(
         config_ns.get_scope().slots.values(),
         list(
             chain.from_iterable(
                 tp.get_all_instances() for tp in types.values() if isinstance(tp, Entity) and tp.namespace is config_ns
             )
         ),
     )
 
 
-def anchormap(refs: Optional[abc.Mapping[object, object]] = None) -> Sequence[tuple[Location, AnchorTarget]]:
+def anchormap(refs: Optional[abc.Mapping[object, object]] = None) -> Sequence[Tuple[Location, AnchorTarget]]:
     """
     Return all lexical references
 
     Performs compilation up to and including the type resolution, but doesn't start executing
 
     :param refs: Datastructure used to pass on mocking information to the compiler. Supported options:
                     * key="facts"; value=Dict with the following structure: {"<resource_id": {"<fact_name>": "<fact_value"}}
@@ -124,41 +123,41 @@
     LOGGER.debug("Starting compile")
 
     (statements, blocks) = compiler.compile()
     sched = scheduler.Scheduler()
     return sched.get_anchormap(compiler, statements, blocks)
 
 
-def get_types_and_scopes() -> tuple[dict[str, inmanta_type.Type], Namespace]:
+def get_types_and_scopes() -> Tuple[Dict[str, inmanta_type.Type], Namespace]:
     """
     Only run the compilation steps required to extract the different types and scopes.
     """
     compiler = Compiler()
     (statements, blocks) = compiler.compile()
     sched = scheduler.Scheduler(compiler_config.track_dataflow())
     sched.define_types(compiler, statements, blocks)
     return sched.get_types(), compiler.get_ns()
 
 
-class Compiler:
+class Compiler(object):
     """
     An inmanta compiler
 
     :param cf_file: DEPRECATED
     :param refs: Datastructure used to pass on mocking information to the compiler. Supported keys:
                     * key="facts"; value=Dict with the following structure: {"<resource_id": {"<fact_name>": "<fact_value"}}
     """
 
     def __init__(self, cf_file: str = "main.cf", refs: Optional[abc.Mapping[object, object]] = None) -> None:
         self.__root_ns: Optional[Namespace] = None
         self._data: CompileData = CompileData()
-        self.plugins: dict[str, Plugin] = {}
+        self.plugins: Dict[str, Plugin] = {}
         self.refs = refs if refs is not None else {}
 
-    def get_plugins(self) -> dict[str, Plugin]:
+    def get_plugins(self) -> Dict[str, Plugin]:
         return self.plugins
 
     def is_loaded(self) -> bool:
         """
         Is everything loaded and the namespace structure built?
         """
         return self.__root_ns is not None
@@ -172,47 +171,48 @@
 
     ns = property(get_ns)
 
     def read(self, path: str) -> str:
         """
         Return the content of the given file
         """
-        with open(path, encoding="utf-8") as file_d:
+        with open(path, "r", encoding="utf-8") as file_d:
             return file_d.read()
 
-    def compile(self) -> tuple[list["Statement"], list["BasicBlock"]]:
+    def compile(self) -> Tuple[List["Statement"], List["BasicBlock"]]:
         """
         This method will parse and prepare everything to start evaluation
         the configuration specification.
 
         This method will:
         - load all modules using Project.get().get_complete_ast()
         - add all plugins
         - create std::Entity
         """
         project = module.Project.get()
         self.__root_ns = project.get_root_namespace()
 
         project.load()
         statements, blocks = project.get_complete_ast()
+
         project.log_installed_modules()
 
         # This lookup variable provides efficiency in the loop below by skipping iterations for plugins
         # that are part of modules that are not imported in the model.
         non_imported_modules: set[str] = set()
 
         # load plugins
         for name, cls in PluginMeta.get_functions().items():
             if cls.__module__ in non_imported_modules:
                 continue
 
             mod_ns = cls.__module__.split(".")
             if mod_ns[0] != const.PLUGINS_PACKAGE:
                 raise Exception(
-                    f"All plugin modules should be loaded in the {const.PLUGINS_PACKAGE} package not in {cls.__module__}"
+                    "All plugin modules should be loaded in the %s package not in %s" % (const.PLUGINS_PACKAGE, cls.__module__)
                 )
 
             mod_ns = mod_ns[1:]
 
             ns: Optional[Namespace] = self.__root_ns
             for part in mod_ns:
                 if ns is None:
@@ -275,28 +275,28 @@
 
         def add_trace(exception: CompilerException) -> bool:
             """
             Add the trace to the deepest possible causes.
             """
             handled: bool = False
             if isinstance(exception, MultiException):
-                unset_attrs: dict[dataflow.AttributeNode, UnsetException] = {
+                unset_attrs: Dict[dataflow.AttributeNode, UnsetException] = {
                     cause.instance.instance_node.node().register_attribute(cause.attribute.name): cause
                     for cause in exception.get_causes()
                     if isinstance(cause, UnsetException)
                     if cause.instance is not None
                     if cause.instance.instance_node is not None
                     if cause.attribute is not None
                 }
-                root_causes: set[dataflow.AttributeNode] = UnsetRootCauseAnalyzer(unset_attrs.keys()).root_causes()
+                root_causes: Set[dataflow.AttributeNode] = UnsetRootCauseAnalyzer(unset_attrs.keys()).root_causes()
                 for attr, e in unset_attrs.items():
                     if attr not in root_causes:
                         exception.others.remove(e)
                 handled = True
-            causes: list[CompilerException] = exception.get_causes()
+            causes: List[CompilerException] = exception.get_causes()
             for cause in causes:
                 if add_trace(cause):
                     handled = True
             if not handled:
                 trace: Optional[str] = None
                 if isinstance(exception, UnsetException):
                     if (
```

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/config.py` & `inmanta-core-9.3.0/src/inmanta/compiler/config.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/data.py` & `inmanta-core-9.3.0/src/inmanta/compiler/data.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,22 +11,23 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
+from typing import List
 
 import inmanta.ast.export as ast_export
 import inmanta.data.model as model
 from inmanta.ast import CompilerException
 
 
 class CompileData(ast_export.Exportable):
     def __init__(self) -> None:
-        self.errors: list[CompilerException] = []
+        self.errors: List[CompilerException] = []
 
     def add_error(self, error: CompilerException) -> None:
         self.errors.append(error)
 
     def export(self) -> "model.CompileData":
         return model.CompileData(errors=[e.export() for e in self.errors])
```

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/help/__init__.py` & `inmanta-core-9.3.0/src/inmanta/compiler/help/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/help/explainer.py` & `inmanta-core-9.3.0/src/inmanta/compiler/help/explainer.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,36 +14,35 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import os
 import re
 from abc import ABC, abstractmethod
-from collections.abc import Mapping, Sequence
-from typing import Generic, Optional, TypeVar
+from typing import Generic, List, Mapping, Optional, Sequence, Set, Type, TypeVar
 
 from jinja2 import Environment, PackageLoader
 
 from inmanta.ast import CompilerException, ModifiedAfterFreezeException
 from inmanta.ast.statements import AssignStatement
 from inmanta.ast.statements.generator import Constructor, IndexCollisionException
 from inmanta.execute.runtime import OptionVariable
 from inmanta.module import ModuleV2InV1PathException
 
 
 def bold(content: Optional[str] = None) -> str:
     if content is None:
         return "\033[1m"
-    return f"\033[1m{content}\033[0m"
+    return "\033[1m{0}\033[0m".format(content)
 
 
 def underline(content: Optional[str] = None) -> str:
     if content is None:
         return "\033[4m"
-    return f"\033[4m{content}\033[0m"
+    return "\033[4m{0}\033[0m".format(content)
 
 
 def noformat(content: Optional[str] = None) -> str:
     return "\033[0m"
 
 
 CUSTOM_FILTERS = {"bold": bold, "underline": underline, "noformat": noformat}
@@ -52,37 +51,37 @@
 class ExplainerABC(ABC):
     """
     Abstract base class for explainers. This class is purposely kept non-Generic to present a public interface that is invariant
     of the compiler exception type. This allows correct typing of sequences of explainers.
     """
 
     @abstractmethod
-    def explain(self, problem: CompilerException) -> list[str]:
+    def explain(self, problem: CompilerException) -> List[str]:
         ...
 
 
 Explainable = TypeVar("Explainable", bound=CompilerException)
 
 
 class Explainer(Generic[Explainable], ExplainerABC, ABC):
     """
     Abstract explainer, Generic in the compiler exception subtype to allow correct typing of the exception for subtype-specific
     explanation logic.
     Concrete subclasses must not be generic in the exception type because this would break explainable checking.
     """
 
-    explainable_type: type[Explainable]
+    explainable_type: Type[Explainable]
 
-    def explain(self, problem: CompilerException) -> list[str]:
+    def explain(self, problem: CompilerException) -> List[str]:
         """
         Returns a list of explanations for this exception. If neither the exception or any of its causes (recursively)
         is explainable by this explainer, returns an empty list.
         """
-        allcauses: set[CompilerException] = set()
-        work: list[CompilerException] = [problem]
+        allcauses: Set[CompilerException] = set()
+        work: List[CompilerException] = [problem]
         while work:
             w = work.pop()
             allcauses.add(w)
             work.extend(w.get_causes())
 
         return [self.do_explain(c) for c in allcauses if isinstance(c, self.explainable_type)]
 
@@ -102,15 +101,15 @@
     """
 
     def __init__(self, template: str) -> None:
         self.template: str = template
 
     def get_template(self, problem: Explainable) -> str:
         path = os.path.join(os.path.dirname(__file__), self.template)
-        with open(path, encoding="utf-8") as fh:
+        with open(path, "r", encoding="utf-8") as fh:
             return fh.read()
 
     def do_explain(self, problem: Explainable) -> str:
         env = Environment(loader=PackageLoader("inmanta.compiler.help"))
         for name, filter in CUSTOM_FILTERS.items():
             env.filters[name] = filter
 
@@ -126,35 +125,35 @@
 
 
 class ModifiedAfterFreezeExplainer(JinjaExplainer[ModifiedAfterFreezeException]):
     """
     Explainer for ModifiedAfterFreezeException.
     """
 
-    explainable_type: type[ModifiedAfterFreezeException] = ModifiedAfterFreezeException
+    explainable_type: Type[ModifiedAfterFreezeException] = ModifiedAfterFreezeException
 
     def __init__(self) -> None:
         super().__init__("modified_after_freeze.j2")
 
     def build_reverse_hint(self, problem: ModifiedAfterFreezeException) -> str:
         if isinstance(problem.stmt, AssignStatement):
-            return "{}.{} = {}".format(
+            return "%s.%s = %s" % (
                 problem.stmt.rhs.pretty_print(),
                 problem.attribute.get_name(),
                 problem.stmt.lhs.pretty_print(),
             )
 
         if isinstance(problem.stmt, Constructor):
             # find right parameter:
             attr = problem.attribute.end.get_name()
             if attr not in problem.stmt.get_attributes():
                 attr_rhs = "?"
             else:
                 attr_rhs = problem.stmt.get_attributes()[attr].pretty_print()
-            return f"{attr_rhs}.{problem.attribute.get_name()} = {problem.stmt.pretty_print()}"
+            return "%s.%s = %s" % (attr_rhs, problem.attribute.get_name(), problem.stmt.pretty_print())
 
     def get_arguments(self, problem: ModifiedAfterFreezeException) -> Mapping[str, object]:
         return {
             "relation": problem.attribute.get_name(),
             "instance": problem.instance,
             "values": problem.resultvariable.value,
             "value": problem.value,
@@ -166,15 +165,15 @@
 
 
 class ModuleV2InV1PathExplainer(JinjaExplainer[ModuleV2InV1PathException]):
     """
     Explainer for ModuleV2InV1PathException
     """
 
-    explainable_type: type[ModuleV2InV1PathException] = ModuleV2InV1PathException
+    explainable_type: Type[ModuleV2InV1PathException] = ModuleV2InV1PathException
 
     def __init__(self) -> None:
         super().__init__("module_v2_in_v1_path.j2")
 
     def get_arguments(self, problem: ModuleV2InV1PathException) -> Mapping[str, object]:
         v2_source_configured: bool = problem.project.module_v2_source_configured() if problem.project is not None else False
         return {
@@ -186,15 +185,15 @@
 
 
 class IndexCollisionExplainer(JinjaExplainer[IndexCollisionException]):
     """
     Explainer for IndexCollisionException
     """
 
-    explainable_type: type[IndexCollisionException] = IndexCollisionException
+    explainable_type: Type[IndexCollisionException] = IndexCollisionException
 
     def __init__(self) -> None:
         super().__init__("index_collision.j2")
 
     def get_arguments(self, problem: IndexCollisionException) -> Mapping[str, object]:
         return {
             "constructor_str": problem.constructor.pretty_print(),
@@ -209,15 +208,15 @@
     return ansi_escape.sub("", line)
 
 
 class ExplainerFactory:
     def get_explainers(self) -> Sequence[ExplainerABC]:
         return [ModifiedAfterFreezeExplainer(), ModuleV2InV1PathExplainer(), IndexCollisionExplainer()]
 
-    def explain(self, problem: CompilerException) -> list[str]:
+    def explain(self, problem: CompilerException) -> List[str]:
         return [explanation for explainer in self.get_explainers() for explanation in explainer.explain(problem)]
 
     def explain_and_format(self, problem: CompilerException, plain: bool = True) -> Optional[str]:
         """
         :param plain: remove tty color codes, only return plain text
         """
         raw = self.explain(problem)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/help/templates/modified_after_freeze.j2` & `inmanta-core-9.3.0/src/inmanta/compiler/help/templates/modified_after_freeze.j2`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/compiler/help/templates/module_v2_in_v1_path.j2` & `inmanta-core-9.3.0/src/inmanta/compiler/help/templates/module_v2_in_v1_path.j2`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/config.py` & `inmanta-core-9.3.0/src/inmanta/config.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,22 +23,21 @@
 import re
 import ssl
 import sys
 import uuid
 import warnings
 from collections import abc, defaultdict
 from configparser import ConfigParser, Interpolation, SectionProxy
-from typing import Callable, Generic, Optional, TypeVar, Union, overload
+from typing import Callable, Dict, Generic, List, Optional, TypeVar, Union, overload
 from urllib import error, request
 
 from cryptography.hazmat.backends import default_backend
 from cryptography.hazmat.primitives import serialization
 from cryptography.hazmat.primitives.asymmetric.rsa import RSAPublicNumbers
 
-from crontab import CronTab
 from inmanta import const
 
 LOGGER = logging.getLogger(__name__)
 
 
 def _normalize_name(name: str) -> str:
     return name.replace("_", "-")
@@ -47,49 +46,49 @@
 def _get_from_env(section: str, name: str) -> Optional[str]:
     return os.environ.get(f"INMANTA_{section}_{name}".replace("-", "_").upper(), default=None)
 
 
 class LenientConfigParser(ConfigParser):
     def optionxform(self, name: str) -> str:
         name = _normalize_name(name)
-        return super().optionxform(name)
+        return super(LenientConfigParser, self).optionxform(name)
 
 
-class Config:
+class Config(object):
     __instance: Optional[ConfigParser] = None
     _config_dir: Optional[str] = None  # The directory this config was loaded from
-    __config_definition: dict[str, dict[str, "Option"]] = defaultdict(dict)
+    __config_definition: Dict[str, Dict[str, "Option"]] = defaultdict(lambda: {})
 
     @classmethod
-    def get_config_options(cls) -> dict[str, dict[str, "Option"]]:
+    def get_config_options(cls) -> Dict[str, Dict[str, "Option"]]:
         return cls.__config_definition
 
     @classmethod
     def load_config(
         cls,
         min_c_config_file: Optional[str] = None,
         config_dir: Optional[str] = None,
         main_cfg_file: str = "/etc/inmanta/inmanta.cfg",
     ) -> None:
         """
         Load the configuration file
         """
 
-        cfg_files_in_config_dir: list[str]
+        cfg_files_in_config_dir: List[str]
         if config_dir and os.path.isdir(config_dir):
             cfg_files_in_config_dir = sorted(
                 [os.path.join(config_dir, f) for f in os.listdir(config_dir) if f.endswith(".cfg")]
             )
         else:
             cfg_files_in_config_dir = []
 
-        local_dot_inmanta_cfg_files: list[str] = [os.path.expanduser("~/.inmanta.cfg"), ".inmanta", ".inmanta.cfg"]
+        local_dot_inmanta_cfg_files: List[str] = [os.path.expanduser("~/.inmanta.cfg"), ".inmanta", ".inmanta.cfg"]
 
         # Files with a higher index in the list, override config options defined by files with a lower index
-        files: list[str]
+        files: List[str]
         if min_c_config_file is not None:
             files = [main_cfg_file] + cfg_files_in_config_dir + local_dot_inmanta_cfg_files + [min_c_config_file]
         else:
             files = [main_cfg_file] + cfg_files_in_config_dir + local_dot_inmanta_cfg_files
 
         config = LenientConfigParser(interpolation=Interpolation())
         config.read(files)
@@ -176,15 +175,15 @@
     @classmethod
     def validate_option_request(cls, section: str, name: str, default_value: Optional[str]) -> Optional["Option"]:
         if section not in cls.__config_definition:
             LOGGER.warning("Config section %s not defined" % (section))
             # raise Exception("Config section %s not defined" % (section))
             return None
         if name not in cls.__config_definition[section]:
-            LOGGER.warning(f"Config name {name} not defined in section {section}")
+            LOGGER.warning("Config name %s not defined in section %s" % (name, section))
             # raise Exception("Config name %s not defined in section %s" % (name, section))
             return None
         opt = cls.__config_definition[section][name]
         if default_value is not None and opt.get_default_value() != default_value:
             LOGGER.warning(
                 "Inconsistent default value for option %s.%s: defined as %s, got %s"
                 % (section, name, opt.default, default_value)
@@ -204,42 +203,30 @@
 
 
 def is_time(value: str) -> int:
     """Time, the number of seconds represented as an integer value"""
     return int(value)
 
 
-def is_time_or_cron(value: str) -> Union[int, str]:
-    """Time, the number of seconds represented as an integer value or a cron-like expression"""
-    try:
-        return is_time(value)
-    except ValueError:
-        try:
-            CronTab(value)
-        except ValueError as e:
-            raise ValueError("Not an int or cron expression: %s" % value)
-        return value
-
-
 def is_bool(value: Union[bool, str]) -> bool:
     """Boolean value, represented as any of true, false, on, off, yes, no, 1, 0. (Case-insensitive)"""
     if isinstance(value, bool):
         return value
     boolean_states: abc.Mapping[str, bool] = Config._get_instance().BOOLEAN_STATES
     if value.lower() not in boolean_states:
         raise ValueError("Not a boolean: %s" % value)
     return boolean_states[value.lower()]
 
 
-def is_list(value: str) -> list[str]:
+def is_list(value: str) -> List[str]:
     """List of comma-separated values"""
     return [] if value == "" else [x.strip() for x in value.split(",")]
 
 
-def is_map(map_in: str) -> dict[str, str]:
+def is_map(map_in: str) -> Dict[str, str]:
     """List of comma-separated key=value pairs"""
     map_out = {}
     if map_in is not None:
         mappings = map_in.split(",")
 
         for mapping in mappings:
             parts = re.split("=", mapping.strip(), 1)
@@ -260,36 +247,29 @@
 def is_str_opt(value: str) -> Optional[str]:
     """optional str"""
     if value is None:
         return None
     return str(value)
 
 
-def is_uuid_opt(value: str) -> Optional[uuid.UUID]:
+def is_uuid_opt(value: str) -> uuid.UUID:
     """optional uuid"""
     if value is None:
         return None
     return uuid.UUID(value)
 
 
-def is_int_opt(value: str) -> Optional[int]:
-    """optional int"""
-    if value is None:
-        return None
-    return int(value)
-
-
 T = TypeVar("T")
 
 
 class Option(Generic[T]):
     """
     Defines an option and exposes it for use
 
-    All config option should be defined prior to use
+    All config option should be define prior to use
     For the document generator to work properly, they should be defined at the module level.
 
     :param section: section in the config file
     :param name: name of the option
     :param default: default value for this option
         the default value is either a value or a function.
         If it is a value, `str(default)` will be used a default value.
@@ -321,15 +301,15 @@
     def get(self) -> T:
         cfg = Config._get_instance()
         if self.predecessor_option:
             has_deprecated_option = cfg.has_option(self.predecessor_option.section, self.predecessor_option.name)
             has_new_option = cfg.has_option(self.section, self.name)
             if has_deprecated_option and not has_new_option:
                 warnings.warn(
-                    f"Config option {self.predecessor_option.name} is deprecated. Use {self.name} instead.",
+                    "Config option %s is deprecated. Use %s instead." % (self.predecessor_option.name, self.name),
                     category=DeprecationWarning,
                 )
                 return self.predecessor_option.get()
         out = cfg.get(self.section, self.name, fallback=self.get_default_value())
         return self.validate(out)
 
     def get_type(self) -> Optional[str]:
@@ -406,15 +386,15 @@
 nodename = Option("config", "node-name", get_default_nodename, "Force the hostname of this machine to a specific value", is_str)
 feature_file_config = Option("config", "feature-file", None, "The loacation of the inmanta feature file.", is_str_opt)
 
 
 ###############################
 # Transport Config
 ###############################
-class TransportConfig:
+class TransportConfig(object):
     """
     A class to register the config options for Client classes
     """
 
     def __init__(self, name: str, port: int = 8888) -> None:
         self.prefix = "%s_rest_transport" % name
         self.host = Option(self.prefix, "host", "localhost", "IP address or hostname of the server", is_str)
@@ -423,51 +403,44 @@
         self.ssl_ca_cert_file = Option(
             self.prefix, "ssl_ca_cert_file", None, "CA cert file used to validate the server certificate against", is_str_opt
         )
         self.token = Option(self.prefix, "token", None, "The bearer token to use to connect to the API", is_str_opt)
         self.request_timeout = Option(
             self.prefix, "request_timeout", 120, "The time before a request times out in seconds", is_int
         )
-        self.max_clients = Option(
-            self.prefix,
-            "max_clients",
-            None,
-            "The maximum number of simultaneous connections that can be open in parallel",
-            is_int_opt,
-        )
 
 
 compiler_transport = TransportConfig("compiler")
 TransportConfig("client")
 cmdline_rest_transport = TransportConfig("cmdline")
 
 
 #############################
 # auth
 #############################
 AUTH_JWT_PREFIX = "auth_jwt_"
 
 
-class AuthJWTConfig:
+class AuthJWTConfig(object):
     """
     Auth JWT configuration manager
     """
 
-    sections: dict[str, "AuthJWTConfig"] = {}
-    issuers: dict[str, "AuthJWTConfig"] = {}
+    sections: Dict[str, "AuthJWTConfig"] = {}
+    issuers: Dict[str, "AuthJWTConfig"] = {}
 
     validate_cert: bool
 
     @classmethod
     def reset(cls) -> None:
         cls.sections = {}
         cls.issuers = {}
 
     @classmethod
-    def list(cls) -> list[str]:
+    def list(cls) -> List[str]:
         """
         Return a list of all defined auth jwt configurations. This method will load new sections if they were added
         since the last invocation.
         """
         cfg = Config._get_instance()
         prefix_len = len(AUTH_JWT_PREFIX)
 
@@ -541,15 +514,15 @@
         self.validate_generic()
 
         if self.algo.lower() == "hs256":
             self.validate_hs265()
         elif self.algo.lower() == "rs256":
             self.validate_rs265()
         else:
-            raise ValueError(f"Algorithm {self.algo} in {self.section} is not support ")
+            raise ValueError("Algorithm %s in %s is not support " % (self.algo, self.section))
 
     def validate_generic(self) -> None:
         """
         Validate  and parse the generic options that are valid for all algorithms
         """
         if "sign" in self._config:
             self.sign = is_bool(self._config["sign"])
@@ -558,15 +531,15 @@
 
         if "client_types" not in self._config:
             raise ValueError("client_types is a required options for %s" % self.section)
 
         self.client_types = is_list(self._config["client_types"])
         for ct in self.client_types:
             if ct not in [client_type for client_type in const.ClientType]:
-                raise ValueError(f"invalid client_type {ct} in {self.section}")
+                raise ValueError("invalid client_type %s in %s" % (ct, self.section))
 
         if "expire" in self._config:
             self.expire = is_int(self._config["expire"])
         else:
             self.expire = 0
 
         if "issuer" in self._config:
@@ -580,15 +553,15 @@
             self.audience = self.issuer
 
     def validate_hs265(self) -> None:
         """
         Validate and parse HS256 algorithm configuration
         """
         if "key" not in self._config:
-            raise ValueError(f"key is required in {self.section} for algorithm {self.algo}")
+            raise ValueError("key is required in %s for algorithm %s" % (self.section, self.algo))
 
         self.key = base64.urlsafe_b64decode((self._config["key"] + "==").encode("ascii"))
         if len(self.key) < 32:
             raise ValueError("HS256 requires a key of 32 bytes (256 bits) or longer in " + self.section)
 
     def _load_public_key(self, e: str, n: str) -> str:
         def to_int(x: str) -> int:
@@ -627,17 +600,16 @@
         try:
             with request.urlopen(self.jwks_uri, timeout=jwks_timeout, context=ctx) as response:
                 key_data = json.loads(response.read().decode("utf-8"))
         except error.URLError as e:
             # HTTPError is raised for non-200 responses; the response
             # can be found in e.response.
             raise ValueError(
-                "Unable to load key data for %s using the provided jwks_uri %s. Got error: %s"
-                % (self.section, self.jwks_uri, e.reason)
+                "Unable to load key data for %s using the provided jwks_uri. Got error: %s" % (self.section, e.response)
             )
         except Exception as e:
             # Other errors are possible, such as IOError.
             raise ValueError("Unable to load key data for %s using the provided jwks_uri." % (self.section))
 
-        self.keys: dict[str, str] = {}
+        self.keys: Dict[str, str] = {}
         for key in key_data["keys"]:
             self.keys[key["kid"]] = self._load_public_key(key["e"], key["n"])
```

### Comparing `inmanta-core-8.7.4/src/inmanta/const.py` & `inmanta-core-9.3.0/src/inmanta/const.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,15 +12,14 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-import datetime
 from enum import Enum
 
 from inmanta.stable_api import stable_api
 
 
 class ResourceState(str, Enum):
     unavailable = "unavailable"  # This state is set by the agent when no handler is available for the resource
@@ -323,16 +322,10 @@
     warning = "warning"
     error = "error"
 
 
 CF_CACHE_DIR = ".cfcache"
 
 PG_ADVISORY_KEY_PUT_VERSION = 1
-PG_ADVISORY_KEY_RELEASE_VERSION = 2
-""" lock against releasing a version in an environment, to prevent release races"""
-
 
 # The filename of the changelog file in an Inmanta module
 MODULE_CHANGELOG_FILE = "CHANGELOG.md"
-
-
-DATETIME_MIN_UTC = datetime.datetime.min.replace(tzinfo=datetime.timezone.utc)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/data/__init__.py` & `inmanta-core-9.3.0/src/inmanta/data/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -24,20 +24,37 @@
 import logging
 import re
 import typing
 import uuid
 import warnings
 from abc import ABC, abstractmethod
 from collections import abc, defaultdict
-from collections.abc import Awaitable, Iterable, Sequence
 from configparser import RawConfigParser
 from contextlib import AbstractAsyncContextManager
 from itertools import chain
-from re import Pattern
-from typing import Any, Callable, Generic, NewType, Optional, TypeVar, Union, cast, overload
+from typing import (
+    Any,
+    Awaitable,
+    Callable,
+    Dict,
+    Generic,
+    Iterable,
+    List,
+    NewType,
+    Optional,
+    Pattern,
+    Sequence,
+    Set,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    cast,
+    overload,
+)
 from uuid import UUID
 
 import asyncpg
 import dateutil
 import pydantic
 import pydantic.tools
 import typing_inspect
@@ -46,15 +63,15 @@
 from asyncpg.protocol import Record
 
 import inmanta.const as const
 import inmanta.db.versions
 import inmanta.resources as resources
 import inmanta.util as util
 from crontab import CronTab
-from inmanta.const import DATETIME_MIN_UTC, DONE_STATES, UNDEPLOYABLE_NAMES, AgentStatus, LogLevel, ResourceState
+from inmanta.const import DONE_STATES, UNDEPLOYABLE_NAMES, AgentStatus, LogLevel, ResourceState
 from inmanta.data import model as m
 from inmanta.data import schema
 from inmanta.data.model import AuthMethod, PagingBoundaries, ResourceIdStr, api_boundary_datetime_normalizer
 from inmanta.protocol.common import custom_json_encoder
 from inmanta.protocol.exceptions import BadRequest, NotFound
 from inmanta.server import config
 from inmanta.stable_api import stable_api
@@ -75,15 +92,14 @@
 
 """
 Locking order rules:
 In general, locks should be acquired consistently with delete cascade lock order, which is top down. Additional lock orderings
 are as follows. This list should be extended when new locks (explicit or implicit) are introduced. The rules below are written
 as `A -> B`, meaning A should be locked before B in any transaction that acquires a lock on both.
 - Code -> ConfigurationModel
-- Agentprocess -> Agentinstance -> Agent
 """
 
 
 @enum.unique
 class QueryType(str, enum.Enum):
     def _generate_next_value_(name, start: int, count: int, last_values: abc.Sequence[object]) -> str:  # noqa: N805
         """
@@ -98,22 +114,21 @@
     RANGE = enum.auto()  # The values in the database are in the range described by the filter values and operators
     NOT_CONTAINS = enum.auto()  # None of the filter values are equal to the value in the database (exact match)
     COMBINED = enum.auto()  # The value describes a combination of other query types
 
 
 class InvalidQueryType(Exception):
     def __init__(self, message: str) -> None:
-        super().__init__(message)
+        super(InvalidQueryType, self).__init__(message)
         self.message = message
 
 
 class TableLockMode(enum.Enum):
     """
     Table level locks as defined in the PostgreSQL docs:
-
     https://www.postgresql.org/docs/13/explicit-locking.html#LOCKING-TABLES. When acquiring a lock, make sure to use the same
     locking order accross transactions (as described at the top of this module) to prevent deadlocks and to otherwise respect
     the consistency docs: https://www.postgresql.org/docs/13/applevel-consistency.html#NON-SERIALIZABLE-CONSISTENCY.
 
     Not all lock modes are currently supported to keep the interface minimal (only include what we actually use). This class
     may be extended when a new lock mode is required.
     """
@@ -154,27 +169,27 @@
             return cls[text.upper()]
         except KeyError:
             raise ValueError(f"Failed to parse {text} as a RangeOperator")
 
 
 RangeConstraint = list[tuple[RangeOperator, int]]
 DateRangeConstraint = list[tuple[RangeOperator, datetime.datetime]]
-QueryFilter = tuple[QueryType, object]
+QueryFilter = Tuple[QueryType, object]
 
 
 class PagingCounts:
     def __init__(self, total: int, before: int, after: int) -> None:
         self.total = total
         self.before = before
         self.after = after
 
 
 class InvalidQueryParameter(Exception):
     def __init__(self, message: str) -> None:
-        super().__init__(message)
+        super(InvalidQueryParameter, self).__init__(message)
         self.message = message
 
 
 class InvalidFieldNameException(Exception):
     def __init__(self, message: str, *args: object) -> None:
         super().__init__(message, *args)
         self.message = message
@@ -234,40 +249,40 @@
         if self == PagingOrder.ASC:
             return OrderStr("ASC NULLS FIRST")
         return OrderStr("DESC NULLS LAST")
 
 
 class InvalidSort(Exception):
     def __init__(self, message: str, *args: object) -> None:
-        super().__init__(message, *args)
+        super(InvalidSort, self).__init__(message, *args)
         self.message = message
 
 
 class ColumnType:
     """
     Class encapsulating all handling of specific column types
 
     This implementation supports the PRIMITIVE_SQL_TYPES types, for more specific behavior, make a subclass.
     """
 
-    def __init__(self, base_type: type[PRIMITIVE_SQL_TYPES], nullable: bool):
+    def __init__(self, base_type: Type[PRIMITIVE_SQL_TYPES], nullable: bool):
         self.base_type = base_type
         self.nullable = nullable
 
-    def as_basic_filter_elements(self, name: str, value: object) -> Sequence[tuple[str, "ColumnType", object]]:
+    def as_basic_filter_elements(self, name: str, value: object) -> Sequence[Tuple[str, "ColumnType", object]]:
         """
         Break down this filter into more elementary filters
 
         :param name: column name, intended to be passed through get_accessor
         :param value: the value of this column
         :return: a list of (name, type, value) items
         """
         return [(name, self, self.get_value(value))]
 
-    def as_basic_order_elements(self, name: str, order: PagingOrder) -> Sequence[tuple[str, "ColumnType", PagingOrder]]:
+    def as_basic_order_elements(self, name: str, order: PagingOrder) -> Sequence[Tuple[str, "ColumnType", PagingOrder]]:
         """
         Break down this filter into more elementary filters
 
         :param name: column name, intended to be passed through get_accessor
         :return: a list of (name, type, order) items
         """
         return [(name, self, order)]
@@ -358,30 +373,30 @@
         return super().get_accessor(column_name, table_prefix) + "::" + self.forced_type
 
 
 class ResourceVersionIdColumnType(ColumnType):
     def __init__(self) -> None:
         self.nullable = False
 
-    def as_basic_filter_elements(self, name: str, value: object) -> Sequence[tuple[str, "ColumnType", object]]:
+    def as_basic_filter_elements(self, name: str, value: object) -> Sequence[Tuple[str, "ColumnType", object]]:
         """
         Break down this filter into more elementary filters
 
         :param name: column name, intended to be passed through get_accessor
         :param value: the value of this column
         :return: a list of (name, type, value) items
         """
         assert isinstance(value, str)
         id = resources.Id.parse_resource_version_id(value)
         return [
             ("resource_id", StringColumn, StringColumn.get_value(id.resource_str())),
             ("model", PositiveIntColumn, PositiveIntColumn.get_value(id.version)),
         ]
 
-    def as_basic_order_elements(self, name: str, order: PagingOrder) -> Sequence[tuple[str, "ColumnType", PagingOrder]]:
+    def as_basic_order_elements(self, name: str, order: PagingOrder) -> Sequence[Tuple[str, "ColumnType", PagingOrder]]:
         """
         Break down this filter into more elementary filters
 
         :param name: column name, intended to be passed through get_accessor
         :return: a list of (name, type, order) items
         """
         return [("resource_id", StringColumn, order), ("model", PositiveIntColumn, order)]
@@ -434,15 +449,15 @@
     @abstractmethod
     def as_filter(
         self,
         offset: int,
         column_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         id_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         start: bool = True,
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         """
         Produce a filter for this order, to select all record before or after the given id
 
         :param offset: the next free number to use for query parameters
         :param column_value: the boundary value for the user specified order
         :param id_value: the boundary value for the built in order order
         :param start: is this the start filter? if so, retain all values`  > (column_value, id_value)`
@@ -462,26 +477,30 @@
         1. when we have a single order, and `column_value` is not None, this singe value is used for filtering
         2. when we have a double order and the 'id_value' is not None and `self.get_order_by_column_type().nullable`,
             we consider the null an effective value and filter on both `column_value` and `id_value`
         3. when we have a double order and the 'id_value' is not None and `not self.get_order_by_column_type().nullable`,
             we consider the null not a value and filter only on `id_value`
 
         """
+        pass
 
     @abstractmethod
     def get_order_by_statement(self, invert: bool = False, table: Optional[str] = None) -> str:
         """Get this order as an order_by statement"""
+        pass
 
     @abstractmethod
     def get_order(self) -> PagingOrder:
         """Return the order of this paging request"""
+        pass
 
     @abstractmethod
     def get_paging_boundaries(self, first: abc.Mapping[str, object], last: abc.Mapping[str, object]) -> PagingBoundaries:
         """Return the page boundaries, given the first and last record of the page"""
+        pass
 
 
 T_SELF = TypeVar("T_SELF", bound="SingleDatabaseOrder")
 
 
 class SingleDatabaseOrder(DatabaseOrderV2, ABC):
     """
@@ -496,22 +515,22 @@
     ) -> None:
         """The order_by_column and order parameters should be validated"""
         self.order_by_column = order_by_column
         self.order = order
 
     # Configuration methods
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Return all valid columns for lookup and their type"""
         raise NotImplementedError()
 
     #  Factory
     @classmethod
     def parse_from_string(
-        cls: type[T_SELF],
+        cls: Type[T_SELF],
         sort: str,
     ) -> T_SELF:
         valid_sort_pattern: Pattern[str] = re.compile(
             f"^({'|'.join(cls.get_valid_sort_columns().keys())})\\.(asc|desc)$", re.IGNORECASE
         )
         match = valid_sort_pattern.match(sort)
         if match and len(match.groups()) == 2:
@@ -538,15 +557,15 @@
     # External API
     def as_filter(
         self,
         offset: int,
         column_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         id_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         start: bool = True,
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         """
         Produce a filter for this order, to select all record before or after the given id
 
         :param offset: the next free number to use for query parameters
         :param column_value: the value for the user specified order
         :param id_value: the value for the built in order order, if this class has one. Otherwise this value is ignored.
         :param start: is this the start filter? if so, retain all values`  > (column_value, id_value)`
@@ -612,25 +631,26 @@
     Abstract Base class for ordering when using
     - a user specified order
     - an additional built in order to make the ordering unique (the id_collumn)
     """
 
     @property
     @abstractmethod
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
+        pass
 
     # External API
     def as_filter(
         self,
         offset: int,
         column_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         id_value: Optional[PRIMITIVE_SQL_TYPES] = None,
         start: bool = True,
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         """
         Produce a filter for this order, to select all record before or after the given id
 
         :param offset: the next free number to use for query parameters
         :param column_value: the value for the user specified order
         :param id_value: the value for the built in order order
         :param start: is this the start filter? if so, retain all values`> (column_value, id_value)`,
@@ -711,42 +731,42 @@
         )
 
 
 class VersionedResourceOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which resources should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("resource_type"): StringColumn,
             ColumnNameStr("agent"): StringColumn,
             ColumnNameStr("resource_id_value"): StringColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name of the id column of this database order"""
         return ColumnNameStr("resource_id"), StringColumn
 
 
 class ResourceOrder(VersionedResourceOrder):
     """Represents the ordering by which resources should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("resource_type"): StringColumn,
             ColumnNameStr("agent"): StringColumn,
             ColumnNameStr("resource_id"): StringColumn,
             ColumnNameStr("resource_id_value"): StringColumn,
             ColumnNameStr("status"): TextColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name of the id column of this database order"""
         return ColumnNameStr("resource_version_id"), ResourceVersionIdColumn
 
     def get_paging_boundaries(self, first: abc.Mapping[str, object], last: abc.Mapping[str, object]) -> PagingBoundaries:
         if self.get_order() == PagingOrder.ASC:
             first, last = last, first
 
@@ -767,148 +787,148 @@
         )
 
 
 class ResourceHistoryOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which resource history should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Describes the names and types of the columns that are valid for this DatabaseOrder"""
         return {ColumnNameStr("date"): DateTimeColumn}
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("attribute_hash"), StringColumn)
 
 
 class ResourceLogOrder(SingleDatabaseOrder):
     """Represents the ordering by which resource logs should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("timestamp"): DateTimeColumn,
         }
 
 
 class CompileReportOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which compile reports should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Describes the names and types of the columns that are valid for this DatabaseOrder"""
         return {ColumnNameStr("requested"): DateTimeColumn}
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("id"), UUIDColumn)
 
 
 class AgentOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which agents should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Describes the names and types of the columns that are valid for this DatabaseOrder"""
         return {
             ColumnNameStr("name"): TablePrefixWrapper("a", StringColumn),
             ColumnNameStr("process_name"): OptionalStringColumn,
             ColumnNameStr("paused"): BoolColumn,
             ColumnNameStr("last_failover"): OptionalDateTimeColumn,
             ColumnNameStr("status"): StringColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("name"), TablePrefixWrapper("a", StringColumn))
 
 
 class DesiredStateVersionOrder(SingleDatabaseOrder):
     """Represents the ordering by which desired state versions should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("version"): PositiveIntColumn,
         }
 
 
 class ParameterOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which parameters should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("name"): StringColumn,
             ColumnNameStr("source"): StringColumn,
             ColumnNameStr("updated"): OptionalDateTimeColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("id"), UUIDColumn)
 
 
 class FactOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which facts should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         return {
             ColumnNameStr("name"): StringColumn,
             ColumnNameStr("resource_id"): StringColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("id"), UUIDColumn)
 
 
 class NotificationOrder(AbstractDatabaseOrderV2):
     """Represents the ordering by which notifications should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Describes the names and types of the columns that are valid for this DatabaseOrder"""
         return {
             ColumnNameStr("created"): DateTimeColumn,
         }
 
     @property
-    def id_column(self) -> tuple[ColumnNameStr, ColumnType]:
+    def id_column(self) -> Tuple[ColumnNameStr, ColumnType]:
         """Name and type of the id column of this database order"""
         return (ColumnNameStr("id"), UUIDColumn)
 
 
 class DiscoveredResourceOrder(SingleDatabaseOrder):
     """Represents the ordering by which discovered resources should be sorted"""
 
     @classmethod
-    def get_valid_sort_columns(cls) -> dict[ColumnNameStr, ColumnType]:
+    def get_valid_sort_columns(cls) -> Dict[ColumnNameStr, ColumnType]:
         """Describes the names and types of the columns that are valid for this DatabaseOrder"""
         return {
             ColumnNameStr("discovered_resource_id"): StringColumn,
         }
 
 
 class BaseQueryBuilder(ABC):
     """Provides a way to build up a sql query from its parts.
     Each method returns a new query builder instance, with the additional parameters processed"""
 
     def __init__(
         self,
         select_clause: Optional[str] = None,
         from_clause: Optional[str] = None,
-        filter_statements: Optional[list[str]] = None,
-        values: Optional[list[object]] = None,
+        filter_statements: Optional[List[str]] = None,
+        values: Optional[List[object]] = None,
     ) -> None:
         """
         The parameters are the parts of an sql query,
         which can also be added to the builder with the appropriate methods
 
         :param select_clause: The select clause of the query
         :param from_clause: From clause of the query
@@ -916,15 +936,15 @@
         :param values: The values to be used for the filter statements
         """
         self.select_clause = select_clause
         self._from_clause = from_clause
         self.filter_statements = filter_statements or []
         self.values = values or []
 
-    def _join_filter_statements(self, filter_statements: list[str]) -> str:
+    def _join_filter_statements(self, filter_statements: List[str]) -> str:
         """Join multiple filter statements"""
         if filter_statements:
             return "WHERE " + " AND ".join(filter_statements)
         return ""
 
     @abstractmethod
     def from_clause(self, from_clause: str) -> "BaseQueryBuilder":
@@ -933,33 +953,33 @@
 
     @property
     def offset(self) -> int:
         """The current offset of the values to be used for filter statements"""
         return len(self.values) + 1
 
     @abstractmethod
-    def filter(self, filter_statements: list[str], values: list[object]) -> "BaseQueryBuilder":
+    def filter(self, filter_statements: List[str], values: List[object]) -> "BaseQueryBuilder":
         """Add filters to the query"""
         raise NotImplementedError()
 
     @abstractmethod
-    def build(self) -> tuple[str, list[object]]:
+    def build(self) -> Tuple[str, List[object]]:
         """Builds up the full query string, and the parametrized value list, ready to be executed"""
         raise NotImplementedError()
 
 
 class SimpleQueryBuilder(BaseQueryBuilder):
     """A query builder suitable for most queries"""
 
     def __init__(
         self,
         select_clause: Optional[str] = None,
         from_clause: Optional[str] = None,
-        filter_statements: Optional[list[str]] = None,
-        values: Optional[list[object]] = None,
+        filter_statements: Optional[List[str]] = None,
+        values: Optional[List[object]] = None,
         db_order: Optional[DatabaseOrderV2] = None,
         limit: Optional[int] = None,
         backward_paging: bool = False,
         prelude: Optional[str] = None,
     ) -> None:
         """
         :param select_clause: The select clause of the query
@@ -1015,27 +1035,27 @@
             self.values,
             db_order,
             limit,
             backward_paging,
             self.prelude,
         )
 
-    def filter(self, filter_statements: list[str], values: list[object]) -> "SimpleQueryBuilder":
+    def filter(self, filter_statements: List[str], values: List[object]) -> "SimpleQueryBuilder":
         return SimpleQueryBuilder(
             self.select_clause,
             self._from_clause,
             self.filter_statements + filter_statements,
             self.values + values,
             self.db_order,
             self.limit,
             self.backward_paging,
             self.prelude,
         )
 
-    def build(self) -> tuple[str, list[object]]:
+    def build(self) -> Tuple[str, List[object]]:
         if not self.select_clause or not self._from_clause:
             raise InvalidQueryParameter("A valid query must have a SELECT and a FROM clause")
         full_query = f"""{self.select_clause}
                          {self._from_clause}
                          {self._join_filter_statements(self.filter_statements)}
                          """
         if self.prelude:
@@ -1061,15 +1081,15 @@
 
 T = TypeVar("T")
 
 
 class Field(Generic[T]):
     def __init__(
         self,
-        field_type: type[T],
+        field_type: Type[T],
         required: bool = False,
         is_many: bool = False,
         part_of_primary_key: bool = False,
         ignore: bool = False,
         default: object = default_unset,
         **kwargs: object,
     ) -> None:
@@ -1095,15 +1115,15 @@
         if default != default_unset:
             self._default = True
             self._default_value = default
         else:
             self._default = False
             self._default_value = None
 
-    def get_field_type(self) -> type[T]:
+    def get_field_type(self) -> Type[T]:
         return self._field_type
 
     field_type = property(get_field_type)
 
     def is_required(self) -> bool:
         return self._required
 
@@ -1130,31 +1150,31 @@
 
     @property
     def is_many(self) -> bool:
         return self._is_many
 
     def _validate_single(self, name: str, value: object) -> None:
         """Validate a single value against the types in this field."""
-        if not isinstance(value, self.field_type):
+        if not (value.__class__ is self.field_type or isinstance(value, self.field_type)):
             raise TypeError(
                 "Field %s should have the correct type (%s instead of %s)"
                 % (name, self.field_type.__name__, type(value).__name__)
             )
 
     def validate(self, name: str, value: T) -> None:
         """Validate the value against the constraint in this field. Treat value as list when is_many is true"""
         if value is None and self.required:
             raise TypeError("%s field is required" % name)
 
         if value is None:
             return None
 
         if self.is_many:
-            if not isinstance(value, list):
-                TypeError(f"Field {name} should be a list, but got {type(value).__name__}")
+            if not isinstance(value, List):
+                TypeError("Field %s should be a list, but got %s" % (name, type(value).__name__))
             else:
                 [self._validate_single(name, v) for v in value]
         else:
             self._validate_single(name, value)
 
     def from_db(self, name: str, value: object) -> object:
         """Load values from database. Treat value as a list when is_many is true. Converts database
@@ -1162,23 +1182,23 @@
         if value is None and self.required:
             raise TypeError("%s field is required" % name)
 
         if value is None:
             return None
 
         if self.is_many:
-            if not isinstance(value, list):
-                TypeError(f"Field {name} should be a list, but got {type(value).__name__}")
+            if not isinstance(value, List):
+                TypeError("Field %s should be a list, but got %s" % (name, type(value).__name__))
             else:
                 return [self._from_db_single(name, v) for v in value]
         return self._from_db_single(name, value)
 
     def _from_db_single(self, name: str, value: object) -> object:
         """Load a single database value. Converts database representation to appropriately typed object."""
-        if isinstance(value, self.field_type):
+        if value.__class__ is self.field_type or isinstance(value, self.field_type):
             return value
 
         # asyncpg does not convert a jsonb field to a dict
         if isinstance(value, str) and self.field_type is dict:
             return json.loads(value)
         # asyncpg does not convert an enum field to an enum type
         if isinstance(value, str) and issubclass(self.field_type, enum.Enum):
@@ -1187,19 +1207,19 @@
         if isinstance(value, str) and issubclass(self.field_type, pydantic.BaseModel):
             jsv = json.loads(value)
             return self.field_type(**jsv)
         if self.field_type == pydantic.AnyHttpUrl:
             return pydantic.tools.parse_obj_as(pydantic.AnyHttpUrl, value)
 
         raise TypeError(
-            f"Field {name} should have the correct type ({self.field_type.__name__} instead of {type(value).__name__})"
+            "Field %s should have the correct type (%s instead of %s)" % (name, self.field_type.__name__, type(value).__name__)
         )
 
 
-class DataDocument:
+class DataDocument(object):
     """
     A baseclass for objects that represent data in inmanta. The main purpose of this baseclass is to group dict creation
     logic. These documents are not stored in the database
     (use BaseDocument for this purpose). It provides a to_dict method that the inmanta rpc can serialize. You can store
     DataDocument children in BaseDocument fields, they will be serialized to dict. However, on retrieval this is not
     performed.
     """
@@ -1217,28 +1237,28 @@
 class InvalidAttribute(Exception):
     def __init__(self, message: str) -> None:
         super().__init__(message)
         self.message = message
 
 
 class DocumentMeta(type):
-    def __new__(cls, class_name: str, bases: tuple[type, ...], dct: dict[str, object]) -> type:
+    def __new__(cls, class_name: str, bases: Tuple[type, ...], dct: Dict[str, object]) -> Type:
         dct["_fields_metadata"] = {}
-        new_type: type[BaseDocument] = type.__new__(cls, class_name, bases, dct)
+        new_type: Type[BaseDocument] = type.__new__(cls, class_name, bases, dct)
         if class_name != "BaseDocument":
             new_type.load_fields()
         return new_type
 
 
 TBaseDocument = TypeVar("TBaseDocument", bound="BaseDocument")  # Part of the stable API
 TransactionResult = TypeVar("TransactionResult")
 
 
 @stable_api
-class BaseDocument(metaclass=DocumentMeta):
+class BaseDocument(object, metaclass=DocumentMeta):
     """
     A base document in the database. Subclasses of this document determine collections names. This type is mainly used to
     bundle query methods and generate validate and query methods for optimized DB access. This is not a full ODM.
 
     Fields are
     modelled using type annotations similar to protocol and pydantic. The following is supported:
 
@@ -1248,17 +1268,17 @@
       without a default value, none will be set as default value so that the field is available.
     - Fields that should be ignored, can be added to __ignore_fields__ This attribute is a tuple of strings
     - Fields that are part of the primary key should be added to the __primary_key__ attributes. This attribute is a tuple of
       strings.
     """
 
     _connection_pool: Optional[asyncpg.pool.Pool] = None
-    _fields_metadata: dict[str, Field]
-    __primary_key__: tuple[str, ...]
-    __ignore_fields__: tuple[str, ...]
+    _fields_metadata: Dict[str, Field]
+    __primary_key__: Tuple[str, ...]
+    __ignore_fields__: Tuple[str, ...]
 
     def __init__(self, from_postgres: bool = False, **kwargs: object) -> None:
         """
         :param kwargs: The values to create the document. When id is defined in the fields but not provided, a new UUID is
                        generated.
         """
         self.__process_kwargs(from_postgres, kwargs)
@@ -1282,33 +1302,33 @@
     def table_name(cls) -> str:
         """
         Return the name of the collection
         """
         return cls.__name__.lower()
 
     @classmethod
-    def get_field_metadata(cls) -> dict[str, Field]:
+    def get_field_metadata(cls) -> Dict[str, Field]:
         return cls._fields_metadata.copy()
 
     @staticmethod
     def _annotation_to_field(
         attribute: str,
-        annotation: type[object],
+        annotation: Type[object],
         has_value: bool = True,
         value: Optional[object] = None,
         part_of_primary_key: bool = False,
         ignore_field: bool = False,
     ) -> Field:
         """Convert an annotated definition to a Field instance. The conversion rules are the following:
         - The value assigned to the field is the default value
         - When the default value is None the type has to be Optional
         - When the field is not optional, None is not a valid value
         - When the field has no default value, it is not required
         """
-        field_type: type[object] = annotation
+        field_type: Type[object] = annotation
         required: bool = not has_value
         default: object = default_unset
         is_many: bool = False
 
         # Only union with None (optional) is support
         if typing_inspect.is_union_type(annotation) and not typing_inspect.is_optional_type(annotation):
             raise InvalidAttribute(f"A union that is not an optional in field {attribute} is not supported.")
@@ -1328,28 +1348,28 @@
             # A default value is available, so not required. When optional type, override the default None
             required = False
             default = value
 
         if typing_inspect.is_generic_type(field_type):
             orig = typing_inspect.get_origin(field_type)
             # First two are for python3.6, the last two for 3.7 and up
-            if orig in [list, typing.Sequence, list, abc.Sequence]:
+            if orig in [typing.List, typing.Sequence, list, abc.Sequence]:
                 is_many = True
                 type_args = typing_inspect.get_args(field_type)
                 if len(type_args) == 0 or isinstance(type_args[0], typing.TypeVar):
                     # In python3.8 type_args is not empty when you write List but it will contain an instance of TypeVar
                     raise InvalidAttribute(f"Generic type of field {attribute} requires a type argument.")
                 field_type = type_args[0]
 
                 # List of Dict for example still cannot be validated. If the type is still a generic. Set the type to List of
                 # object.
                 if typing_inspect.is_generic_type(field_type):
                     field_type = object
 
-            elif orig in [typing.Mapping, dict, abc.Mapping, dict]:
+            elif orig in [typing.Mapping, typing.Dict, abc.Mapping, dict]:
                 field_type = dict
 
         if typing_inspect.is_new_type(field_type):
             # Python 3.10 and later NewType is a real type and an isinstance will work. On older version NewType is a function.
             # If this is the case we need to get the real supertype
             if callable(field_type):
                 field_type = field_type.__supertype__
@@ -1365,16 +1385,16 @@
 
     @classmethod
     def load_fields(cls) -> None:
         """Load the field metadata from the class definition. This method supports two different mechanisms:
         1. Using the field class as the value of the attribute.
         2. Using type annotations on the attributes
         """
-        primary_key: tuple[str, ...] = tuple()
-        ignore: tuple[str, ...] = tuple()
+        primary_key: Tuple[str, ...] = tuple()
+        ignore: Tuple[str, ...] = tuple()
         if "__primary_key__" in cls.__dict__:
             primary_key = cls.__primary_key__
 
         if "__ignore_fields__" in cls.__dict__:
             ignore = cls.__ignore_fields__
 
         for attribute, value in cls.__dict__.items():
@@ -1406,24 +1426,24 @@
                 )
 
     @classmethod
     def get_field_names(cls) -> typing.KeysView[str]:
         """Returns all field names in the document"""
         return cls.get_field_metadata().keys()
 
-    def __process_kwargs(self, from_postgres: bool, kwargs: dict[str, object]) -> None:
+    def __process_kwargs(self, from_postgres: bool, kwargs: Dict[str, object]) -> None:
         """This helper method process the kwargs provided to the constructor and populates the fields of the object."""
         fields = self.get_field_metadata()
 
         if "id" in fields and "id" not in kwargs:
             kwargs["id"] = uuid.uuid4()
 
         for name, value in kwargs.items():
             if name not in fields:
-                raise AttributeError(f"{name} field is not defined for this document {type(self).__name__.lower()}")
+                raise AttributeError("%s field is not defined for this document %s" % (name, type(self).__name__.lower()))
 
             field = fields[name]
             if not from_postgres:
                 field.validate(name, value)
             elif not field.ignore:
                 value = field.from_db(name, value)
             else:
@@ -1443,22 +1463,22 @@
             elif fields[name].required:
                 required_fields.append(name)
 
         if len(required_fields) > 0:
             raise AttributeError("The fields %s are required and no value was provided." % ", ".join(required_fields))
 
     @classmethod
-    def get_valid_field_names(cls) -> list[str]:
+    def get_valid_field_names(cls) -> List[str]:
         return list(cls.get_field_names())
 
     @classmethod
-    def _get_names_of_primary_key_fields(cls) -> list[str]:
+    def _get_names_of_primary_key_fields(cls) -> List[str]:
         return [name for name, value in cls.get_field_metadata().items() if value.is_part_of_primary_key()]
 
-    def _get_filter_on_primary_key_fields(self, offset: int = 1) -> tuple[str, list[Any]]:
+    def _get_filter_on_primary_key_fields(self, offset: int = 1) -> Tuple[str, List[Any]]:
         names_primary_key_fields = self._get_names_of_primary_key_fields()
         query = {field_name: self.__getattribute__(field_name) for field_name in names_primary_key_fields}
         return self._get_composed_filter(offset=offset, **query)
 
     @classmethod
     def _new_id(cls) -> uuid.UUID:
         """
@@ -1505,35 +1525,35 @@
             field.validate(name, value)
             object.__setattr__(self, name, value)
             return
 
         raise AttributeError(name)
 
     @classmethod
-    def _convert_field_names_to_db_column_names(cls, field_dict: dict[str, Any]) -> dict[str, Any]:
+    def _convert_field_names_to_db_column_names(cls, field_dict: Dict[str, Any]) -> Dict[str, Any]:
         return field_dict
 
     def get_value(self, name: str, default_value: Optional[object] = None) -> object:
         """Check if a value is set for a field. Fields that are declared but that do not have a value are only present
         in annotations but not as attribute (in __dict__)"""
         if hasattr(self, name):
             return getattr(self, name)
         return default_value
 
-    def _get_column_names_and_values(self) -> tuple[list[str], list[object]]:
-        column_names: list[str] = []
-        values: list[object] = []
+    def _get_column_names_and_values(self) -> Tuple[List[str], List[object]]:
+        column_names: List[str] = []
+        values: List[object] = []
         for name, metadata in self.get_field_metadata().items():
             if metadata.ignore:
                 continue
 
             value = self.get_value(name)
 
             if metadata.required and value is None:
-                raise TypeError(f"{self.__name__} should have field '{name}'")
+                raise TypeError("%s should have field '%s'" % (self.__name__, name))
 
             metadata.validate(name, value)
             column_names.append(name)
             values.append(self._get_value(value))
 
         return column_names, values
 
@@ -1595,38 +1615,14 @@
         """
         Acquire a table-level lock on a single environment. Callers should adhere to a consistent locking order accross
         transactions as described at the top of this module.
         Passing a connection object is mandatory. The connection is expected to be in a transaction.
         """
         await cls._execute_query(f"LOCK TABLE {cls.table_name()} IN {mode.value} MODE", connection=connection)
 
-    async def _xact_lock(
-        self, lock_key: int, instance_key: uuid.UUID, *, shared: bool = False, connection: asyncpg.Connection
-    ) -> None:
-        """
-        Acquires a transaction-level advisory lock for concurrency control
-
-        :param lock_key: the key identifying this lock (32 bit signed int)
-        :param instance_key: the key identifying the instance to lock.
-        We only use the lower 32 bits, so it can collide.
-
-        :param shared: If true, doesn't conflict with other shared locks, only with non-shared ones.
-        :param connection: The connection hosting the transaction for which to acquire a lock.
-        """
-        lock: str = "pg_advisory_xact_lock_shared" if shared else "pg_advisory_xact_lock"
-        await connection.execute(
-            # Advisory lock keys are only 32 bit (or a single 64 bit key), while a full uuid is 128 bit.
-            # Since locking slightly too strictly at extremely low odds is acceptable, we only use a 32 bit subvalue
-            # of the uuid. For uuid4, time_low is (despite the name) randomly generated. Since it is an unsigned
-            # integer while Postgres expects a signed one, we shift it by 2**31.
-            f"SELECT {lock}($1, $2)",
-            lock_key,
-            instance_key.time_low - 2**31,
-        )
-
     @classmethod
     async def insert_many(
         cls, documents: Sequence["BaseDocument"], *, connection: Optional[asyncpg.connection.Connection] = None
     ) -> None:
         """
         Insert multiple objects at once
         """
@@ -1655,15 +1651,15 @@
             return
         column_names = cls.get_field_names()
         primary_key_fields = cls._get_names_of_primary_key_fields()
         primary_key_string = ",".join(primary_key_fields)
         update_set = set(column_names) - set(cls._get_names_of_primary_key_fields())
         update_set_string = ",\n".join([f"{item} = EXCLUDED.{item}" for item in update_set])
 
-        values: list[list[object]] = [document._get_column_names_and_values()[1] for document in documents]
+        values: List[List[object]] = [document._get_column_names_and_values()[1] for document in documents]
 
         column_names_as_sql_string = ", ".join(column_names)
 
         number_of_columns = len(values[0])
         placeholders = ", ".join(
             [
                 "(" + ", ".join([f"${doc * number_of_columns + col}" for col in range(1, number_of_columns + 1)]) + ")"
@@ -1677,15 +1673,15 @@
                     ON CONFLICT ({primary_key_string})
                     DO UPDATE SET
                     {update_set_string};"""
 
         flattened_values = [item for sublist in values for item in sublist]
         await cls._execute_query(query, *flattened_values)
 
-    def add_default_values_when_undefined(self, **kwargs: object) -> dict[str, object]:
+    def add_default_values_when_undefined(self, **kwargs: object) -> Dict[str, object]:
         result = dict(kwargs)
         for name, field in self._fields.items():
             if name not in kwargs:
                 default_value = field.default_value
                 result[name] = default_value
         return result
 
@@ -1700,15 +1696,15 @@
         (column_names, values) = self._get_column_names_and_values()
         values_as_parameterized_sql_string = ",".join([column_names[i - 1] + "=$" + str(i) for i in range(1, len(values) + 1)])
         (filter_statement, values_for_filter) = self._get_filter_on_primary_key_fields(offset=len(column_names) + 1)
         values = values + values_for_filter
         query = "UPDATE " + self.table_name() + " SET " + values_as_parameterized_sql_string + " WHERE " + filter_statement
         await self._execute_query(query, *values, connection=connection)
 
-    def _get_set_statement(self, **kwargs: object) -> tuple[str, list[object]]:
+    def _get_set_statement(self, **kwargs: object) -> Tuple[str, List[object]]:
         counter = 1
         parts_of_set_statement = []
         values = []
         for name, value in kwargs.items():
             setattr(self, name, value)
             parts_of_set_statement.append(name + "=$" + str(counter))
             values.append(self._get_value(value))
@@ -1730,29 +1726,29 @@
         (filter_statement, values_for_filter) = self._get_filter_on_primary_key_fields(offset=len(kwargs) + 1)
         values = values_set_statement + values_for_filter
         query = "UPDATE " + self.table_name() + " SET " + set_statement + " WHERE " + filter_statement
         await self._execute_query(query, *values, connection=connection)
 
     @classmethod
     async def get_by_id(
-        cls: type[TBaseDocument], doc_id: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None
+        cls: Type[TBaseDocument], doc_id: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None
     ) -> Optional[TBaseDocument]:
         """
         Get a specific document based on its ID
 
         :return: An instance of this class with its fields filled from the database.
         """
         result = await cls.get_list(id=doc_id, connection=connection)
         if len(result) > 0:
             return result[0]
         return None
 
     @classmethod
     async def get_one(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         connection: Optional[asyncpg.connection.Connection] = None,
         lock: Optional[RowLockMode] = None,
         **query: object,
     ) -> Optional[TBaseDocument]:
         results = await cls.get_list(
             connection=connection,
             order_by_column=None,
@@ -1764,15 +1760,15 @@
             **query,
         )
         if results:
             return results[0]
         return None
 
     @classmethod
-    def _validate_order(cls, order_by_column: str, order: str) -> tuple[ColumnNameStr, OrderStr]:
+    def _validate_order(cls, order_by_column: str, order: str) -> Tuple[ColumnNameStr, OrderStr]:
         """Validate the correct values for order and if the order column is an existing column name
         :param order_by_column: The name of the column to order by
         :param order: The sorting order.
         :return:
         """
         for o in order.split(" "):
             possible = ["ASC", "DESC", "NULLS", "FIRST", "LAST"]
@@ -1781,15 +1777,15 @@
 
         if order_by_column not in cls.get_field_names():
             raise RuntimeError(f"{order_by_column} is not a valid field name.")
 
         return ColumnNameStr(order_by_column), OrderStr(order)
 
     @classmethod
-    def _validate_order_strict(cls, order_by_column: str, order: str) -> tuple[ColumnNameStr, PagingOrder]:
+    def _validate_order_strict(cls, order_by_column: str, order: str) -> Tuple[ColumnNameStr, PagingOrder]:
         """Validate the correct values for order ('ASC' or 'DESC')  and if the order column is an existing column name
         :param order_by_column: The name of the column to order by
         :param order: The sorting order.
         :return:
         """
         for o in order.split(" "):
             possible = ["ASC", "DESC"]
@@ -1799,26 +1795,26 @@
         if order_by_column not in cls.get_valid_field_names():
             raise RuntimeError(f"{order_by_column} is not a valid field name.")
 
         return ColumnNameStr(order_by_column), PagingOrder[order]
 
     @classmethod
     async def get_list(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         *,
         # All defaults None rather actual values to allow explicitly requesting defaults to improve type safety with **query
         order_by_column: Optional[str] = None,
         order: Optional[str] = None,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
         **query: object,
-    ) -> list[TBaseDocument]:
+    ) -> List[TBaseDocument]:
         """
         Get a list of documents matching the filter args
         """
         return await cls.get_list_with_columns(
             order_by_column=order_by_column,
             order=order,
             limit=limit,
@@ -1828,26 +1824,26 @@
             connection=connection,
             columns=None,
             **query,
         )
 
     @classmethod
     async def get_list_with_columns(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         *,
         order_by_column: Optional[str] = None,
         order: Optional[str] = None,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
-        columns: Optional[list[str]] = None,
+        columns: Optional[List[str]] = None,
         **query: object,
-    ) -> list[TBaseDocument]:
+    ) -> List[TBaseDocument]:
         """
         Get a list of documents matching the filter args
         """
         if order is None:
             order = "ASC"
         if order_by_column:
             cls._validate_order(order_by_column, order)
@@ -1874,27 +1870,27 @@
         if lock is not None:
             sql_query += f" {lock.value}"
         result = await cls.select_query(sql_query, values, no_obj=no_obj, connection=connection)
         return result
 
     @classmethod
     async def get_list_paged(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         *,
         page_by_column: str,
         order_by_column: Optional[str] = None,
         order: Optional[str] = None,
         limit: Optional[int] = None,
         start: Optional[Any] = None,
         end: Optional[Any] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
         **query: object,
-    ) -> list[TBaseDocument]:
+    ) -> List[TBaseDocument]:
         """
         Get a list of documents matching the filter args, with paging support
 
         :param page_by_column: The name of the column in the database on which the paging should be applied
         :param order_by_column: The name of the column in the database the sorting should be based on
         :param order: The order to apply to the sorting
         :param limit: If specified, the maximum number of entries to return
@@ -1948,42 +1944,42 @@
         result = await cls._execute_query(query, *values, connection=connection)
         record_count = int(result.split(" ")[1])
         return record_count
 
     @classmethod
     def _get_composed_filter(
         cls, offset: int = 1, col_name_prefix: Optional[str] = None, **query: object
-    ) -> tuple[str, list[object]]:
+    ) -> Tuple[str, List[object]]:
         filter_statements = []
         values = []
         index_count = max(1, offset)
         for key, value in query.items():
             cls.validate_field_name(key)
             name = cls._add_column_name_prefix_if_needed(key, col_name_prefix)
             (filter_statement, value) = cls._get_filter(name, value, index_count)
             filter_statements.append(filter_statement)
             values.extend(value)
             index_count += len(value)
         filter_as_string = " AND ".join(filter_statements)
         return (filter_as_string, values)
 
     @classmethod
-    def _get_filter(cls, name: str, value: Any, index: int) -> tuple[str, list[object]]:
+    def _get_filter(cls, name: str, value: Any, index: int) -> Tuple[str, List[object]]:
         if value is None:
             return (name + " IS NULL", [])
         filter_statement = name + "=$" + str(index)
         value = cls._get_value(value)
         return (filter_statement, [value])
 
     @classmethod
     def _get_value(cls, value: object) -> object:
         if isinstance(value, dict):
             return json_encode(value)
 
-        if isinstance(value, DataDocument):
+        if isinstance(value, DataDocument) or issubclass(value.__class__, DataDocument):
             return json_encode(value)
 
         if isinstance(value, list):
             return [cls._get_value(x) for x in value]
 
         if isinstance(value, enum.Enum):
             return value.name
@@ -1992,49 +1988,49 @@
             return str(value)
 
         return value
 
     @classmethod
     def get_composed_filter_with_query_types(
         cls, offset: int = 1, col_name_prefix: Optional[str] = None, **query: QueryFilter
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         filter_statements = []
-        values: list[object] = []
+        values: List[object] = []
         index_count = max(1, offset)
         for key, value_with_query_type in query.items():
             query_type, value = value_with_query_type
             filter_statement: str
-            filter_values: list[object]
+            filter_values: List[object]
             name = cls._add_column_name_prefix_if_needed(key, col_name_prefix)
             filter_statement, filter_values = cls.get_filter_for_query_type(query_type, name, value, index_count)
             filter_statements.append(filter_statement)
             values.extend(filter_values)
             index_count += len(filter_values)
 
         return (filter_statements, values)
 
     @classmethod
     def get_filter_for_query_type(
         cls, query_type: QueryType, key: str, value: object, index_count: int
-    ) -> tuple[str, list[object]]:
+    ) -> Tuple[str, List[object]]:
         if query_type == QueryType.EQUALS:
             (filter_statement, filter_values) = cls._get_filter(key, value, index_count)
         elif query_type == QueryType.IS_NOT_NULL:
             (filter_statement, filter_values) = cls.get_is_not_null_filter(key)
         elif query_type == QueryType.CONTAINS:
             (filter_statement, filter_values) = cls.get_contains_filter(key, value, index_count)
         elif query_type == QueryType.CONTAINS_PARTIAL:
             (filter_statement, filter_values) = cls.get_contains_partial_filter(key, value, index_count)
         elif query_type == QueryType.RANGE:
             (filter_statement, filter_values) = cls.get_range_filter(key, value, index_count)
         elif query_type == QueryType.NOT_CONTAINS:
             (filter_statement, filter_values) = cls.get_not_contains_filter(key, value, index_count)
         elif query_type == QueryType.COMBINED:
             (filter_statement, filter_values) = cls.get_filter_for_combined_query_type(
-                key, cast(dict[QueryType, object], value), index_count
+                key, cast(Dict[QueryType, object], value), index_count
             )
         else:
             raise InvalidQueryType(f"Query type should be one of {[query for query in QueryType]}")
         return (filter_statement, filter_values)
 
     @classmethod
     def validate_field_name(cls, name: str) -> ColumnNameStr:
@@ -2046,110 +2042,110 @@
     @classmethod
     def _add_column_name_prefix_if_needed(cls, filter_statement: str, col_name_prefix: Optional[str] = None) -> str:
         if col_name_prefix is not None:
             filter_statement = f"{col_name_prefix}.{filter_statement}"
         return filter_statement
 
     @classmethod
-    def get_is_not_null_filter(cls, name: str) -> tuple[str, list[object]]:
+    def get_is_not_null_filter(cls, name: str) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter on values that are not null.
         """
         filter_statement = f"{name} IS NOT NULL"
         return (filter_statement, [])
 
     @classmethod
-    def get_contains_filter(cls, name: str, value: object, index: int) -> tuple[str, list[object]]:
+    def get_contains_filter(cls, name: str, value: object, index: int) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter on values that are contained in a given
         collection.
         """
         filter_statement = f"{name} = ANY (${str(index)})"
         value = cls._get_value(value)
         return (filter_statement, [value])
 
     @classmethod
     def get_filter_for_combined_query_type(
-        cls, name: str, combined_value: dict[QueryType, object], index: int
-    ) -> tuple[str, list[object]]:
+        cls, name: str, combined_value: Dict[QueryType, object], index: int
+    ) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter a single column
         based on the defined query types
         """
         filters = []
         for query_type, value in combined_value.items():
             filter_statement, filter_values = cls.get_filter_for_query_type(query_type, name, value, index)
             filters.append((filter_statement, filter_values))
             index += len(filter_values)
         (filter_statement, values) = cls._combine_filter_statements(filters)
 
         return (filter_statement, values)
 
     @classmethod
-    def get_not_contains_filter(cls, name: str, value: object, index: int) -> tuple[str, list[object]]:
+    def get_not_contains_filter(cls, name: str, value: object, index: int) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter on values that are not contained in a given
         collection.
         """
         filter_statement = f"NOT ({name} = ANY (${str(index)}))"
         value = cls._get_value(value)
         return (filter_statement, [value])
 
     @classmethod
-    def get_contains_partial_filter(cls, name: str, value: object, index: int) -> tuple[str, list[object]]:
+    def get_contains_partial_filter(cls, name: str, value: object, index: int) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter on values that are contained in a given
         collection.
         """
 
         filter_statement = f"{name} ILIKE ANY (${str(index)})"
         value = cls._get_value(value)
         value = [f"%{v}%" for v in value]
         return (filter_statement, [value])
 
     @classmethod
     def get_range_filter(
         cls, name: str, value: Union[DateRangeConstraint, RangeConstraint], index: int
-    ) -> tuple[str, list[object]]:
+    ) -> Tuple[str, List[object]]:
         """
         Returns a tuple of a PostgresQL statement and any query arguments to filter on values that match a given range
         constraint.
         """
         filter_statement: str
-        values: list[object]
+        values: List[object]
         (filter_statement, values) = cls._combine_filter_statements(
             (
                 f"{name} {operator.pg_value} ${str(index + i)}",
                 [cls._get_value(bound)],
             )
             for i, (operator, bound) in enumerate(value)
         )
         return (filter_statement, [cls._get_value(v) for v in values])
 
     @staticmethod
-    def _combine_filter_statements(statements_and_values: Iterable[tuple[str, list[object]]]) -> tuple[str, list[object]]:
-        filter_statements: tuple[str]
-        values: tuple[list[object]]
+    def _combine_filter_statements(statements_and_values: Iterable[Tuple[str, List[object]]]) -> Tuple[str, List[object]]:
+        filter_statements: Tuple[str]
+        values: Tuple[List[object]]
         filter_statements, values = zip(*statements_and_values)  # type: ignore
         return (
             " AND ".join(s for s in filter_statements if s != ""),
             list(chain.from_iterable(values)),
         )
 
     @classmethod
     def _add_start_filter(
         cls,
         offset: int,
         order_by_column: ColumnNameStr,
         id_column: ColumnNameStr,
         start: Optional[Any] = None,
         first_id: Optional[Union[uuid.UUID, str]] = None,
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         filter_statements = []
-        values: list[object] = []
+        values: List[object] = []
         if start is not None and first_id:
             filter_statements.append(f"({order_by_column}, {id_column}) > (${str(offset + 1)}, ${str(offset + 2)})")
             values.append(cls._get_value(start))
             values.append(cls._get_value(first_id))
         elif start is not None:
             filter_statements.append(f"{order_by_column} > ${str(offset + 1)}")
             values.append(cls._get_value(start))
@@ -2159,74 +2155,74 @@
     def _add_end_filter(
         cls,
         offset: int,
         order_by_column: ColumnNameStr,
         id_column: ColumnNameStr,
         end: Optional[Any] = None,
         last_id: Optional[Union[uuid.UUID, str]] = None,
-    ) -> tuple[list[str], list[object]]:
+    ) -> Tuple[List[str], List[object]]:
         filter_statements = []
-        values: list[object] = []
+        values: List[object] = []
         if end is not None and last_id:
             filter_statements.append(f"({order_by_column}, {id_column}) < (${str(offset + 1)}, ${str(offset + 2)})")
             values.append(cls._get_value(end))
             values.append(cls._get_value(last_id))
         elif end is not None:
             filter_statements.append(f"{order_by_column} < ${str(offset + 1)}")
             values.append(cls._get_value(end))
         return filter_statements, values
 
     @classmethod
-    def _join_filter_statements(cls, filter_statements: list[str]) -> str:
+    def _join_filter_statements(cls, filter_statements: List[str]) -> str:
         if filter_statements:
             return "WHERE " + " AND ".join(filter_statements)
         return ""
 
     async def delete(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
         """
         Delete this document
         """
         (filter_as_string, values) = self._get_filter_on_primary_key_fields()
         query = "DELETE FROM " + self.table_name() + " WHERE " + filter_as_string
         await self._execute_query(query, *values, connection=connection)
 
-    async def delete_cascade(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        await self.delete(connection=connection)
+    async def delete_cascade(self) -> None:
+        await self.delete()
 
     @classmethod
     @overload
     async def select_query(
-        cls: type[TBaseDocument], query: str, values: list[object], connection: Optional[asyncpg.connection.Connection] = None
+        cls: Type[TBaseDocument], query: str, values: List[object], connection: Optional[asyncpg.connection.Connection] = None
     ) -> Sequence[TBaseDocument]:
         """Return a sequence of objects of cls type."""
         ...
 
     @classmethod
     @overload
     async def select_query(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         query: str,
-        values: list[object],
+        values: List[object],
         no_obj: bool,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> Sequence[Record]:
         """Return a sequence of records instances"""
         ...
 
     @classmethod
     async def select_query(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         query: str,
-        values: list[object],
+        values: List[object],
         no_obj: bool = False,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> Sequence[Union[Record, TBaseDocument]]:
         async with cls.get_connection(connection) as con:
             async with con.transaction():
-                result: list[Union[Record, TBaseDocument]] = []
+                result: List[Union[Record, TBaseDocument]] = []
                 async for record in con.cursor(query, *values):
                     if no_obj:
                         result.append(record)
                     else:
                         result.append(cls(from_postgres=True, **record))
                 return result
 
@@ -2235,15 +2231,15 @@
         Return a dict representing the document
         """
         result = {}
         for name, metadata in self.get_field_metadata().items():
             value = self.get_value(name)
 
             if metadata.required and value is None:
-                raise TypeError(f"{self.__name__} should have field '{name}'")
+                raise TypeError("%s should have field '%s'" % (self.__name__, name))
 
             if value is not None:
                 metadata.validate(name, value)
                 result[name] = value
 
             elif metadata.default:
                 result[name] = metadata.default_value
@@ -2287,25 +2283,14 @@
 
     id: uuid.UUID
     name: str
 
     def to_dto(self) -> m.Project:
         return m.Project(id=self.id, name=self.name, environments=[])
 
-    async def delete_cascade(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """
-        This method doesn't rely on the DELETE CASCADE functionality of PostgreSQL because it causes deadlocks.
-        As such, we perform the deletes on each table in a separate transaction.
-        """
-        async with self.get_connection(connection=connection) as con:
-            envs_in_project: abc.Sequence[Environment] = await Environment.get_list(project=self.id, connection=con)
-            for env in envs_in_project:
-                await env.delete_cascade(connection=con)
-            await self.delete(connection=con)
-
 
 def convert_boolean(value: Union[bool, str]) -> bool:
     if isinstance(value, bool):
         return value
 
     if value.lower() not in RawConfigParser.BOOLEAN_STATES:
         raise ValueError("Not a boolean: %s" % value)
@@ -2330,15 +2315,15 @@
     else:
         float_value = float(value)
     if float_value < 0:
         raise ValueError(f"This value should be positive, got: {value}")
     return float_value
 
 
-def convert_agent_map(value: dict[str, str]) -> dict[str, str]:
+def convert_agent_map(value: Dict[str, str]) -> Dict[str, str]:
     if not isinstance(value, dict):
         raise ValueError("Agent map should be a dict")
 
     for key, v in value.items():
         if not isinstance(key, str):
             raise ValueError("The key of an agent map should be string")
 
@@ -2359,38 +2344,25 @@
 
 def convert_agent_trigger_method(value: object) -> str:
     if isinstance(value, const.AgentTriggerMethod):
         return value
     value = str(value)
     valid_values = [x.name for x in const.AgentTriggerMethod]
     if value not in valid_values:
-        raise ValueError("{} is not a valid agent trigger method. Valid value: {}".format(value, ",".join(valid_values)))
+        raise ValueError("%s is not a valid agent trigger method. Valid value: %s" % (value, ",".join(valid_values)))
     return value
 
 
-def validate_cron_or_int(value: Union[int, str]) -> str:
-    try:
-        return str(int(value))
-    except ValueError:
-        try:
-            assert isinstance(value, str)  # Make mypy happy
-            return validate_cron(value, allow_empty=False)
-        except ValueError as e:
-            raise ValueError(f"'{value}' is not a valid cron expression or int: {e}")
-
-
-def validate_cron(value: str, allow_empty: bool = True) -> str:
+def validate_cron(value: str) -> str:
     if not value:
-        if allow_empty:
-            return ""
-        raise ValueError("The given cron expression is an empty string")
+        return ""
     try:
         CronTab(value)
     except ValueError as e:
-        raise ValueError(f"'{value}' is not a valid cron expression: {e}")
+        raise ValueError("'%s' is not a valid cron expression: %s" % (value, e))
     return value
 
 
 TYPE_MAP = {
     "int": "integer",
     "bool": "boolean",
     "dict": "jsonb",
@@ -2411,38 +2383,37 @@
 AUTOSTART_ON_START = "autostart_on_start"
 AUTOSTART_AGENT_MAP = "autostart_agent_map"
 AUTOSTART_AGENT_INTERVAL = "autostart_agent_interval"
 AGENT_AUTH = "agent_auth"
 SERVER_COMPILE = "server_compile"
 AUTO_FULL_COMPILE = "auto_full_compile"
 RESOURCE_ACTION_LOGS_RETENTION = "resource_action_logs_retention"
-PURGE_ON_DELETE = "purge_on_delete"
 PROTECTED_ENVIRONMENT = "protected_environment"
 NOTIFICATION_RETENTION = "notification_retention"
 AVAILABLE_VERSIONS_TO_KEEP = "available_versions_to_keep"
 RECOMPILE_BACKOFF = "recompile_backoff"
 ENVIRONMENT_METRICS_RETENTION = "environment_metrics_retention"
 
 
-class Setting:
+class Setting(object):
     """
     A class to define a new environment setting.
     """
 
     def __init__(
         self,
         name: str,
         typ: str,
         default: Optional[m.EnvSettingType] = None,
         doc: Optional[str] = None,
         validator: Optional[Callable[[m.EnvSettingType], m.EnvSettingType]] = None,
         recompile: bool = False,
         update_model: bool = False,
         agent_restart: bool = False,
-        allowed_values: Optional[list[m.EnvSettingType]] = None,
+        allowed_values: Optional[List[m.EnvSettingType]] = None,
     ) -> None:
         """
         :param name: The name of the setting.
         :param type: The type of the value. This type is mainly used for documentation purpose.
         :param default: An optional default value for this setting. When a default is set and the
                         is requested from the database, it will return the default value and also store
                         the default value in the database.
@@ -2499,62 +2470,55 @@
 class Environment(BaseDocument):
     """
     A deployment environment of a project
 
     :param id: A unique, machine generated id
     :param name: The name of the deployment environment.
     :param project: The project this environment belongs to.
-    :param repo_url: The repository url that contains the configuration model code for this environment.
-    :param repo_branch: The repository branch that contains the configuration model code for this environment.
-    :param settings:
-
-        Key/value settings for this environment. This dictionary does not necessarily contain a key
-        for every environment setting known by the server. This is done for backwards compatibility reasons.
-        When a setting was renamed, we need to determine whether the old or the new setting has to be taken into
-        account. The logic to decide that is the following:
-
-        * When the name of the new setting is present in this settings dictionary or when the name of the old
-          setting is not present in the settings dictionary, use the new setting.
-
-        * Otherwise, use the setting with the old name.
-
+    :param repo_url: The repository url that contains the configuration model code for this environment
+    :param repo_branch: The repository branch that contains the configuration model code for this environment
+    :param settings: Key/value settings for this environment. This dictionary does not necessarily contain a key
+                     for every environment setting known by the server. This is done for backwards compatibility reasons.
+                     When a setting was renamed, we need to determine whether the old or the new setting has to be taken into
+                     account. The logic to decide that is the following:
+                        * When the name of the new setting is present in this settings dictionary or when the name of the old
+                          setting is not present in the settings dictionary, use the new setting.
+                        * Otherwise, use the setting with the old name.
     :param last_version: The last version number that was reserved for this environment
     :param description: The description of the environment
     :param icon: An icon for the environment
     """
 
     __primary_key__ = ("id",)
 
     id: uuid.UUID
     name: str
     project: uuid.UUID
     repo_url: str = ""
     repo_branch: str = ""
-    settings: dict[str, m.EnvSettingType] = {}
+    settings: Dict[str, m.EnvSettingType] = {}
     last_version: int = 0
     halted: bool = False
     description: str = ""
     icon: str = ""
-    is_marked_for_deletion: bool = False
 
     def to_dto(self) -> m.Environment:
         return m.Environment(
             id=self.id,
             name=self.name,
             project_id=self.project,
             repo_url=self.repo_url,
             repo_branch=self.repo_branch,
             settings=self.settings,
             halted=self.halted,
-            is_marked_for_deletion=self.is_marked_for_deletion,
             description=self.description,
             icon=self.icon,
         )
 
-    _settings: dict[str, Setting] = {
+    _settings: Dict[str, Setting] = {
         AUTO_DEPLOY: Setting(
             name=AUTO_DEPLOY,
             typ="bool",
             default=True,
             doc="When this boolean is set to true, the orchestrator will automatically release a new version "
             "that was compiled by the orchestrator itself.",
             validator=convert_boolean,
@@ -2589,41 +2553,37 @@
             typ="int",
             default=10,
             doc="[DEPRECATED] Splay time for autostarted agents.",
             validator=convert_int,
         ),
         AUTOSTART_AGENT_DEPLOY_INTERVAL: Setting(
             name=AUTOSTART_AGENT_DEPLOY_INTERVAL,
-            typ="str",
-            default="600",
-            doc="The deployment interval of the autostarted agents. Can be specified as a number of seconds"
-            " or as a cron-like expression."
+            typ="int",
+            default=600,
+            doc="The deployment interval of the autostarted agents."
             " See also: :inmanta.config:option:`config.agent-deploy-interval`",
-            validator=validate_cron_or_int,
+            validator=convert_int,
             agent_restart=True,
         ),
         AUTOSTART_AGENT_DEPLOY_SPLAY_TIME: Setting(
             name=AUTOSTART_AGENT_DEPLOY_SPLAY_TIME,
             typ="int",
             default=10,
             doc="The splay time on the deployment interval of the autostarted agents."
             " See also: :inmanta.config:option:`config.agent-deploy-splay-time`",
             validator=convert_int,
             agent_restart=True,
         ),
         AUTOSTART_AGENT_REPAIR_INTERVAL: Setting(
             name=AUTOSTART_AGENT_REPAIR_INTERVAL,
-            typ="str",
-            default="86400",
-            doc=(
-                "The repair interval of the autostarted agents. Can be specified as a number of seconds"
-                " or as a cron-like expression."
-                " See also: :inmanta.config:option:`config.agent-repair-interval`"
-            ),
-            validator=validate_cron_or_int,
+            typ="int",
+            default=86400,
+            doc="The repair interval of the autostarted agents."
+            " See also: :inmanta.config:option:`config.agent-repair-interval`",
+            validator=convert_int,
             agent_restart=True,
         ),
         AUTOSTART_AGENT_REPAIR_SPLAY_TIME: Setting(
             name=AUTOSTART_AGENT_REPAIR_SPLAY_TIME,
             typ="int",
             default=600,
             doc="The splay time on the repair interval of the autostarted agents."
@@ -2664,17 +2624,16 @@
         ),
         AUTO_FULL_COMPILE: Setting(
             name=AUTO_FULL_COMPILE,
             default="",
             typ="str",
             validator=validate_cron,
             doc=(
-                "Periodically run a full compile following a cron-like time-to-run specification interpreted in UTC with format"
-                " `[sec] min hour dom month dow [year]` (If only 6 values are provided, they are interpreted as"
-                " `min hour dom month dow year`). A compile will be requested at the scheduled time. The actual"
+                "Periodically run a full compile following a cron-like time-to-run specification, interpreted in UTC"
+                " (e.g. `min hour dom month dow`). A compile will be requested at the scheduled time. The actual"
                 " compilation may have to wait in the compile queue for some time, depending on the size of the queue and the"
                 " RECOMPILE_BACKOFF environment setting. This setting has no effect when server_compile is disabled."
             ),
         ),
         RESOURCE_ACTION_LOGS_RETENTION: Setting(
             name=RESOURCE_ACTION_LOGS_RETENTION,
             default=7,
@@ -2683,30 +2642,22 @@
             doc="The number of days to retain resource-action logs",
         ),
         AVAILABLE_VERSIONS_TO_KEEP: Setting(
             name=AVAILABLE_VERSIONS_TO_KEEP,
             default=100,
             typ="int",
             validator=convert_int,
-            doc="The number of versions to keep stored in the database, excluding the latest released version.",
-        ),
-        PURGE_ON_DELETE: Setting(
-            name=PURGE_ON_DELETE,
-            default=False,
-            typ="bool",
-            validator=convert_boolean,
-            doc="Enable purge on delete. When set to true, the server will detect the absence of resources with purge_on_delete"
-            " set to true and automatically purges them.",
+            doc="The number of versions to keep stored in the database",
         ),
         PROTECTED_ENVIRONMENT: Setting(
             name=PROTECTED_ENVIRONMENT,
             default=False,
             typ="bool",
             validator=convert_boolean,
-            doc="When set to true, this environment cannot be cleared, deleted or decommissioned.",
+            doc="When set to true, this environment cannot be cleared or deleted.",
         ),
         NOTIFICATION_RETENTION: Setting(
             name=NOTIFICATION_RETENTION,
             default=365,
             typ="int",
             validator=convert_int,
             doc="The number of days to retain notifications for",
@@ -2752,15 +2703,15 @@
         if key not in self._settings:
             raise KeyError()
 
         if key in self._renamed_settings_map:
             name_deprecated_setting = self._renamed_settings_map[key]
             if name_deprecated_setting in self.settings and key not in self.settings:
                 warnings.warn(
-                    f"Config option {name_deprecated_setting} is deprecated. Use {key} instead.",
+                    "Config option %s is deprecated. Use %s instead." % (name_deprecated_setting, key),
                     category=DeprecationWarning,
                 )
                 return self.settings[name_deprecated_setting]
 
         if key in self.settings:
             return self.settings[key]
 
@@ -2802,17 +2753,18 @@
                         ELSE jsonb_set(settings, $3::text[], to_jsonb($4::{type}), TRUE)
                         END
                     )
                 WHERE {filter_statement}
                 RETURNING settings
         """
         values = [allow_override, self._get_value(key), self._get_value([key]), self._get_value(value)] + values
+
         new_value = await self._fetchval(query, *values, connection=connection)
         new_value_parsed = cast(
-            dict[str, m.EnvSettingType], self.get_field_metadata()["settings"].from_db(name="settings", value=new_value)
+            Dict[str, m.EnvSettingType], self.get_field_metadata()["settings"].from_db(name="settings", value=new_value)
         )
         self.settings[key] = new_value_parsed[key]
 
     async def unset(self, key: str) -> None:
         """
         Unset a setting in this environment. If a default value is provided, this value will replace the current value.
 
@@ -2826,53 +2778,36 @@
             query = "UPDATE " + self.table_name() + " SET settings=settings - $1" + " WHERE " + filter_statement
             values = [self._get_value(key)] + values
             await self._execute_query(query, *values)
             del self.settings[key]
         else:
             await self.set(key, self._settings[key].default)
 
-    async def mark_for_deletion(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """Mark an environment as being in the process of deletion."""
-        await self.update_fields(is_marked_for_deletion=True, connection=connection)
-
-    async def delete_cascade(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """
-        Completely remove this environment from the db
-        """
-        async with self.get_connection(connection=connection) as con:
-            await self.clear(connection=con)
-            await self.delete(connection=con)
-
-    async def clear(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """
-        Delete everything related to this environment from the db, except the entry in the Environment table.
-
-        This method doesn't rely on the DELETE CASCADE functionality of PostgreSQL because it causes deadlocks.
-        This is especially true for the tables resourceaction_resource, resource and resourceaction, because they
-        have a high read/write load. As such, we perform the deletes on each table in a separate transaction.
-        """
-        async with self.get_connection(connection=connection) as con:
-            await Agent.delete_all(environment=self.id, connection=con)
-            await AgentInstance.delete_all(tid=self.id, connection=con)
-            await AgentProcess.delete_all(environment=self.id, connection=con)
-            await Compile.delete_all(environment=self.id, connection=con)  # Triggers cascading delete on report table
-            await Parameter.delete_all(environment=self.id, connection=con)
-            await Notification.delete_all(environment=self.id, connection=con)
-            await Code.delete_all(environment=self.id, connection=con)
-            await DiscoveredResource.delete_all(environment=self.id, connection=con)
-            await EnvironmentMetricsGauge.delete_all(environment=self.id, connection=con)
-            await EnvironmentMetricsTimer.delete_all(environment=self.id, connection=con)
-            await DryRun.delete_all(environment=self.id, connection=con)
-            await UnknownParameter.delete_all(environment=self.id, connection=con)
-            await self._execute_query(
-                "DELETE FROM public.resourceaction_resource WHERE environment=$1", self.id, connection=con
-            )
-            await ResourceAction.delete_all(environment=self.id, connection=con)
-            await Resource.delete_all(environment=self.id, connection=con)
-            await ConfigurationModel.delete_all(environment=self.id, connection=con)
+    async def delete_cascade(self, only_content: bool = False) -> None:
+        if only_content:
+            await Agent.delete_all(environment=self.id)
+
+            procs = await AgentProcess.get_list(environment=self.id)
+            for proc in procs:
+                await proc.delete_cascade()
+
+            compile_list = await Compile.get_list(environment=self.id)
+            for cl in compile_list:
+                await cl.delete_cascade()
+
+            for model in await ConfigurationModel.get_list(environment=self.id):
+                await model.delete_cascade()
+
+            await Parameter.delete_all(environment=self.id)
+            await Resource.delete_all(environment=self.id)
+            await ResourceAction.delete_all(environment=self.id)
+            await Notification.delete_all(environment=self.id)
+        else:
+            # Cascade is done by PostgreSQL
+            await self.delete()
 
     async def get_next_version(self, connection: Optional[asyncpg.connection.Connection] = None) -> int:
         """
         Reserves the next available version and returns it. Increments the last_version counter.
         """
         record = await self._fetchrow(
             f"""
@@ -2897,26 +2832,26 @@
         """
         if setting.name in cls._settings:
             raise KeyError()
         cls._settings[setting.name] = setting
 
     @classmethod
     async def get_list(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         *,
         order_by_column: Optional[str] = None,
         order: Optional[str] = None,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
         details: bool = True,
         **query: object,
-    ) -> list[TBaseDocument]:
+    ) -> List[TBaseDocument]:
         """
         Get a list of documents matching the filter args.
 
         """
         if details:
             return await super().get_list(
                 order_by_column=order_by_column,
@@ -2937,25 +2872,25 @@
             lock=lock,
             connection=connection,
             **query,
         )
 
     @classmethod
     async def get_list_without_details(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         *,
         order_by_column: Optional[str] = None,
         order: Optional[str] = None,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
         **query: object,
-    ) -> list[TBaseDocument]:
+    ) -> List[TBaseDocument]:
         """
         Get a list of environments matching the filter args.
         Don't return the description and icon columns.
         """
         columns = [column_name for column_name in cls.get_valid_field_names() if column_name not in {"description", "icon"}]
         return await super().get_list_with_columns(
             order_by_column=order_by_column,
@@ -2967,56 +2902,29 @@
             connection=connection,
             columns=columns,
             **query,
         )
 
     @classmethod
     async def get_by_id(
-        cls: type[TBaseDocument],
+        cls: Type[TBaseDocument],
         doc_id: uuid.UUID,
         connection: Optional[asyncpg.connection.Connection] = None,
         details: bool = True,
     ) -> Optional[TBaseDocument]:
         """
         Get a specific environment based on its ID
 
         :return: An instance of this class with its fields filled from the database.
         """
         result = await cls.get_list(id=doc_id, connection=connection, details=details)
         if len(result) > 0:
             return result[0]
         return None
 
-    async def acquire_release_version_lock(self, *, shared: bool = False, connection: asyncpg.Connection) -> None:
-        """
-        Acquires a transaction-level advisory lock for concurrency control between release_version and
-        calls that need the latest version.
-
-        This lock should also be held when updating any resource state in any other way than the normal agent deploy path
-        Up to now, this means
-        - setting resource state after increment calculation on release
-        - propagation of resource state from a stale deploy to the latest version
-        - setting resource state after increment calculation on agent pull
-
-        :param env: The environment to acquire the lock for.
-        :param shared: If true, doesn't conflict with other shared locks, only with non-shared ones.
-        :param connection: The connection hosting the transaction for which to acquire a lock.
-        """
-        await self._xact_lock(const.PG_ADVISORY_KEY_RELEASE_VERSION, self.id, shared=shared, connection=connection)
-
-    async def put_version_lock(self, *, shared: bool = False, connection: asyncpg.Connection) -> None:
-        """
-        Acquires a transaction-level advisory lock for concurrency control between put_version and put_partial.
-
-        :param env: The environment to acquire the lock for.
-        :param shared: If true, doesn't conflict with other shared locks, only with non-shared ones.
-        :param connection: The connection hosting the transaction for which to acquire a lock.
-        """
-        await self._xact_lock(const.PG_ADVISORY_KEY_PUT_VERSION, self.id, shared=shared, connection=connection)
-
 
 class Parameter(BaseDocument):
     """
     A parameter that can be used in the configuration model
 
     :param name: The name of the parameter
     :param value: The value of the parameter
@@ -3036,15 +2944,15 @@
     environment: uuid.UUID
     source: str
     resource_id: m.ResourceIdStr = ""
     updated: Optional[datetime.datetime] = None
     metadata: Optional[JsonType] = None
 
     @classmethod
-    async def get_updated_before_active_env(cls, updated_before: datetime.datetime) -> list["Parameter"]:
+    async def get_updated_before_active_env(cls, updated_before: datetime.datetime) -> List["Parameter"]:
         """
         Retrieve the list of parameters that were updated before a specified datetime for environments that are not halted
         """
         query = f"""
          WITH non_halted_envs AS (
           SELECT id FROM public.environment WHERE NOT halted
         )
@@ -3054,15 +2962,15 @@
         ) and updated < $1;
         """
         values = [cls._get_value(updated_before)]
         result = await cls.select_query(query, values)
         return result
 
     @classmethod
-    async def list_parameters(cls, env_id: uuid.UUID, **metadata_constraints: str) -> list["Parameter"]:
+    async def list_parameters(cls, env_id: uuid.UUID, **metadata_constraints: str) -> List["Parameter"]:
         query = "SELECT * FROM " + cls.table_name() + " WHERE environment=$1"
         values = [cls._get_value(env_id)]
         for key, value in metadata_constraints.items():
             query_param_index = len(values) + 1
             query += " AND metadata @> $" + str(query_param_index) + "::jsonb"
             dict_value = {key: value}
             values.append(cls._get_value(dict_value))
@@ -3100,15 +3008,15 @@
 
     id: uuid.UUID
     name: str
     environment: uuid.UUID
     source: str
     resource_id: m.ResourceIdStr = ""
     version: int
-    metadata: Optional[dict[str, Any]]
+    metadata: Optional[Dict[str, Any]]
     resolved: bool = False
 
     def copy(self, new_version: int) -> "UnknownParameter":
         """
         Create a new UnknownParameter using this object as a template. The returned object will
         have the id field unset and the version field set the new_version.
         """
@@ -3128,15 +3036,15 @@
         environment: uuid.UUID,
         source_version: int,
         updated_resource_sets: abc.Set[str],
         deleted_resource_sets: abc.Set[str],
         rids_in_partial_compile: abc.Set[ResourceIdStr],
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list["UnknownParameter"]:
+    ) -> List["UnknownParameter"]:
         """
         Returns a subset of the unknowns in source_version of environment. It returns the unknowns that:
             * Are not associated with a resource
             * Are associated with a resource that:
                - don't belong to the resource set updated_resource_sets and deleted_resource_sets
                - and, don't have a resource_id in rids_in_partial_compile (An unknown might belong to a shared resource that
                  is not exported by the partial compile)
@@ -3178,15 +3086,15 @@
     hostname: str
     environment: uuid.UUID
     first_seen: Optional[datetime.datetime] = None
     last_seen: Optional[datetime.datetime] = None
     expired: Optional[datetime.datetime] = None
 
     @classmethod
-    async def get_live(cls, environment: Optional[uuid.UUID] = None) -> list["AgentProcess"]:
+    async def get_live(cls, environment: Optional[uuid.UUID] = None) -> List["AgentProcess"]:
         if environment is not None:
             result = await cls.get_list(
                 limit=DBLIMIT, environment=environment, expired=None, order_by_column="last_seen", order="ASC NULLS LAST"
             )
         else:
             result = await cls.get_list(limit=DBLIMIT, expired=None, order_by_column="last_seen", order="ASC NULLS LAST")
         return result
@@ -3275,15 +3183,15 @@
                     ON agentinstance.process = agentprocess.sid
                     WHERE agentprocess.sid = a1.sid AND agentinstance.expired IS NULL
                   );
         """
         await cls._execute_query(query, cls._get_value(nr_expired_records_to_keep))
 
     def to_dict(self) -> JsonType:
-        result = super().to_dict()
+        result = super(AgentProcess, self).to_dict()
         # Ensure backward compatibility API
         result["id"] = result["sid"]
         return result
 
     def to_dto(self) -> m.AgentProcess:
         return m.AgentProcess(
             sid=self.sid,
@@ -3313,37 +3221,37 @@
     process: uuid.UUID
     name: str
     expired: Optional[datetime.datetime] = None
     tid: uuid.UUID
 
     @classmethod
     async def active_for(
-        cls: type[TAgentInstance],
+        cls: Type[TAgentInstance],
         tid: uuid.UUID,
         endpoint: str,
         process: Optional[uuid.UUID] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list[TAgentInstance]:
+    ) -> List[TAgentInstance]:
         if process is not None:
             objects = await cls.get_list(expired=None, tid=tid, name=endpoint, process=process, connection=connection)
         else:
             objects = await cls.get_list(expired=None, tid=tid, name=endpoint, connection=connection)
         return objects
 
     @classmethod
-    async def active(cls: type[TAgentInstance]) -> list[TAgentInstance]:
+    async def active(cls: Type[TAgentInstance]) -> List[TAgentInstance]:
         objects = await cls.get_list(expired=None)
         return objects
 
     @classmethod
     async def log_instance_creation(
-        cls: type[TAgentInstance],
+        cls: Type[TAgentInstance],
         tid: uuid.UUID,
         process: uuid.UUID,
-        endpoints: set[str],
+        endpoints: Set[str],
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> None:
         """
         Create new agent instances for a given session.
         """
         if not endpoints:
             return
@@ -3359,26 +3267,26 @@
                 ;
                 """,
                 [tuple(map(cls._get_value, (cls._new_id(), tid, process, name))) for name in endpoints],
             )
 
     @classmethod
     async def log_instance_expiry(
-        cls: type[TAgentInstance],
+        cls: Type[TAgentInstance],
         sid: uuid.UUID,
-        endpoints: set[str],
+        endpoints: Set[str],
         now: datetime.datetime,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> None:
         """
         Expire specific instances for a given session id.
         """
         if not endpoints:
             return
-        instances: list[TAgentInstance] = await cls.get_list(connection=connection, process=sid)
+        instances: List[TAgentInstance] = await cls.get_list(connection=connection, process=sid)
         for ai in instances:
             if ai.name in endpoints:
                 await ai.update_fields(connection=connection, expired=now)
 
     @classmethod
     async def expire_all(cls, now: datetime.datetime, connection: Optional[asyncpg.connection.Connection] = None) -> None:
         query = f"""
@@ -3412,21 +3320,21 @@
     unpause_on_resume: Optional[bool] = None
 
     @property
     def primary(self) -> Optional[uuid.UUID]:
         return self.id_primary
 
     @classmethod
-    def get_valid_field_names(cls) -> list[str]:
+    def get_valid_field_names(cls) -> List[str]:
         # Allow the computed fields
         return super().get_valid_field_names() + ["process_name", "status"]
 
     @classmethod
-    async def get_statuses(cls, env_id: uuid.UUID, agent_names: set[str]) -> dict[str, Optional[AgentStatus]]:
-        result: dict[str, Optional[AgentStatus]] = {}
+    async def get_statuses(cls, env_id: uuid.UUID, agent_names: Set[str]) -> Dict[str, Optional[AgentStatus]]:
+        result: Dict[str, Optional[AgentStatus]] = {}
         for agent_name in agent_names:
             agent = await cls.get_one(environment=env_id, name=agent_name)
             if agent:
                 result[agent_name] = agent.get_status()
             else:
                 result[agent_name] = None
         return result
@@ -3450,15 +3358,15 @@
             del base["id_primary"]
 
         base["state"] = self.get_status().value
 
         return base
 
     @classmethod
-    def _convert_field_names_to_db_column_names(cls, field_dict: dict[str, str]) -> dict[str, str]:
+    def _convert_field_names_to_db_column_names(cls, field_dict: Dict[str, str]) -> Dict[str, str]:
         if "primary" in field_dict:
             field_dict["id_primary"] = field_dict["primary"]
             del field_dict["primary"]
         return field_dict
 
     @classmethod
     async def get(
@@ -3479,38 +3387,38 @@
         await cls._execute_query(
             f"UPDATE {cls.table_name()} SET unpause_on_resume=NOT paused WHERE environment=$1 AND unpause_on_resume IS NULL",
             cls._get_value(env),
             connection=connection,
         )
 
     @classmethod
-    async def persist_on_resume(cls, env: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None) -> list[str]:
+    async def persist_on_resume(cls, env: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None) -> List[str]:
         """
         Restores default halted state. Returns a list of agents that should be unpaused.
         """
 
         async with cls.get_connection(connection) as con:
             async with con.transaction():
                 unpause_on_resume = await cls._fetch_query(
                     # lock FOR UPDATE to avoid deadlocks: next query in this transaction updates the row
-                    f"SELECT name FROM {cls.table_name()} WHERE environment=$1 AND unpause_on_resume FOR NO KEY UPDATE",
+                    f"SELECT name FROM {cls.table_name()} WHERE environment=$1 AND unpause_on_resume FOR UPDATE",
                     cls._get_value(env),
                     connection=con,
                 )
                 await cls._execute_query(
                     f"UPDATE {cls.table_name()} SET unpause_on_resume=NULL WHERE environment=$1",
                     cls._get_value(env),
                     connection=con,
                 )
                 return sorted([r["name"] for r in unpause_on_resume])
 
     @classmethod
     async def pause(
         cls, env: uuid.UUID, endpoint: Optional[str], paused: bool, connection: Optional[asyncpg.connection.Connection] = None
-    ) -> list[str]:
+    ) -> List[str]:
         """
         Pause a specific agent or all agents in an environment when endpoint is set to None.
 
         :return A list of agent names that have been paused/unpaused by this method.
         """
         if endpoint is None:
             query = f"UPDATE {cls.table_name()} SET paused=$1 WHERE environment=$2 RETURNING name"
@@ -3540,15 +3448,15 @@
             values = [cls._get_value(should_be_unpaused_on_resume), cls._get_value(env), cls._get_value(endpoint)]
         await cls._execute_query(query, *values, connection=connection)
 
     @classmethod
     async def update_primary(
         cls,
         env: uuid.UUID,
-        endpoints_with_new_primary: Sequence[tuple[str, Optional[uuid.UUID]]],
+        endpoints_with_new_primary: Sequence[Tuple[str, Optional[uuid.UUID]]],
         now: datetime.datetime,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> None:
         """
         Update the primary agent instance for agents present in the database.
 
         :param env: The environment of the agent
@@ -3556,15 +3464,15 @@
                                            primary agent instance. The sid in the tuple is the session id of the new
                                            primary. If the session id is None, the Agent doesn't have a primary anymore.
         :param now: Timestamp of this failover
         """
         for endpoint, sid in endpoints_with_new_primary:
             # Lock mode is required because we will update in this transaction
             # Deadlocks with cleanup otherwise
-            agent = await cls.get(env, endpoint, connection=connection, lock=RowLockMode.FOR_NO_KEY_UPDATE)
+            agent = await cls.get(env, endpoint, connection=connection, lock=RowLockMode.FOR_UPDATE)
             if agent is None:
                 continue
 
             if sid is None:
                 await agent.update_fields(last_failover=now, primary=None, connection=connection)
             else:
                 instances = await AgentInstance.active_for(tid=env, endpoint=agent.name, process=sid, connection=connection)
@@ -3671,15 +3579,14 @@
         to this one that actually got compiled.
     :param partial: True if the compile only contains the entities/resources for the resource sets that should be updated
     :param removed_resource_sets: indicates the resource sets that should be removed from the model
     :param exporter_plugin: Specific exporter plugin to use
     :param notify_failed_compile: if true use the notification service to notify that a compile has failed.
         By default, notifications are enabled only for exporting compiles.
     :param failed_compile_message: Optional message to use when a notification for a failed compile is created
-    :param soft_delete: Prevents deletion of resources in removed_resource_sets if they are being exported.
     """
 
     __primary_key__ = ("id",)
 
     id: uuid.UUID
     remote_id: Optional[uuid.UUID] = None
     environment: uuid.UUID
@@ -3706,36 +3613,33 @@
     removed_resource_sets: list[str] = []
 
     exporter_plugin: Optional[str] = None
 
     notify_failed_compile: Optional[bool] = None
     failed_compile_message: Optional[str] = None
 
-    soft_delete: bool = False
-
     @classmethod
-    async def get_substitute_by_id(cls, compile_id: uuid.UUID, connection: Optional[Connection] = None) -> Optional["Compile"]:
+    async def get_substitute_by_id(cls, compile_id: uuid.UUID) -> Optional["Compile"]:
         """
         Get a compile's substitute compile if it exists, otherwise get the compile by id.
 
         :param compile_id: The id of the compile for which to get the substitute compile.
         :return: The compile object for compile c2 that is the substitute of compile c1 with the given id. If c1 does not have
             a substitute, returns c1 itself.
         """
-        async with Compile.get_connection(connection=connection) as con:
-            result: Optional[Compile] = await cls.get_by_id(compile_id, connection=con)
-            if result is None:
-                return None
-            if result.substitute_compile_id is None:
-                return result
-            return await cls.get_substitute_by_id(result.substitute_compile_id, connection=con)
+        result: Optional[Compile] = await cls.get_by_id(compile_id)
+        if result is None:
+            return None
+        if result.substitute_compile_id is None:
+            return result
+        return await cls.get_substitute_by_id(result.substitute_compile_id)
 
     @classmethod
     # TODO: Use join
-    async def get_report(cls, compile_id: uuid.UUID) -> Optional[dict[str, Any]]:
+    async def get_report(cls, compile_id: uuid.UUID) -> Optional[Dict]:
         """
         Get the compile and the associated reports from the database
         """
         result: Optional[Compile] = await cls.get_substitute_by_id(compile_id)
         if result is None:
             return None
 
@@ -3903,15 +3807,15 @@
                     {cls.table_name()} comp
                     INNER JOIN compiledetails cd ON cd.substitute_compile_id = comp.id
                     LEFT JOIN public.report rep on comp.id = rep.compile
         ) SELECT * FROM compiledetails ORDER BY report_started ASC;
         """
         values = [cls._get_value(environment), cls._get_value(id)]
         result = await cls.select_query(query, values, no_obj=True)
-        result = cast(list[Record], result)
+        result = cast(List[Record], result)
         # The result is a list of Compiles joined with Reports
         # This includes the Compile with the requested id,
         # as well as Compile(s) that have been used as a substitute for the requested Compile (if there are any)
         if not result:
             return None
 
         # The details, such as the requested timestamp, etc. should be returned from
@@ -3995,15 +3899,15 @@
     """
 
     @property
     def msg(self) -> str:
         return self._data["msg"]
 
     @property
-    def args(self) -> list[object]:
+    def args(self) -> List:
         return self._data["args"]
 
     @property
     def log_level(self) -> LogLevel:
         level: str = self._data["level"]
         return LogLevel[level]
 
@@ -4045,25 +3949,25 @@
     :param change: The change result of an action
     """
 
     __primary_key__ = ("action_id",)
 
     environment: uuid.UUID
     version: int
-    resource_version_ids: list[m.ResourceVersionIdStr]
+    resource_version_ids: List[m.ResourceVersionIdStr]
 
     action_id: uuid.UUID
     action: const.ResourceAction
 
     started: datetime.datetime
     finished: Optional[datetime.datetime] = None
 
-    messages: Optional[list[dict[str, Any]]] = None
+    messages: Optional[List[Dict[str, Any]]] = None
     status: Optional[const.ResourceState] = None
-    changes: Optional[dict[m.ResourceIdStr, dict[str, object]]] = None
+    changes: Optional[Dict[m.ResourceIdStr, Dict[str, object]]] = None
     change: Optional[const.Change] = None
 
     def __init__(self, from_postgres: bool = False, **kwargs: object) -> None:
         super().__init__(from_postgres, **kwargs)
         self._updates = {}
 
         # rewrite some data
@@ -4085,21 +3989,16 @@
 
     @classmethod
     async def get_by_id(cls, doc_id: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None) -> "ResourceAction":
         return await cls.get_one(action_id=doc_id, connection=connection)
 
     @classmethod
     async def get_log(
-        cls,
-        environment: uuid.UUID,
-        resource_version_id: m.ResourceVersionIdStr,
-        action: Optional[str] = None,
-        limit: int = 0,
-        connection: Optional[Connection] = None,
-    ) -> list["ResourceAction"]:
+        cls, environment: uuid.UUID, resource_version_id: m.ResourceVersionIdStr, action: Optional[str] = None, limit: int = 0
+    ) -> List["ResourceAction"]:
         query = """
         SELECT ra.* FROM public.resourceaction as ra
                     INNER JOIN public.resourceaction_resource as jt
                         ON ra.action_id = jt.resource_action_id
                     WHERE jt.environment=$1 AND jt.resource_id = $2 AND  jt.resource_version = $3
         """
         id = resources.Id.parse_id(resource_version_id)
@@ -4107,55 +4006,50 @@
         if action is not None:
             query += " AND action=$4"
             values.append(cls._get_value(action))
         query += " ORDER BY started DESC"
         if limit is not None and limit > 0:
             query += " LIMIT $%d" % (len(values) + 1)
             values.append(cls._get_value(limit))
-        async with cls.get_connection(connection) as con:
+        async with cls.get_connection() as con:
             async with con.transaction():
                 return [cls(**dict(record), from_postgres=True) async for record in con.cursor(query, *values)]
 
     @classmethod
     async def get_logs_for_version(
-        cls,
-        environment: uuid.UUID,
-        version: int,
-        action: Optional[str] = None,
-        limit: int = 0,
-        connection: Optional[Connection] = None,
-    ) -> list["ResourceAction"]:
+        cls, environment: uuid.UUID, version: int, action: Optional[str] = None, limit: int = 0
+    ) -> List["ResourceAction"]:
         query = f"""SELECT *
                         FROM {cls.table_name()}
                         WHERE environment=$1 AND version=$2
                      """
         values = [cls._get_value(environment), cls._get_value(version)]
         if action is not None:
             query += " AND action=$3"
             values.append(cls._get_value(action))
         query += " ORDER BY started DESC"
         if limit is not None and limit > 0:
             query += " LIMIT $%d" % (len(values) + 1)
             values.append(cls._get_value(limit))
-        async with cls.get_connection(connection=connection) as con:
+        async with cls.get_connection() as con:
             async with con.transaction():
                 return [cls(**dict(record), from_postgres=True) async for record in con.cursor(query, *values)]
 
     @classmethod
-    def get_valid_field_names(cls) -> list[str]:
+    def get_valid_field_names(cls) -> List[str]:
         return super().get_valid_field_names() + ["timestamp", "level", "msg"]
 
     @classmethod
     async def get(cls, action_id: uuid.UUID, connection: Optional[asyncpg.connection.Connection] = None) -> "ResourceAction":
         return await cls.get_one(action_id=action_id, connection=connection)
 
     async def insert(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
         async with self.get_connection(connection) as con:
             async with con.transaction():
-                await super().insert(con)
+                await super(ResourceAction, self).insert(con)
 
                 # Also do the join table in the same transaction
                 assert self.resource_version_ids
 
                 parsed_rv = [resources.Id.parse_resource_version_id(id) for id in self.resource_version_ids]
                 # No additional checking of field validity is done here, because the insert above validates all fields
                 await con.execute(
@@ -4174,27 +4068,27 @@
     def add_logs(self, messages: Optional[str]) -> None:
         if not messages:
             return
         if "messages" not in self._updates:
             self._updates["messages"] = []
         self._updates["messages"] += messages
 
-    def add_changes(self, changes: dict[m.ResourceIdStr, dict[str, object]]) -> None:
+    def add_changes(self, changes: Dict[m.ResourceIdStr, Dict[str, object]]) -> None:
         for resource, values in changes.items():
             for field, change in values.items():
                 if "changes" not in self._updates:
                     self._updates["changes"] = {}
                 if resource not in self._updates["changes"]:
                     self._updates["changes"][resource] = {}
                 self._updates["changes"][resource][field] = change
 
     async def set_and_save(
         self,
-        messages: list[dict[str, Any]],
-        changes: dict[str, Any],
+        messages: List[Dict[str, Any]],
+        changes: Dict[str, Any],
         status: Optional[const.ResourceState],
         change: Optional[const.Change],
         finished: Optional[datetime.datetime],
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> None:
         if len(messages) > 0:
             self.add_logs(messages)
@@ -4253,17 +4147,15 @@
         resource_id_value: Optional[str] = None,
         log_severity: Optional[str] = None,
         limit: int = 0,
         action_id: Optional[uuid.UUID] = None,
         first_timestamp: Optional[datetime.datetime] = None,
         last_timestamp: Optional[datetime.datetime] = None,
         action: Optional[const.ResourceAction] = None,
-        resource_id: Optional[ResourceIdStr] = None,
-        exclude_changes: Optional[list[const.Change]] = None,
-    ) -> list["ResourceAction"]:
+    ) -> List["ResourceAction"]:
         query = """SELECT DISTINCT ra.*
                     FROM public.resource as r
                     INNER JOIN public.resourceaction_resource as jt
                         ON r.environment = jt.environment
                         AND r.resource_id = jt.resource_id
                         AND r.model = jt.resource_version
                     INNER JOIN public.resourceaction as ra
@@ -4288,18 +4180,14 @@
             values.append(cls._get_value(attribute))
             values.append(cls._get_value(escaped_value))
             parameter_index += 2
         if resource_id_value:
             query += f" AND r.resource_id_value = ${parameter_index}::varchar"
             values.append(cls._get_value(resource_id_value))
             parameter_index += 1
-        if resource_id:
-            query += f" AND r.resource_id = ${parameter_index}::varchar"
-            values.append(cls._get_value(resource_id))
-            parameter_index += 1
         if log_severity:
             # <@ Is contained by
             query += f" AND ${parameter_index} <@ ANY(messages)"
             values.append(cls._get_value({"level": log_severity.upper()}))
             parameter_index += 1
         if action is not None:
             query += f" AND ra.action=${parameter_index}"
@@ -4319,22 +4207,14 @@
             values.append(cls._get_value(last_timestamp))
             values.append(cls._get_value(action_id))
             parameter_index += 2
         elif last_timestamp:
             query += f" AND started < ${parameter_index}"
             values.append(cls._get_value(last_timestamp))
             parameter_index += 1
-
-        if exclude_changes:
-            # Create a string with placeholders for each item in exclude_changes
-            exclude_placeholders = ", ".join([f"${parameter_index + i}" for i in range(len(exclude_changes))])
-            query += f" AND ra.change NOT IN ({exclude_placeholders})"
-            values.extend([cls._get_value(change) for change in exclude_changes])
-            parameter_index += len(exclude_changes)
-
         if first_timestamp:
             query += " ORDER BY started, action_id"
         else:
             query += " ORDER BY started DESC, action_id DESC"
         if limit is not None and limit > 0:
             query += " LIMIT $%d" % parameter_index
             values.append(cls._get_value(limit))
@@ -4346,15 +4226,15 @@
         async with cls.get_connection() as con:
             async with con.transaction():
                 return [cls(**record, from_postgres=True) async for record in con.cursor(query, *values)]
 
     @classmethod
     async def get_resource_events(
         cls, env: Environment, resource_id: "resources.Id", exclude_change: Optional[const.Change] = None
-    ) -> dict[ResourceIdStr, list["ResourceAction"]]:
+    ) -> Dict[ResourceIdStr, List["ResourceAction"]]:
         """
         Get all events that should be processed by this specific resource, for the current deployment
 
         This method searches across versions!
 
         This means:
         1. assure a deployment is ongoing
@@ -4366,49 +4246,74 @@
         :param resource_id: resource to consider, should be in deploying state
         :param exclude_change: in step 4, exclude all resource actions with this specific type of change
         """
 
         # This is bang on the critical path for the agent
         # Squeeze out as much performance from postgresql as we can
 
+        # steps 1 and 2:
+        # find the interval between the current deploy and the previous successful deploy
+        # also check we are currently deploying
+        # do all of this in one query
         resource_version_id_str = resource_id.resource_version_str()
         resource_id_str = resource_id.resource_str()
 
         # These two variables are actually of type datetime.datetime
         # but mypy doesn't know as they come from the DB
         # mypy also doesn't care, because they go back into the DB
+        current_deploy_start: object
         last_deploy_start: Optional[object]
 
-        async with cls.get_connection() as connection:
-            # Step 1: Get the resource
-            # also check we are currently deploying
-            resource: Optional[Resource] = await Resource.get_one(
-                environment=env.id, resource_id=resource_id_str, model=resource_id.version, connection=connection
+        end_query = """
+        with
+            base_ra as (
+            SELECT ra.*
+                FROM public.resourceaction_resource as jt
+                    INNER JOIN public.resourceaction as ra
+                        ON ra.action_id = jt.resource_action_id
+                    WHERE jt.environment=$1 AND ra.environment=$1 AND jt.resource_id=$2::varchar AND ra.action='deploy'
+                    ORDER BY ra.started DESC
             )
-            if resource is None:
-                raise NotFound(f"Resource with id {resource_version_id_str} was not found in environment {env.id}")
+        SELECT
+            (SELECT started from base_ra ORDER BY started DESC LIMIT 1) as begin_started,
+            (SELECT status from base_ra ORDER BY started DESC LIMIT 1) as begin_status,
+            COALESCE((SELECT started from base_ra where status='deployed' ORDER BY started DESC LIMIT 1), NULL) as started
+        """
+
+        async with cls.get_connection() as connection:
+            result = await connection.fetchrow(end_query, env.id, resource_id_str)
 
-            if resource.status != const.ResourceState.deploying:
+            if not result or result["begin_status"] is None:
+                raise BadRequest(
+                    "Fetching resource events only makes sense when the resource is currently deploying. Resource"
+                    f" {resource_version_id_str} has not started deploying yet."
+                )
+            if result["begin_status"] != const.ResourceState.deploying:
                 raise BadRequest(
                     "Fetching resource events only makes sense when the resource is currently deploying. Current deploy state"
-                    f" for resource {resource_version_id_str} is {resource.status}."
+                    f" for resource {resource_version_id_str} is {result['begin_status']}."
                 )
+            current_deploy_start = result["begin_started"]
+            last_deploy_start = result["started"]
 
-            # Step 2:
-            # find the interval between the current deploy (now) and the previous successful deploy
-            last_deploy_start = resource.last_success
+            # Step3: Get the resource
+            resource: Optional[Resource] = await Resource.get_one(
+                environment=env.id, resource_id=resource_id_str, model=resource_id.version, connection=connection
+            )
+            if resource is None:
+                raise NotFound(f"Resource with id {resource_version_id_str} was not found in environment {env.id}")
 
-            # Step 3: get the relevant resource actions
+            # Step 4: get the relevant resource actions
             # Do it in one query for all dependencies
 
             # Construct the query
             arg = ArgumentCollector(offset=2)
 
             # First make the filter
-            filter = ""
+            filter = f"AND ra.started<{arg(current_deploy_start)}"
             if last_deploy_start:
                 filter += f" AND ra.started > {arg(last_deploy_start)}"
             if exclude_change:
                 filter += f" AND ra.change <> {arg(exclude_change.value)}"
 
             # then the query around it
             get_all_query = f"""
@@ -4421,15 +4326,15 @@
             """
 
             # Convert resource version ids into resource ids
             ids = [resources.Id.parse_id(req).resource_str() for req in resource.attributes["requires"]]
             # Get the result
             result2 = await connection.fetch(get_all_query, env.id, ids, *arg.get_values())
             # Collect results per resource_id
-            collector: dict[ResourceIdStr, list["ResourceAction"]] = {
+            collector: Dict[ResourceIdStr, List["ResourceAction"]] = {
                 rid: [] for rid in ids
             }  # eagerly initialize, we expect one entry per dependency, even when empty
             for record in result2:
                 fields = dict(record)
                 del fields["resource_id"]
                 collector[cast(ResourceIdStr, record[0])].append(ResourceAction(from_postgres=True, **fields))
 
@@ -4461,15 +4366,14 @@
     :param resource: The resource for which this defines the state
     :param model: The configuration model (versioned) this resource state is associated with
     :param attributes: The state of this version of the resource
     :param attribute_hash: hash of the attributes, excluding requires, provides and version,
                            used to determine if a resource describes the same state across versions
     :param resource_id_value: The attribute value from the resource id
     :param last_non_deploying_status: The last status of this resource that is not the 'deploying' status.
-    :param last_success: The last time this resource (with this ID) was deployed successfully, across versions and hashes
     """
 
     __primary_key__ = ("environment", "model", "resource_id")
 
     environment: uuid.UUID
     model: int
 
@@ -4478,28 +4382,26 @@
     resource_type: m.ResourceType
     resource_id_value: str
 
     agent: str
 
     # Field based on content from the resource actions
     last_deploy: Optional[datetime.datetime] = None
-    last_success: Optional[datetime.datetime] = None
-    last_produced_events: Optional[datetime.datetime] = None
 
     # State related
-    attributes: dict[str, Any] = {}
+    attributes: Dict[str, Any] = {}
     attribute_hash: Optional[str]
     status: const.ResourceState = const.ResourceState.available
     last_non_deploying_status: const.NonDeployingResourceState = const.NonDeployingResourceState.available
     resource_set: Optional[str] = None
 
     # internal field to handle cross agent dependencies
     # if this resource is updated, it must notify all RV's in this list
     # the list contains full rv id's
-    provides: list[m.ResourceIdStr] = []
+    provides: List[m.ResourceIdStr] = []
 
     # Methods for backward compatibility
     @property
     def resource_version_id(self):
         # This field was removed from the DB, this method keeps code compatibility
         return resources.Id.set_version_in_id(self.resource_id, self.model)
 
@@ -4524,15 +4426,15 @@
         # version field is present in the attributes dictionary served out via the API.
         record["attributes"]["version"] = version
         record["provides"] = [resources.Id.set_version_in_id(id, version) for id in record["provides"]]
 
     @classmethod
     async def get_last_non_deploying_state_for_dependencies(
         cls, environment: uuid.UUID, resource_version_id: "resources.Id", connection: Optional[Connection] = None
-    ) -> dict[m.ResourceVersionIdStr, ResourceState]:
+    ) -> Dict[m.ResourceVersionIdStr, ResourceState]:
         """
         Return the last state of each dependency of the given resource that was not 'deploying'.
         """
         if not resource_version_id.is_resource_version_id_obj():
             raise Exception("Argument resource_version_id is not a resource_version_id")
         query = """
             SELECT r1.resource_id, r1.model, r1.last_non_deploying_status
@@ -4549,54 +4451,14 @@
             cls._get_value(environment),
             cls._get_value(resource_version_id.version),
             resource_version_id.resource_str(),
         ]
         result = await cls._fetch_query(query, *values, connection=connection)
         return {r["resource_id"] + ",v=" + str(r["model"]): const.ResourceState(r["last_non_deploying_status"]) for r in result}
 
-    @classmethod
-    async def update_event_timers_if_newer(
-        cls,
-        environment: uuid.UUID,
-        resource_id: ResourceIdStr,
-        version: int,
-        last_success: Optional[datetime.datetime],
-        last_produced_events: datetime.datetime,
-        *,
-        connection: Optional[Connection] = None,
-    ) -> None:
-        """
-        This method makes sure the resource's event timers (last_success and last_produced_events) are up-to-date
-
-        used for propagation between versions
-
-        :param last_success: ignored if none
-        """
-        if last_success is None:
-            query = f"""
-                    UPDATE {cls.table_name()} as resource
-                    SET
-                        last_produced_events = GREATEST($4, last_produced_events)
-                    WHERE resource.model=$2
-                    AND resource.environment=$1
-                    AND resource.resource_id=$3  """
-            await cls._execute_query(query, environment, version, resource_id, last_produced_events, connection=connection)
-        else:
-            query = f"""
-                    UPDATE {cls.table_name()} as resource
-                    SET
-                        last_produced_events = GREATEST($4, last_produced_events),
-                        last_success = GREATEST($5, last_success)
-                    WHERE resource.model=$2
-                    AND resource.environment=$1
-                    AND resource.resource_id=$3  """
-            await cls._execute_query(
-                query, environment, version, resource_id, last_produced_events, last_success, connection=connection
-            )
-
     def make_hash(self) -> None:
         character = json.dumps(
             {k: v for k, v in self.attributes.items() if k not in ["requires", "provides", "version"]},
             default=custom_json_encoder,
             sort_keys=True,  # sort the keys for stable hashes when using dicts, see #5306
         )
         m = hashlib.md5()
@@ -4604,18 +4466,18 @@
         m.update(character.encode("utf-8"))
         self.attribute_hash = m.hexdigest()
 
     @classmethod
     async def get_resources(
         cls,
         environment: uuid.UUID,
-        resource_version_ids: list[m.ResourceVersionIdStr],
+        resource_version_ids: List[m.ResourceVersionIdStr],
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list["Resource"]:
+    ) -> List["Resource"]:
         """
         Get all resources listed in resource_version_ids
         """
         if not resource_version_ids:
             return []
         query_lock: str = lock.value if lock is not None else ""
 
@@ -4643,15 +4505,15 @@
             query,
             [cls._get_value(environment), [(id.resource_str(), id.get_version()) for id in effective_parsed_rv]],
             connection=connection,
         )
         return out
 
     @classmethod
-    async def get_undeployable(cls, environment: uuid.UUID, version: int) -> list["Resource"]:
+    async def get_undeployable(cls, environment: uuid.UUID, version: int) -> List["Resource"]:
         """
         Returns a list of resources with an undeployable state
         """
         (filter_statement, values) = cls._get_composed_filter(environment=environment, model=version)
         undeployable_states = ", ".join(["$" + str(i + 3) for i in range(len(const.UNDEPLOYABLE_STATES))])
         values = values + [cls._get_value(s) for s in const.UNDEPLOYABLE_STATES]
         query = (
@@ -4661,18 +4523,18 @@
         return resources
 
     @classmethod
     async def get_resources_in_latest_version(
         cls,
         environment: uuid.UUID,
         resource_type: Optional[m.ResourceType] = None,
-        attributes: dict[PrimitiveTypes, PrimitiveTypes] = {},
+        attributes: Dict[PrimitiveTypes, PrimitiveTypes] = {},
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list["Resource"]:
+    ) -> List["Resource"]:
         """
         Returns the resources in the latest version of the configuration model of the given environment, that satisfy the
         given constraints.
 
         :param environment: The resources should belong to this environment.
         :param resource_type: The environment should have this resource_type.
         :param attributes: The resource should contain these key-value pairs in its attributes list.
@@ -4722,15 +4584,15 @@
             async with con.transaction():
                 async for record in con.cursor(query, *values):
                     assert isinstance(record["count"], int)
                     result[str(record["resource_type"])] = record["count"]
         return result
 
     @classmethod
-    async def get_resources_report(cls, environment: uuid.UUID) -> list[JsonType]:
+    async def get_resources_report(cls, environment: uuid.UUID) -> List[JsonType]:
         """
         This method generates a report of all resources in the given environment,
         with their latest version and when they are last deployed.
         """
         query_resource_ids = f"""
                 SELECT DISTINCT resource_id
                 FROM {Resource.table_name()}
@@ -4784,45 +4646,45 @@
         cls,
         environment: uuid.UUID,
         version: int,
         agent: Optional[str] = None,
         no_obj: bool = False,
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list["Resource"]:
+    ) -> List["Resource"]:
         if agent:
             (filter_statement, values) = cls._get_composed_filter(environment=environment, model=version, agent=agent)
         else:
             (filter_statement, values) = cls._get_composed_filter(environment=environment, model=version)
 
         query = f"SELECT * FROM {Resource.table_name()} WHERE {filter_statement}"
-        resources_list: Union[list[Resource], list[dict[str, object]]] = []
+        resources_list: Union[List[Resource], List[Dict[str, object]]] = []
         async with cls.get_connection(connection) as con:
             async with con.transaction():
                 async for record in con.cursor(query, *values):
                     if no_obj:
                         record = dict(record)
                         record["attributes"] = json.loads(record["attributes"])
                         cls.__mangle_dict(record)
                         resources_list.append(record)
                     else:
                         resources_list.append(cls(from_postgres=True, **record))
         return resources_list
 
     @classmethod
     async def get_resources_for_version_raw(
-        cls, environment: uuid.UUID, version: int, projection: Optional[list[str]], *, connection: Optional[Connection] = None
-    ) -> list[dict[str, Any]]:
+        cls, environment: uuid.UUID, version: int, projection: Optional[List[str]]
+    ) -> List[Dict[str, Any]]:
         if not projection:
             projection = "*"
         else:
             projection = ",".join(projection)
         (filter_statement, values) = cls._get_composed_filter(environment=environment, model=version)
         query = "SELECT " + projection + " FROM " + cls.table_name() + " WHERE " + filter_statement
-        resource_records = await cls._fetch_query(query, *values, connection=connection)
+        resource_records = await cls._fetch_query(query, *values)
         resources = [dict(record) for record in resource_records]
         for res in resources:
             if "attributes" in res:
                 res["attributes"] = json.loads(res["attributes"])
         return resources
 
     @classmethod
@@ -4896,110 +4758,14 @@
             status=new_resource_state,
             last_non_deploying_status=const.NonDeployingResourceState[new_resource_state.name],
             resource_set=self.resource_set,
             provides=self.provides,
         )
 
     @classmethod
-    async def get_deleted_resources(
-        cls,
-        environment: uuid.UUID,
-        current_version: int,
-        current_resources: Sequence[m.ResourceIdStr],
-        *,
-        connection: Optional[asyncpg.connection.Connection] = None,
-    ) -> list["Resource"]:
-        """
-        This method returns all resources that have been deleted from the model and are not yet marked as purged. It returns
-        the latest version of the resource from a released model.
-
-        :param environment:
-        :param current_version:
-        :param current_resources: A Sequence of all resource ids in the current version.
-        """
-        LOGGER.debug("Starting purge_on_delete queries")
-
-        # get all models that have been released
-        query = (
-            "SELECT version FROM "
-            + ConfigurationModel.table_name()
-            + " WHERE environment=$1 AND released=TRUE ORDER BY version DESC LIMIT "
-            + str(DBLIMIT)
-        )
-        versions = set()
-        latest_version = None
-        async with cls.get_connection(connection) as con:
-            async with con.transaction():
-                async for record in con.cursor(query, cls._get_value(environment)):
-                    version = record["version"]
-                    versions.add(version)
-                    if latest_version is None:
-                        latest_version = version
-
-        LOGGER.debug("  All released versions: %s", versions)
-        LOGGER.debug("  Latest released version: %s", latest_version)
-
-        # find all resources in previous versions that have "purge_on_delete" set
-        (filter_statement, values) = cls._get_composed_filter(environment=environment, model=latest_version)
-        query = (
-            "SELECT DISTINCT resource_id FROM "
-            + cls.table_name()
-            + " WHERE "
-            + filter_statement
-            + " AND attributes @> $"
-            + str(len(values) + 1)
-        )
-        values.append(cls._get_value({"purge_on_delete": True}))
-        resources_records = await cls._fetch_query(query, *values, connection=connection)
-        resources = [r["resource_id"] for r in resources_records]
-
-        LOGGER.debug("  Resource with purge_on_delete true: %s", resources)
-
-        # all resources on current model
-        LOGGER.debug("  All resource in current version (%s): %s", current_version, current_resources)
-
-        # determined deleted resources
-
-        deleted = set(resources) - set(current_resources)
-        LOGGER.debug("  These resources are no longer present in current model: %s", deleted)
-
-        # filter out resources that should not be purged:
-        # 1- resources from versions that have not been deployed
-        # 2- resources that are already recorded as purged (purged and deployed)
-        should_purge = []
-        for deleted_resource in deleted:
-            # get the full resource history, and determine the purge status of this resource
-            (filter_statement, values) = cls._get_composed_filter(environment=environment, resource_id=deleted_resource)
-            query = (
-                "SELECT *"
-                + " FROM "
-                + cls.table_name()
-                + " WHERE "
-                + filter_statement
-                + " AND model < $"
-                + str(len(values) + 1)
-                + " ORDER BY model DESC"
-            )
-            values.append(cls._get_value(current_version))
-
-            async with cls.get_connection(connection) as con:
-                async with con.transaction():
-                    async for obj in con.cursor(query, *values):
-                        # if a resource is part of a released version and it is deployed (this last condition is actually enough
-                        # at the moment), we have found the last status of the resource. If it was not purged in that version,
-                        # add it to the should purge list.
-                        if obj["model"] in versions and obj["status"] == const.ResourceState.deployed.name:
-                            attributes = json.loads(str(obj["attributes"]))
-                            if not attributes["purged"]:
-                                should_purge.append(cls(from_postgres=True, **obj))
-                            break
-
-        return should_purge
-
-    @classmethod
     async def get_resource_details(cls, env: uuid.UUID, resource_id: m.ResourceIdStr) -> Optional[m.ReleasedResourceDetails]:
         status_subquery = """
         (CASE WHEN
             (SELECT resource.model < MAX(configurationmodel.version)
             FROM configurationmodel
             WHERE configurationmodel.released=TRUE
             AND environment = $1)
@@ -5191,95 +4957,45 @@
             FROM {cls.table_name()} AS r
             WHERE r.environment=$1 AND r.model=$2 AND {resource_set_filter_statement}
         """
         async with cls.get_connection(connection) as con:
             result = await con.fetch(query, environment, version, resource_sets)
             return {record["resource_id"]: cls(from_postgres=True, **record) for record in result}
 
-    @classmethod
-    async def copy_last_success(
-        cls,
-        environment: uuid.UUID,
-        from_version: int,
-        to_version: int,
-        *,
-        connection: Optional[Connection] = None,
-    ) -> None:
-        query = f"""
-        UPDATE {cls.table_name()} as new_resource
-        SET
-            last_success = (
-                SELECT last_success from {cls.table_name()} as old_resource
-                WHERE old_resource.model=$3
-                AND old_resource.environment=$2
-                AND old_resource.resource_id=new_resource.resource_id
-            )
-        WHERE new_resource.model=$1
-        AND new_resource.environment=$2
-        AND new_resource.last_success is null"""
-        await cls._execute_query(query, to_version, environment, from_version, connection=connection)
-
-    @classmethod
-    async def copy_last_produced_events(
-        cls,
-        environment: uuid.UUID,
-        from_version: int,
-        to_version: int,
-        *,
-        connection: Optional[Connection] = None,
-    ) -> None:
-        """
-        Copy the value of last_produced events for every resource in the to_version from the from_version
-        """
-        query = f"""
-           UPDATE {cls.table_name()} as new_resource
-           SET
-               last_produced_events = (
-                   SELECT old_resource.last_produced_events
-                   FROM {cls.table_name()} as old_resource
-                   WHERE old_resource.model=$3
-                   AND old_resource.environment=$2
-                   AND old_resource.resource_id=new_resource.resource_id
-               )
-           WHERE new_resource.model=$1
-           AND new_resource.environment=$2
-           AND new_resource.last_produced_events is null"""
-        await cls._execute_query(query, to_version, environment, from_version, connection=connection)
-
     async def insert(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
         self.make_hash()
-        await super().insert(connection=connection)
+        await super(Resource, self).insert(connection=connection)
 
     @classmethod
     async def insert_many(
         cls, documents: Sequence["Resource"], *, connection: Optional[asyncpg.connection.Connection] = None
     ) -> None:
         for doc in documents:
             doc.make_hash()
-        await super().insert_many(documents, connection=connection)
+        await super(Resource, cls).insert_many(documents, connection=connection)
 
     async def update(self, connection: Optional[asyncpg.connection.Connection] = None, **kwargs: Any) -> None:
         self.make_hash()
-        await super().update(connection=connection, **kwargs)
+        await super(Resource, self).update(connection=connection, **kwargs)
 
     async def update_fields(self, connection: Optional[asyncpg.connection.Connection] = None, **kwargs: Any) -> None:
         self.make_hash()
-        await super().update_fields(connection=connection, **kwargs)
+        await super(Resource, self).update_fields(connection=connection, **kwargs)
 
     def get_requires(self) -> abc.Sequence[ResourceIdStr]:
         """
         Returns the content of the requires field in the attributes.
         """
         if "requires" not in self.attributes:
             return []
         return list(self.attributes["requires"])
 
-    def to_dict(self) -> dict[str, Any]:
+    def to_dict(self) -> Dict[str, Any]:
         self.make_hash()
-        dct = super().to_dict()
+        dct = super(Resource, self).to_dict()
         self.__mangle_dict(dct)
         return dct
 
     def to_dto(self) -> m.Resource:
         attributes = self.attributes.copy()
 
         if "requires" in self.attributes:
@@ -5331,30 +5047,30 @@
     environment: uuid.UUID
     date: Optional[datetime.datetime] = None
     partial_base: Optional[int] = None
 
     released: bool = False
     deployed: bool = False
     result: const.VersionState = const.VersionState.pending
-    version_info: Optional[dict[str, Any]] = None
+    version_info: Optional[Dict[str, Any]] = None
     is_suitable_for_partial_compiles: bool
 
     total: int = 0
 
     # cached state for release
-    undeployable: list[m.ResourceIdStr] = []
-    skipped_for_undeployable: list[m.ResourceIdStr] = []
+    undeployable: List[m.ResourceIdStr] = []
+    skipped_for_undeployable: List[m.ResourceIdStr] = []
 
     def __init__(self, **kwargs: object) -> None:
-        super().__init__(**kwargs)
+        super(ConfigurationModel, self).__init__(**kwargs)
         self._status = {}
         self._done = 0
 
     @classmethod
-    def get_valid_field_names(cls) -> list[str]:
+    def get_valid_field_names(cls) -> List[str]:
         return super().get_valid_field_names() + ["status", "model"]
 
     @property
     def done(self) -> int:
         # Keep resources which are deployed in done, even when a repair operation
         # changes its state to deploying again.
         if self.deployed:
@@ -5367,68 +5083,39 @@
         env_id: uuid.UUID,
         version: int,
         total: int,
         version_info: Optional[JsonType],
         undeployable: abc.Sequence[ResourceIdStr],
         skipped_for_undeployable: abc.Sequence[ResourceIdStr],
         partial_base: int,
-        updated_resource_sets: abc.Set[str],
-        deleted_resource_sets: abc.Set[str],
+        rids_in_partial_compile: abc.Set[ResourceIdStr],
         connection: Optional[Connection] = None,
     ) -> "ConfigurationModel":
         """
-        Create and insert a new configurationmodel that is the result of a partial compile. The new ConfigurationModel will
+        Create and insert a new configurationmodel that is the result of a partial compile. The new ConfigururationModel will
         contain all the undeployables and skipped_for_undeployables present in the partial_base version that are not part of
         the partial compile, i.e. not present in rids_in_partial_compile.
         """
         query = f"""
             WITH base_version_exists AS (
                 SELECT EXISTS(
                     SELECT 1
                     FROM {cls.table_name()} AS c1
                     WHERE c1.environment=$1 AND c1.version=$8
                 ) AS base_version_found
             ),
             rids_undeployable_base_version AS (
-                SELECT t.rid
-                FROM (
-                    SELECT DISTINCT unnest(c2.undeployable) AS rid
-                    FROM {cls.table_name()} AS c2
-                    WHERE c2.environment=$1 AND c2.version=$8
-                ) AS t(rid)
-                WHERE (
-                    EXISTS (
-                        SELECT 1
-                        FROM {Resource.table_name()} AS r
-                        WHERE r.environment=$1
-                            AND r.model=$8
-                            AND r.resource_id=t.rid
-                            -- Keep only resources that belong to the shared resource set or a resource set that was not updated
-                            AND (r.resource_set IS NULL OR NOT r.resource_set=ANY($9))
-                    )
-                )
+                SELECT DISTINCT unnest(c2.undeployable) AS rid
+                FROM {cls.table_name()} AS c2
+                WHERE c2.environment=$1 AND c2.version=$8
             ),
             rids_skipped_for_undeployable_base_version AS (
-                SELECT t.rid
-                FROM(
-                    SELECT DISTINCT unnest(c3.skipped_for_undeployable) AS rid
-                    FROM {cls.table_name()} AS c3
-                    WHERE c3.environment=$1 AND c3.version=$8
-                ) AS t(rid)
-                WHERE (
-                    EXISTS (
-                        SELECT 1
-                        FROM {Resource.table_name()} AS r
-                        WHERE r.environment=$1
-                            AND r.model=$8
-                            AND r.resource_id=t.rid
-                            -- Keep resources that belong to the shared resource set or a resource set that was not updated
-                            AND (r.resource_set IS NULL OR NOT r.resource_set=ANY($9))
-                    )
-                )
+                SELECT DISTINCT unnest(c3.skipped_for_undeployable) AS rid
+                FROM {cls.table_name()} AS c3
+                WHERE c3.environment=$1 AND c3.version=$8
             )
             INSERT INTO {cls.table_name()}(
                 environment,
                 version,
                 date,
                 total,
                 version_info,
@@ -5439,34 +5126,38 @@
             ) VALUES(
                 $1,
                 $2,
                 $3,
                 $4,
                 $5,
                 (
-                    SELECT coalesce(array_agg(rid), '{{}}')
+                    SELECT array_agg(rid)
                     FROM (
                         -- Undeployables in previous version of the model that are not part of the partial compile.
                         (
-                            SELECT rid FROM rids_undeployable_base_version AS undepl
+                            SELECT rid
+                            FROM rids_undeployable_base_version AS undepl
+                            WHERE NOT undepl.rid=ANY($9)
                         )
                         UNION
                         -- Undeployables part of the partial compile.
                         (
                             SELECT DISTINCT rid FROM unnest($6::varchar[]) AS undeploy_filtered_new(rid)
                         )
                     ) AS all_undeployable
                 ),
                 (
-                    SELECT coalesce(array_agg(rid), '{{}}')
+                    SELECT array_agg(rid)
                     FROM (
                         -- skipped_for_undeployables in previous version of the model that are not part of the partial
                         -- compile.
                         (
-                            SELECT skipped.rid FROM rids_skipped_for_undeployable_base_version AS skipped
+                            SELECT skipped.rid
+                            FROM rids_skipped_for_undeployable_base_version AS skipped
+                            WHERE NOT skipped.rid=ANY($9)
                         )
                         UNION
                         -- Skipped_for_undeployables part of the partial compile.
                         (
                             SELECT DISTINCT rid FROM unnest($7::varchar[]) AS skipped_filtered_new(rid)
                         )
                     ) AS all_skipped
@@ -5496,25 +5187,25 @@
                 version,
                 datetime.datetime.now().astimezone(),
                 total,
                 cls._get_value(version_info),
                 undeployable,
                 skipped_for_undeployable,
                 partial_base,
-                updated_resource_sets | deleted_resource_sets,
+                list(rids_in_partial_compile),
             )
             # Make mypy happy
             assert result is not None
             if not result["base_version_found"]:
                 raise Exception(f"Model with version {partial_base} not found in environment {env_id}")
             fields = {name: val for name, val in result.items() if name != "base_version_found"}
             return cls(from_postgres=True, **fields)
 
     @classmethod
-    async def _get_status_field(cls, environment: uuid.UUID, values: str) -> dict[str, str]:
+    async def _get_status_field(cls, environment: uuid.UUID, values: str) -> Dict[str, str]:
         """
         This field is required to ensure backward compatibility on the API.
         """
         result = {}
         values = json.loads(values)
         for value_entry in values:
             entry_uuid = str(uuid.uuid5(environment, value_entry["id"]))
@@ -5529,15 +5220,15 @@
         order: Optional[str] = None,
         limit: Optional[int] = None,
         offset: Optional[int] = None,
         no_obj: Optional[bool] = None,
         lock: Optional[RowLockMode] = None,
         connection: Optional[asyncpg.connection.Connection] = None,
         **query: Any,
-    ) -> list["ConfigurationModel"]:
+    ) -> List["ConfigurationModel"]:
         # sanitize and validate order parameters
         if order is None:
             order = "ASC"
         if order_by_column:
             cls._validate_order(order_by_column, order)
 
         if no_obj is None:
@@ -5608,153 +5299,107 @@
     @classmethod
     async def get_version(
         cls,
         environment: uuid.UUID,
         version: int,
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
-        lock: Optional[RowLockMode] = None,
     ) -> Optional["ConfigurationModel"]:
         """
         Get a specific version
         """
-        result = await cls.get_one(environment=environment, version=version, connection=connection, lock=lock)
+        result = await cls.get_one(environment=environment, version=version, connection=connection)
         return result
 
     @classmethod
-    async def get_version_internal(
-        cls,
-        environment: uuid.UUID,
-        version: int,
-        *,
-        connection: Optional[asyncpg.connection.Connection] = None,
-        lock: Optional[RowLockMode] = None,
-    ) -> Optional["ConfigurationModel"]:
-        """Return a version, but don't populate the status and done fields, which are expensive to construct"""
-        query = f"""SELECT *
-                          FROM {ConfigurationModel.table_name()}
-                          WHERE environment=$1 AND version=$2 {lock.value};
-                          """
-        result = await cls.select_query(query, [environment, version], connection=connection)
-        if not result:
-            return None
-        return result[0]
-
-    @classmethod
-    async def get_latest_version(
-        cls,
-        environment: uuid.UUID,
-        *,
-        connection: Optional[Connection] = None,
-    ) -> Optional["ConfigurationModel"]:
+    async def get_latest_version(cls, environment: uuid.UUID) -> Optional["ConfigurationModel"]:
         """
         Get the latest released (most recent) version for the given environment
         """
-        versions = await cls.get_list(
-            order_by_column="version", order="DESC", limit=1, environment=environment, released=True, connection=connection
-        )
+        versions = await cls.get_list(order_by_column="version", order="DESC", limit=1, environment=environment, released=True)
         if len(versions) == 0:
             return None
 
         return versions[0]
 
     @classmethod
-    async def get_version_nr_latest_version(
-        cls,
-        environment: uuid.UUID,
-        connection: Optional[Connection] = None,
-    ) -> Optional[int]:
+    async def get_version_nr_latest_version(cls, environment: uuid.UUID) -> Optional[int]:
         """
         Get the version number of the latest released version in the given environment.
         """
         query = f"""SELECT version
                     FROM {ConfigurationModel.table_name()}
                     WHERE environment=$1 AND released=true
                     ORDER BY version DESC
                     LIMIT 1
                     """
-        result = await cls._fetchrow(query, cls._get_value(environment), connection=connection)
+        result = await cls._fetchrow(query, cls._get_value(environment))
         if not result:
             return None
         return int(result["version"])
 
     @classmethod
     async def get_agents(
         cls, environment: uuid.UUID, version: int, *, connection: Optional[asyncpg.connection.Connection] = None
-    ) -> list[str]:
+    ) -> List[str]:
         """
         Returns a list of all agents that have resources defined in this configuration model
         """
         (filter_statement, values) = cls._get_composed_filter(environment=environment, model=version)
         query = "SELECT DISTINCT agent FROM " + Resource.table_name() + " WHERE " + filter_statement
         result = []
         async with cls.get_connection(connection) as con:
             async with con.transaction():
                 async for record in con.cursor(query, *values):
                     result.append(record["agent"])
         return result
 
     @classmethod
-    async def get_versions(
-        cls, environment: uuid.UUID, start: int = 0, limit: int = DBLIMIT, connection: Optional[Connection] = None
-    ) -> list["ConfigurationModel"]:
+    async def get_versions(cls, environment: uuid.UUID, start: int = 0, limit: int = DBLIMIT) -> List["ConfigurationModel"]:
         """
         Get all versions for an environment ordered descending
         """
         versions = await cls.get_list(
-            order_by_column="version", order="DESC", limit=limit, offset=start, environment=environment, connection=connection
+            order_by_column="version", order="DESC", limit=limit, offset=start, environment=environment
         )
         return versions
 
-    async def delete_cascade(self, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """
-        This method doesn't rely on the DELETE CASCADE functionality of PostgreSQL because it causes deadlocks.
-        As such, we perform the deletes on each table in a separate transaction.
-        """
-        async with self.get_connection(connection=connection) as con:
-            # Delete of compile record triggers cascading delete report table
-            await Compile.delete_all(environment=self.environment, version=self.version, connection=con)
-            await Code.delete_all(environment=self.environment, version=self.version, connection=con)
-            await DryRun.delete_all(environment=self.environment, model=self.version, connection=con)
-            await UnknownParameter.delete_all(environment=self.environment, version=self.version, connection=con)
-            await self._execute_query(
-                "DELETE FROM public.resourceaction_resource WHERE environment=$1 AND resource_version=$2",
-                self.environment,
-                self.version,
-                connection=con,
-            )
-            await ResourceAction.delete_all(environment=self.environment, version=self.version, connection=con)
-            await Resource.delete_all(environment=self.environment, model=self.version, connection=con)
-            await self.delete(connection=con)
+    async def delete_cascade(self) -> None:
+        async with self.get_connection() as con:
+            async with con.transaction():
+                # Delete all code associated with this version
+                await Code.delete_all(connection=con, environment=self.environment, version=self.version)
+
+                # Delete ConfigurationModel and cascade delete on connected tables
+                await self.delete(connection=con)
 
             # Delete facts when the resources in this version are the only
-            await self._execute_query(
+            await con.execute(
                 f"""
                 DELETE FROM {Parameter.table_name()} p
                 WHERE(
                     environment=$1 AND
                     resource_id<>'' AND
                     NOT EXISTS(
                         SELECT 1
                         FROM {Resource.table_name()} r
                         WHERE p.resource_id=r.resource_id
                     )
                 )
                 """,
                 self.environment,
-                connection=con,
             )
 
-    def get_undeployable(self) -> list[m.ResourceIdStr]:
+    async def get_undeployable(self) -> List[m.ResourceIdStr]:
         """
         Returns a list of resource ids (NOT resource version ids) of resources with an undeployable state
         """
         return self.undeployable
 
-    def get_skipped_for_undeployable(self) -> list[m.ResourceIdStr]:
+    async def get_skipped_for_undeployable(self) -> List[m.ResourceIdStr]:
         """
         Returns a list of resource ids (NOT resource version ids)
         of resources which should get a skipped_for_undeployable state
         """
         return self.skipped_for_undeployable
 
     async def mark_done(self, *, connection: Optional[asyncpg.connection.Connection] = None) -> None:
@@ -5813,80 +5458,50 @@
                     cls._get_value(const.VersionState.failed),
                     cls._get_value(const.VersionState.success),
                     cls._get_value(DONE_STATES),
                 ]
                 await cls._execute_query(query, *values, connection=con)
 
     @classmethod
-    async def get_increment(
-        cls, environment: uuid.UUID, version: int, *, connection: Optional[Connection] = None
-    ) -> tuple[set[m.ResourceIdStr], set[m.ResourceIdStr]]:
+    async def get_increment(cls, environment: uuid.UUID, version: int) -> tuple[set[m.ResourceIdStr], set[m.ResourceIdStr]]:
         """
         Find resources incremented by this version compared to deployment state transitions per resource
 
         available -> next version
         not present -> increment
         skipped -> increment
         unavailable -> increment
         error -> increment
         Deployed and same hash -> not increment
         deployed and different hash -> increment
         """
-        projection_a = ["resource_id", "status", "attribute_hash", "attributes", "last_success", "last_produced_events"]
+        projection_a = ["resource_id", "status", "attribute_hash", "attributes"]
         projection = ["resource_id", "status", "attribute_hash"]
 
         # get resources for agent
-        resources = await Resource.get_resources_for_version_raw(environment, version, projection_a, connection=connection)
+        resources = await Resource.get_resources_for_version_raw(environment, version, projection_a)
 
         # to increment
         increment: list[abc.Mapping[str, Any]] = []
         not_increment: list[abc.Mapping[str, Any]] = []
         # todo in this version
         work: list[abc.Mapping[str, object]] = [r for r in resources if r["status"] not in UNDEPLOYABLE_NAMES]
 
-        # start with outstanding events
-        id_to_resource = {r["resource_id"]: r for r in resources}
-        next: list[abc.Mapping[str, object]] = []
-        for resource in work:
-            in_increment = False
-            last_success = resource["last_success"] or DATETIME_MIN_UTC
-            attributes = resource["attributes"]
-            assert isinstance(attributes, dict)  # mypy
-            for req in attributes["requires"]:
-                req_res = id_to_resource[req]
-                assert req_res is not None  # todo
-                req_res_attributes = req_res["attributes"]
-                assert isinstance(req_res_attributes, dict)  # mypy
-                last_produced_events = req_res["last_produced_events"]
-                if (
-                    last_produced_events is not None
-                    and last_produced_events > last_success
-                    and "send_event" in req_res_attributes
-                    and req_res_attributes["send_event"]
-                ):
-                    in_increment = True
-                    break
-            if in_increment:
-                increment.append(resource)
-            else:
-                next.append(resource)
-        work = next
-
         # get versions
         query = f"SELECT version FROM {cls.table_name()} WHERE environment=$1 AND released=true ORDER BY version DESC"
         values = [cls._get_value(environment)]
-        version_records = await cls._fetch_query(query, *values, connection=connection)
+        version_records = await cls._fetch_query(query, *values)
 
         versions = [record["version"] for record in version_records]
 
         for version in versions:
             # todo in next version
-            next = []
+            next: list[abc.Mapping[str, object]] = []
 
-            vresources = await Resource.get_resources_for_version_raw(environment, version, projection, connection=connection)
+            vresources = await Resource.get_resources_for_version_raw(environment, version, projection)
             id_to_resource = {r["resource_id"]: r for r in vresources}
 
             for res in work:
                 # not present -> increment
                 if res["resource_id"] not in id_to_resource:
                     increment.append(res)
                     continue
@@ -5938,15 +5553,15 @@
         negative: set[ResourceIdStr] = {res["resource_id"] for res in not_increment}
 
         # patch up the graph
         # 1-include stuff for send-events.
         # 2-adapt requires/provides to get closured set
 
         outset: set[ResourceIdStr] = {res["resource_id"] for res in increment}
-        original_provides: dict[str, list[ResourceIdStr]] = defaultdict(list)
+        original_provides: dict[str, List[ResourceIdStr]] = defaultdict(lambda: [])
         send_events: list[ResourceIdStr] = []
 
         # build lookup tables
         for res in resources:
             for req in res["attributes"]["requires"]:
                 original_provides[req].append(res["resource_id"])
             if "send_event" in res["attributes"] and res["attributes"]["send_event"]:
@@ -5969,27 +5584,27 @@
             increment_work.extend(provides)
             outset.update(provides)
             negative.difference_update(provides)
 
         return outset, negative
 
     @classmethod
-    def active_version_subquery(cls, environment: uuid.UUID) -> tuple[str, list[object]]:
+    def active_version_subquery(cls, environment: uuid.UUID) -> Tuple[str, List[object]]:
         query_builder = SimpleQueryBuilder(
             select_clause="""
             SELECT max(version)
             """,
             from_clause=f" FROM {cls.table_name()} ",
             filter_statements=[" environment = $1 AND released = TRUE"],
             values=[cls._get_value(environment)],
         )
         return query_builder.build()
 
     @classmethod
-    def desired_state_versions_subquery(cls, environment: uuid.UUID) -> tuple[str, list[object]]:
+    def desired_state_versions_subquery(cls, environment: uuid.UUID) -> Tuple[str, List[object]]:
         active_version, values = cls.active_version_subquery(environment)
         # Coalesce to 0 in case there is no active version
         active_version = f"(SELECT COALESCE(({active_version}), 0))"
         query_builder = SimpleQueryBuilder(
             select_clause=f"""SELECT cm.version, cm.date, cm.total,
                                      version_info -> 'export_metadata' ->> 'message' as message,
                                      version_info -> 'export_metadata' ->> 'type' as type,
@@ -6041,26 +5656,26 @@
     """
 
     __primary_key__ = ("environment", "resource", "version")
 
     environment: uuid.UUID
     resource: str
     version: int
-    source_refs: Optional[dict[str, tuple[str, str, list[str]]]] = None
+    source_refs: Optional[Dict[str, Tuple[str, str, List[str]]]] = None
 
     @classmethod
     async def get_version(cls, environment: uuid.UUID, version: int, resource: str) -> Optional["Code"]:
         codes = await cls.get_list(environment=environment, version=version, resource=resource)
         if len(codes) == 0:
             return None
 
         return codes[0]
 
     @classmethod
-    async def get_versions(cls, environment: uuid.UUID, version: int) -> list["Code"]:
+    async def get_versions(cls, environment: uuid.UUID, version: int) -> List["Code"]:
         codes = await cls.get_list(environment=environment, version=version)
         return codes
 
     @classmethod
     async def copy_versions(
         cls,
         environment: uuid.UUID,
@@ -6100,15 +5715,15 @@
 
     id: uuid.UUID
     environment: uuid.UUID
     model: int
     date: datetime.datetime
     total: int = 0
     todo: int = 0
-    resources: dict[str, Any] = {}
+    resources: Dict[str, Any] = {}
 
     @classmethod
     async def update_resource(cls, dryrun_id: uuid.UUID, resource_id: m.ResourceVersionIdStr, dryrun_data: JsonType) -> None:
         """
         Register a resource update with a specific query that sets the dryrun_data and decrements the todo counter, only
         if the resource has not been saved yet.
         """
@@ -6142,15 +5757,15 @@
 
     @classmethod
     async def list_dryruns(
         cls,
         order_by_column: Optional[str] = None,
         order: str = "ASC",
         **query: object,
-    ) -> list[m.DryRun]:
+    ) -> List[m.DryRun]:
         records = await cls.get_list_with_columns(
             order_by_column=order_by_column,
             order=order,
             columns=["id", "environment", "model", "date", "total", "todo"],
             limit=None,
             offset=None,
             no_obj=None,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/data/dataview.py` & `inmanta-core-9.3.0/src/inmanta/data/dataview.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,17 +15,16 @@
 
     Contact: code@inmanta.com
 """
 
 import abc
 import json
 from abc import ABC
-from collections.abc import Sequence
 from datetime import datetime
-from typing import Generic, Optional, TypeVar, Union, cast
+from typing import Dict, Generic, List, Optional, Sequence, Tuple, Type, TypeVar, Union, cast
 from urllib import parse
 from urllib.parse import quote
 from uuid import UUID
 
 from asyncpg import Record
 
 from inmanta import data
@@ -69,15 +68,14 @@
     ResourceIdStr,
     ResourceLog,
     ResourceVersionIdStr,
 )
 from inmanta.protocol.exceptions import BadRequest
 from inmanta.protocol.return_value_meta import ReturnValueWithMeta
 from inmanta.resources import Id
-from inmanta.server import config as opt
 from inmanta.server.validate_filter import (
     BooleanEqualityFilter,
     BooleanIsNotNullFilter,
     CombinedContainsFilterResourceState,
     ContainsFilter,
     ContainsFilterResourceAction,
     ContainsPartialFilter,
@@ -85,15 +83,15 @@
     Filter,
     FilterValidator,
     IntRangeFilter,
     InvalidFilter,
     LogLevelFilter,
 )
 from inmanta.types import JsonType, SimpleTypes
-from inmanta.util import datetime_iso_format
+from inmanta.util import datetime_utc_isoformat
 
 T_ORDER = TypeVar("T_ORDER", bound=DatabaseOrderV2)
 T_DTO = TypeVar("T_DTO", bound=BaseModel)
 
 
 class RequestedPagingBoundaries:
     """Represents the lower and upper bounds that the user requested for the paging boundaries, if any."""
@@ -143,15 +141,15 @@
 class PagingMetadata:
     def __init__(self, total: int, before: int, after: int, page_size: int) -> None:
         self.total = total
         self.before = before
         self.after = after
         self.page_size = page_size
 
-    def to_dict(self) -> dict[str, int]:
+    def to_dict(self) -> Dict[str, int]:
         return {
             "total": self.total,
             "before": self.before,
             "after": self.after,
             "page_size": self.page_size,
         }
 
@@ -161,38 +159,39 @@
         self,
         order: T_ORDER,
         limit: Optional[int] = None,
         first_id: Optional[PRIMITIVE_SQL_TYPES] = None,
         last_id: Optional[PRIMITIVE_SQL_TYPES] = None,
         start: Optional[PRIMITIVE_SQL_TYPES] = None,
         end: Optional[PRIMITIVE_SQL_TYPES] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         self.limit = self.validate_limit(limit)
         self.raw_filter = filter or {}
-        self.filter: dict[str, QueryFilter] = self.process_filters(filter)
+        self.filter: Dict[str, QueryFilter] = self.process_filters(filter)
         self.order = order
         self.requested_page_boundaries = RequestedPagingBoundaries(start, end, first_id, last_id)
         self.requested_page_boundaries.validate()
 
     @abc.abstractmethod
     def get_base_url(self) -> str:
         """
         Return the base URL used to construct the paging links
 
         e.g. "/api/v2/resource"
         """
+        pass
 
-    def get_extra_url_parameters(self) -> dict[str, str]:
+    def get_extra_url_parameters(self) -> Dict[str, str]:
         """
         Return additional URL query parameters required to construct the paging links
         """
         return {}
 
-    async def get_data(self) -> tuple[Sequence[T_DTO], Optional[PagingBoundaries]]:
+    async def get_data(self) -> Tuple[Sequence[T_DTO], Optional[PagingBoundaries]]:
         query_builder = self.get_base_query()
 
         # In this method, we use `data.Resource`
         # we need the generic functionality of `data.BaseDocument`
         # But that one doesn't actually hold a connection, as it is abstract
 
         # Project
@@ -213,36 +212,32 @@
         return dtos, paging_boundaries
 
     @abc.abstractmethod
     def construct_dtos(self, records: Sequence[Record]) -> Sequence[T_DTO]:
         """
         Convert the sequence of records into a sequence of DTO's
         """
+        pass
 
     @abc.abstractmethod
     def get_base_query(self) -> SimpleQueryBuilder:
         """
         Return the base query to get the data.
 
         Must contain select, from and where clause if specific filtering is required
         """
-
-    def get_base_query_for_page_count(self) -> SimpleQueryBuilder:
-        """
-        Override this method to use a different query than returned by get_base_query()
-        to calculate the page count for a certain page.
-        """
-        return self.get_base_query()
+        pass
 
     @property
     @abc.abstractmethod
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         """
         Return the specification of the allowed filters, see FilterValidator
         """
+        pass
 
     def clip_to_page(self, query_builder: SimpleQueryBuilder) -> SimpleQueryBuilder:
         """
         Update the query builder to constrain it to the page boundaries, order and size
         """
         order = self.order.get_order()
         backward_paging: bool = (order == PagingOrder.ASC and self.requested_page_boundaries.has_end()) or (
@@ -299,15 +294,15 @@
     async def _get_page_count(self, bounds: Union[PagingBoundaries, RequestedPagingBoundaries]) -> PagingMetadata:
         """
         Construct the page counts,
 
         either from the PagingBoundaries if we have a valid page,
         or from the RequestedPagingBoundaries if we got an empty page
         """
-        query_builder = self.get_base_query_for_page_count()
+        query_builder = self.get_base_query()
 
         query_builder = query_builder.filter(
             *data.BaseDocument.get_composed_filter_with_query_types(
                 offset=query_builder.offset, col_name_prefix=None, **self.filter
             )
         )
 
@@ -353,36 +348,36 @@
             + (f", COUNT(*) filter ({after_filter}) as count_after " if after_filter else "")
         )
 
         query_builder = query_builder.select(select_clause)
 
         sql_query, values = query_builder.build()
         result = await data.Resource.select_query(sql_query, values, no_obj=True)
-        result = cast(list[Record], result)
+        result = cast(List[Record], result)
         if not result:
             raise InvalidQueryParameter("Could not determine page bounds")
         return PagingMetadata(
             total=cast(int, result[0]["count_total"]),
             before=cast(int, result[0].get("count_before", 0)),
             after=cast(int, result[0].get("count_after", 0)),
             page_size=self.limit,
         )
 
     async def prepare_paging_links(
         self,
         dtos: Sequence[T_DTO],
         paging_boundaries: Union[PagingBoundaries, RequestedPagingBoundaries],
         meta: PagingMetadata,
-    ) -> dict[str, str]:
+    ) -> Dict[str, str]:
         """
         Construct the paging links
         """
         links = {}
 
-        url_query_params: dict[str, Optional[Union[SimpleTypes, list[str]]]] = {
+        url_query_params: Dict[str, Optional[Union[SimpleTypes, List[str]]]] = {
             "limit": self.limit,
             "sort": str(self.order),
         }
 
         for key, value in self.raw_filter.items():
             if value is not None:
                 url_query_params[f"filter.{key}"] = value
@@ -391,16 +386,16 @@
 
         if dtos:
             base_url = self.get_base_url()
 
             def value_to_string(value: Union[str, int, UUID, datetime]) -> str:
                 if isinstance(value, datetime):
                     # Accross API boundaries, all naive datetime instances are assumed UTC.
-                    # Returns ISO timestamp.
-                    return datetime_iso_format(value, tz_aware=opt.server_tz_aware_timestamps.get())
+                    # Returns ISO timestamp implicitly in UTC.
+                    return datetime_utc_isoformat(value, naive_utc=True)
                 return str(value)
 
             def make_link(**args: Optional[Union[str, int, UUID, datetime]]) -> str:
                 params = url_query_params.copy()
                 params.update({k: value_to_string(v) for k, v in args.items() if v is not None})
                 return f"{base_url}?{parse.urlencode(params, doseq=True)}"
 
@@ -450,15 +445,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[ResourceVersionIdStr] = None,
         last_id: Optional[ResourceVersionIdStr] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
         deploy_summary: bool = False,
     ) -> None:
         super().__init__(
             order=ResourceOrder.parse_from_string(sort),
             limit=limit,
             first_id=first_id,
@@ -467,26 +462,26 @@
             end=end,
             filter=filter,
         )
         self.environment = env
         self.deploy_summary = deploy_summary
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "resource_type": ContainsPartialFilter,
             "agent": ContainsPartialFilter,
             "resource_id_value": ContainsPartialFilter,
             "status": CombinedContainsFilterResourceState,
         }
 
     def get_base_url(self) -> str:
         return "/api/v2/resource"
 
-    def get_extra_url_parameters(self) -> dict[str, str]:
+    def get_extra_url_parameters(self) -> Dict[str, str]:
         return {"deploy_summary": str(self.deploy_summary)}
 
     def get_base_query(self) -> SimpleQueryBuilder:
         def subquery_latest_version_for_single_resource(higher_than: Optional[str]) -> str:
             """
             Returns a subquery to select a single row from a resource table:
                 - for the first resource id higher than the given boundary
@@ -565,15 +560,15 @@
 
 class ResourcesInVersionView(DataView[VersionedResourceOrder, model.VersionedResource]):
     def __init__(
         self,
         environment: data.Environment,
         version: int,
         limit: Optional[int] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
         first_id: Optional[ResourceVersionIdStr] = None,
         last_id: Optional[ResourceVersionIdStr] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
     ) -> None:
         super().__init__(
@@ -589,15 +584,15 @@
         self.version = version
 
     # Per view config
     def get_base_url(self) -> str:
         return f"/api/v2/desiredstate/{self.version}"
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "resource_type": ContainsPartialFilter,
             "agent": ContainsPartialFilter,
             "resource_id_value": ContainsPartialFilter,
         }
 
     def get_base_query(self) -> SimpleQueryBuilder:
@@ -622,15 +617,15 @@
 
 
 class CompileReportView(DataView[CompileReportOrder, CompileReport]):
     def __init__(
         self,
         environment: data.Environment,
         limit: Optional[int] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
         first_id: Optional[UUID] = None,
         last_id: Optional[UUID] = None,
         start: Optional[datetime] = None,
         end: Optional[datetime] = None,
     ) -> None:
         super().__init__(
@@ -641,15 +636,15 @@
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "requested": DateRangeFilter,
             "success": BooleanEqualityFilter,
             "started": BooleanIsNotNullFilter,
             "completed": BooleanIsNotNullFilter,
         }
 
@@ -695,15 +690,15 @@
 
 
 class DesiredStateVersionView(DataView[DesiredStateVersionOrder, DesiredStateVersion]):
     def __init__(
         self,
         environment: data.Environment,
         limit: Optional[int] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
         start: Optional[int] = None,
         end: Optional[int] = None,
     ) -> None:
         super().__init__(
             order=DesiredStateVersionOrder.parse_from_string(sort),
             limit=limit,
@@ -712,15 +707,15 @@
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "version": IntRangeFilter,
             "date": DateRangeFilter,
             "status": ContainsFilter,
         }
 
     def get_base_url(self) -> str:
@@ -771,15 +766,15 @@
             end=end,
             filter={},
         )
         self.environment = environment
         self.rid = rid
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {}
 
     def get_base_url(self) -> str:
         return f"/api/v2/resource/{quote(self.rid,safe='')}/history"
 
     def get_base_query(self) -> SimpleQueryBuilder:
         query_builder = SimpleQueryBuilder(
@@ -844,15 +839,15 @@
 class ResourceLogsView(DataView[ResourceLogOrder, ResourceLog]):
     def __init__(
         self,
         environment: data.Environment,
         rid: ResourceIdStr,
         limit: Optional[int] = None,
         sort: str = "resource_type.desc",
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         start: Optional[datetime] = None,
         end: Optional[datetime] = None,
     ) -> None:
         super().__init__(
             order=ResourceLogOrder.parse_from_string(sort),
             limit=limit,
             first_id=None,
@@ -861,23 +856,23 @@
             end=end,
             filter=filter,
         )
         self.environment = environment
         self.rid = rid
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "minimal_log_level": LogLevelFilter,
             "timestamp": DateRangeFilter,
             "message": ContainsPartialFilter,
             "action": ContainsFilterResourceAction,
         }
 
-    def process_filters(self, filter: Optional[dict[str, list[str]]]) -> dict[str, QueryFilter]:
+    def process_filters(self, filter: Optional[Dict[str, List[str]]]) -> Dict[str, QueryFilter]:
         # Change the api names of the filters to the names used internally in the database
         query = super().process_filters(filter)
         if query.get("minimal_log_level"):
             filter_value = query.pop("minimal_log_level")
             query["level"] = filter_value
         if query.get("message"):
             filter_value = query.pop("message")
@@ -945,29 +940,29 @@
         environment: data.Environment,
         limit: Optional[int] = None,
         sort: str = "resource_type.desc",
         first_id: Optional[UUID] = None,
         last_id: Optional[UUID] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         super().__init__(
             order=FactOrder.parse_from_string(sort),
             limit=limit,
             first_id=first_id,
             last_id=last_id,
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "name": ContainsPartialFilter,
             "resource_id": ContainsPartialFilter,
         }
 
     def get_base_url(self) -> str:
         return "/api/v2/facts"
@@ -1003,29 +998,29 @@
         environment: data.Environment,
         limit: Optional[int] = None,
         sort: str = "resource_type.desc",
         first_id: Optional[UUID] = None,
         last_id: Optional[UUID] = None,
         start: Optional[datetime] = None,
         end: Optional[datetime] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         super().__init__(
             order=NotificationOrder.parse_from_string(sort),
             limit=limit,
             first_id=first_id,
             last_id=last_id,
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "title": ContainsPartialFilter,
             "message": ContainsPartialFilter,
             "read": BooleanEqualityFilter,
             "cleared": BooleanEqualityFilter,
             "severity": ContainsFilter,
         }
@@ -1064,29 +1059,29 @@
         environment: data.Environment,
         limit: Optional[int] = None,
         sort: str = "resource_type.desc",
         first_id: Optional[UUID] = None,
         last_id: Optional[UUID] = None,
         start: Optional[Union[str, datetime]] = None,
         end: Optional[Union[str, datetime]] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         super().__init__(
             order=ParameterOrder.parse_from_string(sort),
             limit=limit,
             first_id=first_id,
             last_id=last_id,
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "name": ContainsPartialFilter,
             "source": ContainsPartialFilter,
             "updated": DateRangeFilter,
         }
 
     def get_base_url(self) -> str:
@@ -1121,36 +1116,36 @@
         environment: data.Environment,
         limit: Optional[int] = None,
         sort: str = "resource_type.desc",
         start: Optional[Union[datetime, bool, str]] = None,
         end: Optional[Union[datetime, bool, str]] = None,
         first_id: Optional[str] = None,
         last_id: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         super().__init__(
             order=AgentOrder.parse_from_string(sort),
             limit=limit,
             first_id=first_id,
             last_id=last_id,
             start=start,
             end=end,
             filter=filter,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         return {
             "name": ContainsPartialFilter,
             "process_name": ContainsPartialFilter,
             "status": ContainsFilter,
         }
 
-    def process_filters(self, filter: Optional[dict[str, list[str]]]) -> dict[str, QueryFilter]:
+    def process_filters(self, filter: Optional[Dict[str, List[str]]]) -> Dict[str, QueryFilter]:
         out_filter = super().process_filters(filter)
         # name is ambiguous, qualify
         if "name" in out_filter:
             out_filter["a.name"] = out_filter.pop("name")
         return out_filter
 
     def get_base_url(self) -> str:
@@ -1214,15 +1209,15 @@
             start=start,
             end=end,
             filter=None,
         )
         self.environment = environment
 
     @property
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         """
         Return the specification of the allowed filters, see FilterValidator
         """
         return {}
 
     def get_base_url(self) -> str:
         return "/api/v2/discovered"
@@ -1240,96 +1235,7 @@
         return [
             model.DiscoveredResource(
                 discovered_resource_id=res["discovered_resource_id"],
                 values=json.loads(res["values"]),
             ).dict()
             for res in records
         ]
-
-
-class PreludeBasedFilteringQueryBuilder(SimpleQueryBuilder):
-    """
-    A query builder that applies any filters and the LIMIT statement to the prelude query rather than the outer query.
-    The outer query may use the table name "prelude" to refer to the inner query.
-    """
-
-    def __init__(
-        self,
-        prelude_query_builder: SimpleQueryBuilder,
-        select_clause: Optional[str] = None,
-        from_clause: Optional[str] = None,
-        db_order: Optional[DatabaseOrderV2] = None,
-        backward_paging: bool = False,
-    ) -> None:
-        super().__init__(
-            select_clause=select_clause,
-            from_clause=from_clause,
-            filter_statements=None,
-            values=None,
-            db_order=db_order,
-            limit=None,
-            backward_paging=backward_paging,
-            prelude=None,
-        )
-        self._prelude_query_builder = prelude_query_builder
-
-    @property
-    def offset(self) -> int:
-        """The current offset of the values to be used for filter statements"""
-        return len(self.values) + len(self._prelude_query_builder.values) + 1
-
-    def build(self) -> tuple[str, list[object]]:
-        prelude_query, prelude_values = self._prelude_query_builder.build()
-        prelude_query_in_with_block = f"WITH prelude AS ({prelude_query})"
-        delegate: SimpleQueryBuilder = SimpleQueryBuilder(
-            select_clause=self.select_clause,
-            from_clause=self._from_clause,
-            filter_statements=self._prelude_query_builder.filter_statements + self.filter_statements,
-            values=self._prelude_query_builder.values + self.values,
-            db_order=self.db_order,
-            limit=None,
-            backward_paging=self.backward_paging,
-            prelude=prelude_query_in_with_block,
-        )
-        full_query, values_full = delegate.build()
-        return full_query, prelude_values
-
-    def select(self, select_clause: str) -> "PreludeBasedFilteringQueryBuilder":
-        """Set the select clause of the query"""
-        return PreludeBasedFilteringQueryBuilder(
-            select_clause=select_clause,
-            from_clause=self._from_clause,
-            db_order=self.db_order,
-            backward_paging=self.backward_paging,
-            prelude_query_builder=self._prelude_query_builder,
-        )
-
-    def from_clause(self, from_clause: str) -> "PreludeBasedFilteringQueryBuilder":
-        """Set the from clause of the query"""
-        return PreludeBasedFilteringQueryBuilder(
-            select_clause=self.select_clause,
-            from_clause=from_clause,
-            db_order=self.db_order,
-            backward_paging=self.backward_paging,
-            prelude_query_builder=self._prelude_query_builder,
-        )
-
-    def order_and_limit(
-        self, db_order: DatabaseOrderV2, limit: Optional[int] = None, backward_paging: bool = False
-    ) -> "PreludeBasedFilteringQueryBuilder":
-        """Set the order and limit of the query"""
-        return PreludeBasedFilteringQueryBuilder(
-            select_clause=self.select_clause,
-            from_clause=self._from_clause,
-            db_order=db_order,
-            backward_paging=backward_paging,
-            prelude_query_builder=self._prelude_query_builder.order_and_limit(db_order, limit, backward_paging),
-        )
-
-    def filter(self, filter_statements: list[str], values: list[object]) -> "PreludeBasedFilteringQueryBuilder":
-        return PreludeBasedFilteringQueryBuilder(
-            select_clause=self.select_clause,
-            from_clause=self._from_clause,
-            db_order=self.db_order,
-            backward_paging=self.backward_paging,
-            prelude_query_builder=self._prelude_query_builder.filter(filter_statements, values),
-        )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/data/model.py` & `inmanta-core-9.3.0/src/inmanta/data/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,21 +15,20 @@
 
     Contact: code@inmanta.com
 """
 import datetime
 import uuid
 from enum import Enum
 from itertools import chain
-from typing import Any, ClassVar, NewType, Optional, Union
+from typing import Any, ClassVar, Dict, List, NewType, Optional, Union
 
 import pydantic
 import pydantic.schema
 from pydantic import Extra, root_validator, validator
 from pydantic.fields import ModelField
-from pydantic.types import StrictFloat, StrictInt, StrictStr
 
 import inmanta
 import inmanta.ast.export as ast_export
 from inmanta import const, data, protocol, resources
 from inmanta.stable_api import stable_api
 from inmanta.types import ArgumentTypes, JsonType, SimpleTypes, StrictNonIntBool
 
@@ -103,15 +102,15 @@
 
 class SliceStatus(BaseModel):
     """
     Status response for slices loaded in the the server
     """
 
     name: str
-    status: dict[str, ArgumentTypes]
+    status: Dict[str, ArgumentTypes]
 
 
 class FeatureStatus(BaseModel):
     """
     Status of the feature
     """
 
@@ -124,27 +123,27 @@
     """
     Response for the status method call
     """
 
     product: str
     edition: str
     version: str
-    license: Union[str, dict[str, SimpleTypes]]
-    extensions: list[ExtensionStatus]
-    slices: list[SliceStatus]
-    features: list[FeatureStatus]
+    license: Union[str, Dict[str, SimpleTypes]]
+    extensions: List[ExtensionStatus]
+    slices: List[SliceStatus]
+    features: List[FeatureStatus]
 
 
 @stable_api
 class CompileData(BaseModel):
     """
     Top level structure of compiler data to be exported.
     """
 
-    errors: list[ast_export.Error]
+    errors: List[ast_export.Error]
     """
         All errors occurred while trying to compile.
     """
 
 
 class CompileRunBase(BaseModel):
     id: uuid.UUID
@@ -152,15 +151,15 @@
     environment: uuid.UUID
     requested: Optional[datetime.datetime]
     started: Optional[datetime.datetime]
 
     do_export: bool
     force_update: bool
     metadata: JsonType
-    environment_variables: dict[str, str]
+    environment_variables: Dict[str, str]
 
     partial: bool
     removed_resource_sets: list[str]
 
     exporter_plugin: Optional[str]
 
     notify_failed_compile: Optional[bool]
@@ -186,15 +185,15 @@
     errstream: str
     outstream: str
     returncode: Optional[int]
 
 
 class CompileDetails(CompileReport):
     compile_data: Optional[CompileData]
-    reports: Optional[list[CompileRunReport]]
+    reports: Optional[List[CompileRunReport]]
 
 
 ResourceVersionIdStr = NewType("ResourceVersionIdStr", str)  # Part of the stable API
 """
     The resource id with the version included.
 """
 
@@ -231,44 +230,43 @@
                 raise Exception(f"Failed to serialize attribute {v}")
             else:
                 # In production, try to cast the non-serializable value to str to prevent the handler from failing.
                 return str(v)
         return v
 
 
-EnvSettingType = Union[StrictNonIntBool, StrictInt, StrictFloat, StrictStr, dict[str, Union[str, int, StrictNonIntBool]]]
+EnvSettingType = Union[StrictNonIntBool, int, float, str, Dict[str, Union[str, int, StrictNonIntBool]]]
 
 
 class Environment(BaseModel):
     """
     An inmanta environment.
 
     :note: repo_url and repo_branch will be moved to the settings.
     """
 
     id: uuid.UUID
     name: str
     project_id: uuid.UUID
     repo_url: str
     repo_branch: str
-    settings: dict[str, EnvSettingType]
+    settings: Dict[str, EnvSettingType]
     halted: bool
     description: Optional[str]
     icon: Optional[str]
-    is_marked_for_deletion: bool = False
 
 
 class Project(BaseModel):
     """
     An inmanta environment.
     """
 
     id: uuid.UUID
     name: str
-    environments: list[Environment]
+    environments: List[Environment]
 
 
 class EnvironmentSetting(BaseModel):
     """A class to define a new environment setting.
 
     :param name: The name of the setting.
     :param type: The type of the value. This type is mainly used for documentation purpose.
@@ -285,45 +283,34 @@
     name: str
     type: str
     default: EnvSettingType
     doc: str
     recompile: bool
     update_model: bool
     agent_restart: bool
-    allowed_values: Optional[list[EnvSettingType]]
+    allowed_values: Optional[List[EnvSettingType]]
 
 
 class EnvironmentSettingsReponse(BaseModel):
-    settings: dict[str, EnvSettingType]
-    definition: dict[str, EnvironmentSetting]
+    settings: Dict[str, EnvSettingType]
+    definition: Dict[str, EnvironmentSetting]
 
 
 class ModelMetadata(BaseModel):
     """Model metadata"""
 
     inmanta_compile_state: const.Compilestate = const.Compilestate.success
     message: str
     type: str
     extra_data: Optional[JsonType]
 
     class Config:
         fields = {"inmanta_compile_state": {"alias": "inmanta:compile:state"}}
 
 
-class ModelVersionInfo(BaseModel):
-    """Version information that can be associated with an orchestration model
-
-    :param export_metadata: Metadata associated with this version
-    :param model: A serialization of the complete orchestration model
-    """
-
-    export_metadata: ModelMetadata
-    model: Optional[JsonType]
-
-
 class ResourceMinimal(BaseModel):
     """
     Represents a resource object as it comes in over the API. Provides strictly required validation only.
     """
 
     id: ResourceVersionIdStr
 
@@ -351,51 +338,51 @@
     status: const.ResourceState
     resource_set: Optional[str]
 
 
 class ResourceAction(BaseModel):
     environment: uuid.UUID
     version: int
-    resource_version_ids: list[ResourceVersionIdStr]
+    resource_version_ids: List[ResourceVersionIdStr]
     action_id: uuid.UUID
     action: const.ResourceAction
     started: datetime.datetime
     finished: Optional[datetime.datetime]
-    messages: Optional[list[JsonType]]
+    messages: Optional[List[JsonType]]
     status: Optional[const.ResourceState]
     changes: Optional[JsonType]
     change: Optional[const.Change]
     send_event: Optional[bool] = None  # Deprecated field
 
 
 class ResourceDeploySummary(BaseModel):
     """
     :param total: The total number of resources
     :param by_state: The number of resources by state in the latest released version
     """
 
     total: int
-    by_state: dict[str, int]
+    by_state: Dict[str, int]
 
     @classmethod
-    def create_from_db_result(cls, summary_by_state: dict[str, int]) -> "ResourceDeploySummary":
+    def create_from_db_result(cls, summary_by_state: Dict[str, int]) -> "ResourceDeploySummary":
         full_summary_by_state = cls._ensure_summary_has_all_states(summary_by_state)
         total = cls._count_all_resources(full_summary_by_state)
         return ResourceDeploySummary(by_state=full_summary_by_state, total=total)
 
     @classmethod
-    def _ensure_summary_has_all_states(cls, summary_by_state: dict[str, int]) -> dict[str, int]:
+    def _ensure_summary_has_all_states(cls, summary_by_state: Dict[str, int]) -> Dict[str, int]:
         full_summary = summary_by_state.copy()
         for state in const.ResourceState:
             if state not in summary_by_state.keys() and state != const.ResourceState.dry:
                 full_summary[state] = 0
         return full_summary
 
     @classmethod
-    def _count_all_resources(cls, summary_by_state: dict[str, int]) -> int:
+    def _count_all_resources(cls, summary_by_state: Dict[str, int]) -> int:
         return sum(resource_count for resource_count in summary_by_state.values())
 
 
 class LogLine(BaseModel):
     class Config:
         """
         Pydantic config.
@@ -405,15 +392,15 @@
         # serialises using the name of the enum instead of its value. This is required
         # to make sure that data sent to the API endpoints resource_action_update
         # and resource_deploy_done are serialized consistently using the name of the enum.
         use_enum_values = False
 
     level: const.LogLevel
     msg: str
-    args: list[Optional[ArgumentTypes]] = []
+    args: List[Optional[ArgumentTypes]] = []
     kwargs: JsonType = {}
     timestamp: datetime.datetime
 
 
 class ResourceIdDetails(BaseModel):
     resource_type: ResourceType
     agent: str
@@ -434,18 +421,18 @@
 )
 
 
 class VersionedResource(BaseModel):
     resource_id: ResourceIdStr
     resource_version_id: ResourceVersionIdStr
     id_details: ResourceIdDetails
-    requires: list[ResourceVersionIdStr]
+    requires: List[ResourceVersionIdStr]
 
     @property
-    def all_fields(self) -> dict[str, Any]:
+    def all_fields(self) -> Dict[str, Any]:
         return {**self.dict(), **self.id_details.dict()}
 
 
 class LatestReleasedResource(VersionedResource):
     status: ReleasedResourceState
 
 
@@ -513,23 +500,23 @@
     :param requires_status: The id and status of the resources this resource requires
     """
 
     last_deploy: Optional[datetime.datetime]
     first_generated_time: datetime.datetime
     first_generated_version: int
     status: ReleasedResourceState
-    requires_status: dict[ResourceIdStr, ReleasedResourceState]
+    requires_status: Dict[ResourceIdStr, ReleasedResourceState]
 
 
 class ResourceHistory(BaseModel):
     resource_id: ResourceIdStr
     date: datetime.datetime
     attributes: JsonType
     attribute_hash: str
-    requires: list[ResourceIdStr]
+    requires: List[ResourceIdStr]
 
 
 class ResourceLog(LogLine):
     action_id: uuid.UUID
     action: const.ResourceAction
 
 
@@ -561,15 +548,15 @@
     """
     :param resource_id: The id of the resource the diff is about (without version)
     :param attributes: The diff between the attributes of two versions of the resource
     :param status: The kind of diff between the versions of the resource
     """
 
     resource_id: ResourceIdStr
-    attributes: dict[str, AttributeDiff]
+    attributes: Dict[str, AttributeDiff]
     status: ResourceDiffStatus
 
 
 class Parameter(BaseModel):
     id: uuid.UUID
     name: str
     value: str
@@ -608,27 +595,27 @@
 class AgentProcess(BaseModel):
     sid: uuid.UUID
     hostname: str
     environment: uuid.UUID
     first_seen: Optional[datetime.datetime]
     last_seen: Optional[datetime.datetime]
     expired: Optional[datetime.datetime]
-    state: Optional[dict[str, Union[dict[str, list[str]], dict[str, str], dict[str, float], str]]]
+    state: Optional[Dict[str, Union[Dict[str, List[str]], Dict[str, str], Dict[str, float], str]]]
 
 
 class DesiredStateLabel(BaseModel):
     name: str
     message: str
 
 
 class DesiredStateVersion(BaseModel):
     version: int
     date: datetime.datetime
     total: int
-    labels: list[DesiredStateLabel]
+    labels: List[DesiredStateLabel]
     status: const.DesiredStateVersionStatus
 
 
 class NoPushTriggerMethod(str, Enum):
     no_push = "no_push"
 
 
@@ -644,15 +631,15 @@
     date: Optional[datetime.datetime]
     total: int = 0
     todo: int = 0
 
 
 class DryRunReport(BaseModel):
     summary: DryRun
-    diff: list[ResourceDiff]
+    diff: List[ResourceDiff]
 
 
 class Notification(BaseModel):
     """
     :param id: The id of this notification
     :param environment: The environment this notification belongs to
     :param created: The date the notification was created at
@@ -679,35 +666,35 @@
 
 class Source(BaseModel):
     """Model for source code"""
 
     hash: str
     is_byte_code: bool
     module_name: str
-    requirements: list[str]
+    requirements: List[str]
 
 
 class EnvironmentMetricsResult(BaseModel):
     """
     A container for metrics as returned by the /metrics endpoint.
 
-    :param start: The starting of the aggregation interval.
-    :param end: The end of the aggregation interval.
+    :param start: The starting of the requested aggregation interval.
+    :param end: The end of the requested aggregation interval.
     :param timestamps: The timestamps that belongs to the aggregated metrics present in the `metrics` dictionary.
     :param metrics: A dictionary that maps the name of a metric to a list of aggregated datapoints. For metrics that are not
                     grouped on a specific property, this list only contains the values of the metrics. For metrics that
                     are grouped by a specific property, this list contains a dictionary where the key is the grouping
                     attribute and the value is the value of the metric. The value is None when no data is available
                     for that specific time window.
     """
 
     start: datetime.datetime
     end: datetime.datetime
-    timestamps: list[datetime.datetime]
-    metrics: dict[str, list[Optional[Union[float, dict[str, float]]]]]
+    timestamps: List[datetime.datetime]
+    metrics: Dict[str, List[Optional[Union[float, Dict[str, float]]]]]
 
 
 class AuthMethod(str, Enum):
     database = "database"
     oidc = "oidc"
```

### Comparing `inmanta-core-8.7.4/src/inmanta/data/schema.py` & `inmanta-core-9.3.0/src/inmanta/data/schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,18 +15,17 @@
 
     Contact: code@inmanta.com
 """
 
 import logging
 import pkgutil
 import re
-from collections.abc import Callable, Coroutine
 from itertools import takewhile
 from types import ModuleType
-from typing import Any, Optional
+from typing import Any, Callable, Coroutine, List, Optional, Set, Tuple
 
 from asyncpg import Connection, UndefinedColumnError, UndefinedTableError
 from asyncpg.protocol import Record
 
 # Name of core schema in the DB schema verions
 CORE_SCHEMA_NAME = "core"
 
@@ -43,33 +42,37 @@
 );
 """
 
 
 class TableNotFound(Exception):
     """Raised when a table is not found in the database"""
 
+    pass
+
 
 class ColumnNotFound(Exception):
     """Raised when a column is not found in the database"""
 
+    pass
+
 
-class Version:
+class Version(object):
     """Internal representation of a version"""
 
     def __init__(self, name: str, function: Callable[[Connection], Coroutine[Any, Any, None]]):
         self.name = name
         self.function = function
         self.version = self.parse(name)
 
     @classmethod
     def parse(cls, name: str) -> int:
         return int(name[1:])
 
 
-class DBSchema:
+class DBSchema(object):
     """
     Schema Manager, ensures the schema is up to date.
 
     Concurrent updates are safe
     """
 
     def __init__(self, name: str, package: ModuleType, connection: Connection) -> None:
@@ -146,15 +149,15 @@
                     ADD COLUMN installed_versions integer[]
                     ;
                     """
                 )
             else:
                 self.logger.info("Other process has already performed a database upgrade.")
 
-    async def _legacy_migration_row(self, all_versions: Optional[list[int]] = None) -> None:
+    async def _legacy_migration_row(self, all_versions: Optional[List[int]] = None) -> None:
         """
         Migration for this instance's row to new (2021) schema management. Backfills the installed_versions column for this
         instance based on the legacy_version column and the currently available versions. Assumes all versions lower than the
         current version have been applied at the time of migration.
 
         :param all_versions: allows overriding the available versions, for example for testing purposes.
             If not specified, available update functions' versions are used.
@@ -172,15 +175,15 @@
                 SET installed_versions=$1
                 WHERE name=$2
                 """,
                 list(takewhile(lambda x: x <= legacy_version, all_versions)),
                 self.name,
             )
 
-    async def _update_db_schema(self, update_functions: Optional[list[Version]] = None) -> None:
+    async def _update_db_schema(self, update_functions: Optional[List[Version]] = None) -> None:
         """
         Main update function
 
         Wrapped in transaction, that holds a lock on the schemamanager table.
         When a version update fails, the whole transaction is rolled back.
 
         :param update_functions: allows overriding the available update functions, for example for testing purposes.
@@ -189,15 +192,15 @@
             sorted(update_functions, key=lambda x: x.version) if update_functions is not None else self._get_update_functions()
         )
         async with self.connection.transaction():
             # get lock
             await self.connection.execute(f"LOCK TABLE {SCHEMA_VERSION_TABLE} IN ACCESS EXCLUSIVE MODE")
             # get current version again, in transaction this time
             try:
-                installed_versions: set[int] = await self.get_installed_versions()
+                installed_versions: Set[int] = await self.get_installed_versions()
             except TableNotFound:
                 self.logger.exception("Schemamanager table disappeared, should not occur.")
                 raise
             # get relevant updates
             updates = [v for v in update_functions if v.version not in installed_versions]
             for version in updates:
                 try:
@@ -229,15 +232,15 @@
             )
         except UndefinedColumnError as e:
             raise ColumnNotFound() from e
         except UndefinedTableError as e:
             raise TableNotFound() from e
         return version["legacy_version"] if version is not None else 0
 
-    async def get_installed_versions(self) -> set[int]:
+    async def get_installed_versions(self) -> Set[int]:
         """
         Returns the set of all versions that have been installed.
 
         :raises TableNotFound:
         """
         versions: Optional[Record] = None
         try:
@@ -260,18 +263,18 @@
             VALUES ($1, $2) ON CONFLICT (name) DO UPDATE
             SET installed_versions = {SCHEMA_VERSION_TABLE}.installed_versions || excluded.installed_versions
             """,
             self.name,
             {version},
         )
 
-    def _get_update_functions(self) -> list[Version]:
+    def _get_update_functions(self) -> List[Version]:
         module_names = [modname for _, modname, ispkg in pkgutil.iter_modules(self.package.__path__) if not ispkg]
 
-        def get_modules(mod_name: str) -> tuple[str, ModuleType]:
+        def get_modules(mod_name: str) -> Tuple[str, ModuleType]:
             fq_module_name = self.package.__name__ + "." + mod_name
             return mod_name, __import__(fq_module_name, fromlist=["update"])
 
         def make_version(mod_name: str, module: ModuleType) -> Version:
             update_function = module.update
             return Version(mod_name, update_function)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/__init__.py` & `inmanta-core-9.3.0/src/inmanta/db/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/util.py` & `inmanta-core-9.3.0/src/inmanta/db/util.py`

 * *Files 10% similar despite different names*

```diff
@@ -13,18 +13,17 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import collections.abc
 import logging
-import re
 from collections import abc
 from dataclasses import dataclass
-from typing import NamedTuple, Optional
+from typing import List, NamedTuple, Optional
 
 from asyncpg import Connection
 
 from inmanta.stable_api import stable_api
 
 logger = logging.getLogger(__name__)
 
@@ -49,24 +48,19 @@
         return item
 
 
 @stable_api
 class PGRestore:
     """
     Class that offers support to restore a database dump.
-
-    This class assumes that the names of schemas, tables and columns in the dump don't contain a dot, double quote or
-    whitespace character.
     """
 
-    PARSE_EXT_BUFFER_REGEX = re.compile(r"COPY (?P<fq_table_name>[^ ]+)[ ]+\((?P<columns>[^)]+)\)[ ]+FROM stdin")
-
     # asyncpg execute method can not read in COPY IN
 
-    def __init__(self, script: list[str], postgresql_client: Connection) -> None:
+    def __init__(self, script: List[str], postgresql_client: Connection) -> None:
         self.commandbuffer = ""
         self.extbuffer = ""
         self.mode = MODE_READ_COMMAND
         self.script = script
         self.client = postgresql_client
 
     async def run(self) -> None:
@@ -96,58 +90,20 @@
 
     async def execute_buffer(self) -> None:
         if not self.commandbuffer.strip():
             return
         await self.client.execute(self.commandbuffer)
         self.commandbuffer = ""
 
-    async def _parse_fq_table_name(self, fq_table_name: str) -> tuple[Optional[str], str]:
-        """
-        Parse a fully qualified PostgreSQL table name into its schema and table components.
-
-        :return: A tuple where the first element is the schema name and the second the table name.
-                 If the provided fq_table_name doesn't contain a schema, the first element in the tuple
-                 will be None.
-        """
-        if "." in fq_table_name:
-            schema, table_name = fq_table_name.split(".", maxsplit=1)
-        else:
-            schema = None
-            table_name = fq_table_name
-
-        # The schema or table name might be surrounded in quotes when the name conflicts with a keyword.
-        if schema:
-            schema = schema.strip(' "')
-        table_name = table_name.strip(' "')
-
-        return schema, table_name
-
-    async def _parse_copy_command_in_ext_buffer(self) -> tuple[Optional[str], str, list[str]]:
-        assert self.extbuffer
-        match = self.PARSE_EXT_BUFFER_REGEX.match(self.extbuffer)
-        if match is None:
-            raise Exception(f"Invalid COPY command: {self.extbuffer}")
-        schema, table_name = await self._parse_fq_table_name(match.group("fq_table_name"))
-        # A column name might be surrounded in quotes when the name conflicts with a keyword.
-        columns = [elem.strip(' "') for elem in match.group("columns").split(",")]
-        return schema, table_name, columns
-
     async def execute_input(self) -> None:
-        schema_name, table_name, column_names = await self._parse_copy_command_in_ext_buffer()
-        await self.client.copy_to_table(
-            schema_name=schema_name,
-            table_name=table_name,
-            source=AsyncSingleton(self.commandbuffer.encode()),
-            columns=column_names,
-            timeout=10,
-        )
+        await self.client._copy_in(self.extbuffer, AsyncSingleton(self.commandbuffer.encode()), 10)
         self.commandbuffer = ""
 
 
-async def postgres_get_custom_types(postgresql_client: Connection) -> list[str]:
+async def postgres_get_custom_types(postgresql_client: Connection) -> List[str]:
     """
     Returns all custom types defined in the database.
     """
     # Query extracted from CLI
     # psql -E
     # \dT
 
@@ -162,15 +118,15 @@
            AND n.nspname <> 'pg_catalog'
           AND n.nspname <> 'information_schema'
       AND pg_catalog.pg_type_is_visible(t.oid)
     ORDER BY 1, 2;
     """
 
     types_in_db = await postgresql_client.fetch(get_custom_types)
-    type_names: list[str] = [str(x["Name"]) for x in types_in_db]
+    type_names: List[str] = [str(x["Name"]) for x in types_in_db]
 
     return type_names
 
 
 @stable_api
 async def clear_database(postgresql_client: Connection) -> None:
     """
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/__init__.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v1.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v1.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v17.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v17.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v2.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v2.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202105170.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202105170.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,23 +13,24 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import json
 from datetime import datetime
+from typing import Dict, List
 
 from asyncpg import Connection, Record
 
 from inmanta import const
 
 DISABLED = False
 
 
-TIMESTAMP_COLUMNS: dict[str, list[str]] = {
+TIMESTAMP_COLUMNS: Dict[str, List[str]] = {
     "agent": ["last_failover"],
     "agentinstance": ["expired"],
     "agentprocess": ["first_seen", "last_seen", "expired"],
     "compile": ["started", "completed", "requested"],
     "configurationmodel": ["date"],
     "dryrun": ["date"],
     "parameter": ["updated"],
@@ -47,22 +48,22 @@
             % ", ".join(f"ALTER COLUMN {column} TYPE TIMESTAMP WITH TIME ZONE" for column in columns)
             for table, columns in TIMESTAMP_COLUMNS.items()
         )
     )
 
     # update timestamps embedded in jsonb types
     def transform_message(message: str) -> str:
-        obj: dict = json.loads(message)
+        obj: Dict = json.loads(message)
         if "timestamp" in obj:
             obj["timestamp"] = (
                 datetime.strptime(obj["timestamp"], const.TIME_ISOFMT).astimezone().isoformat(timespec="microseconds")
             )
         return json.dumps(obj)
 
-    records: list[Record] = await connection.fetch("SELECT action_id, messages FROM public.resourceaction")
+    records: List[Record] = await connection.fetch("SELECT action_id, messages FROM public.resourceaction")
     await connection.executemany(
         """
         UPDATE public.resourceaction
         SET messages = $1
         WHERE action_id = $2
         """,
         [
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202106080.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202106080.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202106210.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202106210.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202109100.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202109100.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202111260.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202111260.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202203140.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202203140.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202203160.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202203160.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202205250.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202205250.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202206290.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202206290.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202208180.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202208180.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202208190.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202208190.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202209090.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202209090.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202209130.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202209130.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202209160.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301170.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2022 Inmanta
+    Copyright 2023 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -16,12 +16,9 @@
     Contact: code@inmanta.com
 """
 
 from asyncpg import Connection
 
 
 async def update(connection: Connection) -> None:
-    schema = """
-    ALTER TABLE public.compile
-        ADD COLUMN exporter_plugin varchar DEFAULT NULL;
-    """
-    await connection.execute(schema)
+    # Add index to avoid a sequential scan in CompileTimeMetricsCollector.get_metric_value query
+    await connection.execute("CREATE INDEX ON public.compile (completed, environment)")
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202211230.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202211230.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202212010.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202212010.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301100.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301100.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301110.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301110.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301120.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301120.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301160.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301160.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301170.py` & `inmanta-core-9.3.0/tests/test_param.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2023 Inmanta
+    Copyright 2017 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -11,14 +11,23 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
+import logging
+import uuid
 
-from asyncpg import Connection
+LOGGER = logging.getLogger(__name__)
 
 
-async def update(connection: Connection) -> None:
-    # Add index to avoid a sequential scan in CompileTimeMetricsCollector.get_metric_value query
-    await connection.execute("CREATE INDEX ON public.compile (completed, environment)")
+async def test_param(client, environment):
+    """
+    Test creating and updating forms
+    """
+    fake_uuid = uuid.uuid4()
+    result = await client.list_params(tid=fake_uuid)
+    assert result.code == 404
+
+    result = await client.list_params(tid=environment)
+    assert result.code == 200
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202301190.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202301190.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202302200.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202302200.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202302270.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202302270.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202303070.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202303070.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202303071.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202303071.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202304070.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202304070.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202306060.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202306060.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202308020.py` & `inmanta-core-9.3.0/src/inmanta/stable_api.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,25 +1,28 @@
 """
-    Copyright 2023 Inmanta
+    Copyright 2021 Inmanta
+
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
+
         http://www.apache.org/licenses/LICENSE-2.0
+
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
+
     Contact: code@inmanta.com
 """
+from typing import Callable, Type, TypeVar
 
-from asyncpg import Connection
+T = TypeVar("T", Callable, Type)
 
 
-async def update(connection: Connection) -> None:
-    schema = """
-    -- change the type of the 'discovered_at' column
-    ALTER TABLE public.discoveredresource
-    ALTER COLUMN discovered_at TYPE TIMESTAMP WITH TIME ZONE,
-    ALTER COLUMN discovered_at SET NOT NULL;
+def stable_api(elem: T) -> T:
+    """
+    A decorator used to annotate the classes and functions which are part
+    of the stable API.
     """
-    await connection.execute(schema)
+    return elem
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202309130.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v202304060.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,23 +1,28 @@
 """
     Copyright 2023 Inmanta
+
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
+
         http://www.apache.org/licenses/LICENSE-2.0
+
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
+
     Contact: code@inmanta.com
 """
 from asyncpg import Connection
 
+from inmanta.data import Environment
+
 
 async def update(connection: Connection) -> None:
-    schema = """
-    -- Add the 'last_produced_events' column
-    ALTER TABLE public.resource
-      ADD COLUMN last_produced_events TIMESTAMP WITH TIME ZONE;
     """
-    await connection.execute(schema)
+    Ensure that the purge_on_delete setting is removed from each environment.
+    """
+    # Add index on resource table
+    await connection.execute(f"UPDATE {Environment.table_name()} SET settings=settings - $1", "purge_on_delete")
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202310040.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v5.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2023 Inmanta
+    Copyright 2020 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -13,18 +13,28 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 from asyncpg import Connection
 
+DISABLED = False
+
 
 async def update(connection: Connection) -> None:
-    """
-    Add the indexes required to perform a manual cascading delete of a configurationmodel.
-    """
-    schema = """
-    CREATE INDEX compile_environment_version_index ON public.compile (environment, version);
-    CREATE INDEX resourceaction_resource_environment_resource_version_index
-        ON public.resourceaction_resource (environment, resource_version);
-    """
-    await connection.execute(schema)
+    await connection.execute(
+        """
+-- Compile queue might be collapsed if it contains similar compile requests.
+-- In that case, substitute_compile_id will reference the actually compiled request.
+ALTER TABLE public.compile ADD COLUMN substitute_compile_id uuid REFERENCES public.compile (id);
+
+
+-- Compile data json exported by compiling with the --export-compile-data parameter.
+ALTER TABLE public.compile ADD COLUMN compile_data jsonb;
+
+
+-- Add halted column to environment table to support halting all orchestrator operations.
+ALTER TABLE public.environment ADD COLUMN halted boolean NOT NULL DEFAULT false;
+-- Add unpause_on_resume column to agent table to persist paused state when halting the environment.
+ALTER TABLE public.agent ADD COLUMN unpause_on_resume boolean;
+        """
+    )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202310180.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v6.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2023 Inmanta
+    Copyright 2020 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -11,16 +11,23 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-
-
 from asyncpg import Connection
 
+DISABLED = False
+
 
 async def update(connection: Connection) -> None:
-    # Add an index to speed up counting the different types of resources per version.
-    # e.g. in inmanta-license get_license_metrics.
-    await connection.execute("CREATE INDEX ON public.resource (environment, model, resource_type)")
+    await connection.execute(
+        """
+ALTER TABLE public.compile DROP CONSTRAINT compile_substitute_compile_id_fkey;
+ALTER TABLE public.compile
+    ADD CONSTRAINT compile_substitute_compile_id_fkey
+    FOREIGN KEY (substitute_compile_id) REFERENCES public.compile (id)
+    ON DELETE CASCADE;
+
+        """
+    )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v202403120.py` & `inmanta-core-9.3.0/src/inmanta/server/compilerservice.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2024 Inmanta
+    Copyright 2019 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -12,19 +12,8 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from asyncpg import Connection
-
-
-async def update(connection: Connection) -> None:
-    schema = """
-    -- Add the 'soft_delete' column to support marking a resource set for deletion
-    -- and deleting it iff the model doesn't export resources for it.
-
-    ALTER TABLE public.compile
-    ADD COLUMN soft_delete boolean DEFAULT false NOT NULL;
-    """
-    await connection.execute(schema)
+from .services.compilerservice import *  # noqa: F401, F403
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v3.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v3.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v4.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v4.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v5.py` & `inmanta-core-9.3.0/src/inmanta/db/versions/v7.py`

 * *Files 27% similar despite different names*

```diff
@@ -19,22 +19,28 @@
 
 DISABLED = False
 
 
 async def update(connection: Connection) -> None:
     await connection.execute(
         """
--- Compile queue might be collapsed if it contains similar compile requests.
--- In that case, substitute_compile_id will reference the actually compiled request.
-ALTER TABLE public.compile ADD COLUMN substitute_compile_id uuid REFERENCES public.compile (id);
-
-
--- Compile data json exported by compiling with the --export-compile-data parameter.
-ALTER TABLE public.compile ADD COLUMN compile_data jsonb;
-
-
--- Add halted column to environment table to support halting all orchestrator operations.
-ALTER TABLE public.environment ADD COLUMN halted boolean NOT NULL DEFAULT false;
--- Add unpause_on_resume column to agent table to persist paused state when halting the environment.
-ALTER TABLE public.agent ADD COLUMN unpause_on_resume boolean;
+        CREATE INDEX resourceaction_environment_version_started_index ON resourceaction(environment,version,started DESC);
         """
     )
+    await enforce_unique_agent_instances(connection)
+
+
+async def enforce_unique_agent_instances(connection: Connection) -> None:
+    """
+    Deletes duplicate AgentInstance records and adds a uniqueness constraint.
+    """
+    async with connection.transaction():
+        await connection.execute(
+            """
+            DELETE FROM public.agentinstance a
+            USING public.agentinstance b
+            WHERE a.id < b.id AND a.tid = b.tid AND a.process = b.process AND a.name = b.name
+            ;
+
+            ALTER TABLE public.agentinstance ADD CONSTRAINT agentinstance_unique UNIQUE (tid, process, name);
+            """
+        )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/db/versions/v6.py` & `inmanta-core-9.3.0/src/inmanta/profile_mem.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2020 Inmanta
+    Copyright 2019 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -11,23 +11,13 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from asyncpg import Connection
+import gc
+import sys
 
-DISABLED = False
 
-
-async def update(connection: Connection) -> None:
-    await connection.execute(
-        """
-ALTER TABLE public.compile DROP CONSTRAINT compile_substitute_compile_id_fkey;
-ALTER TABLE public.compile
-    ADD CONSTRAINT compile_substitute_compile_id_fkey
-    FOREIGN KEY (substitute_compile_id) REFERENCES public.compile (id)
-    ON DELETE CASCADE;
-
-        """
-    )
+def total_size() -> int:
+    return sum(sys.getsizeof(x) for x in gc.get_objects())
```

### Comparing `inmanta-core-8.7.4/src/inmanta/deploy.py` & `inmanta-core-9.3.0/src/inmanta/deploy.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,19 +18,18 @@
 import argparse
 import logging
 import os
 import socket
 import subprocess
 import sys
 import time
-from typing import Optional
+from typing import Dict, List, Optional, Set, Tuple
 
 from inmanta import config, const, module, postgresproc, protocol
 from inmanta.config import Config
-from inmanta.protocol import Result
 from inmanta.types import JsonType
 from inmanta.util import get_free_tcp_port
 
 LOGGER = logging.getLogger(__name__)
 MAX_TRIES = 25
 
 
@@ -40,15 +39,15 @@
 
 class FinishedException(Exception):
     """
     This exception is raised when the deploy is ready
     """
 
 
-class Deploy:
+class Deploy(object):
     _data_path: str
     _project_path: str
     _server_proc: subprocess.Popen
     _postgresproc: postgresproc.PostgresProc
     _client: protocol.SyncClient
     _environment_id: str
 
@@ -158,15 +157,15 @@
 
         while self._server_proc.poll() is None:
             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
             try:
                 try:
                     s.connect(("localhost", int(self._server_port)))
                     return True
-                except OSError:
+                except (IOError, socket.error):
                     time.sleep(0.25)
             finally:
                 s.close()
 
         return False
 
     def setup_postgresql(self) -> bool:
@@ -205,24 +204,24 @@
         self._check_result(self._client.set_setting(env_id, "autostart_agent_deploy_splay_time", 0))
         self._check_result(self._client.set_setting(env_id, "autostart_agent_deploy_interval", 0))
         self._check_result(self._client.set_setting(env_id, "autostart_agent_repair_splay_time", 0))
         self._check_result(self._client.set_setting(env_id, "autostart_agent_repair_interval", 600))
 
         return env_id
 
-    def _latest_version_instance(self, environment_id: str) -> Optional[JsonType]:
-        result: Result = self._client.list_versions(tid=environment_id)
+    def _latest_version(self, environment_id: str) -> Optional[int]:
+        result = self._client.list_versions(tid=environment_id)
         if result.code != 200:
             LOGGER.error("Unable to get all version of environment %s", environment_id)
             return None
 
-        if result.result and "versions" in result.result and len(result.result["versions"]) > 0:
-            version = result.result["versions"][0]
-            assert isinstance(version, dict)  # mypy
-            return version
+        if "versions" in result.result and len(result.result["versions"]) > 0:
+            versions: List[int] = [x["version"] for x in result.result["versions"]]
+            sorted(versions)
+            return versions[0]
 
         return None
 
     def setup_project(self) -> bool:
         """
         Set up the configured project and environment on the embedded server
         """
@@ -314,15 +313,15 @@
 
         if not self.setup_project():
             LOGGER.error("Failed to setup project")
             return False
 
         return True
 
-    def export(self, main_file: str) -> bool:
+    def export(self) -> bool:
         """
         Export a version to the embedded server
         """
         inmanta_path = [sys.executable, "-m", "inmanta.app"]
 
         cmd = inmanta_path + [
             "--config-dir",
@@ -331,16 +330,14 @@
             "export",
             "-e",
             str(self._environment_id),
             "--server_address",
             "localhost",
             "--server_port",
             str(self._server_port),
-            "-f",
-            main_file,
         ]
 
         sub_process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
 
         log_out, log_err = sub_process.communicate()
 
         if sub_process.returncode > 0:
@@ -352,50 +349,39 @@
 
             return False
 
         LOGGER.info("Export of model complete")
         return True
 
     def deploy(self, dry_run: bool, report: bool = True) -> None:
-        version_instance = self._latest_version_instance(self._environment_id)
-
-        if version_instance is None:
-            return
-
-        version: int = version_instance["version"]
+        version = self._latest_version(self._environment_id)
         LOGGER.info("Latest version for created environment is %s", version)
+        if version is None:
+            return
 
         # release the version!
         if not dry_run:
-            if not version_instance["released"]:
-                self._check_result(
-                    self._client.release_version(
-                        tid=self._environment_id,
-                        id=version,
-                        push=True,
-                        agent_trigger_method=const.AgentTriggerMethod.push_full_deploy,
-                    )
-                )
-            else:
-                self._check_result(
-                    self._client.deploy(
-                        tid=self._environment_id,
-                        agent_trigger_method=const.AgentTriggerMethod.push_full_deploy,
-                    )
+            self._check_result(
+                self._client.release_version(
+                    tid=self._environment_id,
+                    id=version,
+                    push=True,
+                    agent_trigger_method=const.AgentTriggerMethod.push_full_deploy,
                 )
+            )
             if report:
                 self.progress_deploy_report(version)
 
         else:
             result = self._check_result(self._client.dryrun_request(tid=self._environment_id, id=version))
             dryrun_id = result.result["dryrun"]["id"]
             if report:
                 self.progress_dryrun_report(dryrun_id)
 
-    def _get_deploy_stats(self, version: int) -> tuple[int, int, dict[str, str]]:
+    def _get_deploy_stats(self, version: int) -> Tuple[int, int, Dict[str, str]]:
         version_result = self._client.get_version(tid=self._environment_id, id=version)
         if version_result.code != 200:
             LOGGER.error("Unable to get version %d of environment %s", version, self._environment_id)
             return (0, 0, {})
 
         total = 0
         deployed = 0
@@ -407,15 +393,15 @@
                 deployed += 1
                 ready[res["id"]] = res["status"]
 
         return total, deployed, ready
 
     def progress_deploy_report(self, version: int) -> None:
         print("Starting deploy")
-        current_ready: set[str] = set()
+        current_ready: Set[str] = set()
         total = 0
         deployed = -1
         while total > deployed:
             total, deployed, ready = self._get_deploy_stats(version)
 
             ready_keys = set(ready.keys())
             new = ready_keys - current_ready
@@ -423,49 +409,49 @@
 
             # if we already printed progress, move cursor one line up
             if deployed >= 0:
                 sys.stdout.write("\033[1A")
                 sys.stdout.flush()
 
             for res in new:
-                print(f"{res} - {ready[res]}")
+                print("%s - %s" % (res, ready[res]))
 
             print("[%d / %d]" % (deployed, total))
             time.sleep(1)
 
         print("Deploy ready")
 
-    def _get_dryrun_status(self, dryrun_id: str) -> tuple[int, int, JsonType]:
+    def _get_dryrun_status(self, dryrun_id: str) -> Tuple[int, int, JsonType]:
         result = self._client.dryrun_report(self._environment_id, dryrun_id)
 
         if result.code != 200:
             raise Exception("Unable to get dryrun report")
 
         data = result.result["dryrun"]
         return data["total"], data["todo"], data["resources"]
 
     def progress_dryrun_report(self, dryrun_id: str) -> None:
         print("Starting dryrun")
 
-        current_ready: set[str] = set()
+        current_ready: Set[str] = set()
         todo = 1
         while todo > 0:
             # if we already printed progress, move cursor one line up
             if len(current_ready) > 0:
                 sys.stdout.write("\033[1A")
                 sys.stdout.flush()
 
             total, todo, ready = self._get_dryrun_status(dryrun_id)
 
-            ready_keys: set[str] = set(ready.keys())
+            ready_keys: Set[str] = set(ready.keys())
             new = ready_keys - current_ready
             current_ready = ready_keys
 
             for res in new:
-                changes: dict[str, tuple[str, str]] = ready[res]["changes"]
+                changes: Dict[str, Tuple[str, str]] = ready[res]["changes"]
                 if len(changes) == 0:
                     print("%s - no changes" % res)
                 else:
                     print("%s:" % res)
                     for field, values in changes.items():
                         if field == "hash":
                             diff_result = self._client.diff(a=values[0], b=values[1])
@@ -482,26 +468,22 @@
 
             print("[%d / %d]" % (total - todo, total))
             time.sleep(1)
 
         raise FinishedException()
 
     def run(self) -> None:
-        self.export(main_file=self._options.main_file)
+        self.export()
         self.deploy(dry_run=self._options.dryrun)
 
     def stop(self) -> None:
         loud_logger = logging.getLogger("inmanta.protocol")
         loud_logger.propagate = True
 
         loud_logger = logging.getLogger("tornado")
         loud_logger.propagate = True
 
         if hasattr(self, "_server_proc"):
             self._server_proc.terminate()
 
         if hasattr(self, "_postgresproc"):
             self._postgresproc.stop()
-
-        # ensure children are down
-        if hasattr(self, "_server_proc"):
-            self._server_proc.wait(20)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/docstring_parser.py` & `inmanta-core-9.3.0/src/inmanta/docstring_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import logging
-from typing import Optional
+from typing import Dict, Optional
 
 import docstring_parser
 
 LOGGER = logging.getLogger(__name__)
 
 
 class DocString:
@@ -33,15 +33,15 @@
             # colons splitted on white spaces. This check enforces the format :attr <attribute-name>:
             if len(attr.args) != 2 or attr.args[0] != "attr":
                 LOGGER.warning("Failed to parse attribute: ':%s: %s'", " ".join(attr.args), attr.description)
             else:
                 new_meta.append(attr)
         doc_string.meta = new_meta
 
-        self._attr_description_map: dict[str, str] = {attr.args[1]: attr.description for attr in doc_string.meta}
+        self._attr_description_map: Dict[str, str] = {attr.args[1]: attr.description for attr in doc_string.meta}
         self._doc_string: docstring_parser.Docstring = doc_string
 
     def get_description(self) -> Optional[str]:
         """
         Return the general description in the docstring.
         """
         if self._doc_string.short_description is None:
@@ -53,15 +53,15 @@
 
     def get_description_for_attribute(self, attr_name: str) -> Optional[str]:
         """
         Return the description for a certain attribute.
         """
         return self._attr_description_map.get(attr_name, None)
 
-    def get_attribute_description_map(self) -> dict[str, str]:
+    def get_attribute_description_map(self) -> Dict[str, str]:
         """
         Return the dict which maps the attribute name to its description.
         """
         return dict(self._attr_description_map)
 
 
 def parse_docstring(doc_string: str) -> DocString:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/env.py` & `inmanta-core-9.3.0/src/inmanta/env.py`

 * *Files 3% similar despite different names*

```diff
@@ -24,34 +24,31 @@
 import re
 import site
 import subprocess
 import sys
 import tempfile
 import venv
 from collections import abc
-from collections.abc import Iterator, Mapping, Sequence
 from dataclasses import dataclass
 from functools import reduce
 from importlib.abc import Loader
 from importlib.machinery import ModuleSpec
 from itertools import chain
-from re import Pattern
 from subprocess import CalledProcessError
 from textwrap import indent
-from typing import Any, NamedTuple, Optional, TypeVar
+from typing import Any, Dict, Iterator, List, Mapping, NamedTuple, Optional, Pattern, Sequence, Set, Tuple, TypeVar
 
 import pkg_resources
 from pkg_resources import DistInfoDistribution, Distribution, Requirement
 
 import inmanta.module
 from inmanta import const
 from inmanta.ast import CompilerException
 from inmanta.server.bootloader import InmantaBootloader
 from inmanta.stable_api import stable_api
-from inmanta.util import strtobool
 from packaging import version
 
 try:
     from typing import TYPE_CHECKING
 except ImportError:
     TYPE_CHECKING = False
 
@@ -107,15 +104,15 @@
 
     Can be used in two ways:
     - if we don't know the exact conflicts (detected by e.g. pip), the messages is used
     - if we have detailed conflict info, the message is derived from it
 
     """
 
-    def __init__(self, message: str, conflicts: Optional[set[VersionConflict]] = None):
+    def __init__(self, message: str, conflicts: Optional[Set[VersionConflict]] = None):
         CompilerException.__init__(self, msg=message)
         self.conflicts = conflicts
 
     def get_message(self) -> str:
         # The message has three potential parts
         # First the advices, derived from the conflicts, if present
         # Then the message, if present
@@ -184,15 +181,15 @@
     @classmethod
     def are_installed(cls, requirements: req_list) -> bool:
         """
         Return True iff the given requirements are installed in this workingset.
         """
         if not requirements:
             return True
-        installed_packages: dict[str, version.Version] = cls.get_packages_in_working_set()
+        installed_packages: Dict[str, version.Version] = cls.get_packages_in_working_set()
 
         def _are_installed_recursive(
             reqs: Sequence[Requirement],
             seen_requirements: Sequence[Requirement],
             contained_in_extra: Optional[str] = None,
         ) -> bool:
             """
@@ -219,30 +216,30 @@
                 if r.key not in installed_packages or str(installed_packages[r.key]) not in r:
                     return False
                 if r.extras:
                     for extra in r.extras:
                         distribution: Optional[Distribution] = pkg_resources.working_set.find(r)
                         if distribution is None:
                             return False
-                        pkgs_required_by_extra: set[Requirement] = set(distribution.requires(extras=(extra,))) - set(
+                        pkgs_required_by_extra: Set[Requirement] = set(distribution.requires(extras=(extra,))) - set(
                             distribution.requires(extras=())
                         )
                         if not _are_installed_recursive(
                             reqs=list(pkgs_required_by_extra),
                             seen_requirements=list(seen_requirements) + list(reqs),
                             contained_in_extra=extra,
                         ):
                             return False
             return True
 
         reqs_as_requirements: Sequence[Requirement] = cls._get_as_requirements_type(requirements)
         return _are_installed_recursive(reqs_as_requirements, seen_requirements=[])
 
     @classmethod
-    def get_packages_in_working_set(cls, inmanta_modules_only: bool = False) -> dict[str, version.Version]:
+    def get_packages_in_working_set(cls, inmanta_modules_only: bool = False) -> Dict[str, version.Version]:
         """
         Return all packages present in `pkg_resources.working_set` together with the version of the package.
 
         :param inmanta_modules_only: Only return inmanta modules from the working set
         """
         return {
             dist_info.key: version.Version(dist_info.version)
@@ -322,51 +319,66 @@
     Class used to compose pip commands.
     """
 
     @classmethod
     def compose_install_command(
         cls,
         python_path: str,
-        requirements: Optional[list[Requirement]] = None,
-        paths: Optional[list[LocalPackagePath]] = None,
-        index_urls: Optional[list[str]] = None,
+        requirements: Optional[List[Requirement]] = None,
+        paths: Optional[List[LocalPackagePath]] = None,
+        index_urls: Optional[List[str]] = None,
         upgrade: bool = False,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
         allow_pre_releases: bool = False,
-        constraints_files: Optional[list[str]] = None,
-        requirements_files: Optional[list[str]] = None,
-    ) -> list[str]:
+        constraints_files: Optional[List[str]] = None,
+        requirements_files: Optional[List[str]] = None,
+        use_pip_config: bool = False,
+    ) -> List[str]:
         """
         Generate `pip install` command from the given arguments.
 
         :param python_path: The python interpreter to use in the command
         :param requirements: The requirements that should be installed
         :param paths: Paths to python projects on disk that should be installed in the venv.
         :param index_urls: The Python package repositories to use. When set to None, the system default will be used.
         :param upgrade: Upgrade the specified packages to the latest version.
         :param upgrade_strategy: The upgrade strategy to use for requirements' dependencies.
         :param allow_pre_releases: Allow the installation of packages with pre-releases and development versions.
         :param constraints_files: Files that should be passed to pip using the `-c` option.
         :param requirements_files: Files that should be passed to pip using the `-r` option.
+        :param use_pip_config: Whether the pip config file specified in the PIP_CONFIG_FILE env var should be used
         """
         requirements = requirements if requirements is not None else []
         paths = paths if paths is not None else []
         local_paths: Iterator[LocalPackagePath] = (
             # make sure we only try to install from a local source: add leading `./` and trailing `/` to explicitly tell pip
             # we're pointing to a local directory.
             LocalPackagePath(path=os.path.join(".", path.path, ""), editable=path.editable)
             for path in paths
         )
-        index_args: list[str] = (
-            []
-            if index_urls is None
-            else ["--index-url", index_urls[0], *chain.from_iterable(["--extra-index-url", url] for url in index_urls[1:])]
-            if index_urls
-            else ["--no-index"]
-        )
+        index_args: list[str] = []
+
+        if use_pip_config:
+            if index_urls:
+                # Use only --extra-index-url arguments
+                for url in index_urls:
+                    index_args.append("--extra-index-url")
+                    index_args.append(url)
+        elif index_urls is None:
+            pass
+        elif index_urls:
+            # Use separate --index-url and --extra-index-url arguments
+            index_args.append("--index-url")
+            index_args.append(index_urls[0])
+            for url in index_urls[1:]:
+                index_args.append("--extra-index-url")
+                index_args.append(url)
+        else:
+            index_args = ["--no-index"]
+
         constraints_files = constraints_files if constraints_files is not None else []
         requirements_files = requirements_files if requirements_files is not None else []
         return [
             python_path,
             "-m",
             "pip",
             "install",
@@ -376,27 +388,27 @@
             *chain.from_iterable(["-r", f] for f in requirements_files),
             *(str(requirement) for requirement in requirements),
             *chain.from_iterable(["-e", path.path] if path.editable else [path.path] for path in local_paths),
             *index_args,
         ]
 
     @classmethod
-    def compose_uninstall_command(cls, python_path: str, pkg_names: Sequence[str]) -> list[str]:
+    def compose_uninstall_command(cls, python_path: str, pkg_names: Sequence[str]) -> List[str]:
         """
         Return the pip command to uninstall the given python packages.
 
         :param python_path: The python interpreter to use in the command.
         :param pkg_names: The names of the python packages that should be uninstalled.
         """
         return [python_path, "-m", "pip", "uninstall", "-y", *pkg_names]
 
     @classmethod
     def compose_list_command(
         cls, python_path: str, format: Optional[PipListFormat] = None, only_editable: bool = False
-    ) -> list[str]:
+    ) -> List[str]:
         """
         Generate a `pip list` command for the given arguments.
 
         :param python_path: The python interpreter to use in the command.
         :param format: The output format to use.
         :param only_editable: Whether the output should only contain project installed in editable mode.
         """
@@ -463,49 +475,48 @@
                 env_path, "lib", "python%s" % ".".join(str(digit) for digit in sys.version_info[:2]), "site-packages"
             )
         )
 
     def _run_pip_install_command(
         self,
         python_path: str,
-        requirements: Optional[list[Requirement]] = None,
-        paths: Optional[list[LocalPackagePath]] = None,
-        index_urls: Optional[list[str]] = None,
+        requirements: Optional[List[Requirement]] = None,
+        paths: Optional[List[LocalPackagePath]] = None,
+        index_urls: Optional[List[str]] = None,
         upgrade: bool = False,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
         allow_pre_releases: bool = False,
-        constraints_files: Optional[list[str]] = None,
-        requirements_files: Optional[list[str]] = None,
+        constraints_files: Optional[List[str]] = None,
+        requirements_files: Optional[List[str]] = None,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
-        cmd: list[str] = PipCommandBuilder.compose_install_command(
+        cmd: List[str] = PipCommandBuilder.compose_install_command(
             python_path=python_path,
             requirements=requirements,
             paths=paths,
             index_urls=index_urls,
             upgrade=upgrade,
             upgrade_strategy=upgrade_strategy,
             allow_pre_releases=allow_pre_releases,
             constraints_files=constraints_files,
             requirements_files=requirements_files,
+            use_pip_config=use_pip_config,
         )
-
         sub_env = os.environ.copy()
 
         # if index_urls are set, only use those. Otherwise, use the one from the environment
-        if index_urls is not None:
+        if index_urls is not None and not use_pip_config:
             # setting this env_var to os.devnull disables the loading of all pip configuration files
             sub_env["PIP_CONFIG_FILE"] = os.devnull
         if index_urls is not None and "PIP_EXTRA_INDEX_URL" in sub_env:
             del sub_env["PIP_EXTRA_INDEX_URL"]
         if index_urls is not None and "PIP_INDEX_URL" in sub_env:
             del sub_env["PIP_INDEX_URL"]
-        if index_urls is not None and "PIP_NO_INDEX" in sub_env:
-            del sub_env["PIP_NO_INDEX"]
 
-        def create_log_content_files(title: str, files: list[str]) -> list[str]:
+        def create_log_content_files(title: str, files: List[str]) -> List[str]:
             """
             Log the content of a list of files with indentations in the following format:
 
             Content of [title]:
                 [files[0]]:
                     line 1 in files[0]
                 [files[1]]:
@@ -514,123 +525,118 @@
                     line 3 in files[1]
                     ...
                 [files[2]]:
                 ...
 
             this function will skip empty lines in files
             """
-            log_msg: list[str] = [f"Content of {title}:\n"]
+            log_msg: List[str] = [f"Content of {title}:\n"]
             indentation: str = "    "
             for file in files:
                 log_msg.append(indent(file + ":\n", indentation))
                 with open(file) as f:
                     for line in f:
                         if line.strip():
                             log_msg.append(indent(line.strip() + "\n", 2 * indentation))
             return log_msg
 
-        log_msg: list[str] = []
+        log_msg: List[str] = []
         if requirements_files:
             log_msg.extend(create_log_content_files("requirements files", requirements_files))
         if constraints_files:
             log_msg.extend(create_log_content_files("constraints files", constraints_files))
         log_msg.append("Pip command: " + " ".join(cmd))
         LOGGER_PIP.debug("".join(log_msg).strip())
         return_code, full_output = CommandRunner(LOGGER_PIP).run_command_and_stream_output(cmd, env_vars=sub_env)
 
         if return_code != 0:
-            not_found: list[str] = []
-            conflicts: list[str] = []
-            indexes: str = ""
+            not_found: List[str] = []
+            conflicts: List[str] = []
             for line in full_output:
                 m = re.search(r"No matching distribution found for ([\S]+)", line)
                 if m:
                     # Add missing package name to not_found list
                     not_found.append(m.group(1))
 
                 if "versions have conflicting dependencies" in line:
                     conflicts.append(line)
-                # Get the indexes line from full_output
-                # This is not printed when not using any index or when only using PyPi
-                if "Looking in indexes:" in line:
-                    indexes = line
             if not_found:
-                no_index: bool = "--no-index" in cmd or strtobool(sub_env.get("PIP_NO_INDEX", "false"))
-                if no_index:
-                    msg = "Packages %s were not found. No indexes were used." % ", ".join(not_found)
-                elif indexes:
-                    msg = "Packages %s were not found in the given indexes. (%s)" % (", ".join(not_found), indexes)
-                else:
-                    msg = "Packages %s were not found at PyPI." % (", ".join(not_found))
-                raise PackageNotFound(msg)
+                raise PackageNotFound("Packages %s were not found in the given indexes." % ", ".join(not_found))
             if conflicts:
                 raise ConflictingRequirements("\n".join(conflicts))
             raise PipInstallError(
                 f"Process {cmd} exited with return code {return_code}. "
                 "Increase the verbosity level with the -v option for more information."
             )
 
     @classmethod
     def get_env_path_for_python_path(cls, python_path: str) -> str:
         """
         For a given path to a python binary, return the path to the venv directory.
         """
         return os.path.dirname(os.path.dirname(python_path))
 
-    def get_installed_packages(self, only_editable: bool = False) -> dict[str, version.Version]:
+    def get_installed_packages(self, only_editable: bool = False) -> Dict[str, version.Version]:
         """
         Return a list of all installed packages in the site-packages of a python interpreter.
 
         :param only_editable: List only packages installed in editable mode.
         :return: A dict with package names as keys and versions as values
         """
         cmd = PipCommandBuilder.compose_list_command(self.python_path, format=PipListFormat.json, only_editable=only_editable)
         output = CommandRunner(LOGGER_PIP).run_command_and_log_output(cmd, stderr=subprocess.DEVNULL, env=os.environ.copy())
         return {r["name"]: version.Version(r["version"]) for r in json.loads(output)}
 
     def install_from_index(
         self,
-        requirements: list[Requirement],
-        index_urls: Optional[list[str]] = None,
+        requirements: List[Requirement],
+        index_urls: Optional[List[str]] = None,
         upgrade: bool = False,
         allow_pre_releases: bool = False,
-        constraint_files: Optional[list[str]] = None,
+        constraint_files: Optional[List[str]] = None,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         if len(requirements) == 0:
             raise Exception("install_from_index requires at least one requirement to install")
         constraint_files = constraint_files if constraint_files is not None else []
         inmanta_requirements = self._get_requirements_on_inmanta_package()
         self._run_pip_install_command(
             python_path=self.python_path,
             requirements=[*requirements, *inmanta_requirements],
             index_urls=index_urls,
             upgrade=upgrade,
             allow_pre_releases=allow_pre_releases,
             constraints_files=[*constraint_files],
             upgrade_strategy=upgrade_strategy,
+            use_pip_config=use_pip_config,
         )
 
-    def install_from_source(self, paths: list[LocalPackagePath], constraint_files: Optional[list[str]] = None) -> None:
+    def install_from_source(
+        self,
+        paths: List[LocalPackagePath],
+        constraint_files: Optional[List[str]] = None,
+    ) -> None:
         """
         Install one or more packages from source. Any path arguments should be local paths to a package directory or wheel.
         """
         if len(paths) == 0:
             raise Exception("install_from_source requires at least one package to install")
         constraint_files = constraint_files if constraint_files is not None else []
         inmanta_requirements = self._get_requirements_on_inmanta_package()
         self._run_pip_install_command(
             python_path=self.python_path,
             paths=paths,
             constraints_files=constraint_files,
             requirements=inmanta_requirements,
+            use_pip_config=True,
         )
 
     @classmethod
-    def get_protected_inmanta_packages(cls) -> list[str]:
+    def get_protected_inmanta_packages(cls) -> List[str]:
         """
         Returns the list of packages that should not be installed/updated by any operation on a Python environment.
         """
         return [
             # Protect product packages
             "inmanta",
             "inmanta-service-orchestrator",
@@ -640,25 +646,25 @@
 
     @classmethod
     def _get_requirements_on_inmanta_package(cls) -> Sequence[Requirement]:
         """
         Returns the content of the requirement file that should be supplied to each `pip install` invocation
         to make sure that no Inmanta packages gets overridden.
         """
-        protected_inmanta_packages: list[str] = cls.get_protected_inmanta_packages()
-        workingset: dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
+        protected_inmanta_packages: List[str] = cls.get_protected_inmanta_packages()
+        workingset: Dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
         return [Requirement.parse(f"{pkg}=={workingset[pkg]}") for pkg in workingset if pkg in protected_inmanta_packages]
 
 
 class CommandRunner:
     def __init__(self, logger: logging.Logger) -> None:
         self.logger = logger
 
     def run_command_and_log_output(
-        self, cmd: list[str], env: Optional[dict[str, str]] = None, stderr: Optional[int] = None
+        self, cmd: List[str], env: Optional[Dict[str, str]] = None, stderr: Optional[int] = None
     ) -> str:
         output: bytes = b""  # Make sure the var is always defined in the except bodies
         try:
             output = subprocess.check_output(cmd, stderr=stderr, env=env)
         except CalledProcessError as e:
             if e.stderr:
                 msg = e.stderr.decode()
@@ -673,24 +679,24 @@
             raise
         else:
             self.logger.debug("%s: %s", cmd, output.decode())
             return output.decode()
 
     def run_command_and_stream_output(
         self,
-        cmd: list[str],
+        cmd: List[str],
         shell: bool = False,
         timeout: float = 10,
         env_vars: Optional[Mapping[str, str]] = None,
-    ) -> tuple[int, list[str]]:
+    ) -> Tuple[int, List[str]]:
         """
         Similar to the _run_command_and_log_output method, but here, the output is logged on the fly instead of at the end
         of the sub-process.
         """
-        full_output: list[str] = []
+        full_output: List[str] = []
         process = subprocess.Popen(
             cmd,
             stdout=subprocess.PIPE,
             stderr=subprocess.STDOUT,
             shell=shell,
             env=env_vars,
         )
@@ -727,15 +733,15 @@
     Activating another environment that inherits from this one is allowed.
     """
 
     _egg_fragment_re = re.compile(r"#egg=(?P<name>[^&]*)")
     _at_fragment_re = re.compile(r"^(?P<name>[^@]+)@(?P<req>.+)")
 
     def __init__(self, *, env_path: Optional[str] = None, python_path: Optional[str] = None) -> None:
-        super().__init__(env_path=env_path, python_path=python_path)
+        super(ActiveEnv, self).__init__(env_path=env_path, python_path=python_path)
 
     def is_using_virtual_env(self) -> bool:
         return True
 
     def use_virtual_env(self) -> None:
         """
         Activate the virtual environment.
@@ -746,38 +752,43 @@
         """
         Return True iff the given requirements are installed in this environment.
         """
         return PythonWorkingSet.are_installed(requirements)
 
     def install_from_index(
         self,
-        requirements: list[Requirement],
-        index_urls: Optional[list[str]] = None,
+        requirements: List[Requirement],
+        index_urls: Optional[List[str]] = None,
         upgrade: bool = False,
         allow_pre_releases: bool = False,
-        constraint_files: Optional[list[str]] = None,
+        constraint_files: Optional[List[str]] = None,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         if not upgrade and self.are_installed(requirements):
             return
         try:
-            super().install_from_index(
-                requirements, index_urls, upgrade, allow_pre_releases, constraint_files, upgrade_strategy
+            super(ActiveEnv, self).install_from_index(
+                requirements, index_urls, upgrade, allow_pre_releases, constraint_files, upgrade_strategy, use_pip_config
             )
         finally:
             self.notify_change()
 
-    def install_from_source(self, paths: list[LocalPackagePath], constraint_files: Optional[list[str]] = None) -> None:
+    def install_from_source(
+        self,
+        paths: List[LocalPackagePath],
+        constraint_files: Optional[List[str]] = None,
+    ) -> None:
         try:
             super().install_from_source(paths, constraint_files)
         finally:
             self.notify_change()
 
     @classmethod
-    def _parse_line(cls, req_line: str) -> tuple[Optional[str], str]:
+    def _parse_line(cls, req_line: str) -> Tuple[Optional[str], str]:
         """
         Parse the requirement line
         """
         at = VirtualEnv._at_fragment_re.search(req_line)
         if at is not None:
             d = at.groupdict()
             return d["name"], d["req"] + "#egg=" + d["name"]
@@ -791,19 +802,22 @@
 
     @classmethod
     def _gen_content_requirements_file(cls, requirements_list: Sequence[str]) -> str:
         """Generate a new requirements file based on the requirements list.
         :param requirements_list:  A list of Python requirements as strings.
         :return: A string that can be written to a requirements file that pip understands.
         """
-        modules: dict[str, Any] = {}
+        modules: Dict[str, Any] = {}
         for req in requirements_list:
             parsed_name, req_spec = cls._parse_line(req)
 
-            name = req if parsed_name is None else parsed_name
+            if parsed_name is None:
+                name = req
+            else:
+                name = parsed_name
 
             url = None
             version = None
             marker = None
             extras = None
             try:
                 # this will fail if an url is supplied
@@ -819,77 +833,84 @@
                     if hasattr(item, "url"):
                         url = item.url
                     if hasattr(item, "extras") and len(item.extras) > 0:
                         extras = sorted(item.extras)
             except InvalidRequirement:
                 url = req_spec
 
-            requirement_id: str = name + "_" + str(marker) if marker else name
-            if requirement_id not in modules:
-                modules[requirement_id] = {"name": name, "version": [], "markers": [], "extras": []}
+            if name not in modules:
+                modules[name] = {"name": name, "version": [], "markers": []}
 
             if version is not None:
-                modules[requirement_id]["version"].extend(version)
+                modules[name]["version"].extend(version)
 
             if marker is not None:
-                modules[requirement_id]["markers"].append(marker)
+                modules[name]["markers"].append(marker)
+
             if url is not None:
-                modules[requirement_id]["url"] = url
+                modules[name]["url"] = url
 
             if extras is not None:
-                modules[requirement_id]["extras"].extend(extras)
+                modules[name]["extras"] = extras
 
         requirements_file = ""
-        for _, info in modules.items():
-            name = info["url"] if "url" in info else info["name"]
+        for module, info in modules.items():
             version_spec = ""
             markers: str = ""
             extras_spec: str = ""
             if len(info["version"]) > 0:
-                version_spec = " " + (", ".join([f"{a} {b}" for a, b in info["version"]]))
+                version_spec = " " + (", ".join(["%s %s" % (a, b) for a, b in info["version"]]))
 
             if len(info["markers"]) > 0:
                 markers = " ; " + (" and ".join(map(str, info["markers"])))
 
-            if "extras" in info and info["extras"]:
+            if "url" in info:
+                module = info["url"]
+
+            if "extras" in info:
                 extras_spec = f"[{','.join(info['extras'])}]"
 
-            requirements_file += name + extras_spec + version_spec + markers + "\n"
+            requirements_file += module + extras_spec + version_spec + markers + "\n"
 
         return requirements_file
 
     def install_from_list(
         self,
         requirements_list: Sequence[str],
         *,
         upgrade: bool = False,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         """
         Install requirements from a list of requirement strings. This method uses the Python package repositories
         configured on the host.
 
         :param requirements_list: List of requirement strings to install.
         :param upgrade: Upgrade requirements to the latest compatible version.
         :param upgrade_strategy: The upgrade strategy to use for requirements' dependencies.
+        :param use_pip_config: Whether the pip config file specified in the PIP_CONFIG_FILE env var should be used
         """
         if not upgrade and self.are_installed(requirements_list):
             # don't fork subprocess if requirements are already met
             return
         try:
-            self._install_from_list(requirements_list, upgrade=upgrade, upgrade_strategy=upgrade_strategy)
+            self._install_from_list(
+                requirements_list, upgrade=upgrade, upgrade_strategy=upgrade_strategy, use_pip_config=use_pip_config
+            )
         finally:
             self.notify_change()
 
     def _install_from_list(
         self,
         requirements_list: Sequence[str],
         *,
         upgrade: bool = False,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         """
         This method differs from the `install_from_index()` method in the sense that it calls
         `_gen_content_requirements_file()`, which rewrites the requirements from pep440 format to a format that pip understands.
         This method is maintained for V1 modules only: V2 modules do not require this conversion. It is currently used for both
         v1 and v2 for consistency but it can be substituted by `install_from_index` once V1 support is removed.
         """
@@ -899,25 +920,26 @@
             try:
                 self._run_pip_install_command(
                     python_path=self.python_path,
                     requirements_files=[requirements_file],
                     requirements=inmanta_requirements,
                     upgrade=upgrade,
                     upgrade_strategy=upgrade_strategy,
+                    use_pip_config=use_pip_config,
                 )
             except Exception:
                 LOGGER.info("requirements:\n%s", content_requirements_file)
                 raise
 
     @classmethod
     def get_constraint_violations_for_check(
         cls,
         strict_scope: Optional[Pattern[str]] = None,
-        constraints: Optional[list[Requirement]] = None,
-    ) -> tuple[set[VersionConflict], set[VersionConflict]]:
+        constraints: Optional[List[Requirement]] = None,
+    ) -> Tuple[Set[VersionConflict], Set[VersionConflict]]:
         """
         Return the constraint violations that exist in this venv. Returns a tuple of non-strict and strict violations,
         in that order.
         """
 
         class OwnedRequirement(NamedTuple):
             requirement: Requirement
@@ -949,15 +971,15 @@
                     else (dist_info.key for dist_info in pkg_resources.working_set if strict_scope.fullmatch(dist_info.key))
                 ),
                 (requirement.requirement.key for requirement in inmanta_constraints),
                 (requirement.requirement.key for requirement in extra_constraints),
             )
         )
 
-        installed_versions: dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
+        installed_versions: Dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
 
         constraint_violations: set[VersionConflict] = set()
         constraint_violations_strict: set[VersionConflict] = set()
         for c in all_constraints:
             requirement = c.requirement
             if (requirement.key not in installed_versions or str(installed_versions[requirement.key]) not in requirement) and (
                 not requirement.marker or (requirement.marker and requirement.marker.evaluate())
@@ -974,15 +996,15 @@
 
         return constraint_violations, constraint_violations_strict
 
     @classmethod
     def check(
         cls,
         strict_scope: Optional[Pattern[str]] = None,
-        constraints: Optional[list[Requirement]] = None,
+        constraints: Optional[List[Requirement]] = None,
     ) -> None:
         """
         Check this Python environment for incompatible dependencies in installed packages.
 
         :param strict_scope: A full pattern representing the package names that are considered in scope for the installed
             packages compatibility check. strict_scope packages' dependencies will also be considered for conflicts.
             Any conflicts for packages that do not match this pattern will only raise a warning.
@@ -998,15 +1020,15 @@
                 constraint_violations_strict,
             )
 
         for violation in constraint_violations:
             LOGGER.warning("%s", violation)
 
     @classmethod
-    def check_legacy(cls, in_scope: Pattern[str], constraints: Optional[list[Requirement]] = None) -> bool:
+    def check_legacy(cls, in_scope: Pattern[str], constraints: Optional[List[Requirement]] = None) -> bool:
         """
         Check this Python environment for incompatible dependencies in installed packages. This method is a legacy method
         in the sense that it has been replaced with a more correct check defined in self.check(). This method is invoked
         when the `--no-strict-deps-check` commandline option is provided.
 
         :param in_scope: A full pattern representing the package names that are considered in scope for the installed packages'
             compatibility check. Only in scope packages' dependencies will be considered for conflicts. The pattern is matched
@@ -1017,36 +1039,36 @@
         """
         constraint_violations_non_strict, constraint_violations_strict = cls.get_constraint_violations_for_check(
             in_scope, constraints
         )
 
         working_set: abc.Iterable[DistInfoDistribution] = pkg_resources.working_set
         # add all requirements of all in scope packages installed in this environment
-        all_constraints: set[Requirement] = set(constraints if constraints is not None else []).union(
+        all_constraints: Set[Requirement] = set(constraints if constraints is not None else []).union(
             requirement
             for dist_info in working_set
             if in_scope.fullmatch(dist_info.key)
             for requirement in dist_info.requires()
         )
 
-        installed_versions: dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
-        constraint_violations: set[VersionConflict] = {
+        installed_versions: Dict[str, version.Version] = PythonWorkingSet.get_packages_in_working_set()
+        constraint_violations: Set[VersionConflict] = set(
             VersionConflict(constraint, installed_versions.get(constraint.key, None))
             for constraint in all_constraints
             if constraint.key not in installed_versions or str(installed_versions[constraint.key]) not in constraint
-        }
+        )
 
         all_violations = constraint_violations_non_strict | constraint_violations_strict | constraint_violations
         for violation in all_violations:
             LOGGER.warning("%s", violation)
 
         return len(constraint_violations) == 0
 
     @classmethod
-    def get_module_file(cls, module: str) -> Optional[tuple[Optional[str], Loader]]:
+    def get_module_file(cls, module: str) -> Optional[Tuple[Optional[str], Loader]]:
         """
         Get the location of the init file for a Python module within the active environment. Returns the file path as observed
         by Python. For editable installs, this may or may not be a symlink to the actual location (see implementation
         mechanisms in setuptools docs: https://setuptools.pypa.io/en/latest/userguide/development_mode.html).
 
         :return: A tuple of the path and the associated loader, if the module is found.
         """
@@ -1124,46 +1146,22 @@
 
 @stable_api
 class VirtualEnv(ActiveEnv):
     """
     Creates and uses a virtual environment for this process. This virtualenv inherits from the previously active one.
     """
 
-    _invalid_chars_in_path_re = re.compile(r'["$`]')
-
     def __init__(self, env_path: str) -> None:
-        super().__init__(env_path=env_path)
-        self.validate_path(env_path)
+        super(VirtualEnv, self).__init__(env_path=env_path)
         self.env_path: str = env_path
         self.virtual_python: Optional[str] = None
         self._using_venv: bool = False
         self._parent_python: Optional[str] = None
         self._path_pth_file = os.path.join(self.site_packages_dir, "inmanta-inherit-from-parent-venv.pth")
 
-    def validate_path(self, path: str) -> None:
-        """
-        The given path is used in the `./bin/activate` file of the created venv without escaping any special characters.
-        As such, we refuse all special characters here that might cause the given path to be interpreted incorrectly:
-
-            * $: Character used for variable expansion in bash strings.
-            * `: Character used to perform command substitution in bash strings.
-            * ": Character that will be interpreted incorrectly as the end of the string.
-
-        :param path: Path to validate.
-        """
-        if not path:
-            raise ValueError("Cannot create virtual environment because the provided path is an empty string.")
-
-        match = VirtualEnv._invalid_chars_in_path_re.search(path)
-        if match:
-            raise ValueError(
-                f"Cannot create virtual environment because the provided path `{path}` contains an"
-                f" invalid character (`{match.group()}`)."
-            )
-
     def exists(self) -> bool:
         """
         Returns True iff the venv exists on disk.
         """
         return os.path.exists(self.python_path) and os.path.exists(self._path_pth_file)
 
     def init_env(self) -> None:
@@ -1262,15 +1260,15 @@
 
     def _write_pth_file(self) -> None:
         """
         Write an inmanta-inherit-from-parent-venv.pth file to the venv to ensure that an activation of this venv will also
         activate the parent venv. The site directories of the parent venv should appear later in sys.path than the ones of
         this venv.
         """
-        site_dir_strings: list[str] = ['"' + p.replace('"', r"\"") + '"' for p in list(sys.path)]
+        site_dir_strings: List[str] = ['"' + p.replace('"', r"\"") + '"' for p in list(sys.path)]
         add_site_dir_statements: str = "\n".join(
             [f"site.addsitedir({p}) if {p} not in sys.path else None" for p in site_dir_strings]
         )
         script = f"""
 import os
 import site
 import sys
@@ -1312,40 +1310,50 @@
 
         sys.real_prefix = sys.prefix
         sys.prefix = base
         self._update_sys_path()
 
     def install_from_index(
         self,
-        requirements: list[Requirement],
-        index_urls: Optional[list[str]] = None,
+        requirements: List[Requirement],
+        index_urls: Optional[List[str]] = None,
         upgrade: bool = False,
         allow_pre_releases: bool = False,
-        constraint_files: Optional[list[str]] = None,
+        constraint_files: Optional[List[str]] = None,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         if not self._using_venv:
             raise Exception(f"Not using venv {self.env_path}. use_virtual_env() should be called first.")
-        super().install_from_index(requirements, index_urls, upgrade, allow_pre_releases, constraint_files, upgrade_strategy)
+        super(VirtualEnv, self).install_from_index(
+            requirements, index_urls, upgrade, allow_pre_releases, constraint_files, upgrade_strategy, use_pip_config
+        )
 
-    def install_from_source(self, paths: list[LocalPackagePath], constraint_files: Optional[list[str]] = None) -> None:
+    def install_from_source(
+        self,
+        paths: List[LocalPackagePath],
+        constraint_files: Optional[List[str]] = None,
+    ) -> None:
         if not self._using_venv:
             raise Exception(f"Not using venv {self.env_path}. use_virtual_env() should be called first.")
-        super().install_from_source(paths, constraint_files)
+        super(VirtualEnv, self).install_from_source(paths, constraint_files)
 
     def install_from_list(
         self,
         requirements_list: Sequence[str],
         *,
         upgrade: bool = False,
         upgrade_strategy: PipUpgradeStrategy = PipUpgradeStrategy.ONLY_IF_NEEDED,
+        use_pip_config: Optional[bool] = False,
     ) -> None:
         if not self._using_venv:
             raise Exception(f"Not using venv {self.env_path}. use_virtual_env() should be called first.")
-        super().install_from_list(requirements_list, upgrade=upgrade, upgrade_strategy=upgrade_strategy)
+        super(VirtualEnv, self).install_from_list(
+            requirements_list, upgrade=upgrade, upgrade_strategy=upgrade_strategy, use_pip_config=use_pip_config
+        )
 
 
 class VenvCreationFailedError(Exception):
     def __init__(self, msg: str) -> None:
         super().__init__(msg)
         self.msg = msg
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/__init__.py` & `inmanta-core-9.3.0/src/inmanta/execute/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/dataflow/__init__.py` & `inmanta-core-9.3.0/src/inmanta/execute/dataflow/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,18 +12,17 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from collections.abc import Callable, Iterable, Iterator
 from functools import reduce
 from itertools import chain, filterfalse
-from typing import TYPE_CHECKING, Generic, Optional, TypeVar
+from typing import TYPE_CHECKING, Callable, Dict, FrozenSet, Generic, Iterable, Iterator, List, Optional, Set, Tuple, TypeVar
 
 if TYPE_CHECKING:
     from inmanta.ast import Locatable
     from inmanta.ast.attribute import Attribute
     from inmanta.ast.entity import Entity
     from inmanta.ast.statements.generator import Constructor
     from inmanta.execute.runtime import Resolver, ResultVariable
@@ -166,17 +165,17 @@
 
     def __init__(self, resolver: "Resolver", parent: Optional["DataflowGraph"] = None) -> None:
         self.resolver: "Resolver" = resolver
         self.parent: Optional[DataflowGraph] = parent if parent is not None else None
         # keeps track of variables that have not been declared in the resolver's scope. This should only be populated
         # if the model refers to a variable in the rhs that has no declaration in the left hand side.
         # For example `n = y.n` in a scope that does not contain a `y = ...` statement.
-        self._own_variables: dict[str, AssignableNode] = {}
+        self._own_variables: Dict[str, AssignableNode] = {}
         # keeps track of instance nodes and their responsible
-        self._own_instances: dict["Constructor", InstanceNode] = {}
+        self._own_instances: Dict["Constructor", InstanceNode] = {}
 
     def get_own_variable(self, name: str) -> "AssignableNodeReference":
         """
         Returns a reference to one of this graph's own variable nodes.
         """
         if name not in self._own_variables:
             self._own_variables[name] = AssignableNode(name)
@@ -375,15 +374,15 @@
 
     def __eq__(self, other: object) -> bool:
         if not isinstance(other, AttributeNodeReference):
             return NotImplemented
         return self.instance_var_ref == other.instance_var_ref and self.attribute == other.attribute
 
     def __repr__(self) -> str:
-        return f"{repr(self.instance_var_ref)}.{self.attribute}"
+        return "%s.%s" % (repr(self.instance_var_ref), self.attribute)
 
 
 class InstanceAttributeNodeReference(AssignableNodeReference):
     """
     Reference to a node representing an attribute of an instance.
     """
 
@@ -598,17 +597,17 @@
         "equivalence",
         "result_variable",
     )
 
     def __init__(self, name: str) -> None:
         Node.__init__(self)
         self.name: str = name
-        self.assignable_assignments: list[Assignment[AssignableNodeReference]] = []
-        self.value_assignments: list[Assignment[ValueNodeReference]] = []
-        self.instance_assignments: list[Assignment[InstanceNodeReference]] = []
+        self.assignable_assignments: List[Assignment[AssignableNodeReference]] = []
+        self.value_assignments: List[Assignment[ValueNodeReference]] = []
+        self.instance_assignments: List[Assignment[InstanceNodeReference]] = []
         self.equivalence: Equivalence = Equivalence(frozenset([self]))
         self.result_variable: Optional[ResultVariable] = None
 
     def reference(self) -> AssignableNodeReference:
         return VariableNodeReference(self)
 
     def leaves(self) -> Iterator["AssignableNodeReference"]:
@@ -647,15 +646,15 @@
 
     def assign_assignable(self, var_ref: AssignableNodeReference, responsible: "Locatable", context: "DataflowGraph") -> None:
         """
         Assigns an assignable node to this node, by reference.
         """
         # Gather all equivalences on the path between the rhs's leaves and this node.
         # The existence of such a trail indicates an assignment loop.
-        equivalence_trail: set[Equivalence] = reduce(
+        equivalence_trail: Set[Equivalence] = reduce(
             set.union,
             (n.equivalence.equivalences_on_path(self) for n in var_ref.nodes()),
             set(),
         )
         # merge all equivalences on the trail
         new_equivalence: Equivalence = reduce(
             lambda acc, eq: acc.merge(eq),
@@ -681,17 +680,17 @@
     """
     Represents a collection of nodes that are equivalent because of one or more assignment loops.
     """
 
     __slots__ = ("nodes", "tentative_instance")
 
     def __init__(
-        self, nodes: frozenset[AssignableNode] = frozenset(), tentative_instance: Optional["InstanceNode"] = None
+        self, nodes: FrozenSet[AssignableNode] = frozenset(), tentative_instance: Optional["InstanceNode"] = None
     ) -> None:
-        self.nodes: frozenset[AssignableNode] = nodes
+        self.nodes: FrozenSet[AssignableNode] = nodes
         self.tentative_instance: Optional[InstanceNode] = tentative_instance
 
     def merge(self, other: "Equivalence") -> "Equivalence":
         """
         Returns the equivalence that is the union of this one and the one passed as an argument.
         """
         tentative_instance: Optional[InstanceNode] = self.tentative_instance
@@ -721,31 +720,31 @@
             try:
                 yield next(explicit_leaves)
                 yield from explicit_leaves
             except StopIteration:
                 yield from (node.reference() for node in self.nodes)
         yield from (node for assignment in self.external_assignable_assignments() for node in assignment.rhs.leaves())
 
-    def equivalences_on_path(self, node: AssignableNode) -> set["Equivalence"]:
+    def equivalences_on_path(self, node: AssignableNode) -> Set["Equivalence"]:
         """
         Returns the set of all equivalences on the assignment path originating from this equivalence
         and terminating in the equivalence containing node.
         Returns the empty set if there is no such path.
         """
         if node in self.nodes:
             return {self}
-        child_paths: set[Equivalence] = reduce(
+        child_paths: Set[Equivalence] = reduce(
             set.union,
             (
                 n.equivalence.equivalences_on_path(node)
                 for n in set(chain.from_iterable(a.rhs.nodes() for a in self.external_assignable_assignments()))
             ),
             set(),
         )
-        return child_paths.union({self}) if len(child_paths) > 0 else set()
+        return child_paths.union({self}) if len(child_paths) > 0 else set(())
 
     def _is_internal_assignment(self, assignment: Assignment[AssignableNodeReference]) -> bool:
         filtered: Iterator[AssignableNode] = filter(assignment.rhs.ref_to_node, self.nodes)
         return any(filtered)
 
     def interal_assignments(self) -> Iterator[Assignment[AssignableNodeReference]]:
         """
@@ -820,26 +819,26 @@
     """
 
     __slots__ = ("instance", "responsibles")
 
     def __init__(self, instance: "InstanceNode", name: str) -> None:
         AssignableNode.__init__(self, name)
         self.instance: InstanceNode = instance
-        self.responsibles: set[tuple["Locatable", DataflowGraph]] = set()
+        self.responsibles: Set[Tuple["Locatable", DataflowGraph]] = set(())
 
     def assign(self, node_ref: NodeReference, responsible: "Locatable", context: "DataflowGraph") -> None:
         # only add assignment for each responsible once, this check is necessary for bidirectional attributes
         if (responsible, context) in self.responsibles:
             return
         super().assign(node_ref, responsible, context)
         self.responsibles.add((responsible, context))
         self.instance.assign_other_direction(self.name, node_ref, responsible, context)
 
     def __repr__(self) -> str:
-        return f"attribute {super().__repr__()} on {repr(self.instance)}"
+        return "attribute %s on %s" % (super().__repr__(), repr(self.instance))
 
 
 class InstanceNode(Node):
     """
     Node representing an entity instance.
     """
 
@@ -854,20 +853,20 @@
     )
 
     def __init__(
         self,
         attributes: Iterable[str],
     ) -> None:
         Node.__init__(self)
-        self.attributes: dict[str, AttributeNode] = {name: AttributeNode(self, name) for name in attributes}
+        self.attributes: Dict[str, AttributeNode] = {name: AttributeNode(self, name) for name in attributes}
         self.entity: Optional["Entity"] = None
         self.responsible: Optional["Constructor"] = None
         self.context: Optional["DataflowGraph"] = None
         self._index_node: Optional[InstanceNode] = None
-        self._all_index_nodes: set["InstanceNode"] = {self}
+        self._all_index_nodes: Set["InstanceNode"] = {self}
 
     def reference(self) -> InstanceNodeReference:
         return InstanceNodeReference(self)
 
     def get_self(self) -> "InstanceNode":
         """
         Returns the main instance node if this node acts as a proxy due to an index match.
@@ -896,25 +895,25 @@
         if self._index_node is not None:
             raise Exception("Trying to match index on node that already has an index match. Try calling get_self() first")
         assert self.entity == index_node.get_self().entity
         index_node.get_self().merge(self)
         self._index_node = index_node
         self.attributes = {}
         index_node.get_self().update_all_index_nodes(self._all_index_nodes)
-        self._all_index_nodes = set()
+        self._all_index_nodes = set(())
 
-    def update_all_index_nodes(self, index_nodes: set["InstanceNode"]) -> None:
+    def update_all_index_nodes(self, index_nodes: Set["InstanceNode"]) -> None:
         """
         Adds a set of index nodes to this node's set of all index matches.
         """
         if self.get_self() is not self:
             return self.get_self().update_all_index_nodes(index_nodes)
         self._all_index_nodes.update(index_nodes)
 
-    def get_all_index_nodes(self) -> set["InstanceNode"]:
+    def get_all_index_nodes(self) -> Set["InstanceNode"]:
         """
         Returns all index matches for this node.
         """
         if self.get_self() is not self:
             return self.get_self().get_all_index_nodes()
         return self._all_index_nodes
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/dataflow/datatrace.py` & `inmanta-core-9.3.0/src/inmanta/execute/dataflow/datatrace.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,17 +12,16 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from collections.abc import Iterable
 from itertools import chain
-from typing import Optional
+from typing import Iterable, List, Optional
 
 from inmanta.ast import Locatable, NotFoundException
 from inmanta.ast.statements import Statement
 from inmanta.execute.dataflow import (
     AssignableNode,
     AssignableNodeReference,
     Assignment,
@@ -44,59 +43,59 @@
     """
 
     @classmethod
     def render(cls, node_ref: AssignableNodeReference) -> str:
         return "\n".join(cls._render_reference(node_ref, tree_root=True)) + "\n"
 
     @classmethod
-    def _render_reference(cls, node_ref: AssignableNodeReference, tree_root: bool = False) -> list[str]:
+    def _render_reference(cls, node_ref: AssignableNodeReference, tree_root: bool = False) -> List[str]:
         """
         Renders the data trace for all nodes a reference refers to.
         """
-        result: list[str] = []
+        result: List[str] = []
         if tree_root:
             result.append(repr(node_ref))
         if isinstance(node_ref, AttributeNodeReference):
             result.append("SUBTREE for %s:" % node_ref.instance_var_ref)
             result += cls._indent(cls._render_reference(node_ref.instance_var_ref))
         if isinstance(node_ref, InstanceAttributeNodeReference):
             result.append("SUBTREE for %s:" % node_ref.instance)
             result += cls._indent(cls._render_instance(node_ref.instance))
         for node in node_ref.nodes():
             result += cls._render_node(node)
         return result
 
     @classmethod
-    def _render_node(cls, node: AssignableNode) -> list[str]:
+    def _render_node(cls, node: AssignableNode) -> List[str]:
         """
         Renders the data trace for an assignable node. Shows information about:
             - the node's parent instance, if it is an attribute node
             - the node's equivalence
             - assignments to the node:
                 - right hand side
                 - responsible
                 - the dynamic context it lives in, if any
         Recurses on the assignment's right hand side.
 
         :param tree_root: indicates whether this node is the root of the data trace tree. Behaviour for non-root nodes is
             slightly different in order to prevent output duplication.
         """
-        result: list[str] = []
+        result: List[str] = []
         result += cls._render_equivalence(node.equivalence)
-        assignments: list[Assignment] = list(
+        assignments: List[Assignment] = list(
             chain(
                 node.equivalence.external_assignable_assignments(),
                 node.equivalence.instance_assignments(),
                 node.equivalence.value_assignments(),
             )
         )
         nb_assignments: int = len(assignments)
         for i, assignment in enumerate(assignments):
             last: bool = i == nb_assignments - 1
-            subblock: list[str] = []
+            subblock: List[str] = []
 
             subblock += cls._render_assignment(assignment)
             subblock += cls._render_implementation_context(assignment.context)
 
             if isinstance(assignment.rhs, InstanceNodeReference):
                 subblock += cls._render_instance(assignment.rhs.top_node())
             if isinstance(assignment.rhs, AssignableNodeReference):
@@ -111,119 +110,119 @@
         Prefixes a line.
         """
         if line == "":
             return prefix.rstrip()
         return prefix + line
 
     @classmethod
-    def _prefix(cls, prefix: str, lines: Iterable[str]) -> list[str]:
+    def _prefix(cls, prefix: str, lines: Iterable[str]) -> List[str]:
         """
         Prefixes lines.
         """
         return [cls._prefix_line(prefix, line) for line in lines]
 
     @classmethod
-    def _branch(cls, lines: list[str], last: Optional[bool] = False) -> list[str]:
+    def _branch(cls, lines: List[str], last: Optional[bool] = False) -> List[str]:
         """
         Renders a branch in the tree.
 
         :param last: True iff this is the last branch on this level.
         """
         if len(lines) == 0:
             return []
         branch_prefix: str = ("" if last else "") + " "
         block_prefix: str = (" " if last else "") + " " * 3
-        result: list[str] = cls._prefix(branch_prefix, lines[0:1])
+        result: List[str] = cls._prefix(branch_prefix, lines[0:1])
         result += cls._prefix(block_prefix, lines[1:])
         return result
 
     @classmethod
-    def _indent(cls, lines: Iterable[str]) -> list[str]:
+    def _indent(cls, lines: Iterable[str]) -> List[str]:
         """
         Indents lines.
         """
         return cls._prefix(" " * 4, lines)
 
     @classmethod
-    def _render_implementation_context(cls, context: DataflowGraph) -> list[str]:
+    def _render_implementation_context(cls, context: DataflowGraph) -> List[str]:
         """
         Renders information about the dynamic implementation context, if it exists.
         """
         # roundabout way to detect encapsulating context, may lead to false positives, see #1937
         try:
             context.resolver.lookup("self")
         except NotFoundException:
             return []
-        result: list[str] = []
+        result: List[str] = []
         var_node: AssignableNodeReference = context.resolver.get_dataflow_node("self")
         if (
             isinstance(var_node, VariableNodeReference)
             and len(var_node.node.instance_assignments) == 1
             and isinstance(var_node.node.instance_assignments[0].responsible, Instance)
         ):
             instance_node: InstanceNode = var_node.node.instance_assignments[0].rhs.top_node()
             result.append("IN IMPLEMENTATION WITH self = %s" % instance_node)
             result += cls._indent(cls._render_constructor(instance_node))
         return result
 
     @classmethod
-    def _render_constructor(cls, instance: InstanceNode) -> list[str]:
+    def _render_constructor(cls, instance: InstanceNode) -> List[str]:
         """
         Renders information about the construction of an instance node:
             - constructor statement
             - lexical position
             - dynamic context it lives in, if any
         """
-        result: list[str] = []
+        result: List[str] = []
         if instance.responsible is not None:
             result += [
                 "CONSTRUCTED BY `%s`" % instance.responsible.pretty_print(),
                 "AT %s" % instance.responsible.get_location(),
             ]
         if instance.context is not None:
             result += cls._render_implementation_context(instance.context)
         return result
 
     @classmethod
-    def _render_instance(cls, instance: InstanceNode) -> list[str]:
+    def _render_instance(cls, instance: InstanceNode) -> List[str]:
         """
         Renders information about an instance node:
             - construction information
             - index matches and their construction information
         """
-        result: list[str] = []
+        result: List[str] = []
         result += cls._render_constructor(instance)
         for index_node in instance.get_all_index_nodes():
             if index_node is instance:
                 continue
             result += [
                 "",
                 "INDEX MATCH: `%s`" % index_node,
             ]
 
-            subblock: list[str] = []
+            subblock: List[str] = []
             subblock += cls._render_constructor(index_node)
 
             result += cls._indent(subblock)
         return result
 
     @classmethod
-    def _render_assignment(cls, assignment: Assignment) -> list[str]:
+    def _render_assignment(cls, assignment: Assignment) -> List[str]:
         """
         Renders information about an assignment in the dataflow graph.
         """
         responsible: "Locatable" = assignment.responsible
         return [
             "%s" % assignment.rhs,
             "SET BY `%s`" % (responsible.pretty_print() if isinstance(responsible, Statement) else responsible),
             "AT %s" % responsible.get_location(),
         ]
 
     @classmethod
-    def _render_equivalence(cls, equivalence: Equivalence) -> list[str]:
+    def _render_equivalence(cls, equivalence: Equivalence) -> List[str]:
         """
         Renders information about an equivalence unless trivial. Shows the equivalence's members and the responsible
         assignments.
         """
         if len(equivalence.nodes) > 1:
             # sort output for consistency
             return [
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/dataflow/graphic.py` & `inmanta-core-9.3.0/src/inmanta/execute/dataflow/graphic.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,17 +12,16 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from collections.abc import Iterable, Iterator
 from functools import reduce
-from typing import Optional, cast
+from typing import Iterable, Iterator, Optional, Set, cast
 
 from inmanta.ast import RuntimeException
 from inmanta.execute.dataflow import (
     AssignableNode,
     AssignableNodeReference,
     Assignment,
     AttributeNode,
@@ -76,16 +75,16 @@
 class GraphicGraph:
     """
     Graphic representation of a data flow graph. Stateful. Methods add_node and add_assignments have side effects.
     """
 
     def __init__(self) -> None:
         self.digraph: Digraph = Digraph(engine="fdp")
-        self._nodes: set[Node] = set()
-        self._assignments: set[Assignment] = set()
+        self._nodes: Set[Node] = set(())
+        self._assignments: Set[Assignment] = set(())
 
     def view(self) -> None:
         try:
             self.digraph.view()
         except graphviz.ExecutableNotFound:
             raise RuntimeException(
                 None,
@@ -168,20 +167,20 @@
 
             if isinstance(assignment.rhs, InstanceNodeReference):
                 rhs = assignment.rhs.top_node()
             elif isinstance(assignment.rhs, AttributeNodeReference):
                 label = ""
                 instance_var_ref: AssignableNodeReference
                 (label, instance_var_ref) = reduce(
-                    lambda acc, x: (f".{x.attribute}{acc[0]}", x.instance_var_ref),
+                    lambda acc, x: (".%s%s" % (x.attribute, acc[0]), x.instance_var_ref),
                     unroll_attribute_reference(assignment.rhs),
                     ("", cast(AssignableNodeReference, assignment.rhs)),
                 )
                 assert isinstance(instance_var_ref, VariableNodeReference)
                 rhs = instance_var_ref.node
             elif isinstance(assignment.rhs, DirectNodeReference):
                 rhs = assignment.rhs.node
             else:
-                raise Exception(f"Unknown node reference {assignment.rhs} of type {type(assignment.rhs)}")
+                raise Exception("Unknown node reference %s of type %s" % (assignment.rhs, type(assignment.rhs)))
 
             self.add_node(rhs)
             self.digraph.edge(self.node_key(assignment.lhs), self.node_key(rhs), label=label)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/dataflow/root_cause.py` & `inmanta-core-9.3.0/src/inmanta/execute/dataflow/root_cause.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,30 +11,30 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from collections.abc import Iterable
 from itertools import chain
+from typing import FrozenSet, Iterable, Set
 
 from inmanta.execute.dataflow import AssignableNode, AttributeNode, AttributeNodeReference
 
 
 class UnsetRootCauseAnalyzer:
     """
     Analyzes the root causes for attributes being unset among a collection of attribute nodes.
     The main entrypoint for this class is the root_causes method.
     """
 
     def __init__(self, nodes: Iterable[AttributeNode]) -> None:
-        self.nodes: frozenset[AttributeNode] = frozenset(nodes)
+        self.nodes: FrozenSet[AttributeNode] = frozenset(nodes)
 
-    def root_causes(self) -> set[AttributeNode]:
+    def root_causes(self) -> Set[AttributeNode]:
         """
         Returns the root causes from this instances' set of attribute nodes. An attribute node c
         is defined as the cause for an other attribute node n iff c being unset leads to n
         being unset.
         Formally, the relation is_cause(c, x) is defined by three rules:
             1. is_cause(c, x) <- c in `x = c` in graph
                 (If `x = c` then c is responsible for x receiving a value)
@@ -69,19 +69,19 @@
                         <----- is_cause(c.i, V.i)
                         <-(1)- `V.i = c.i` in graph
                         <----- true
         Rules 2 to 4 are implemented as propagation steps by
         _assignment_step, _child_attribute_step and _parent_instance_step respectively.
         """
         # Actual found roots
-        roots: set[AttributeNode] = set()
+        roots: Set[AttributeNode] = set(())
         # Actual roots that we have to filter out
-        ignore_roots: set[AssignableNode] = set()
+        ignore_roots: Set[AssignableNode] = set(())
         # Any node of which the roots are already in the roots set
-        seen: set[AssignableNode] = set()
+        seen: Set[AssignableNode] = set(())
 
         def has_root(node: AssignableNode) -> bool:
             """
             Add underlying roots to roots
 
             :return: is there a valid root below this node
             """
@@ -93,22 +93,24 @@
 
             if node.value_assignments:
                 # Has a value, never has a root cause
                 return False
 
             # Find any root for this equivalence
             n_has_root = any(
-                has_root(subnode)
-                for peernode in node.equivalence.nodes
-                for subnode in chain(
-                    self._assignment_step(peernode),
-                    self._parent_instance_step(peernode),
-                    self._child_attribute_step(peernode),
+                (
+                    has_root(subnode)
+                    for peernode in node.equivalence.nodes
+                    for subnode in chain(
+                        self._assignment_step(peernode),
+                        self._parent_instance_step(peernode),
+                        self._child_attribute_step(peernode),
+                    )
+                    if subnode not in node.equivalence.nodes
                 )
-                if subnode not in node.equivalence.nodes
             )
 
             # This equivalence is done
             seen.update(node.equivalence.nodes)
 
             n_is_root = not n_has_root
 
@@ -127,36 +129,36 @@
             return True
 
         for node in self.nodes:
             has_root(node)
 
         return roots
 
-    def _assignment_step(self, node: AssignableNode) -> frozenset[AssignableNode]:
+    def _assignment_step(self, node: AssignableNode) -> FrozenSet[AssignableNode]:
         """
         Performs one propagation step according to rule 2:
             is_cause(c, x) <- exists y: is_cause(c, y) and is_cause(y, x)
             (Cause is transitive)
         """
         return frozenset(node for assignment in node.assignable_assignments for node in assignment.rhs.nodes())
 
-    def _child_attribute_step(self, node: AssignableNode) -> frozenset[AssignableNode]:
+    def _child_attribute_step(self, node: AssignableNode) -> FrozenSet[AssignableNode]:
         """
         Performs one propagation step according to rule 3:
             is_cause(c, x) <- exists i : is_index_attr(x, i) and is_cause(c, x.i)
             (If an index attribute of x is unset this blocks execution. If c is the cause for the index
                 value being unset, it is the cause for x being unset)
         """
         return frozenset(
             index_attribute
             for instance_assignment in node.instance_assignments
             for index_attribute in instance_assignment.rhs.top_node().get_index_attributes()
         )
 
-    def _parent_instance_step(self, node: AssignableNode) -> frozenset[AssignableNode]:
+    def _parent_instance_step(self, node: AssignableNode) -> FrozenSet[AssignableNode]:
         """
         Performs one propagation step according to rule 4:
             is_cause(c, x) <- exists y, z : `x = y.z` in graph and is_cause(c, y)
             (If x refers to y.z but y is unset, this blocks execution. If c is the cause for y being unset,
                 it is the cause for x being unset)
         """
         return frozenset(
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/proxy.py` & `inmanta-core-9.3.0/src/inmanta/execute/proxy.py`

 * *Files 4% similar despite different names*

```diff
@@ -12,17 +12,17 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from collections.abc import Callable, Iterable, Mapping, Sequence
+from collections.abc import Mapping
 from copy import copy
-from typing import Optional, Union
+from typing import Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union
 
 from inmanta.ast import NotFoundException, RuntimeException
 from inmanta.execute.util import NoneValue, Unknown
 from inmanta.stable_api import stable_api
 from inmanta.types import PrimitiveTypes
 from inmanta.util import JSONSerializable
 
@@ -69,14 +69,16 @@
 class AttributeNotFound(NotFoundException, AttributeError):
     """
     Exception used for backwards compatibility with try-except blocks around some_proxy.some_attr.
     This previously raised `NotFoundException` which is currently deprecated in this context.
     Its new behavior is to raise an AttributeError for compatibility with Python's builtin `hasattr`.
     """
 
+    pass
+
 
 @stable_api
 class DynamicProxy:
     """
     This class wraps an object and makes sure that a model is never modified
     by native code.
     """
@@ -99,28 +101,28 @@
             return item._get_instance()
 
         if isinstance(item, list):
             return [cls.unwrap(x) for x in item]
 
         if isinstance(item, dict):
 
-            def recurse_dict_item(key_value: tuple[object, object]) -> tuple[object, object]:
+            def recurse_dict_item(key_value: Tuple[object, object]) -> Tuple[object, object]:
                 (key, value) = key_value
                 if not isinstance(key, str):
                     raise RuntimeException(
-                        None, f"dict keys should be strings, got {key} of type {type(key)} with dict value {value}"
+                        None, "dict keys should be strings, got %s of type %s with dict value %s" % (key, type(key), value)
                     )
                 return (key, cls.unwrap(value))
 
             return dict(map(recurse_dict_item, item.items()))
 
         return item
 
     @classmethod
-    def return_value(cls, value: object) -> Union[None, str, tuple[object, ...], int, float, bool, "DynamicProxy"]:
+    def return_value(cls, value: object) -> Union[None, str, Tuple[object, ...], int, float, bool, "DynamicProxy"]:
         """
         Converts a value from the internal domain to the plugin domain.
         """
         if value is None:
             return None
 
         if isinstance(value, NoneValue):
@@ -197,51 +199,51 @@
 class SequenceProxy(DynamicProxy, JSONSerializable):
     def __init__(self, iterator: Sequence) -> None:
         DynamicProxy.__init__(self, iterator)
 
     def __getitem__(self, key: str) -> object:
         instance = self._get_instance()
         if isinstance(key, str):
-            raise RuntimeException(self, f"can not get a attribute {key}, {self._get_instance()} is a list")
+            raise RuntimeException(self, "can not get a attribute %s, %s is a list" % (key, self._get_instance()))
 
         return DynamicProxy.return_value(instance[key])
 
     def __len__(self) -> int:
         return len(self._get_instance())
 
     def __iter__(self) -> Iterable:
         instance = self._get_instance()
 
         return IteratorProxy(instance.__iter__())
 
-    def json_serialization_step(self) -> list[PrimitiveTypes]:
+    def json_serialization_step(self) -> List[PrimitiveTypes]:
         # Ensure proper unwrapping by using __getitem__
         return [i for i in self]
 
 
 class DictProxy(DynamicProxy, Mapping, JSONSerializable):
-    def __init__(self, mydict: dict[object, object]) -> None:
+    def __init__(self, mydict: Dict[object, object]) -> None:
         DynamicProxy.__init__(self, mydict)
 
     def __getitem__(self, key):
         instance = self._get_instance()
         if not isinstance(key, str):
-            raise RuntimeException(self, f"Expected string key, but got {key}, {self._get_instance()} is a dict")
+            raise RuntimeException(self, "Expected string key, but got %s, %s is a dict" % (key, self._get_instance()))
 
         return DynamicProxy.return_value(instance[key])
 
     def __len__(self) -> int:
         return len(self._get_instance())
 
     def __iter__(self):
         instance = self._get_instance()
 
         return IteratorProxy(instance.__iter__())
 
-    def json_serialization_step(self) -> dict[str, PrimitiveTypes]:
+    def json_serialization_step(self) -> Dict[str, PrimitiveTypes]:
         # Ensure proper unwrapping by using __getitem__
         return {k: v for k, v in self.items()}
 
 
 class CallProxy(DynamicProxy):
     """
     Proxy a value that implements a __call__ function
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/runtime.py` & `inmanta-core-9.3.0/src/inmanta/execute/runtime.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,16 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 from abc import abstractmethod
-from collections.abc import Hashable, Sequence
-from typing import TYPE_CHECKING, Deque, Generic, List, Literal, Optional, TypeVar, Union, cast
+from typing import TYPE_CHECKING, Deque, Dict, Generic, Hashable, List, Optional, Set, TypeVar, Union, cast
 
 import inmanta.ast.attribute  # noqa: F401 (pyflakes does not recognize partially qualified access ast.attribute)
 from inmanta import ast
 from inmanta.ast import (
     AttributeException,
     CompilerException,
     DoubleSetException,
@@ -68,36 +67,21 @@
         This is a static property of a result collector, i.e. this method will always have the same result at any point within
         the lifetime of the instance.
         """
         return True
 
     def receive_result(self, value: T_contra, location: Location) -> bool:
         """
-        Receive a single value for gradual execution. Called once for each value that is part of the result. May be `null` or
-        Unknown. Does not distinguish between Unknown as an element of a list and Unknown as a top-level value.
+        Receive a single value for gradual execution. Called once for each value that is part of the result.
 
         :return: Whether this collector is complete, i.e. it does not need to receive any further results and its associated
             waiter will no longer cause progress. Once this is signalled, this instance should get no further results.
         """
         raise NotImplementedError()
 
-    def receive_result_flatten(self, value: Union[T_contra, Sequence[T_contra]], location: Location) -> bool:
-        """
-        Receive one or more values for gradual execution. When a list is passed, its values will be passed to receive_result
-        one by one. Otherwise the value itself is passed unmodified.
-
-        :return: Whether this collector is complete, i.e. it does not need to receive any further results and its associated
-            waiter will no longer cause progress. Once this is signalled, this instance should get no further results.
-        """
-        for subvalue in value if isinstance(value, list) else [value]:
-            done: bool = self.receive_result(subvalue, location)
-            if done:
-                return True
-        return False
-
 
 class IPromise:
     """
     A promise to the owner to provide a value or progression towards a value in some way, either directly or indirectly.
     To provide strict provider tracking, overpromising is allowed in case of uncertainty as to whether progression towards
     a value will be made, as long as progression towards certainty is made.
     """
@@ -113,14 +97,15 @@
     __slots__ = ()
 
     @abstractmethod
     def set_value(self, value: T, location: Location) -> None:
         """
         Fulfills this promise by setting the owner's value and notifying the owner of the promise's completion.
         """
+        pass
 
 
 class ProgressionPromise(IPromise):
     """
     A promise from a provider to the owner to progress towards setting a value, for example by emitting additional statements.
     """
 
@@ -154,28 +139,26 @@
         """
         Returns the value object for this variable
 
         :raises OptionalValueException: This is an optional variable that has not received a value (or explicit `null`).
         """
         raise NotImplementedError()
 
-    def listener(self, resultcollector: ResultCollector[T_co], location: Location) -> bool:
+    def listener(self, resultcollector: ResultCollector[T_co], location: Location) -> None:
         """
         Add a listener to report new values to. If the variable already has a value, this is reported immediately. Explicit
         assignments of `null` will not be reported.
 
         Each listener is expected to register one associated waiter to track completeness. The progress potential implementation
         is based on this invariant.
 
         :param resultcollector: The collector for the values of this variable.
         :param location: The location associated with this listener.
-        :return: True iff this variable will report values to the listener. Simple variables may not implement the listen
-            capability and will return False. A variable will always return the same value regardless of the parameters.
         """
-        return False
+        raise NotImplementedError()
 
     def waitfor(self, waiter: "Waiter") -> None:
         """
         Informs this variable that a waiter waits on its value. Once the variable receives a value, it should inform the waiter.
         """
         raise NotImplementedError()
 
@@ -208,17 +191,17 @@
 
     def is_ready(self) -> bool:
         return True
 
     def get_value(self) -> T:
         return self.value
 
-    def listener(self, resultcollector: ResultCollector[T], location: Location) -> Literal[True]:
-        resultcollector.receive_result(self.value, location)
-        return True
+    def listener(self, resultcollector: ResultCollector[T], location: Location) -> None:
+        if not isinstance(self.value, NoneValue):
+            resultcollector.receive_result(self.value, location)
 
     def waitfor(self, waiter: "Waiter") -> None:
         waiter.ready(self)
 
 
 class ResultVariable(VariableABC[T], ResultCollector[T], ISetPromise[T]):
     """
@@ -256,14 +239,15 @@
 
     def fulfill(self, promise: IPromise) -> None:
         """
         Considers the given promise fulfilled. Idempotent. Should only be called with promises that were handed out by thie
         variable.
         """
         # plain ResultVariable does not track promises -> simply return
+        pass
 
     def is_ready(self) -> bool:
         return self.hasValue
 
     def waitfor(self, waiter: "Waiter") -> None:
         if self.is_ready():
             waiter.ready(self)
@@ -303,14 +287,20 @@
 
     def freeze(self) -> None:
         pass
 
     def receive_result(self, value: T, location: Location) -> bool:
         return True
 
+    def listener(self, resultcollector: ResultCollector[T], location: Location) -> None:
+        """
+        Add a listener to report new values to, only for lists. Explicit assignments of `null` will not be reported.
+        """
+        pass
+
     def is_multi(self) -> bool:
         return False
 
     def set_dataflow_node(self, node: dataflow.AssignableNodeReference) -> None:
         assert self._node is None or self._node == node
         self._node = node
         self._node.set_result_variable(self)
@@ -326,87 +316,69 @@
     listeners who will receive this single value.
     """
 
     def __init__(self, value: T, location: Location) -> None:
         super().__init__()
         self.set_value(value, location)
 
-    def listener(self, resultcollector: ResultCollector[T], location: Location) -> Literal[True]:
+    def listener(self, resultcollector: ResultCollector[T], location: Location) -> None:
         assert self.value is not None
-        resultcollector.receive_result(self.value, location)
-        return True
+        if not isinstance(self.value, NoneValue):
+            resultcollector.receive_result(self.value, location)
 
 
 class ResultVariableProxy(VariableABC[T]):
     """
     A proxy for a reading from a ResultVariable that implements the VariableABC interface. Allows for assignment between
-    variables without resolving the right hand side at the time of assignment. Supports a single listener to be registered
-    at construction. This class will ensure that the connected variable's value(s) is (are) reported to the listener, even if
-    the variable itself does not support listeners.
+    variables without resolving the right hand side at the time of assignment.
     This class does not support setting values or related operations such as acquiring progression promises.
     """
 
-    __slots__ = ("variable", "_listener", "_waiters", "_notify_listeners")
+    __slots__ = ("variable", "_listeners", "_waiters")
 
-    def __init__(
-        self, variable: Optional[VariableABC[T]] = None, listener: Optional[tuple[ResultCollector[T], Location]] = None
-    ) -> None:
+    def __init__(self, variable: Optional[VariableABC[T]] = None) -> None:
         self.variable: Optional[VariableABC[T]] = variable
-        self._listener: Optional[tuple[ResultCollector[T], Location]] = listener
+        self._listeners: Optional[list[tuple[ResultCollector[T], Location]]] = []
         self._waiters: Optional[list["Waiter"]] = []
-        # are we responsible for notifying listeners ourselves?
-        self._notify_listeners: bool = False
 
     def connect(self, variable: VariableABC[T]) -> None:
         """
         Connect this proxy to a variable. A proxy can only be connected to a single variable.
         """
         if self.variable is not None and self.variable != variable:
             raise Exception("Trying to connect a variable to a proxy that is already connected to another variable.")
         self.variable = variable
+        assert self._listeners is not None  # only set to None after a variable is connected to prevent data leaks
         assert self._waiters is not None  # only set to None after a variable is connected to prevent data leaks
-        if self._listener is not None:
-            registered_listener: bool = self.variable.listener(*self._listener)
-            if registered_listener:
-                # clear listener to prevent data leaks
-                self._listener = None
-            else:
-                # variable does not support listeners, we'll have to notify the listener ourselves
-                self._notify_listeners = True
+        for listener in self._listeners:
+            self.variable.listener(*listener)
         for waiter in self._waiters:
             self.variable.waitfor(waiter)
-        # clear waiters to prevent data leaks
+        self._listeners = None
         self._waiters = None
 
     def is_ready(self) -> bool:
         return self.variable is not None and self.variable.is_ready()
 
     def get_value(self) -> T:
         """
         Returns the value object for this variable
         """
         if self.variable is None:
             raise Exception(
                 "Trying to get value for proxy variable that has not been connected yet. Use `waitfor` to wait for a value."
             )
-        value: T = self.variable.get_value()
-        if self._notify_listeners:
-            assert self._listener is not None
-            listener, location = self._listener
-            # simple case: single value. Multi-value variables implement their own listener functionality
-            listener.receive_result_flatten(value, location)
-            # clean up: prevent data leaks and ensure listener is only notified once
-            self._listener = None
-            self._notify_listeners = False
-        return value
-
-    def listener(self, resultcollector: ResultCollector[T], location: Location) -> Literal[False]:
-        # no need for this right now and implementing it greatly complicates the logic of this class
-        # a single listener can be registered at construction time
-        return False
+        return self.variable.get_value()
+
+    def listener(self, resultcollector: ResultCollector[T], location: Location) -> None:
+        if self.variable is None:
+            assert self._listeners is not None  # only set to None after a variable is connected to prevent data leaks
+            self._listeners.append((resultcollector, location))
+        else:
+            self.variable.listener(resultcollector, location)
 
     def waitfor(self, waiter: "Waiter") -> None:
         """
         Informs this variable that a waiter waits on its value. Once the variable receives a value, it should inform the waiter.
         """
         if self.variable is None:
             assert self._waiters is not None  # only set to None after a variable is connected to prevent data leaks
@@ -491,16 +463,16 @@
         (a queue variable can be dequeued by the scheduler when a provider is added)
     """
 
     __slots__ = ("queued", "queues", "promises", "done_promises")
 
     def __init__(self, queue: "QueueScheduler", value: Optional[T] = None) -> None:
         ResultVariable.__init__(self, value)
-        self.promises: Optional[list[IPromise]] = []
-        self.done_promises: Optional[set[IPromise]] = set()
+        self.promises: Optional[List[IPromise]] = []
+        self.done_promises: Optional[Set[IPromise]] = set()
         self.queued = False
         self.queues = queue
         if self.can_get():
             self.queue()
 
     def get_promise(self, provider: "Statement") -> ISetPromise[T]:
         promise: ISetPromise[T] = SetPromise(self, provider)
@@ -561,15 +533,15 @@
     def get_progress_potential(self) -> int:
         """
         Returns the number of blocked waiters, meaning any waiters that may progress when this variable is frozen.
         """
         return len(self.waiters)
 
 
-ListValue = Union["Instance", list["Instance"]]
+ListValue = Union["Instance", List["Instance"]]
 
 
 class BaseListVariable(DelayedResultVariable[ListValue]):
     """
     List variable, but only the part that is independent of an instance
     """
 
@@ -660,28 +632,27 @@
     def can_get(self) -> bool:
         return self.get_waiting_providers() == 0
 
     def receive_result(self, value: ListValue, location: Location) -> bool:
         self.set_value(value, location)
         return False
 
-    def listener(self, resultcollector: ResultCollector["Instance"], location: Location) -> Literal[True]:
+    def listener(self, resultcollector: ResultCollector["Instance"], location: Location) -> None:
         for value in self.value:
             resultcollector.receive_result(value, location)
         if not self.hasValue:
             assert self._listeners is not None
             if resultcollector in self._listeners:
                 # may happen in case of a duplicate assignment, e.g. `x.a = [y.a, y.a]`
                 # consider the new one to have no progress potential because we don't track it separately
                 self._nb_gradual_waiters += 1
-                return True
+                return
             self._listeners[resultcollector] = None
             if resultcollector.pure_gradual():
                 self._nb_gradual_waiters += 1
-        return True
 
     def is_multi(self) -> bool:
         return True
 
     def get_progress_potential(self) -> int:
         # purely gradual waiters aren't blocked on this variable being frozen
         return len(self.waiters) - self._nb_gradual_waiters
@@ -747,15 +718,15 @@
             return
         try:
             if not self._set_value(value, location, recur):
                 return
         except ModifiedAfterFreezeException as e:
             if len(self.value) == self.attribute.high:
                 new_exception: CompilerException = RuntimeException(
-                    None, f"Exceeded relation arity on attribute '{self.attribute.name}' of instance '{self.myself}'"
+                    None, "Exceeded relation arity on attribute '%s' of instance '%s'" % (self.attribute.name, self.myself)
                 )
                 new_exception.set_location(location)
                 raise new_exception
             raise e
         # set counterpart
         if self.attribute.end is not None and recur:
             value.set_attribute(self.attribute.end.name, self.myself, location, False)
@@ -772,15 +743,15 @@
         if self.can_get():
             self.queue()
 
     def can_get(self) -> bool:
         return len(self.value) >= self.attribute.low and self.get_waiting_providers() == 0
 
     def __str__(self) -> str:
-        return f"ListVariable {self.myself} {self.attribute} = {self.value}"
+        return "ListVariable %s %s = %s" % (self.myself, self.attribute, self.value)
 
     def get_progress_potential(self) -> int:
         # Ensure that relationships with a relation precedence rule cannot end up in the zerowaiters queue
         # of the scheduler. We know the order in which those types can be frozen safely.
         return super().get_progress_potential() + int(self.attribute.has_relation_precedence_rules())
 
 
@@ -843,36 +814,36 @@
     def get_value(self) -> "Instance":
         result = DelayedResultVariable.get_value(self)
         if result is None:
             raise OptionalValueException(self.myself, self.attribute)
         return result
 
     def __str__(self) -> str:
-        return f"OptionVariable {self.myself} {self.attribute} = {self.value}"
+        return "OptionVariable %s %s = %s" % (self.myself, self.attribute, self.value)
 
     def get_progress_potential(self) -> int:
         return super().get_progress_potential() + int(self.attribute.has_relation_precedence_rules())
 
 
-class QueueScheduler:
+class QueueScheduler(object):
     """
     Object representing the compiler to the AST nodes. It provides access to the queueing mechanism and the type system.
 
     MUTABLE!
     """
 
     __slots__ = ("compiler", "runqueue", "waitqueue", "types", "allwaiters")
 
     def __init__(
         self,
         compiler: "Compiler",
         runqueue: "Deque[Waiter]",
         waitqueue: "PrioritisedDelayedResultVariableQueue",
-        types: dict[str, Type],
-        allwaiters: "set[Waiter]",
+        types: Dict[str, Type],
+        allwaiters: "Set[Waiter]",
     ) -> None:
         self.compiler = compiler
         self.runqueue = runqueue
         self.waitqueue = waitqueue
         self.types = types
         self.allwaiters = allwaiters
 
@@ -881,15 +852,15 @@
 
     def add_possible(self, rv: DelayedResultVariable) -> None:
         self.waitqueue.append(rv)
 
     def get_compiler(self) -> "Compiler":
         return self.compiler
 
-    def get_types(self) -> dict[str, Type]:
+    def get_types(self) -> Dict[str, Type]:
         return self.types
 
     def add_to_all(self, item: "Waiter") -> None:
         self.allwaiters.add(item)
 
     def remove_from_all(self, item: "Waiter") -> None:
         self.allwaiters.remove(item)
@@ -913,15 +884,15 @@
 
     def add_possible(self, rv: DelayedResultVariable) -> None:
         self.__delegate.add_possible(rv)
 
     def get_compiler(self) -> "Compiler":
         return self.__delegate.get_compiler()
 
-    def get_types(self) -> dict[str, Type]:
+    def get_types(self) -> Dict[str, Type]:
         return self.__delegate.get_types()
 
     def add_to_all(self, item: "Waiter") -> None:
         self.__delegate.add_to_all(item)
 
     def remove_from_all(self, item: "Waiter") -> None:
         self.__delegate.remove_from_all(item)
@@ -929,22 +900,22 @@
     def get_tracker(self) -> Tracker:
         return self.__tracker
 
     def for_tracker(self, tracer: Tracker) -> QueueScheduler:
         return DelegateQueueScheduler(self.__delegate, tracer)
 
 
-class Waiter:
+class Waiter(object):
     """
     Waiters represent an executable unit, that can be executed the result variables they depend on have their values.
     """
 
     __slots__ = ("waitcount", "queue", "done", "requires")
 
-    requires: dict[object, VariableABC]
+    requires: Dict[object, VariableABC]
 
     def __init__(self, queue: QueueScheduler):
         self.waitcount = 1
         self.queue = queue
         self.queue.add_to_all(self)
         self.done = False
 
@@ -983,15 +954,15 @@
     __slots__ = ("result", "expression", "resolver", "queue_scheduler", "owner")
 
     def __init__(
         self,
         queue_scheduler: QueueScheduler,
         resolver: "Resolver",
         result: ResultVariable[object],
-        requires: dict[object, VariableABC],
+        requires: Dict[object, VariableABC],
         expression: "RequiresEmitStatement",
         owner: "Optional[Statement]" = None,
     ):
         Waiter.__init__(self, queue_scheduler)
         self.result: ISetPromise[object] = result.get_promise(expression)
         self.requires = requires
         self.expression = expression
@@ -1011,15 +982,16 @@
         self.result.set_value(value, self.expression.location)
         self.done = True
 
     def execute(self) -> None:
         try:
             self._unsafe_execute()
         except RuntimeException as e:
-            e.set_statement(self.owner, False)
+            e.set_statement(self.owner)
+            e.location = self.owner.location
             raise e
 
     def __repr__(self) -> str:
         return repr(self.expression)
 
 
 class HangUnit(Waiter):
@@ -1029,15 +1001,15 @@
 
     __slots__ = ("resolver", "resumer", "target")
 
     def __init__(
         self,
         queue_scheduler: QueueScheduler,
         resolver: "Resolver",
-        requires: dict[object, VariableABC],
+        requires: Dict[object, VariableABC],
         target: Optional[ResultVariable],
         resumer: "Resumer",
     ) -> None:
         Waiter.__init__(self, queue_scheduler)
         self.resolver = resolver
         self.requires = requires
         self.resumer = resumer
@@ -1063,15 +1035,15 @@
 
     __slots__ = ("resolver", "resumer", "override_exception_location")
 
     def __init__(
         self,
         queue_scheduler: QueueScheduler,
         resolver: "Resolver",
-        requires: dict[object, VariableABC],
+        requires: Dict[object, VariableABC],
         resumer: "RawResumer",
         override_exception_location: bool = True,
     ) -> None:
         Waiter.__init__(self, queue_scheduler)
         self.resolver = resolver
         self.requires = requires
         self.resumer = resumer
@@ -1105,15 +1077,15 @@
  - N: to resolver -> to parents -> to NS (lex root) -> directlookup
 
 """
 
 Typeorvalue = Union[Type, ResultVariable]
 
 
-class Resolver:
+class Resolver(object):
     __slots__ = ("namespace", "dataflow_graph")
 
     def __init__(self, namespace: Namespace, enable_dataflow_graph: bool = False) -> None:
         self.namespace = namespace
         self.dataflow_graph: Optional[DataflowGraph] = DataflowGraph(self) if enable_dataflow_graph else None
 
     def lookup(self, name: str, root: Optional[Namespace] = None) -> Typeorvalue:
@@ -1196,15 +1168,15 @@
 
 
 class ExecutionContext(Resolver):
     __slots__ = ("block", "slots", "resolver")
 
     def __init__(self, block: "BasicBlock", resolver: Resolver):
         self.block = block
-        self.slots: dict[str, ResultVariable] = {n: ResultVariable() for n in block.get_variables()}
+        self.slots: Dict[str, ResultVariable] = {n: ResultVariable() for n in block.get_variables()}
         self.resolver = resolver
         self.dataflow_graph: Optional[DataflowGraph] = None
         if resolver.dataflow_graph is not None:
             self.dataflow_graph = DataflowGraph(self, resolver.dataflow_graph)
             for name, var in self.slots.items():
                 node_ref: dataflow.AssignableNodeReference = dataflow.AssignableNode(name).reference()
                 var.set_dataflow_node(node_ref)
@@ -1261,15 +1233,15 @@
         queue: QueueScheduler,
         node: Optional["dataflow.InstanceNodeReference"] = None,
     ) -> None:
         Locatable.__init__(self)
         # ExecutionContext, Resolver -> this class only uses it as an "interface", so no constructor call!
         self.resolver = resolver.get_root_resolver()
         self.type = mytype
-        self.slots: dict[str, ResultVariable] = {}
+        self.slots: Dict[str, ResultVariable] = {}
         for attr_name in mytype.get_all_attribute_names():
             if attr_name in self.slots:
                 # prune duplicates because get_new_result_variable() has side effects
                 # don't use set for pruning because side effects drive control flow and set iteration is nondeterministic
                 continue
             attribute = mytype.get_attribute(attr_name)
             assert attribute is not None  # Make mypy happy
@@ -1287,51 +1259,51 @@
         self.slots["self"].set_value(self, None)
         if self.instance_node is not None:
             self_var_node: dataflow.AssignableNodeReference = dataflow.AssignableNode("__self__").reference()
             self_var_node.assign(self.instance_node, self, cast(DataflowGraph, self.dataflow_graph))
             self.slots["self"].set_dataflow_node(self_var_node)
 
         self.sid = id(self)
-        self.implementations: "set[Implementation]" = set()
+        self.implementations: "Set[Implementation]" = set()
 
         # see inmanta.ast.execute.scheduler.QueueScheduler
-        self.trackers: list[Tracker] = []
+        self.trackers: List[Tracker] = []
 
-        self.locations: list[Location] = []
+        self.locations: List[Location] = []
 
     def get_type(self) -> "Entity":
         return self.type
 
     def set_attribute(self, name: str, value: object, location: Location, recur: bool = True) -> None:
         if name not in self.slots:
-            raise NotFoundException(None, name, f"cannot set attribute with name {name} on type {str(self.type)}")
+            raise NotFoundException(None, name, "cannot set attribute with name %s on type %s" % (name, str(self.type)))
         try:
             self.slots[name].set_value(value, location, recur)
         except RuntimeException as e:
             raise AttributeException(self, self, name, cause=e)
 
     def get_attribute(self, name: str) -> ResultVariable:
         try:
             return self.slots[name]
         except KeyError:
-            raise NotFoundException(None, name, f"could not find attribute with name: {name} in type {self.type}")
+            raise NotFoundException(None, name, "could not find attribute with name: %s in type %s" % (name, self.type))
 
     def __repr__(self) -> str:
-        return f"{self.type} {self.sid:02x}"
+        return "%s %02x" % (self.type, self.sid)
 
     def __str__(self) -> str:
-        return "{} (instantiated at {})".format(self.type, ",".join([str(location) for location in self.get_locations()]))
+        return "%s (instantiated at %s)" % (self.type, ",".join([str(location) for location in self.get_locations()]))
 
     def add_implementation(self, impl: "Implementation") -> bool:
         if impl in self.implementations:
             return False
         self.implementations.add(impl)
         return True
 
-    def final(self, excns: list[CompilerException]) -> None:
+    def final(self, excns: List[CompilerException]) -> None:
         """
         The object should be complete, freeze all attributes
         """
         if len(self.implementations) == 0:
             excns.append(RuntimeException(self, "Unable to select implementation for entity %s" % self.type.name))
 
         for k, v in self.slots.items():
@@ -1353,32 +1325,32 @@
                                 self,
                                 attr,
                             )
                         )
                     else:
                         excns.append(
                             proxy.UnsetException(
-                                f"The object {self} is not complete: attribute {k} ({attr.location}) is not set",
+                                "The object %s is not complete: attribute %s (%s) is not set" % (self, k, attr.location),
                                 self,
                                 attr,
                             )
                         )
 
     def dump(self) -> None:
         print("------------ ")
         print(str(self))
         print("------------ ")
         for n, v in self.slots.items():
             if v.can_get():
                 value = v.value
-                print(f"{n}\t\t{value}")
+                print("%s\t\t%s" % (n, value))
             else:
-                print("BAD: {}\t\t{}".format(n, ", ".join(repr(prom) for prom in v.promises)))
+                print("BAD: %s\t\t%s" % (n, ", ".join(repr(prom) for prom in v.promises)))
 
     def verify_done(self) -> bool:
         for v in self.slots.values():
             if not v.can_get():
                 return False
         return True
 
-    def get_locations(self) -> list[Location]:
+    def get_locations(self) -> List[Location]:
         return self.locations
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/scheduler.py` & `inmanta-core-9.3.0/src/inmanta/execute/scheduler.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,16 +16,15 @@
     Contact: code@inmanta.com
 """
 import itertools
 import logging
 import os
 import time
 from collections import deque
-from collections.abc import Iterable, Iterator, Sequence
-from typing import TYPE_CHECKING, Any, Deque, Optional
+from typing import TYPE_CHECKING, Any, Deque, Dict, Iterable, Iterator, List, Optional, Sequence, Set, Tuple
 
 from inmanta import plugins
 from inmanta.ast import Anchor, AnchorTarget, CompilerException, CycleException, Location, MultiException, RuntimeException
 from inmanta.ast.attribute import RelationAttribute
 from inmanta.ast.entity import Entity, Implementation
 from inmanta.ast.statements import DefinitionStatement, TypeDefinitionStatement
 from inmanta.ast.statements.define import DefineEntity, DefineImplement, DefineIndex, DefineRelation, DefineTypeConstraint
@@ -52,34 +51,34 @@
     from inmanta.module import RelationPrecedenceRule
 
 
 DEBUG = True
 LOGGER = logging.getLogger(__name__)
 
 
-MAX_ITERATIONS = 100_000
+MAX_ITERATIONS = 10000
 
 
-class Scheduler:
+class Scheduler(object):
     """
     This class schedules statements for execution
     """
 
     def __init__(
-        self, track_dataflow: bool = False, relation_precedence_rules: Optional[list["RelationPrecedenceRule"]] = None
+        self, track_dataflow: bool = False, relation_precedence_rules: Optional[List["RelationPrecedenceRule"]] = None
     ) -> None:
         if relation_precedence_rules is None:
             relation_precedence_rules = []
         self.track_dataflow: bool = track_dataflow
-        self.types: dict[str, Type] = {}
+        self.types: Dict[str, Type] = {}
         # The precedence rules specified in the project.yml file. This list may contain rules that are invalid with
         # respect to the model.
-        self.relation_precedence_rules: list["RelationPrecedenceRule"] = relation_precedence_rules
+        self.relation_precedence_rules: List["RelationPrecedenceRule"] = relation_precedence_rules
 
-    def _set_precedence_rules_on_relationship_attributes(self) -> list[RelationAttribute]:
+    def _set_precedence_rules_on_relationship_attributes(self) -> List[RelationAttribute]:
         """
         This method:
            * Validates the relation precedence rules in self.relation_precedence_policy and raises an exception for invalid
              relation precedence rules.
            * Set the RelationAttribute.relation_precedence_rules field on all RelationAttributes.
            * Returns the list of RelationAttributes for which a relation precedence policy exists saying that it should
              be frozen before another RelationshipAttribute.
@@ -130,55 +129,55 @@
         if not isinstance(attribute, RelationAttribute):
             raise InvalidRelationPrecedenceRuleError(
                 f"A relation precedence rule was defined for {entity_type_name}.{relationship_name}, "
                 f"but attribute {relationship_name} is not a relationship attribute.",
             )
         return attribute
 
-    def freeze_all(self, exns: list[CompilerException]) -> None:
+    def freeze_all(self, exns: List[CompilerException]) -> None:
         for t in [t for t in self.types.values() if isinstance(t, Entity)]:
             t.final(exns)
 
-        instances: list[Instance] = self.types["std::Entity"].get_all_instances()
+        instances: List[Instance] = self.types["std::Entity"].get_all_instances()
 
         for i in instances:
             i.final(exns)
 
     def dump(self, type: str = "std::Entity") -> None:
-        instances: list[Instance] = self.types[type].get_all_instances()
+        instances: List[Instance] = self.types[type].get_all_instances()
 
         for i in instances:
             i.dump()
 
-    def verify_done(self) -> list[Instance]:
-        instances: list[Instance] = self.types["std::Entity"].get_all_instances()
+    def verify_done(self) -> List[Instance]:
+        instances: List[Instance] = self.types["std::Entity"].get_all_instances()
         notdone = []
         for i in instances:
             if not i.verify_done():
                 notdone.append(i)
 
         return notdone
 
-    def get_types(self) -> dict[str, Type]:
+    def get_types(self) -> Dict[str, Type]:
         return self.types
 
     def dump_not_done(self) -> None:
         for i in self.verify_done():
             i.dump()
 
-    def sort_entities(self, entity_map: dict[str, DefineEntity]) -> list[DefineEntity]:
-        out: list[DefineEntity] = []
-        loopstack: set[str] = set()
+    def sort_entities(self, entity_map: Dict[str, DefineEntity]) -> List[DefineEntity]:
+        out: List[DefineEntity] = []
+        loopstack: Set[str] = set()
         while len(entity_map) > 0:
             workon = next(iter(entity_map.keys()))
             self.do_sort_entities(entity_map, workon, out, loopstack)
         return out
 
     def do_sort_entities(
-        self, entity_map: dict[str, DefineEntity], name: str, acc: list[DefineEntity], loopstack: set[str]
+        self, entity_map: Dict[str, DefineEntity], name: str, acc: List[DefineEntity], loopstack: Set[str]
     ) -> None:
         nexte = entity_map[name]
         try:
             del entity_map[name]
             loopstack.add(name)
             for p in nexte.get_full_parent_names():
                 if p in loopstack:
@@ -192,38 +191,38 @@
             raise
 
     def define_types(self, compiler: "Compiler", statements: Sequence["Statement"], blocks: Sequence["BasicBlock"]) -> None:
         """
         This is the first compiler stage that defines all types_and_impl
         """
         # get all relevant stmts
-        definitions: list["DefinitionStatement"] = [d for d in statements if isinstance(d, DefinitionStatement)]
-        others: list["Statement"] = [d for d in statements if not isinstance(d, DefinitionStatement)]
+        definitions: List["DefinitionStatement"] = [d for d in statements if isinstance(d, DefinitionStatement)]
+        others: List["Statement"] = [d for d in statements if not isinstance(d, DefinitionStatement)]
 
         if not len(others) == 0:
             raise Exception("others not empty %s" % repr(others))
 
         # collect all  types and impls
         types_and_impl = {}
 
         # set primitive types
         compiler.get_ns().set_primitives(TYPES)
 
         # all stmts contributing types and impls
-        newtypes: list[tuple[str, NamedType]] = [
+        newtypes: List[Tuple[str, NamedType]] = [
             k for k in [t.register_types() for t in definitions if isinstance(t, TypeDefinitionStatement)] if k is not None
         ]
 
         for name, type_symbol in newtypes:
             types_and_impl[name] = type_symbol
 
         # now that we have objects for all types, populate them
         implements = [t for t in definitions if isinstance(t, DefineImplement)]
         other_definitions = [t for t in definitions if not isinstance(t, DefineImplement)]
-        entities: dict[str, DefineEntity] = {t.fullName: t for t in other_definitions if isinstance(t, DefineEntity)}
+        entities: Dict[str, DefineEntity] = {t.fullName: t for t in other_definitions if isinstance(t, DefineEntity)}
         type_constraints = [t for t in other_definitions if isinstance(t, DefineTypeConstraint)]
         other_definitions = [t for t in other_definitions if not isinstance(t, (DefineEntity, DefineTypeConstraint))]
         indices = [t for t in other_definitions if isinstance(t, DefineIndex)]
         other_definitions = [t for t in other_definitions if not isinstance(t, DefineIndex)]
 
         # first type constraints so attribute defaults can be type checked
         for tc in type_constraints:
@@ -261,18 +260,15 @@
         for block in blocks:
             block.normalize()
 
         self.types = {k: v for k, v in types_and_impl.items() if isinstance(v, Type)}
 
     def get_anchormap(
         self, compiler: "Compiler", statements: Sequence["Statement"], blocks: Sequence["BasicBlock"]
-    ) -> Sequence[tuple[Location, AnchorTarget]]:
-        """
-        This function should only be called after normalization is done
-        """
+    ) -> Sequence[Tuple[Location, AnchorTarget]]:
         prev = time.time()
 
         # first evaluate all definitions, this should be done in one iteration
         self.define_types(compiler, statements, blocks)
 
         # relations are also in blocks
         not_relation_statements: Iterator[Statement] = (s for s in statements if not isinstance(s, DefineRelation))
@@ -290,24 +286,24 @@
         now = time.time()
         LOGGER.debug("Anchormap took %f seconds", now - prev)
 
         return range_to_anchor_target
 
     def anchormap(
         self, compiler: "Compiler", statements: Sequence["Statement"], blocks: Sequence["BasicBlock"]
-    ) -> Sequence[tuple[Location, Location]]:
+    ) -> Sequence[Tuple[Location, Location]]:
         """
         This methode exists for backward compatibility with inmantals
         """
         range_to_anchor_target = self.get_anchormap(compiler, statements, blocks)
         range_to_range = [(f, t.location) for f, t in range_to_anchor_target]
 
         return range_to_range
 
-    def find_wait_cycle(self, attributes_with_precedence_rule: list[RelationAttribute], allwaiters: set[Waiter]) -> bool:
+    def find_wait_cycle(self, attributes_with_precedence_rule: List[RelationAttribute], allwaiters: Set[Waiter]) -> bool:
         """
         Preconditions: no progress is made anymore
 
         This means that all DelayedResultVariable that have not been frozen either have
         no progress potential or have outstanding promises.
         In this case, all gradual execution has been executed to the maximal extent.
 
@@ -327,15 +323,15 @@
 
         def resolve_proxies(variable: Optional[VariableABC]) -> Optional[VariableABC]:
             if variable is None or not isinstance(variable, ResultVariableProxy):
                 return variable
             return resolve_proxies(variable.variable)
 
         # Determine drvs that should be frozen to break the cycle
-        freeze_candidates: list[DelayedResultVariable[object]] = []
+        freeze_candidates: List[DelayedResultVariable[object]] = []
         for waiter in allwaiters:
             for rv in waiter.requires.values():
                 real_rv: Optional[VariableABC] = resolve_proxies(rv)
                 if isinstance(real_rv, DelayedResultVariable):
                     if real_rv.hasValue:
                         # get_progress_potential fails when there is a value already
                         continue
@@ -343,28 +339,28 @@
                         freeze_candidates.append(real_rv)
 
         if not freeze_candidates:
             return False
         # Use the relation precedence rules to determine which drv should be frozen
         queue = PrioritisedDelayedResultVariableQueue(attributes_with_precedence_rule, freeze_candidates)
         drv_to_freeze = queue.popleft()
-        LOGGER.log(LOG_LEVEL_TRACE, "Waiting blocked on %s", drv_to_freeze)
+        LOGGER.debug("Waiting blocked on %s", drv_to_freeze)
         drv_to_freeze.freeze()
         return True
 
     def run(self, compiler: "Compiler", statements: Sequence["Statement"], blocks: Sequence["BasicBlock"]) -> bool:
         """
         Evaluate the current graph
         """
         prev = time.time()
         start = prev
 
         # first evaluate all definitions, this should be done in one iteration
         self.define_types(compiler, statements, blocks)
-        attributes_with_precedence_rule: list[RelationAttribute] = self._set_precedence_rules_on_relationship_attributes()
+        attributes_with_precedence_rule: List[RelationAttribute] = self._set_precedence_rules_on_relationship_attributes()
 
         # give all loose blocks an empty XC
         # register the XC's as scopes
         # All named scopes are now present
 
         for block in blocks:
             res = Resolver(block.namespace, self.track_dataflow)
@@ -377,15 +373,15 @@
         # queue for runnable items
         basequeue: Deque[Waiter] = deque()
         # queue for RV's that are delayed
         waitqueue = PrioritisedDelayedResultVariableQueue(attributes_with_precedence_rule)
         # queue for RV's that are delayed and had no effective waiters when they were first in the waitqueue
         zerowaiters: Deque[DelayedResultVariable[Any]] = deque()
         # queue containing everything, to find hanging statements
-        all_statements: set[Waiter] = set()
+        all_statements: Set[Waiter] = set()
 
         # Wrap in object to pass around
         queue = QueueScheduler(compiler, basequeue, waitqueue, self.types, all_statements)
 
         # emit all top level statements
         for block in blocks:
             block.context.emit(queue.for_tracker(ModuleTracker(block)))
@@ -399,16 +395,15 @@
 
             # check if we can stop the execution
             if len(basequeue) == 0 and len(waitqueue) == 0 and len(zerowaiters) == 0:
                 break
             else:
                 i += 1
 
-            LOGGER.log(
-                LOG_LEVEL_TRACE,
+            LOGGER.debug(
                 "Iteration %d (e: %d, w: %d, p: %d, done: %d, time: %f)",
                 i,
                 len(basequeue),
                 len(waitqueue),
                 len(zerowaiters),
                 count,
                 now - prev,
@@ -452,56 +447,55 @@
             # no waiters in waitqueue,...
             # see if any zerowaiters have become gotten waiters
             if not progress:
                 zerowaiters_tmp = [w for w in zerowaiters if not w.hasValue]
                 waitqueue.replace(w for w in zerowaiters_tmp if w.get_progress_potential() > 0)
                 zerowaiters = deque(w for w in zerowaiters_tmp if w.get_progress_potential() <= 0)
                 while len(waitqueue) > 0 and not progress:
-                    LOGGER.log(LOG_LEVEL_TRACE, "Moved zerowaiters to waiters")
+                    LOGGER.debug("Moved zerowaiters to waiters")
                     next_rv = waitqueue.popleft()
                     if next_rv.get_waiting_providers() > 0:
                         next_rv.unqueue()
                     else:
                         LOGGER.log(LOG_LEVEL_TRACE, "Freezing %s", next_rv)
                         next_rv.freeze()
                         progress = True
 
             if not progress:
                 # nothing works anymore, attempt to unfreeze wait cycle
                 progress = self.find_wait_cycle(attributes_with_precedence_rule, queue.allwaiters)
 
             if not progress:
                 # no one waiting anymore, all done, freeze and finish
-                LOGGER.log(LOG_LEVEL_TRACE, "Finishing statements with no waiters")
+                LOGGER.debug("Finishing statements with no waiters")
 
                 while len(zerowaiters) > 0:
                     next_rv = zerowaiters.pop()
                     next_rv.freeze()
 
         now = time.time()
-        LOGGER.log(
-            LOG_LEVEL_TRACE,
+        LOGGER.debug(
             "Iteration %d (e: %d, w: %d, p: %d, done: %d, time: %f)",
             i,
             len(basequeue),
             len(waitqueue),
             len(zerowaiters),
             count,
             now - prev,
         )
 
         if i == max_iterations:
             raise CompilerException(f"Could not complete model, max_iterations {max_iterations} reached.")
 
-        excns: list[CompilerException] = []
+        excns: List[CompilerException] = []
         self.freeze_all(excns)
 
         now = time.time()
-        LOGGER.debug(
-            "Compilation took %0.03f seconds",
+        LOGGER.info(
+            "Total compilation time %f",
             now - start,
         )
 
         if len(excns) == 0:
             pass
         elif len(excns) == 1:
             raise excns[0]
@@ -526,15 +520,15 @@
     """
     A CompilerException that is raised when the project.yml file
     contains a relation precedence rule that invalid with respect
     to the given project.
     """
 
     def __init__(self, msg: str) -> None:
-        super().__init__(msg)
+        super(InvalidRelationPrecedenceRuleError, self).__init__(msg)
 
 
 class PrioritisedDelayedResultVariableQueue:
     """
     A queue for DelayedResultVariables that is prioritized based on the
     relation precedence policy passed to the Compiler. This queue will return elements
     in the following order:
@@ -544,27 +538,27 @@
       They are returned in an order that is valid with respect to the constraints.
     * Finally, all DelayedResultVariables that are not associated with an entity are
       returned.
     """
 
     def __init__(
         self,
-        attributes_with_precedence_rule: list[RelationAttribute],
-        drvs: Optional[list[DelayedResultVariable[object]]] = None,
+        attributes_with_precedence_rule: List[RelationAttribute],
+        drvs: Optional[List[DelayedResultVariable[object]]] = None,
     ) -> None:
         relation_precedence_graph = RelationPrecedenceGraph(attributes_with_precedence_rule)
         # A queue that indicates a valid order in which the self._constraint_variables have to be returned
         # This queue is never modified.
         self._freeze_order: Deque[RelationAttribute] = deque(relation_precedence_graph.get_freeze_order())
         # Copy of self._freeze_order. At all times the first element of this queue
         # points to the next type that should be returned from self._constraint_variables
         self._freeze_order_working_list: Deque[RelationAttribute] = self._freeze_order.copy()
 
         self._unconstraint_variables: Deque[DelayedResultVariable[object]] = deque()
-        self._constraint_variables: dict[RelationAttribute, Deque[DelayedResultVariable[object]]] = {
+        self._constraint_variables: Dict[RelationAttribute, Deque[DelayedResultVariable[object]]] = {
             relation_attribute: deque() for relation_attribute in self._freeze_order
         }
         self._non_relation_variables: Deque[DelayedResultVariable] = deque()
 
         # Populate queue with given DelayedResultVariables
         drvs = drvs if drvs else []
         for drv in drvs:
@@ -639,28 +633,28 @@
 
 class CycleInRelationPrecedencePolicyError(CompilerException):
     """
     Raised when a cycle exists in the relation precedence rules provided to the compiler.
     """
 
     def __init__(self) -> None:
-        super().__init__("A cycle exists in the relation precedence policy")
+        super(CycleInRelationPrecedencePolicyError, self).__init__("A cycle exists in the relation precedence policy")
 
 
 class RelationPrecedenceGraph:
     """
     A graph representation of the relation precedence policy provided to the compiler.
     """
 
-    def __init__(self, relation_attributes_with_precedence_rule: Optional[list[RelationAttribute]] = None) -> None:
+    def __init__(self, relation_attributes_with_precedence_rule: Optional[List[RelationAttribute]] = None) -> None:
         if relation_attributes_with_precedence_rule is None:
             relation_attributes_with_precedence_rule = []
         # The root nodes of the graph, where all other nodes attach to.
-        self.root_nodes: set[RelationPrecedenceGraphNode] = set()
-        self.attribute_to_node: dict[RelationAttribute, RelationPrecedenceGraphNode] = {}
+        self.root_nodes: Set[RelationPrecedenceGraphNode] = set()
+        self.attribute_to_node: Dict[RelationAttribute, RelationPrecedenceGraphNode] = {}
         # Creates nodes in graph
         for first_attribute in relation_attributes_with_precedence_rule:
             for then_attribute in first_attribute.freeze_dependents:
                 self.add_precedence_rule(first_attribute, then_attribute)
 
     def add_precedence_rule(self, first_attribute: RelationAttribute, then_attribute: RelationAttribute) -> None:
         """
@@ -684,23 +678,23 @@
             self.attribute_to_node[relation_attribute] = node
             if attach_to_root:
                 self.root_nodes.add(node)
         else:
             node = self.attribute_to_node[relation_attribute]
         return node
 
-    def get_freeze_order(self) -> list[RelationAttribute]:
+    def get_freeze_order(self) -> List[RelationAttribute]:
         """
         Return all the RelationAttributes in this graph in the order in which
         they should be frozen.
         """
         if not self.attribute_to_node:
             return []
-        work: set[RelationPrecedenceGraphNode] = set(self.root_nodes)
-        result: list[RelationAttribute] = []
+        work: Set[RelationPrecedenceGraphNode] = set(self.root_nodes)
+        result: List[RelationAttribute] = []
 
         def get_next_ready_item_in_work() -> RelationPrecedenceGraphNode:
             assert work
             for current_node in work:
                 if all(dep.relation_attribute in result for dep in current_node.dependencies):
                     return current_node
             raise CycleInRelationPrecedencePolicyError()
@@ -721,13 +715,13 @@
 class RelationPrecedenceGraphNode:
     """
     A node in the RelationPrecedenceGraph that represents the relationship of an Inmanta entity.
     """
 
     def __init__(self, relation_attribute: RelationAttribute) -> None:
         self.relation_attribute: RelationAttribute = relation_attribute
-        self.dependents: set[RelationPrecedenceGraphNode] = set()
-        self.dependencies: set[RelationPrecedenceGraphNode] = set()
+        self.dependents: Set[RelationPrecedenceGraphNode] = set()
+        self.dependencies: Set[RelationPrecedenceGraphNode] = set()
 
     def add_dependent(self, dependent: "RelationPrecedenceGraphNode") -> None:
         self.dependents.add(dependent)
         dependent.dependencies.add(self)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/tracking.py` & `inmanta-core-9.3.0/src/inmanta/execute/tracking.py`

 * *Files 7% similar despite different names*

```diff
@@ -31,15 +31,15 @@
 
 if TYPE_CHECKING:
     from inmanta.ast.blocks import BasicBlock
     from inmanta.ast.statements.generator import SubConstructor
     from inmanta.execute.runtime import Instance
 
 
-class Tracker:
+class Tracker(object):
     def get_next(self) -> "List[Tracker]":
         return []
 
 
 class ModuleTracker(Tracker):
     def __init__(self, block: "BasicBlock") -> None:
         self.block = block
```

### Comparing `inmanta-core-8.7.4/src/inmanta/execute/util.py` & `inmanta-core-9.3.0/src/inmanta/execute/util.py`

 * *Files 12% similar despite different names*

```diff
@@ -11,24 +11,26 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from collections.abc import Iterable
+from typing import Iterable
 
 from inmanta.stable_api import stable_api
 
 
-class AnyType:
+class AnyType(object):
     """
     Supertype for objects that are an instance of all types
     """
 
+    pass
+
 
 @stable_api
 class Unknown(AnyType):
     """
     An instance of this class is used to indicate that this value can not be determined yet.
 
     :param source: The source object that can determine the value
@@ -37,15 +39,15 @@
     def __init__(self, source: object) -> None:
         self.source = source
 
     def __iter__(self) -> Iterable[object]:
         return iter([])
 
 
-class NoneValue:
+class NoneValue(object):
     def __eq__(self, other: object) -> bool:
         return isinstance(other, NoneValue)
 
     def __hash__(self) -> int:
         return hash(None)
 
     def __str__(self) -> str:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/export.py` & `inmanta-core-9.3.0/src/inmanta/export.py`

 * *Files 6% similar despite different names*

```diff
@@ -18,16 +18,15 @@
 
 import argparse
 import base64
 import logging
 import os
 import time
 import uuid
-from collections.abc import Callable, Sequence
-from typing import Any, Optional, Union
+from typing import Any, Callable, Dict, List, Optional, Sequence, Set, Tuple, Union
 
 import pydantic
 
 from inmanta import const, loader, protocol
 from inmanta.agent.handler import Commander
 from inmanta.ast import CompilerException, Namespace
 from inmanta.ast.entity import Entity
@@ -39,30 +38,30 @@
 from inmanta.execute.util import Unknown
 from inmanta.resources import Id, IgnoreResourceException, Resource, resource, to_id
 from inmanta.stable_api import stable_api
 from inmanta.util import get_compiler_version, hash_file
 
 LOGGER = logging.getLogger(__name__)
 
-unknown_parameters: list[dict[str, str]] = []
+unknown_parameters: List[Dict[str, str]] = []
 
 cfg_env = Option("config", "environment", None, "The environment this model is associated with", is_uuid_opt)
 cfg_export = Option(
     "config",
     "export",
     "",
     "The list of exporters to use. This option is ignored when the --export-plugin option is used.",
     is_list,
 )
 cfg_unknown_handler = Option("unknown_handler", "default", "prune-agent", "default method to handle unknown values ", is_str)
 
 
-ModelDict = dict[str, Entity]
-ResourceDict = dict[Id, Resource]
-ProxiedType = dict[str, Sequence[Union[str, tuple, int, float, bool, "DynamicProxy"]]]
+ModelDict = Dict[str, Entity]
+ResourceDict = Dict[Id, Resource]
+ProxiedType = Dict[str, Sequence[Union[str, tuple, int, float, bool, "DynamicProxy"]]]
 
 
 class DependencyCycleException(Exception):
     def __init__(self, start: Resource) -> None:
         super().__init__()
         self.start = start
         self.cycle = [start]
@@ -85,61 +84,41 @@
 
     for file in res.result["files"]:
         content = code_manager.get_file_content(file)
         res = conn.upload_file(id=file, content=base64.b64encode(content).decode("ascii"))
         if res is None or res.code != 200:
             raise Exception("Unable to upload handler plugin code to the server (msg: %s)" % res.result)
 
-    # Example of what a source_map may look like:
-    # Type Name: mymodule::Mytype"
-    # Source Files:
-    #   /path/to/__init__.py (hash: 'abc123', module: 'inmanta_plugins.mymodule.Mytype')
-    #   /path/to/utils.py (hash: 'def456', module: 'inmanta_plugins.mymodule.Mytype')
-    #
-    # source_map = {
-    #    "mymodule::Mytype": {
-    #      'abc123': ('/path/to/__init__.py', 'inmanta_plugins.mymodule.Mytype', <requirements if any>),
-    #      'def456': ('/path/to/utils.py', 'inmanta_plugins.mymodule.Mytype', <requirements if any>)
-    #    },
-    # ...other types would be included as well
-    # }
     source_map = {
         resource_name: {source.hash: (source.path, source.module_name, source.requires) for source in sources}
         for resource_name, sources in code_manager.get_types()
     }
 
     res = conn.upload_code_batched(tid=tid, id=version, resources=source_map)
     if res is None or res.code != 200:
         raise Exception("Unable to upload handler plugin code to the server (msg: %s)" % res.result)
 
 
-class Exporter:
+class Exporter(object):
     """
     This class handles exporting the compiled configuration model
     """
 
     # instance vars
-    types: Optional[dict[str, Entity]]
+    types: Optional[Dict[str, Entity]]
     scopes: Optional[Namespace]
     failed: bool  # did the compile fail?
 
     # class vars
-    __export_functions: dict[str, tuple[list[str], Callable[["Exporter", ProxiedType], None]]] = {}
+    __export_functions: Dict[str, Tuple[List[str], Callable[["Exporter", ProxiedType], None]]] = {}
     # type is not entirely right, ProxiedType argument can be absent
-    __dep_manager: list[Callable[[ModelDict, ResourceDict], None]] = []
+    __dep_manager: List[Callable[[ModelDict, ResourceDict], None]] = []
 
     @classmethod
-    def clear(cls) -> None:
-        cls.types = None
-        cls.scopes = None
-        cls.__export_functions = {}
-        cls.__dep_manager = []
-
-    @classmethod
-    def add(cls, name: str, types: list[str], function: Callable[["Exporter", ProxiedType], None]) -> None:
+    def add(cls, name: str, types: List[str], function: Callable[["Exporter", ProxiedType], None]) -> None:
         """
         Add a new export function
         """
         cls.__export_functions[name] = (types, function)
 
     @classmethod
     def add_dependency_manager(cls, function: Callable[[ModelDict, ResourceDict], None]) -> None:
@@ -148,43 +127,43 @@
         """
         cls.__dep_manager.append(function)
 
     def __init__(self, options: Optional[argparse.Namespace] = None) -> None:
         self.options = options
 
         self._resources: ResourceDict = {}
-        self._resource_sets: dict[str, Optional[str]] = {}
-        self._removed_resource_sets: set[str] = set()
-        self._resource_state: dict[str, ResourceState] = {}
-        self._unknown_objects: set[str] = set()
+        self._resource_sets: Dict[str, Optional[str]] = {}
+        self._empty_resource_sets: List[str] = []
+        self._resource_state: Dict[str, ResourceState] = {}
+        self._unknown_objects: Set[str] = set()
         # Actual version (placeholder for partial export) is set as soon as export starts.
         self._version: Optional[int] = None
         self._scope = None
         self.failed = False
 
-        self._file_store: dict[str, bytes] = {}
+        self._file_store: Dict[str, bytes] = {}
 
-    def _get_instance_proxies_of_types(self, types: list[str]) -> dict[str, Sequence[ProxiedType]]:
+    def _get_instance_proxies_of_types(self, types: List[str]) -> Dict[str, Sequence[ProxiedType]]:
         """Returns a dict of instances for the given types"""
-        proxies: dict[str, Sequence[ProxiedType]] = {}
+        proxies: Dict[str, Sequence[ProxiedType]] = {}
         for t in types:
             if self.types is not None and t in self.types:
                 proxies[t] = [DynamicProxy.return_value(i) for i in self.types[t].get_all_instances()]
             else:
                 proxies[t] = []
 
         return proxies
 
-    def _load_resources(self, types: dict[str, Entity]) -> None:
+    def _load_resources(self, types: Dict[str, Entity]) -> None:
         """
         Load all registered resources and resource_sets
         """
         resource.validate()
         entities = resource.get_entity_resources()
-        resource_mapping: dict[Instance, Resource] = {}
+        resource_mapping = {}
         ignored_set = set()
 
         for entity in entities:
             if entity not in types:
                 continue
             instances = types[entity].get_all_instances()
             if len(instances) > 0:
@@ -210,28 +189,28 @@
                             entity,
                             instance.location,
                         )
 
         self._load_resource_sets(types, resource_mapping)
         Resource.convert_requires(resource_mapping, ignored_set)
 
-    def _load_resource_sets(self, types: dict[str, Entity], resource_mapping: dict["Instance", "Resource"]) -> None:
+    def _load_resource_sets(self, types: Dict[str, Entity], resource_mapping: Dict["Instance", "Resource"]) -> None:
         """
         load the resource_sets in a dict with as keys resource_ids and as values the name of the resource_set
         the resource belongs to.
         This method should only be called after all resources have been extracted from the model.
         """
-        resource_sets: dict[str, Optional[str]] = {}
-        resource_set_instances: list["Instance"] = (
+        resource_sets: Dict[str, Optional[str]] = {}
+        resource_set_instances: List["Instance"] = (
             types["std::ResourceSet"].get_all_instances() if "std::ResourceSet" in types else []
         )
         for resource_set_instance in resource_set_instances:
             name: str = resource_set_instance.get_attribute("name").get_value()
             empty_set: bool = True
-            resources_in_set: list[Instance] = resource_set_instance.get_attribute("resources").get_value()
+            resources_in_set: List[Instance] = resource_set_instance.get_attribute("resources").get_value()
             for resource_in_set in resources_in_set:
                 if resource_in_set in resource_mapping:
                     resource_id: str = resource_mapping[resource_in_set].id.resource_str()
                     if resource_id in resource_sets and resource_sets[resource_id] != name:
                         raise CompilerException(
                             f"resource '{resource_id}' can not be part of multiple ResourceSets: "
                             f"{resource_sets[resource_id]} and {name}"
@@ -241,21 +220,15 @@
                 else:
                     LOGGER.warning(
                         "resource %s is part of ResourceSet %s but will not be exported.",
                         str(resource_in_set),
                         str(resource_set_instance.get_attribute("name").get_value()),
                     )
             if empty_set:
-                # Implicit deletion of empty sets
-                self._removed_resource_sets.add(name)
-            else:
-                # When soft_delete option is set, un-mark resource sets with exporting resources from deletion
-                if self.options and self.options.soft_delete:
-                    self._removed_resource_sets.discard(name)
-
+                self._empty_resource_sets.append(name)
         self._resource_sets = resource_sets
 
     def _run_export_plugins_specified_in_config_file(self) -> None:
         """
         Run any additional export plug-ins
         """
         export = []
@@ -313,24 +286,24 @@
             raise Exception(
                 f"A dependency manager inserted the object {repr(requires)} of type {type(requires)} "
                 "into a requires relation. However, only string, Resource or Id are allowable types "
             )
 
         # Clean up requires and resource_requires
         for res in self._resources.values():
-            res.requires = {cleanup(r) for r in res.requires}
-            res.resource_requires = {self._resources[r] for r in res.requires}
+            res.requires = set((cleanup(r) for r in res.requires))
+            res.resource_requires = set(self._resources[r] for r in res.requires)
 
     def _validate_graph(self) -> None:
         """
         Validate the graph and if requested by the user, dump it
         """
-        done: set[Resource] = set()
+        done: Set[Resource] = set()
 
-        def find_cycle(current: Resource, working: set[Resource]) -> None:
+        def find_cycle(current: Resource, working: Set[Resource]) -> None:
             if current in done:
                 return
             if current in working:
                 raise DependencyCycleException(current)
             working.add(current)
             for dep in current.resource_requires:
                 try:
@@ -348,15 +321,15 @@
         if self.options and self.options.depgraph:
             dot = "digraph G {\n"
             for res in self._resources.values():
                 res_id = res.id.resource_version_str()
                 dot += '\t"%s";\n' % res_id
 
                 for req in res.resource_requires:
-                    dot += f'\t"{res_id}" -> "{str(req)}";\n'
+                    dot += '\t"%s" -> "%s";\n' % (res_id, str(req))
 
             dot += "}\n"
 
             with open("dependencies.dot", "wb+") as fd:
                 fd.write(dot.encode())
 
     def get_version(self, no_commit: bool = False, partial_compile: bool = False) -> int:
@@ -371,41 +344,41 @@
             result = conn.reserve_version(tid)
             if result.code != 200:
                 raise Exception(f"Unable to reserve version number from server (msg: {result.result})")
             return result.result["data"]
 
     def run(
         self,
-        types: Optional[dict[str, Entity]],
+        types: Optional[Dict[str, Entity]],
         scopes: Optional[Namespace],
-        metadata: dict[str, str] = {},
+        metadata: Dict[str, str] = {},
         no_commit: bool = False,
         include_status: bool = False,
         model_export: bool = False,
         export_plugin: Optional[str] = None,
         partial_compile: bool = False,
         resource_sets_to_remove: Optional[Sequence[str]] = None,
     ) -> Union[tuple[int, ResourceDict], tuple[int, ResourceDict, dict[str, ResourceState]]]:
         """
         Run the export functions. Return value for partial json export uses 0 as version placeholder.
         """
-        start = time.time()
         if not partial_compile and resource_sets_to_remove:
             raise Exception("Cannot remove resource sets when a full compile was done")
-        self._removed_resource_sets = set(resource_sets_to_remove) if resource_sets_to_remove is not None else set()
+        resource_sets_to_remove_all: List[str] = list(resource_sets_to_remove) if resource_sets_to_remove is not None else []
 
         self.types = types
         self.scopes = scopes
 
         self._version = self.get_version(no_commit, partial_compile)
 
         if types is not None:
             # then process the configuration model to submit it to the mgmt server
             # This is the actual export : convert entities to resources.
             self._load_resources(types)
+            resource_sets_to_remove_all += self._empty_resource_sets
             # call dependency managers
             self._call_dep_manager(types)
             metadata[const.META_DATA_COMPILE_STATE] = const.Compilestate.success
             self.failed = False
         else:
             metadata[const.META_DATA_COMPILE_STATE] = const.Compilestate.failed
             self.failed = True
@@ -419,35 +392,29 @@
                 self._run_export_plugins_specified_in_config_file()
 
         # validate the dependency graph
         self._validate_graph()
 
         resources = self.resources_to_list()
 
-        export_done = time.time()
-        LOGGER.debug("Generating resources from the compiled model took %0.03f seconds", export_done - start)
-
         if len(self._resources) == 0:
             LOGGER.warning("Empty deployment model.")
 
         if self.options and self.options.json:
             with open(self.options.json, "wb+") as fd:
                 fd.write(protocol.json_encode(resources).encode("utf-8"))
         elif (not self.failed or len(self._resources) > 0 or len(unknown_parameters) > 0) and not no_commit:
             self._version = self.commit_resources(
-                self._version, resources, metadata, partial_compile, list(self._removed_resource_sets)
+                self._version, resources, metadata, partial_compile, resource_sets_to_remove_all
             )
             LOGGER.info("Committed resources with version %d" % self._version)
 
         exported_version: int = self._version
         if include_status:
             return exported_version, self._resources, self._resource_state
-
-        LOGGER.debug("Committing resources took %0.03f seconds", time.time() - export_done)
-
         return exported_version, self._resources
 
     def add_resource(self, resource: Resource) -> None:
         """
         Add a new resource to the list of exported resources. When
         commit_resources is called, the entire list of resources is sent
         to the server.
@@ -475,18 +442,16 @@
         if is_undefined:
             self._resource_state[resource.id.resource_str()] = const.ResourceState.undefined
         else:
             self._resource_state[resource.id.resource_str()] = const.ResourceState.available
 
         self._resources[resource.id] = resource
 
-    def resources_to_list(self) -> list[dict[str, Any]]:
-        """
-        Convert the resource list to a json representation
-        """
+    def resources_to_list(self) -> List[Dict[str, Any]]:
+        """Convert the resource list to a json representation"""
         resources = []
 
         for res in self._resources.values():
             resources.append(res.serialize())
 
         return resources
 
@@ -508,18 +473,18 @@
         LOGGER.info("Uploading source files")
 
         upload_code(conn, tid, version, code_manager)
 
     def commit_resources(
         self,
         version: Optional[int],
-        resources: list[dict[str, str]],
-        metadata: dict[str, str],
+        resources: List[Dict[str, str]],
+        metadata: Dict[str, str],
         partial_compile: bool,
-        resource_sets_to_remove: list[str],
+        resource_sets_to_remove: List[str],
     ) -> int:
         """
         Commit the entire list of resources to the configuration server.
 
         :return: The version for which resources were committed.
         """
         tid = cfg_env.get()
@@ -629,33 +594,33 @@
         if env is None:
             raise Exception("The environment of the model should be configured in config>environment")
 
         return env
 
 
 @stable_api
-class dependency_manager:  # noqa: N801
+class dependency_manager(object):  # noqa: N801
     """
     Register a function that manages dependencies in the configuration model that will be deployed.
     """
 
     def __init__(self, function: Callable[[ModelDict, ResourceDict], None]) -> None:
         Exporter.add_dependency_manager(function)
 
 
-class code_manager:  # noqa: N801
+class code_manager(object):  # noqa: N801
     """Register a function that will be invoked after all resource and handler code is collected. A code manager can add
     or modify code before it is uploaded to the server.
     """
 
     def __init__(self, function: Callable[[], None]) -> None:
         pass
 
 
-class export:  # noqa: N801
+class export(object):  # noqa: N801
     """
     A decorator that registers an export function
     """
 
     def __init__(self, name: str, *args: str) -> None:
         self.name = name
         self.types = args
@@ -682,13 +647,13 @@
                 fd.write("UNKNOWN -> error")
             else:
                 fd.write(file.content)  # type: ignore
 
     path = os.path.join(prefix, "services")
     with open(path, "w+", encoding="utf-8") as fd:
         for svc in types["std::Service"]:
-            fd.write(f"{svc.host.name} -> {svc.name}\n")  # type: ignore
+            fd.write("%s -> %s\n" % (svc.host.name, svc.name))  # type: ignore
 
     path = os.path.join(prefix, "packages")
     with open(path, "w+", encoding="utf-8") as fd:
         for pkg in types["std::Package"]:
-            fd.write(f"{pkg.host.name} -> {pkg.name}\n")  # type: ignore
+            fd.write("%s -> %s\n" % (pkg.host.name, pkg.name))  # type: ignore
```

### Comparing `inmanta-core-8.7.4/src/inmanta/file_parser.py` & `inmanta-core-9.3.0/src/inmanta/file_parser.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import os
+from typing import List
 
 from pkg_resources import Requirement
 
 from ruamel.yaml import YAML
 from ruamel.yaml.comments import CommentedMap
 
 
@@ -35,15 +36,15 @@
         # Make sure the indentation settings are used consistently
         parser.indent(mapping=2, sequence=4, offset=2)
         return parser
 
     @classmethod
     def parse(cls, filename: str) -> CommentedMap:
         parser = cls._get_parser()
-        with open(filename, encoding="utf-8") as fd:
+        with open(filename, "r", encoding="utf-8") as fd:
             return parser.load(fd)
 
     @classmethod
     def dump(cls, filename: str, content: CommentedMap) -> None:
         parser = cls._get_parser()
         with open(filename, "w", encoding="utf-8") as fd:
             parser.dump(content, stream=fd)
@@ -51,27 +52,27 @@
 
 class RequirementsTxtParser:
     """
     Parser for a requirements.txt file
     """
 
     @classmethod
-    def parse(cls, filename: str) -> list[Requirement]:
+    def parse(cls, filename: str) -> List[Requirement]:
         """
         Get all the requirements in `filename` as a list of `Requirement` instances.
         """
         return [Requirement.parse(r) for r in cls.parse_requirements_as_strs(filename)]
 
     @classmethod
-    def parse_requirements_as_strs(cls, filename: str) -> list[str]:
+    def parse_requirements_as_strs(cls, filename: str) -> List[str]:
         """
         Get all the requirements in `filename` as a list of strings.
         """
         if os.path.exists(filename):
-            with open(filename, encoding="utf-8") as fd:
+            with open(filename, "r", encoding="utf-8") as fd:
                 requirements_txt_content = fd.read()
                 req_lines = [x.strip() for x in requirements_txt_content.split("\n") if len(x.strip()) > 0]
                 req_lines = cls._remove_comments(req_lines)
                 req_lines = cls._remove_line_continuations(req_lines)
                 return list(req_lines)
         else:
             return []
@@ -83,15 +84,15 @@
         This method preserves all the comments.
         """
         if not os.path.exists(filename):
             raise Exception(f"File {filename} doesn't exist")
 
         result = ""
         line_continuation_buffer = ""
-        with open(filename, encoding="utf-8") as fd:
+        with open(filename, "r", encoding="utf-8") as fd:
             for line in fd.readlines():
                 if line_continuation_buffer:
                     line_continuation_buffer += line
                     if not line.endswith("\\"):
                         if Requirement.parse(line_continuation_buffer).key != remove_dep_on_pkg:
                             result += line_continuation_buffer
                         line_continuation_buffer = ""
@@ -103,15 +104,15 @@
                     result += line
                 else:
                     # Dependency matches `remove_dep_on_pkg` => Remove line from result
                     pass
         return result
 
     @classmethod
-    def _remove_comments(cls, lines: list[str]) -> list[str]:
+    def _remove_comments(cls, lines: List[str]) -> List[str]:
         """
         This method removes elements from the given list that only include comments. If the element
         combines a comment with a version constraint, the comment part is removed from the element.
 
         :param lines: The lines from a requirements.txt file with all empty lines removes.
         """
         result = []
@@ -122,15 +123,15 @@
                 line_without_comment = line.split(" #", maxsplit=1)[0]
                 result.append(line_without_comment)
             else:
                 result.append(line)
         return result
 
     @classmethod
-    def _remove_line_continuations(cls, lines: list[str]) -> list[str]:
+    def _remove_line_continuations(cls, lines: List[str]) -> List[str]:
         """
         Join two different list elements together if they are separated by a line continuation token.
 
         :param lines: The lines from a requirements.txt file with all empty lines removes.
         """
         result = []
         line_continuation_buffer = ""
```

### Comparing `inmanta-core-8.7.4/src/inmanta/loader.py` & `inmanta-core-9.3.0/src/inmanta/loader.py`

 * *Files 2% similar despite different names*

```diff
@@ -22,20 +22,19 @@
 import inspect
 import logging
 import os
 import pathlib
 import sys
 import types
 from collections import abc
-from collections.abc import Iterable, Iterator, Sequence
 from dataclasses import dataclass
 from importlib.abc import FileLoader, MetaPathFinder
 from importlib.machinery import ModuleSpec, SourcelessFileLoader
 from itertools import chain, starmap
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, Dict, Iterable, Iterator, List, Optional, Sequence, Set, Tuple
 
 from inmanta import const, module
 from inmanta.stable_api import stable_api
 from inmanta.util import hash_file_streaming
 
 if TYPE_CHECKING:
     from inmanta import protocol
@@ -47,26 +46,26 @@
 LOGGER = logging.getLogger(__name__)
 
 
 class SourceNotFoundException(Exception):
     """This exception is raised when the source of the provided type is not found"""
 
 
-class SourceInfo:
+class SourceInfo(object):
     """This class is used to store information related to source code information"""
 
     def __init__(self, path: str, module_name: str) -> None:
         """
         :param path: The path of the source code file
         :param module_name: The fully qualified name of the Python module. Should be a module in the inmanta_plugins namespace.
         """
         self.path = path
         self._hash: Optional[str] = None
         self._content: Optional[bytes] = None
-        self._requires: Optional[list[str]] = None
+        self._requires: Optional[List[str]] = None
         self.module_name = module_name
 
     @property
     def hash(self) -> str:
         """Get the sha1 hash of the file"""
         if self._hash is None:
             sha1sum = hashlib.new("sha1")
@@ -97,59 +96,54 @@
     def get_siblings(self) -> Iterator["SourceInfo"]:
         """
         Returns an iterator over SourceInfo objects for all plugin source files in this Inmanta module (including this one).
         """
         return starmap(SourceInfo, module.Project.get().modules[self._get_module_name()].get_plugin_files())
 
     @property
-    def requires(self) -> list[str]:
+    def requires(self) -> List[str]:
         """List of python requirements associated with this source file"""
         if self._requires is None:
             project: module.Project = module.Project.get()
             mod: module.Module = project.modules[self._get_module_name()]
             if project.metadata.agent_install_dependency_modules:
                 self._requires = mod.get_all_python_requirements_as_list()
             else:
                 self._requires = mod.get_strict_python_requirements_as_list()
         return self._requires
 
 
-class CodeManager:
+class CodeManager(object):
     """This class is responsible for loading and packaging source code for types (resources, handlers, ...) that need to be
     available in a remote process (e.g. agent).
-
-    __type_file: Maps Inmanta type names (e.g., ``std::File``, ``mymodule::Mytype``) to sets of filenames containing
-                 the necessary source code (all plugin files in the module).
-    __file_info: Stores metadata about each individual source code file. The keys are file paths and the values
-                 in this dictionary are ``SourceInfo`` objects.
     """
 
     def __init__(self) -> None:
-        self.__type_file: dict[str, set[str]] = {}
-        self.__file_info: dict[str, SourceInfo] = {}
+        self.__type_file: Dict[str, Set[str]] = {}
+        self.__file_info: Dict[str, SourceInfo] = {}
 
     def register_code(self, type_name: str, instance: object) -> None:
         """Register the given type_object under the type_name and register the source associated with this type object.
 
         :param type_name: The inmanta type name for which the source of type_object will be registered. For example std::File
         :param instance: An instance for which the code needs to be registered.
         """
         file_name = self.get_object_source(instance)
         if file_name is None:
-            raise SourceNotFoundException(f"Unable to locate source code of instance {inspect} for entity {type_name}")
+            raise SourceNotFoundException("Unable to locate source code of instance %s for entity %s" % (inspect, type_name))
 
         if type_name not in self.__type_file:
             self.__type_file[type_name] = set()
 
         # if file_name is in there, all plugin files should be in there => return
         if file_name in self.__type_file[type_name]:
             return
 
         # don't just store this file, but all plugin files in its Inmanta module to allow for importing helper modules
-        all_plugin_files: list[SourceInfo] = list(SourceInfo(file_name, instance.__module__).get_siblings())
+        all_plugin_files: List[SourceInfo] = list(SourceInfo(file_name, instance.__module__).get_siblings())
         self.__type_file[type_name].update(source_info.path for source_info in all_plugin_files)
 
         if file_name in self.__file_info:
             return
 
         for file_info in all_plugin_files:
             self.__file_info[file_info.path] = file_info
@@ -169,15 +163,15 @@
         """Get the file content for the given hash"""
         for info in self.__file_info.values():
             if info.hash == hash:
                 return info.content
 
         raise KeyError("No file found with this hash")
 
-    def get_types(self) -> Iterable[tuple[str, list[SourceInfo]]]:
+    def get_types(self) -> Iterable[Tuple[str, List[SourceInfo]]]:
         """Get a list of all registered types"""
         return ((type_name, [self.__file_info[path] for path in files]) for type_name, files in self.__type_file.items())
 
 
 @dataclass(frozen=True)
 class ModuleSource:
     """
@@ -205,24 +199,24 @@
         response: protocol.Result = self._client.get_file(self.hash_value)
         if response.code != 200 or response.result is None:
             raise Exception(f"Failed to fetch code for {self.name} with hash {self.hash_value}.")
 
         return base64.b64decode(response.result["content"])
 
 
-class CodeLoader:
+class CodeLoader(object):
     """
     Class responsible for managing code loaded from modules received from the compiler
 
     :param code_dir: The directory where the code is stored
     """
 
     def __init__(self, code_dir: str) -> None:
         self.__code_dir = code_dir
-        self.__modules: dict[str, tuple[str, types.ModuleType]] = {}  # A map with all modules we loaded, and its hv
+        self.__modules: Dict[str, Tuple[str, types.ModuleType]] = {}  # A map with all modules we loaded, and its hv
 
         self.__check_dir()
 
         mod_dir = os.path.join(self.__code_dir, MODULE_DIR)
         PluginModuleFinder.configure_module_finder(modulepaths=[mod_dir], prefer=True)
 
     def __check_dir(self) -> None:
@@ -319,15 +313,15 @@
         else:
             LOGGER.debug(
                 "Not deploying code (hv=%s, module=%s) because of cache hit", module_source.hash_value, module_source.name
             )
             return False
 
     def deploy_version(self, module_sources: Iterable[ModuleSource]) -> None:
-        to_reload: list[ModuleSource] = []
+        to_reload: List[ModuleSource] = []
 
         sources = set(module_sources)
         for module_source in sources:
             is_changed = self.install_source(module_source)
             if is_changed:
                 to_reload.append(module_source)
 
@@ -355,15 +349,15 @@
 
     def exec_module(self, module: types.ModuleType) -> None:
         return super().exec_module(module)
 
     def get_source(self, fullname: str) -> bytes:
         # No __init__.py exists for top level package
         if self._loading_top_level_package():
-            return b""
+            return "".encode("utf-8")
         with open(self.path, "rb") as fd:
             return fd.read()
 
     def is_package(self, fullname: str) -> bool:
         if self._loading_top_level_package():
             return True
         return os.path.basename(self.path) == "__init__.py"
@@ -401,23 +395,23 @@
         if path == "":
             return iter(())
         init, last = os.path.split(path)
         yield from split(init)
         if last != "":
             yield last
 
-    parts: list[str] = list(split(path))
+    parts: List[str] = list(split(path))
 
     if parts == []:
         return const.PLUGINS_PACKAGE
 
     if len(parts) == 1 or parts[1] != PLUGIN_DIR:
-        raise Exception(f"Error parsing module path: expected 'some_module/{PLUGIN_DIR}/some_submodule', got {path}")
+        raise Exception("Error parsing module path: expected 'some_module/%s/some_submodule', got %s" % (PLUGIN_DIR, path))
 
-    def strip_py(module: list[str]) -> list[str]:
+    def strip_py(module: List[str]) -> List[str]:
         """
         Strip __init__.py or .py file extension from module parts.
         """
         if module == []:
             return []
         init, last = module[:-1], module[-1]
         if last == "__init__.py" or last == "__init__.pyc":
@@ -425,15 +419,15 @@
         if last.endswith(".py"):
             return list(chain(init, [last[:-3]]))
         if last.endswith(".pyc"):
             return list(chain(init, [last[:-4]]))
         return module
 
     top_level_inmanta_module: str = parts[0]
-    inmanta_submodule: list[str] = parts[2:]
+    inmanta_submodule: List[str] = parts[2:]
 
     # my_mod/plugins/tail -> inmanta_plugins.my_mod.tail
     return ".".join(chain([const.PLUGINS_PACKAGE, top_level_inmanta_module], strip_py(inmanta_submodule)))
 
 
 def convert_module_to_relative_path(full_mod_name: str) -> str:
     """
@@ -465,15 +459,15 @@
     """
     Custom module finder which handles V1 Inmanta modules. V2 modules are handled using the standard Python finder. This
     finder is stored as the last entry in `meta_path`, as such that the default Python Finders detect V2 modules first.
     """
 
     MODULE_FINDER: "PluginModuleFinder" = None
 
-    def __init__(self, modulepaths: list[str]) -> None:
+    def __init__(self, modulepaths: List[str]) -> None:
         """
         :param modulepaths: The module paths for the inmanta project.
         """
         self._modulepaths = list(modulepaths)
 
     @classmethod
     def get_module_finder(cls) -> "PluginModuleFinder":
@@ -487,15 +481,15 @@
         Remove the PluginModuleFinder from sys.meta_path.
         """
         if cls.MODULE_FINDER is not None and cls.MODULE_FINDER in sys.meta_path:
             sys.meta_path.remove(cls.MODULE_FINDER)
         cls.MODULE_FINDER = None
 
     @classmethod
-    def configure_module_finder(cls, modulepaths: list[str], *, prefer: bool = False) -> None:
+    def configure_module_finder(cls, modulepaths: List[str], *, prefer: bool = False) -> None:
         """
         Setup a custom module loader to handle imports in .py files of the modules. This finder will be stored
         as the last finder in sys.meta_path, unless prefer is True. If the custom module loader has already been
         set up, does nothing (i.e. it is not moved to the front or the back of sys.meta_path).
 
         :param modulepaths: The directories where the module finder should look for modules.
         :param prefer: Prefer this module finder over others, putting it first in sys.meta_path.
@@ -608,11 +602,11 @@
     Unload any modules that are loaded from a given path (site-packages dir).
     """
 
     def module_in_prefix(module: types.ModuleType, prefix: str) -> bool:
         file: Optional[str] = getattr(module, "__file__", None)
         return file.startswith(prefix) if file is not None else False
 
-    loaded_modules: list[str] = [mod_name for mod_name, mod in sys.modules.items() if module_in_prefix(mod, path)]
+    loaded_modules: List[str] = [mod_name for mod_name, mod in sys.modules.items() if module_in_prefix(mod, path)]
     for mod_name in loaded_modules:
         del sys.modules[mod_name]
     importlib.invalidate_caches()
```

### Comparing `inmanta-core-8.7.4/src/inmanta/logging.py` & `inmanta-core-9.3.0/src/inmanta/logging.py`

 * *Files 22% similar despite different names*

```diff
@@ -11,22 +11,18 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-import enum
 import logging
 import os
-import re
 import sys
 from argparse import Namespace
-from collections.abc import Iterator
-from contextlib import contextmanager
 from typing import Optional, TextIO
 
 import colorlog
 from colorlog.formatter import LogColors
 
 from inmanta import const
 from inmanta.stable_api import stable_api
@@ -67,29 +63,14 @@
     - `timed`: if true,  adds the time to the formatter in the log lines.
     """
 
     log_file: Optional[str]
     log_file_level: str = "INFO"
     verbose: int = 1
     timed: bool = False
-    keep_logger_names: bool = False
-
-
-class LoggerMode(enum.Enum):
-    """
-    A different log format is used when the compiler/exporter is executed. This enum
-    indicates which mode we are currently executing in.
-        * COMPILER: the compiler is running.
-        * EXPORT: The exporter is running.
-        * OTHER: We are executing neither the compiler nor the exporter (e.g. running the server).
-    """
-
-    COMPILER = "compiler"
-    EXPORTER = "exporter"
-    OTHER = "other"
 
 
 @stable_api
 class InmantaLoggerConfig:
     """
     A class that provides logging functionality for Inmanta projects.
 
@@ -114,89 +95,22 @@
     def __init__(self, stream: TextIO = sys.stdout) -> None:
         """
         Set up the logging handler for Inmanta
 
         :param stream: The stream to send log messages to. Default is standard output (sys.stdout).
         """
         self._options_applied = False
-        self._keep_logger_names = False
         self._handler: logging.Handler = logging.StreamHandler(stream=stream)
         self.set_log_level("INFO")
         formatter = self._get_log_formatter_for_stream_handler(timed=False)
         self.set_log_formatter(formatter)
 
-        self._logger_mode = LoggerMode.OTHER
-
         logging.root.handlers = []
         logging.root.addHandler(self._handler)
-
-        self._inmanta_plugin_pkg_regex = re.compile(r"^inmanta_plugins\.(?P<module_name>[^.]+)")
-        # Regex that extracts the name of the module from a fully qualified import of a Python
-        # module inside an Inmanta module.
-
-    def wrap_record(self, record: logging.LogRecord) -> logging.LogRecord:
-        """
-        Wrap a log record to perform renaming for specific formatter as determined by the _logger_mode
-
-        This is derived from the way the colorlog.ColoredFormatter works
-        """
-        old_name = record.name
-        new_name = self._get_logger_name_for(old_name)
-        if old_name == new_name:
-            return record
-        attributes = dict(record.__dict__)
-        attributes["name"] = new_name
-        return logging.makeLogRecord(attributes)
-
-    def _get_logger_name_for(self, logger_name: str) -> str:
-        """
-        Returns the logger name that should be used in the log record.
-
-        :attr logger_name: The name of the logger that was used to create the log record.
-        """
-        if not self._keep_logger_names and self._logger_mode in [LoggerMode.COMPILER, LoggerMode.EXPORTER]:
-            if not logger_name.startswith("inmanta"):
-                # This is a log record from a third-party library. Don't adjust the logger name.
-                return logger_name
-            if logger_name == "inmanta.pip":
-                # Log record created by a pip subprocess started by the inmanta.
-                return "pip"
-            match: Optional[re.Match[str]] = self._inmanta_plugin_pkg_regex.match(logger_name)
-            if match:
-                # Log record created by an Inmanta module.
-                return match.groupdict()["module_name"]
-            else:
-                # Log record created by Inmanta code.
-                return self._logger_mode.value
-        else:
-            # Don't modify the logger name
-            return logger_name
-
-    @contextmanager
-    def run_in_logger_mode(self, logger_mode: LoggerMode) -> Iterator[None]:
-        """
-        A contextmanager that can be used to temporarily change the LoggerMode within a code block.
-        This ContextManager updates the InmantaLoggerConfig singleton and is therefore not async- or threadsafe.
-        """
-        prev_logger_mode = self._logger_mode
-        self._logger_mode = logger_mode
-        try:
-            yield
-        finally:
-            self._logger_mode = prev_logger_mode
-
-    @classmethod
-    def get_current_instance(cls) -> "InmantaLoggerConfig":
-        """
-        Obtain the InmantaLoggerConfig singleton. This method assumes that an InmantaLoggerConfig was already initialized
-        using the `get_instance()` method.
-        """
-        if not cls._instance:
-            raise Exception("InmantaLoggerConfig was not yet initialized. Call get_instance() first.")
-        return cls._instance
+        logging.root.setLevel(0)
 
     @classmethod
     @stable_api
     def get_instance(cls, stream: TextIO = sys.stdout) -> "InmantaLoggerConfig":
         """
         This method should be used to obtain an instance of this class, because this class is a singleton.
 
@@ -230,36 +144,23 @@
 
         :param options: The Option object coming from the command line. This function uses the following
             attributes: log_file, log_file_level, verbose, timed
         """
         if self._options_applied:
             raise Exception("Options can only be applied once to a handler.")
         self._options_applied = True
-        self._keep_logger_names = options.keep_logger_names
         if options.log_file:
             self.set_logfile_location(options.log_file)
             formatter = logging.Formatter(fmt="%(asctime)s %(levelname)-8s %(name)-10s %(message)s")
             self.set_log_formatter(formatter)
             self.set_log_level(options.log_file_level, cli=False)
         else:
-            # Use a shorter space padding if we know that we will use short names as the logger name.
-            # Otherwise the log records contains too much white spaces.
-            space_padding_after_logger_name = (
-                15
-                if (
-                    not options.keep_logger_names
-                    and hasattr(options, "func")
-                    and options.func.__name__ in ["compile_project", "export"]
-                )
-                else 25
-            )
-            formatter = self._get_log_formatter_for_stream_handler(
-                timed=options.timed, space_padding_after_logger_name=space_padding_after_logger_name
-            )
-            self.set_log_formatter(formatter)
+            if options.timed:
+                formatter = self._get_log_formatter_for_stream_handler(timed=True)
+                self.set_log_formatter(formatter)
             self.set_log_level(str(options.verbose))
 
     @stable_api
     def set_log_level(self, inmanta_log_level: str, cli: bool = True) -> None:
         """
         Set the logging level. A handler should have been created before.
         The possible inmanta log levels and their associated python log level
@@ -275,15 +176,14 @@
         # The minimal log level on the CLI is always WARNING
         if cli and (inmanta_log_level == "ERROR" or (inmanta_log_level.isdigit() and int(inmanta_log_level) < 1)):
             inmanta_log_level = "WARNING"
 
         # Converts the Inmanta log level to the Python log level
         python_log_level = log_levels[inmanta_log_level]
         self._handler.setLevel(python_log_level)
-        logging.root.setLevel(python_log_level)
 
     @stable_api
     def set_log_formatter(self, formatter: logging.Formatter) -> None:
         """
         Set the log formatter. A handler should have been created before
 
         :param formatter: The log formatter.
@@ -310,30 +210,26 @@
         """
         Get the logging handler
 
         :return: The logging handler
         """
         return self._handler
 
-    def _get_log_formatter_for_stream_handler(
-        self, timed: bool, space_padding_after_logger_name: int = 25
-    ) -> logging.Formatter:
+    def _get_log_formatter_for_stream_handler(self, timed: bool) -> logging.Formatter:
         log_format = "%(asctime)s " if timed else ""
         if _is_on_tty():
-            log_format += f"%(log_color)s%(name)-{space_padding_after_logger_name}s%(levelname)-8s%(reset)s%(blue)s%(message)s"
+            log_format += "%(log_color)s%(name)-25s%(levelname)-8s%(reset)s%(blue)s%(message)s"
             formatter = MultiLineFormatter(
-                self,
                 log_format,
                 reset=True,
                 log_colors={"DEBUG": "cyan", "INFO": "green", "WARNING": "yellow", "ERROR": "red", "CRITICAL": "red"},
             )
         else:
-            log_format += f"%(name)-{space_padding_after_logger_name}s%(levelname)-8s%(message)s"
+            log_format += "%(name)-25s%(levelname)-8s%(message)s"
             formatter = MultiLineFormatter(
-                self,
                 log_format,
                 reset=False,
                 no_color=True,
             )
         return formatter
 
 
@@ -343,15 +239,14 @@
 
     This class extends the `colorlog.ColoredFormatter` class to provide a custom formatting method for log records that
     span multiple lines.
     """
 
     def __init__(
         self,
-        logger_config: InmantaLoggerConfig,
         fmt: Optional[str] = None,
         *,
         # keep interface minimal: only include fields we actually use
         log_colors: Optional[LogColors] = None,
         reset: bool = True,
         no_color: bool = False,
     ):
@@ -360,15 +255,14 @@
 
         :param fmt: Optional string specifying the log record format.
         :param log_colors: Optional `LogColors` object mapping log level names to color codes.
         :param reset: Boolean indicating whether to reset terminal colors at the end of each log record.
         :param no_color: Boolean indicating whether to disable colors in the output.
         """
         super().__init__(fmt, log_colors=log_colors, reset=reset, no_color=no_color)
-        self._logger_config = logger_config
         self.fmt = fmt
 
     def get_header_length(self, record: logging.LogRecord) -> int:
         """
         Get the header length of a given log record.
 
         :param record: The `logging.LogRecord` object for which to calculate the header length.
@@ -379,29 +273,28 @@
             fmt=self.fmt,
             log_colors=self.log_colors,
             reset=False,
             no_color=True,
         )
         header = formatter.format(
             logging.LogRecord(
-                record.name,
-                record.levelno,
-                record.pathname,
-                record.lineno,
-                "",
-                (),
-                None,
+                name=record.name,
+                level=record.levelno,
+                pathname=record.pathname,
+                lineno=record.lineno,
+                msg="",
+                args=(),
+                exc_info=None,
             )
         )
         return len(header)
 
     def format(self, record: logging.LogRecord) -> str:
         """
         Format a log record with added indentation.
 
         :param record: The `logging.LogRecord` object to format.
         :return: The formatted log record as a string.
         """
-        record = self._logger_config.wrap_record(record)
         indent: str = " " * self.get_header_length(record)
         head, *tail = super().format(record).splitlines(True)
         return head + "".join(indent + line for line in tail)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/main.py` & `inmanta-core-9.3.0/src/inmanta/main.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,33 +18,31 @@
 
 import datetime
 import logging
 import os
 import shutil
 import uuid
 from collections import defaultdict
-from collections.abc import Callable
 from time import sleep
-from typing import Any, Optional, Union, cast
+from typing import Any, Callable, Dict, List, Optional, Union, cast
 
 import click
 import texttable
 from click_plugins import with_plugins
 from pkg_resources import iter_entry_points
 
 from inmanta import protocol
 from inmanta.config import Config, cmdline_rest_transport
-from inmanta.const import AgentAction, AgentTriggerMethod, ResourceAction
+from inmanta.const import TIME_ISOFMT, AgentAction, AgentTriggerMethod, ResourceAction
 from inmanta.data.model import ResourceVersionIdStr
 from inmanta.resources import Id
 from inmanta.types import JsonType
-from inmanta.util import parse_timestamp
 
 
-class Client:
+class Client(object):
     log = logging.getLogger(__name__)
 
     def __init__(self, host: Optional[str], port: Optional[int]) -> None:
         if host is None:
             self.host = cmdline_rest_transport.host.get()
         else:
             self.host = host
@@ -80,50 +78,50 @@
         if result.code == 200:
             if key_name is None:
                 return result.result
 
             if result.result and key_name in result.result:
                 return result.result[key_name]
 
-            raise Exception(f"Expected {key_name} in the response of {method_name}.")
+            raise Exception("Expected %s in the response of %s." % (key_name, method_name))
         elif result.code == 404:
             if not allow_none:
                 raise Exception("Requested %s not found on server" % key_name)
             return None
 
         else:
             msg = ": "
             if result.result is not None and "message" in result.result:
                 msg += result.result["message"]
 
             raise Exception(("An error occurred while requesting %s" % key_name) + msg)
 
-    def get_list(self, method_name: str, key_name: Optional[str] = None, arguments: JsonType = {}) -> list[dict[str, Any]]:
+    def get_list(self, method_name: str, key_name: Optional[str] = None, arguments: JsonType = {}) -> List[Dict[str, Any]]:
         """
         Same as do request, but return type is a list of dicts
         """
-        return cast(list[dict[str, Any]], self.do_request(method_name, key_name, arguments, False))
+        return cast(List[Dict[str, Any]], self.do_request(method_name, key_name, arguments, False))
 
-    def get_dict(self, method_name: str, key_name: Optional[str] = None, arguments: JsonType = {}) -> dict[str, str]:
+    def get_dict(self, method_name: str, key_name: Optional[str] = None, arguments: JsonType = {}) -> Dict[str, str]:
         """
         Same as do request, but return type is a list of dicts
         """
-        return cast(dict[str, str], self.do_request(method_name, key_name, arguments, False))
+        return cast(Dict[str, str], self.do_request(method_name, key_name, arguments, False))
 
     def to_project_id(self, ref: str) -> uuid.UUID:
         """
         Convert ref to a uuid
         """
         try:
             project_id = uuid.UUID(ref)
         except ValueError:
             # try to resolve the id as project name
-            projects: list[dict[str, str]] = self.get_list("list_projects", "projects")
+            projects: List[Dict[str, str]] = self.get_list("list_projects", "projects")
 
-            id_list: list[str] = []
+            id_list: List[str] = []
             for project in projects:
                 if ref == project["name"]:
                     id_list.append(project["id"])
 
             if len(id_list) == 0:
                 raise Exception("Unable to find a project with the given id or name")
 
@@ -139,17 +137,17 @@
         """
         Convert ref to an env uuid, optionally scoped to a project
         """
         try:
             env_id = uuid.UUID(ref)
         except ValueError:
             # try to resolve the id as project name
-            envs: list[dict[str, str]] = self.get_list("list_environments", "environments")
+            envs: List[Dict[str, str]] = self.get_list("list_environments", "environments")
 
-            id_list: list[str] = []
+            id_list: List[str] = []
             for env in envs:
                 if ref == env["name"]:
                     if project_id is None or project_id == env["project_id"]:
                         id_list.append(env["id"])
 
             if len(id_list) == 0:
                 raise Exception("Unable to find an environment with the given id or name")
@@ -159,19 +157,19 @@
 
             else:
                 env_id = uuid.UUID(id_list[0])
 
         return env_id
 
 
-def print_table(header: list[str], rows: list[list[str]], data_type: Optional[list[str]] = None) -> None:
+def print_table(header: List[str], rows: List[List[str]], data_type: Optional[List[str]] = None) -> None:
     click.echo(get_table(header, rows, data_type))
 
 
-def get_table(header: list[str], rows: list[list[str]], data_type: Optional[list[str]] = None) -> str:
+def get_table(header: List[str], rows: List[List[str]], data_type: Optional[List[str]] = None) -> str:
     """
     Returns a table that would fit in the current terminal.
     """
     width, _ = shutil.get_terminal_size()
 
     table = texttable.Texttable(max_width=width)
     table.set_deco(texttable.Texttable.HEADER | texttable.Texttable.BORDER | texttable.Texttable.VLINES)
@@ -266,17 +264,15 @@
 @cmd.group("environment", help="Subcommand to manage environments")
 @click.pass_context
 def environment(ctx: click.Context) -> None:
     pass
 
 
 @environment.command(name="create", help="Create a new environment")
-@click.option(
-    "--name", "-n", help="The name of the new environment. The name should be unique for each project.", required=True
-)
+@click.option("--name", "-n", help="The name of the new environment", required=True)
 @click.option("--project", "-p", help="The id of the project this environment belongs to", required=True)
 @click.option(
     "--repo-url", "-r", required=False, default="", help="The url of the repository that contains the configuration model"
 )
 @click.option(
     "--branch",
     "-b",
@@ -304,32 +300,32 @@
 
     print_table(
         ["Environment ID", "Environment name", "Project ID", "Project name"],
         [[env["id"], env["name"], project_data["id"], project_data["name"]]],
     )
 
 
-def save_config(client: Client, env: dict[str, str]) -> None:
+def save_config(client: Client, env: Dict[str, str]) -> None:
     cfg = """
 [config]
 fact-expire = 1800
-environment={env}
+environment=%(env)s
 
 [compiler_rest_transport]
-host={host}
-port={port}
+host=%(host)s
+port=%(port)s
 
 [cmdline_rest_transport]
-host={host}
-port={port}
-""".format(
-        env=env["id"],
-        host=client.host,
-        port=client.port,
-    )
+host=%(host)s
+port=%(port)s
+""" % {
+        "env": env["id"],
+        "host": client.host,
+        "port": client.port,
+    }
 
     if os.path.exists(".inmanta") and not click.confirm(".inmanta exists, do you want to overwrite it?"):
         click.echo("not writing config", err=True)
     else:
         with open(".inmanta", "w", encoding="utf-8") as f:
             f.write(cfg)
 
@@ -479,19 +475,19 @@
 
 
 @env_setting.command(name="list", help="List settings of an environment")
 @click.option("--environment", "-e", help="The environment to use", required=True)
 @click.pass_obj
 def env_setting_list(client: Client, environment: str) -> None:
     tid = client.to_environment_id(environment)
-    settings = cast(dict[str, dict[str, str]], client.do_request("list_settings", arguments=dict(tid=tid)))
+    settings = cast(Dict[str, Dict[str, str]], client.do_request("list_settings", arguments=dict(tid=tid)))
 
     table_body = []
     for key in sorted(settings["metadata"].keys()):
-        meta = cast(dict[str, str], settings["metadata"][key])
+        meta = cast(Dict[str, str], settings["metadata"][key])
         value = ""
         if key in settings["settings"]:
             value = str(settings["settings"][key])
 
         default_value = ""
         if "default" in meta:
             default_value = str(meta["default"])
@@ -539,15 +535,15 @@
 
 @agent.command(name="list", help="List agents in an environment")
 @click.option("--environment", "-e", help="The environment to use", required=True)
 @click.pass_obj
 def agent_list(client: Client, environment: str) -> None:
     env_id = client.to_environment_id(environment)
     agents = client.get_list("list_agents", key_name="agents", arguments=dict(tid=env_id))
-    data: list[list[str]] = []
+    data: List[List[str]] = []
     for agent in agents:
         data.append([agent["name"], agent["environment"], str(agent["paused"]), agent["last_failover"]])
 
     print_table(["Agent", "Environment", "Paused", "Last fail over"], data)
 
 
 @agent.command(name="pause")
@@ -665,27 +661,27 @@
 
 @param.command(name="list", help="List parameters in an environment")
 @click.option("--environment", "-e", help="The environment to use", required=True)
 @click.pass_obj
 def param_list(client: Client, environment: str) -> None:
     result = client.get_dict("list_params", arguments=dict(tid=client.to_environment_id(environment)))
     expire = int(result["expire"])
-    now = parse_timestamp(result["now"])
+    now = datetime.datetime.strptime(result["now"], TIME_ISOFMT)
     when = now - datetime.timedelta(0, expire)
 
     data = []
-    parameters = cast(list[dict[str, str]], result["parameters"])
+    parameters = cast(List[Dict[str, str]], result["parameters"])
     for p in parameters:
         data.append(
             [
                 p["resource_id"],
                 p["name"],
                 p["source"],
                 p["updated"],
-                str(float(parse_timestamp(p["updated"]) < when)),
+                str(float(datetime.datetime.strptime(p["updated"], TIME_ISOFMT) < when)),
             ]
         )
 
     print_table(["Resource", "Name", "Source", "Updated", "Expired"], data)
 
 
 @param.command(name="set", help="Set a parameter in an environment")
@@ -693,15 +689,15 @@
 @click.option("--name", help="The name of the parameter", required=True)
 @click.option("--value", help="The value of the parameter", required=True)
 @click.pass_obj
 def param_set(client: Client, environment: str, name: str, value: str) -> None:
     tid = client.to_environment_id(environment)
     # first fetch the parameter
     param_data = cast(
-        Optional[dict[str, str]],
+        Optional[Dict[str, str]],
         client.do_request("get_param", "parameter", dict(tid=tid, id=name, resource_id=""), allow_none=True),
     )
 
     param = {"source": "user", "metadata": {}} if param_data is None else param_data
     param_return = client.get_dict(
         "set_param",
         "parameter",
@@ -739,26 +735,29 @@
 def version_report(client: Client, environment: str, version: str, show_detailed_report: bool) -> None:
     tid = client.to_environment_id(environment)
     result = client.do_request("get_version", arguments=dict(tid=tid, id=version, include_logs=True))
 
     if not result:
         return
 
-    agents: dict[str, dict[str, list[str]]] = defaultdict(lambda: defaultdict(list))
+    agents: Dict[str, Dict[str, List[str]]] = defaultdict(lambda: defaultdict(lambda: []))
     for res in result["resources"]:
         if len(res["actions"]) > 0 or show_detailed_report:
             agents[res["agent"]][res["resource_type"]].append(res)
 
     for agent in sorted(agents.keys()):
         click.echo(click.style("Agent: %s" % agent, bold=True))
         click.echo("=" * 72)
 
         for t in sorted(agents[agent].keys()):
             parsed_resource_version_id = Id.parse_id(ResourceVersionIdStr(agents[agent][t][0]["resource_version_id"]))
-            click.echo(click.style("Resource type:", bold=True) + f"{t} ({parsed_resource_version_id.attribute})")
+            click.echo(
+                click.style("Resource type:", bold=True)
+                + "{type} ({attr})".format(type=t, attr=parsed_resource_version_id.attribute)
+            )
             click.echo("-" * 72)
 
             for res in agents[agent][t]:
                 parsed_id = Id.parse_id(res["resource_version_id"])
                 click.echo((click.style(parsed_id.attribute_value, bold=True) + " (#actions=%d)") % len(res["actions"]))
                 # for dryrun show only the latest, for deploy all
                 if not result["model"]["released"]:
@@ -796,18 +795,18 @@
     "receiving continuous updates on the deployment status",
 )
 @click.option("--environment", "-e", help="The environment to use", required=True)
 @click.pass_obj
 def monitor_deploy(client: Client, environment: str) -> None:
     tid = client.to_environment_id(environment)
 
-    versions = cast(dict[str, list[dict[str, str]]], client.do_request("list_versions", arguments=dict(tid=tid)))
+    versions = cast(Dict[str, List[Dict[str, str]]], client.do_request("list_versions", arguments=dict(tid=tid)))
     allversion = versions["versions"]
     try:
-        first: dict[str, str] = next(version for version in allversion if version["result"] != "pending")
+        first: Dict[str, str] = next(version for version in allversion if version["result"] != "pending")
     except StopIteration:
         raise click.ClickException("Environment %s doesn't contain a released configuration model" % environment)
 
     total = int(first["total"])
     done = int(first["done"])
     last = done
     ident = int(first["version"])
@@ -816,22 +815,22 @@
         bar.update(done)
         while done != total:
             if done != last:
                 bar.update(done - last)
                 last = done
             sleep(1)
             version = cast(
-                dict[str, dict[str, int]], client.get_dict("get_version", arguments=dict(tid=tid, id=int(ident), limit=0))
+                Dict[str, Dict[str, int]], client.get_dict("get_version", arguments=dict(tid=tid, id=int(ident), limit=0))
             )
             done = version["model"]["done"]
         if done != last:
             bar.update(done - last)
             last = done
 
-    click.echo(f"Complete: {done}/{total}")
+    click.echo("Complete: %s/%s" % (done, total))
 
 
 @cmd.group("token", help="Subcommand to manage access tokens")
 @click.pass_context
 def token(ctx: click.Context) -> None:
     pass
```

### Comparing `inmanta-core-8.7.4/src/inmanta/model.py` & `inmanta-core-9.3.0/src/inmanta/model.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,26 +11,27 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from typing import Optional
+from builtins import str
+from typing import Dict, List, Optional, Tuple
 
 from inmanta.types import JsonType
 
 """
     Objects defining the serialization format for type information.
 
     Types are exported as a Dict[str, :class:`.Entity` ]
 """
 
 
-class Location:
+class Location(object):
     """
     Position in the source
 
     :param str file:  source file name
     :param int lnr: line in the source file
     """
 
@@ -52,15 +53,15 @@
         return {"file": self.file, "lnr": self.lnr}
 
     @staticmethod
     def from_dict(ctx: JsonType) -> "Location":
         return Location(**ctx)
 
 
-class Attribute:
+class Attribute(object):
     """
     Attribute defined on an entity
 
     :param str mytype: fully qualified name of the type of this attribute
     :param bool nullable: can this attribute be null
     :param bool multi: is this attribute a list
     :param str comment: docstring for this attribute
@@ -106,23 +107,23 @@
             nullable=ctx["nullable"],
             multi=ctx["multi"],
             comment=ctx["comment"],
             location=Location.from_dict(ctx["location"]),
         )
 
     @staticmethod
-    def from_list(lst: list[JsonType]) -> dict[str, "Attribute"]:
+    def from_list(lst: List[JsonType]) -> Dict[str, "Attribute"]:
         return {n: Attribute.from_dict(x) for n, x in lst.items()}
 
 
-class Value:
+class Value(object):
     """A value reference from a type either :class:`.DirectValue` or :class:`.ReferenceValue`"""
 
     @staticmethod
-    def from_list(lst: list[JsonType]) -> list["Value"]:
+    def from_list(lst: List[JsonType]) -> List["Value"]:
         return [Value.from_dict(x) for x in lst]
 
     @staticmethod
     def from_dict(ctx: JsonType) -> "Value":
         if "value" in ctx:
             return DirectValue.from_dict(ctx)
         else:
@@ -174,35 +175,35 @@
         return {"reference": self.reference}
 
     @staticmethod
     def from_dict(ctx: JsonType) -> "ReferenceValue":
         return ReferenceValue(**ctx)
 
 
-class Relation:
+class Relation(object):
     """
     A relation between two entities.
 
     :param str mytype: the type this relation refers to
     :param Tuple[int, int] multi: the multiplicity of this relation in the form (lower,upper), -1 for unbounded
     :param str reverse: the fully qualified name of the inverse relation
     :param inmanta.model.Location location: source location this relation was defined at
     :param List[Value] source_annotations: annotations on this relation on the source side
     :param List[Value] target_annotations: annotations on this relation on the target side
     """
 
     def __init__(
         self,
         mytype: str,
-        multi: tuple[int, Optional[int]],
+        multi: Tuple[int, Optional[int]],
         reverse: str,
         comment: str,
         location: Location,
-        source_annotations: list[Value],
-        target_annotations: list[Value],
+        source_annotations: List[Value],
+        target_annotations: List[Value],
     ) -> None:
         self.type = mytype
         lower = multi[0]
         upper = multi[1]
         if upper is None:
             upper = -1
         self.multi = (lower, upper)
@@ -250,30 +251,30 @@
             ctx["comment"],
             Location.from_dict(ctx["location"]),
             Value.from_list(ctx["source_annotations"]),
             Value.from_list(ctx["target_annotations"]),
         )
 
     @staticmethod
-    def from_list(lst: JsonType) -> dict[str, "Relation"]:
+    def from_list(lst: JsonType) -> Dict[str, "Relation"]:
         return {n: Relation.from_dict(x) for n, x in lst.items()}
 
 
-class Entity:
+class Entity(object):
     """
     An entity type
 
     :param List[str] parents: parent types
     :param  Dict[str, Attribute]: all attributes declared on this entity directly, by name
     :param  Dict[str, Relation]: all relations declared on this entity directly, by name
     :param inmanta.model.Location location: source location this entity was defined at
     """
 
     def __init__(
-        self, parents: list[str], attributes: dict[str, Attribute], relations: dict[str, Relation], location: Location
+        self, parents: List[str], attributes: Dict[str, Attribute], relations: Dict[str, Relation], location: Location
     ) -> None:
         self.parents = parents
         self.attributes = attributes
         self.relations = relations
         self.location = location
 
     def to_dict(self) -> JsonType:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/module.py` & `inmanta-core-9.3.0/src/inmanta/module.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,40 +13,59 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import configparser
-import enum
+import glob
 import importlib
+import itertools
 import logging
 import operator
 import os
 import re
 import subprocess
 import sys
 import tempfile
 import textwrap
 import traceback
 import types
 import warnings
 from abc import ABC, abstractmethod
 from collections import abc, defaultdict
-from collections.abc import Iterable, Iterator, Mapping, Sequence
 from configparser import ConfigParser
 from dataclasses import dataclass
+from enum import Enum
 from functools import reduce
 from importlib.abc import Loader
 from io import BytesIO, TextIOBase
 from itertools import chain
 from subprocess import CalledProcessError
 from tarfile import TarFile
 from time import time
-from typing import Any, Dict, Generic, List, NewType, Optional, TextIO, TypeVar, Union, cast
+from typing import (
+    Any,
+    Dict,
+    Generic,
+    Iterable,
+    Iterator,
+    List,
+    Mapping,
+    NewType,
+    Optional,
+    Sequence,
+    Set,
+    TextIO,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    cast,
+)
 
 import more_itertools
 import pkg_resources
 import yaml
 from pkg_resources import Distribution, DistributionNotFound, Requirement, parse_requirements, parse_version
 from pydantic import BaseModel, Field, NameEmail, ValidationError, constr, validator
 from pydantic.error_wrappers import display_errors
@@ -67,14 +86,15 @@
 from ruamel.yaml.comments import CommentedMap
 
 try:
     from typing import TYPE_CHECKING
 except ImportError:
     TYPE_CHECKING = False
 
+
 LOGGER = logging.getLogger(__name__)
 
 Path = NewType("Path", str)
 ModuleName = NewType("ModuleName", str)
 
 T = TypeVar("T")
 TModule = TypeVar("TModule", bound="Module")
@@ -122,25 +142,25 @@
     def __str__(self) -> str:
         return str(self._requirement).replace("-", "_")
 
     def __hash__(self) -> int:
         return self._requirement.__hash__()
 
     @property
-    def specs(self) -> Sequence[tuple[str, str]]:
+    def specs(self) -> Sequence[Tuple[str, str]]:
         return self._requirement.specs
 
     def version_spec_str(self) -> str:
         """
         Returns a string representation of this module requirement's version spec. Includes only the version part.
         """
         return ",".join("".join(spec) for spec in self.specs)
 
     @classmethod
-    def parse(cls: type[TInmantaModuleRequirement], spec: str) -> TInmantaModuleRequirement:
+    def parse(cls: Type[TInmantaModuleRequirement], spec: str) -> TInmantaModuleRequirement:
         if spec.startswith(ModuleV2.PKG_NAME_PREFIX):
             raise ValueError(
                 "Invalid Inmanta module requirement: Use the Inmanta module name instead of the Python package name"
             )
         if "-" in spec:
             raise ValueError("Invalid Inmanta module requirement: Inmanta module names use '_', not '-'.")
         return cls(Requirement.parse(spec))
@@ -232,15 +252,15 @@
     """
     This exception is raised if the metadata file of a project or module is invalid.
     """
 
     def __init__(self, msg: str, validation_error: Optional[ValidationError] = None) -> None:
         if validation_error is not None:
             msg = self._extend_msg_with_validation_information(msg, validation_error)
-        super().__init__(msg=msg)
+        super(InvalidMetadata, self).__init__(msg=msg)
 
     @classmethod
     def _extend_msg_with_validation_information(cls, msg: str, validation_error: ValidationError) -> str:
         errors = validation_error.errors()
         if errors:
             msg += "\n" + textwrap.indent(display_errors(errors), " " * 2)
         return msg
@@ -285,50 +305,50 @@
                 self.cause,
             )
         )
 
     def get_cause_type_name(self) -> str:
         module: Optional[str] = type(self.cause).__module__
         name: str = type(self.cause).__qualname__
-        return name if module is None or module == "builtins" else f"{module}.{name}"
+        return name if module is None or module == "builtins" else "%s.%s" % (module, name)
 
     def to_compiler_exception(self) -> CompilerException:
         module: Optional[str] = type(self.cause).__module__
         name: str = type(self.cause).__qualname__
-        cause_type_name = name if module is None or module == "builtins" else f"{module}.{name}"
+        cause_type_name = name if module is None or module == "builtins" else "%s.%s" % (module, name)
 
         exception = CompilerException(
             f"Unable to load all plug-ins for module {self.module}:"
             f"\n\t{cause_type_name} while loading plugin module {self.fq_import}: {self.cause}"
         )
         exception.set_location(Location(self.path, self.lineno if self.lineno is not None else 0))
         return exception
 
 
-class UntrackedFilesMode(enum.Enum):
+class UntrackedFilesMode(Enum):
     """
     The different options that can be passed to the --untracked-files option of the `git status` command.
     """
 
     ALL = "all"
     NORMAL = "normal"
     NO = "no"
 
 
-class GitProvider:
+class GitProvider(object):
     def clone(self, src: str, dest: str) -> None:
         pass
 
     def fetch(self, repo: str) -> None:
         pass
 
     def status(self, repo: str, untracked_files_mode: Optional[UntrackedFilesMode] = None) -> str:
         pass
 
-    def get_all_tags(self, repo: str) -> list[str]:
+    def get_all_tags(self, repo: str) -> List[str]:
         pass
 
     def get_version_tags(self, repo: str, only_return_stable_versions: bool = False) -> list[version.Version]:
         pass
 
     def get_file_for_version(self, repo: str, tag: str, file: str) -> str:
         pass
@@ -394,27 +414,27 @@
         :param untracked_files_mode: If provided, the --untracked-files option will be passed to `git status` command.
         """
         extra_args = []
         if untracked_files_mode:
             extra_args.append(f"--untracked-files={untracked_files_mode.value}")
         return subprocess.check_output(["git", "status", "--porcelain", *extra_args], cwd=repo).decode("utf-8")
 
-    def get_all_tags(self, repo: str) -> list[str]:
+    def get_all_tags(self, repo: str) -> List[str]:
         return subprocess.check_output(["git", "tag"], cwd=repo).decode("utf-8").splitlines()
 
     def get_version_tags(self, repo: str, only_return_stable_versions: bool = False) -> list[version.Version]:
         """
         Return the Git tags that represent version numbers as version.Version objects. Only PEP440 compliant
         versions will be returned.
 
         :param repo: The path to the directory that contains the git repository on which the git command should be executed.
         :param only_return_stable_versions: Return only version for stable releases.
         """
         result = []
-        all_tags: list[str] = sorted(self.get_all_tags(repo))
+        all_tags: List[str] = sorted(self.get_all_tags(repo))
         for tag in all_tags:
             try:
                 parsed_version: version.Version = version.Version(tag)
             except version.InvalidVersion:
                 continue
             if not only_return_stable_versions or not parsed_version.is_prerelease:
                 result.append(parsed_version)
@@ -528,15 +548,15 @@
         :param project: The project associated with the module.
         :param module_name: The name of the module.
         """
         path: Optional[str] = self.path_for(module_name)
         return self.from_path(project, module_name, path) if path is not None else None
 
     def get_module(
-        self, project: "Project", module_spec: list[InmantaModuleRequirement], install: bool = False
+        self, project: "Project", module_spec: List[InmantaModuleRequirement], install: bool = False
     ) -> Optional[TModule]:
         """
         Returns the appropriate module instance for a given module spec.
 
         :param project: The project associated with the module.
         :param module_spec: The module specification including any constraints on its version. In this case,
                             the project is responsible for verifying constraint compatibility.
@@ -563,49 +583,49 @@
             # Already installed
             return False
 
         if _should_install_module():
             return self.install(project, module_spec)
         return installed
 
-    def _format_constraints(self, module_name: str, module_spec: list[InmantaModuleRequirement]) -> str:
+    def _format_constraints(self, module_name: str, module_spec: List[InmantaModuleRequirement]) -> str:
         """
         Returns the constraints on a given inmanta module as a string.
 
         :param module_name: The name of the module.
         :param module_spec: List of inmanta requirements in which to look for the module.
         """
-        constraints_on_module: list[str] = [str(req) for req in module_spec if module_name == req.key and req.specs]
+        constraints_on_module: List[str] = [str(req) for req in module_spec if module_name == req.key and req.specs]
         if constraints_on_module:
             from_constraints = f"(with constraints {' '.join(constraints_on_module)})"
         else:
             from_constraints = "(with no version constraints)"
         return from_constraints
 
     @abstractmethod
-    def log_pre_install_information(self, module_name: str, module_spec: list[InmantaModuleRequirement]) -> None:
+    def log_pre_install_information(self, module_name: str, module_spec: List[InmantaModuleRequirement]) -> None:
         """
         Display information about this module's installation before the actual installation.
 
         :param module_name: The module's name.
         """
         raise NotImplementedError("Abstract method")
 
-    def _log_version_snapshot(self, header: Optional[str], version_snapshot: dict[str, version.Version]) -> None:
+    def _log_version_snapshot(self, header: Optional[str], version_snapshot: Dict[str, version.Version]) -> None:
         if version_snapshot:
             out = [header] if header is not None else []
             out.extend(f"{mod}: {version}" for mod, version in version_snapshot.items())
             LOGGER.debug("\n".join(out))
 
     def _log_snapshot_difference(
-        self, version_snapshot: dict[str, version.Version], previous_snapshot: dict[str, version.Version], header: Optional[str]
+        self, version_snapshot: Dict[str, version.Version], previous_snapshot: Dict[str, version.Version], header: Optional[str]
     ) -> None:
-        set_pre_install: set[tuple[str, version.Version]] = set(previous_snapshot.items())
-        set_post_install: set[tuple[str, version.Version]] = set(version_snapshot.items())
-        updates_and_additions: set[tuple[str, version.Version]] = set_post_install - set_pre_install
+        set_pre_install: Set[tuple[str, version.Version]] = set(previous_snapshot.items())
+        set_post_install: Set[tuple[str, version.Version]] = set(version_snapshot.items())
+        updates_and_additions: Set[tuple[str, version.Version]] = set_post_install - set_pre_install
 
         if version_snapshot:
             out = [header] if header is not None else []
             for inmanta_module_name, package_version in sorted(version_snapshot.items()):
                 if inmanta_module_name not in previous_snapshot.keys():
                     # new module that wasn't previously installed
                     out.append("+ " + inmanta_module_name + ": " + str(package_version))
@@ -613,15 +633,15 @@
                     # module has a different version
                     out.append("+ " + inmanta_module_name + ": " + str(package_version))
                     out.append("- " + inmanta_module_name + ": " + str(previous_snapshot[inmanta_module_name]))
 
             LOGGER.debug("\n".join(out))
 
     @abstractmethod
-    def install(self, project: "Project", module_spec: list[InmantaModuleRequirement]) -> Optional[TModule]:
+    def install(self, project: "Project", module_spec: List[InmantaModuleRequirement]) -> Optional[TModule]:
         """
         Attempt to install a module given a module spec. Updates a module that is already installed only if it does not match
         the constraints.
 
         :param project: The project associated with the module.
         :param module_spec: The module specification including any constraints on its version.
         :return: The module object when the module was installed. When the module could not be found, None is returned.
@@ -639,28 +659,28 @@
     @abstractmethod
     def from_path(cls, project: Optional["Project"], module_name: str, path: str) -> TModule:
         """
         Returns a module instance given a path to it.
         """
         raise NotImplementedError("Abstract method")
 
-    def _get_module_name(self, module_spec: list[InmantaModuleRequirement]) -> str:
-        module_names: set[str] = {req.project_name for req in module_spec}
+    def _get_module_name(self, module_spec: List[InmantaModuleRequirement]) -> str:
+        module_names: Set[str] = {req.project_name for req in module_spec}
         module_name: str = more_itertools.one(
             module_names,
             too_short=ValueError("module_spec should contain at least one requirement"),
             too_long=ValueError("module_spec should contain requirements for exactly one module"),
         )
         return module_name
 
 
 @stable_api
 class ModuleV2Source(ModuleSource["ModuleV2"]):
-    def __init__(self, urls: list[str]) -> None:
-        self.urls: list[str] = [url if not os.path.exists(url) else os.path.abspath(url) for url in urls]
+    def __init__(self, urls: List[str]) -> None:
+        self.urls: List[str] = [url if not os.path.exists(url) else os.path.abspath(url) for url in urls]
 
     @classmethod
     def get_installed_version(cls, module_name: str) -> Optional[version.Version]:
         """
         Returns the version for a module if it is installed.
         """
         if module_name.startswith(ModuleV2.PKG_NAME_PREFIX):
@@ -687,25 +707,26 @@
         module_name = module_name.replace("_", "-")
         return f"{ModuleV2.PKG_NAME_PREFIX}{module_name}"
 
     @classmethod
     def get_namespace_package_name(cls, module_name: str) -> str:
         return f"{const.PLUGINS_PACKAGE}.{module_name}"
 
-    def install(self, project: "Project", module_spec: list[InmantaModuleRequirement]) -> Optional["ModuleV2"]:
+    def install(self, project: "Project", module_spec: List[InmantaModuleRequirement]) -> Optional["ModuleV2"]:
         module_name: str = self._get_module_name(module_spec)
-        if not self.urls:
+        if not self.urls and not project.metadata.pip.use_config_file:
             raise Exception(
-                f"Attempting to install a v2 module {module_name} but no v2 module source is configured. Add at least one "
-                'repo of type "package" to the project config file. e.g. to add PyPi as a module source, add the following to '
-                "the `repo` section of the project's `project.yml`:"
-                "\n\t- type: package"
-                "\n\t  url: https://pypi.org/simple"
+                f"Attempting to install a v2 module {module_name} but no v2 module source is configured. Add the relevant pip "
+                f"indexes to the project config file. e.g. to add PyPi as a module source, add the following to "
+                "the `pip` section of the project's `project.yml`:"
+                "\n\t  index_urls:"
+                "\n\t\t  - https://pypi.org/simple"
+                "\nAnother option is to set the use_config_file project option to true to use the system's pip config file."
             )
-        requirements: list[Requirement] = [req.get_python_package_requirement() for req in module_spec]
+        requirements: List[Requirement] = [req.get_python_package_requirement() for req in module_spec]
         allow_pre_releases = project is not None and project.install_mode in {InstallMode.prerelease, InstallMode.master}
         preinstalled: Optional[ModuleV2] = self.get_installed_module(project, module_name)
 
         # Get known requires and add them to prevent invalidating constraints through updates
         # These could be constraints (-c) as well, but that requires additional sanitation
         # Because for pip not every valid -r is a valid -c
         current_requires = project.get_strict_python_requirements_as_list()
@@ -720,43 +741,47 @@
                     module_name,
                     preinstalled_version,
                     ",".join(constraint.version_spec_str() for constraint in module_spec if constraint.specs),
                 )
         try:
             self.log_pre_install_information(module_name, module_spec)
             modules_pre_install = self.take_v2_modules_snapshot(header="Modules versions before installation:")
-            env.process_env.install_from_index(requirements, self.urls, allow_pre_releases=allow_pre_releases)
-
+            env.process_env.install_from_index(
+                requirements,
+                self.urls,
+                allow_pre_releases=allow_pre_releases,
+                use_pip_config=project.metadata.pip.use_config_file,
+            )
             self.log_post_install_information(module_name)
             self.log_snapshot_difference_v2_modules(modules_pre_install, header="Modules versions after installation:")
         except env.PackageNotFound:
             return None
         path: Optional[str] = self.path_for(module_name)
         if path is None:
             python_package: str = ModuleV2Source.get_package_name_for(module_name)
             namespace_package: str = self.get_namespace_package_name(module_name)
             raise InvalidModuleException(f"{python_package} does not contain a {namespace_package} module.")
         return self.from_path(project, module_name, path)
 
-    def log_pre_install_information(self, module_name: str, module_spec: list[InmantaModuleRequirement]) -> None:
+    def log_pre_install_information(self, module_name: str, module_spec: List[InmantaModuleRequirement]) -> None:
         LOGGER.debug("Installing module %s (v2) %s.", module_name, super()._format_constraints(module_name, module_spec))
 
-    def take_v2_modules_snapshot(self, header: Optional[str] = None) -> dict[str, version.Version]:
+    def take_v2_modules_snapshot(self, header: Optional[str] = None) -> Dict[str, version.Version]:
         """
         Log and return a dictionary containing currently installed v2 modules and their versions.
 
         :param header: Optional text to be displayed before logging the modules and their versions
         """
         packages = env.PythonWorkingSet.get_packages_in_working_set(inmanta_modules_only=True)
         version_snapshot = {self.get_inmanta_module_name(mod): version for mod, version in packages.items()}
         super()._log_version_snapshot(header, version_snapshot)
         return version_snapshot
 
     def log_snapshot_difference_v2_modules(
-        self, previous_snapshot: dict[str, version.Version], header: Optional[str] = None
+        self, previous_snapshot: Dict[str, version.Version], header: Optional[str] = None
     ) -> None:
         """
         Logs a diff view of v2 inmanta modules currently installed (in alphabetical order) and their version.
 
         :param previous_snapshot: Mapping of inmanta module names to their respective versions. This is the baseline against
         which the currently installed versions will be compared.
         :param header: Optional text to be displayed before logging the diff view
@@ -778,15 +803,15 @@
     def path_for(self, name: str) -> Optional[str]:
         """
         Returns the path to the module root directory. Should be called prior to configuring the module finder for v1 modules.
         """
         if name.startswith(ModuleV2.PKG_NAME_PREFIX):
             raise ValueError("PythonRepo instances work with inmanta module names, not Python package names.")
         package: str = self.get_namespace_package_name(name)
-        mod_spec: Optional[tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(package)
+        mod_spec: Optional[Tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(package)
         if mod_spec is None:
             return None
         init, mod_loader = mod_spec
         if isinstance(mod_loader, loader.PluginModuleLoader):
             # Module was found in the environment but it is associated with the v1 module loader. Since the v2 loader has
             # precedence, we can conclude the module has not been installed in v2 mode. If it were, the module could never
             # be associated with the v1 loader.
@@ -817,42 +842,42 @@
         return ModuleV2(
             project,
             path,
             is_editable_install=os.path.exists(os.path.join(path, const.PLUGINS_PACKAGE)),
             installed_version=cls.get_installed_version(module_name),
         )
 
-    def _get_module_name(self, module_spec: list[InmantaModuleRequirement]) -> str:
+    def _get_module_name(self, module_spec: List[InmantaModuleRequirement]) -> str:
         module_name: str = super()._get_module_name(module_spec)
         if module_name.startswith(ModuleV2.PKG_NAME_PREFIX.replace("-", "_")):
             raise ValueError("PythonRepo instances work with inmanta module names, not Python package names.")
         return module_name
 
 
 class ModuleV1Source(ModuleSource["ModuleV1"]):
     def __init__(self, local_repo: "ModuleRepo", remote_repo: "ModuleRepo") -> None:
         self.local_repo: ModuleRepo = local_repo
         self.remote_repo: ModuleRepo = remote_repo
 
-    def log_pre_install_information(self, module_name: str, module_spec: list[InmantaModuleRequirement]) -> None:
+    def log_pre_install_information(self, module_name: str, module_spec: List[InmantaModuleRequirement]) -> None:
         LOGGER.debug("Installing module %s (v1) %s.", module_name, super()._format_constraints(module_name, module_spec))
 
-    def take_modules_snapshot(self, project: "Project", header: Optional[str] = None) -> dict[str, version.Version]:
+    def take_modules_snapshot(self, project: "Project", header: Optional[str] = None) -> Dict[str, version.Version]:
         """
         Log and return a dictionary containing currently loaded modules and their versions.
 
         :param header: Optional text to be displayed before logging the modules and their versions
         """
 
         version_snapshot = {module_name: module.version for module_name, module in project.modules.items()}
         super()._log_version_snapshot(header, version_snapshot)
         return version_snapshot
 
     def log_snapshot_difference_v1_modules(
-        self, project: "Project", previous_snapshot: dict[str, version.Version], header: Optional[str] = None
+        self, project: "Project", previous_snapshot: Dict[str, version.Version], header: Optional[str] = None
     ) -> None:
         """
         Logs a diff view on inmanta modules (both v1 and v2) currently loaded (in alphabetical order) and their version.
 
         :param project: The currently active project.
         :param previous_snapshot: Mapping of inmanta module names to their respective versions. This is the baseline against
         which the currently installed versions will be compared.
@@ -875,15 +900,15 @@
             "Successfully installed module %s (v1) version %s in %s%s.",
             module.name,
             module.version,
             module.path,
             remote_repo,
         )
 
-    def install(self, project: "Project", module_spec: list[InmantaModuleRequirement]) -> Optional["ModuleV1"]:
+    def install(self, project: "Project", module_spec: List[InmantaModuleRequirement]) -> Optional["ModuleV1"]:
         module_name: str = self._get_module_name(module_spec)
         preinstalled: Optional[ModuleV1] = self.get_installed_module(project, module_name)
         if preinstalled is not None:
             preinstalled_version: str = str(preinstalled.version)
             if all(preinstalled_version in constraint for constraint in module_spec):
                 return preinstalled
             else:
@@ -945,15 +970,15 @@
 
         Used to distinguish an empty compose repo from a non-empty one
         """
         return False
 
 
 class CompositeModuleRepo(ModuleRepo):
-    def __init__(self, children: list[ModuleRepo]) -> None:
+    def __init__(self, children: List[ModuleRepo]) -> None:
         self.children = children
 
     def clone(self, name: str, dest: str) -> bool:
         for child in self.children:
             if child.clone(name, dest):
                 return True
         return False
@@ -1038,15 +1063,15 @@
         if key not in mainspec:
             mainspec[key] = [req]
         else:
             mainspec[key] = mainspec[key] + [req]
 
 
 @stable_api
-class InstallMode(str, enum.Enum):
+class InstallMode(str, Enum):
     """
     The module install mode determines what version of a module should be selected when a module is downloaded.
     """
 
     release = "release"
     """
     Only use a released version that is compatible with the current compiler and any version constraints defined in the
@@ -1068,22 +1093,22 @@
     master = "master"
     """
     For V1 modules: Use the module's master branch.
     For V2 modules: Equivalent to :attr:`InstallMode.prerelease`
     """
 
 
-INSTALL_OPTS: list[str] = [mode.value for mode in InstallMode]  # Part of the stable API
+INSTALL_OPTS: List[str] = [mode.value for mode in InstallMode]  # Part of the stable API
 """
 List of possible module install modes, kept for backwards compatibility. New code should use :class:`InstallMode` instead.
 """
 
 
 @stable_api
-class FreezeOperator(str, enum.Enum):
+class FreezeOperator(str, Enum):
     eq = "=="
     compatible = "~="
     ge = ">="
 
     @classmethod
     def get_regex_for_validation(cls) -> str:
         all_values = [re.escape(o.value) for o in cls]
@@ -1193,33 +1218,33 @@
 @stable_api
 class Metadata(BaseModel):
     name: str
     description: Optional[str] = None
     freeze_recursive: bool = False
     freeze_operator: str = Field(default="~=", regex=FreezeOperator.get_regex_for_validation())
 
-    _raw_parser: type[RawParser]
+    _raw_parser: Type[RawParser]
 
     @classmethod
-    def parse(cls: type[TMetadata], source: Union[str, TextIO]) -> TMetadata:
+    def parse(cls: Type[TMetadata], source: Union[str, TextIO]) -> TMetadata:
         raw: Mapping[str, object] = cls._raw_parser.parse(source)
         try:
             return cls(**raw)
         except ValidationError as e:
             if isinstance(source, TextIOBase):
                 raise InvalidMetadata(msg=f"Metadata defined in {source.name} is invalid:", validation_error=e) from e
             else:
                 raise InvalidMetadata(msg=str(e), validation_error=e) from e
 
 
 class MetadataFieldRequires(BaseModel):
-    requires: list[str] = []
+    requires: List[str] = []
 
     @classmethod
-    def to_list(cls, v: object) -> list[object]:
+    def to_list(cls, v: object) -> List[object]:
         if v is None:
             return []
         if not isinstance(v, list):
             return [v]
         return v
 
     @validator("requires", pre=True)
@@ -1244,16 +1269,16 @@
             version.Version(v)
         except version.InvalidVersion as e:
             raise ValueError(f"Version {v} is not PEP440 compliant") from e
         return v
 
     @classmethod
     def rewrite_version(
-        cls: type[TModuleMetadata], source: str, new_version: str, version_tag: str = ""
-    ) -> tuple[str, TModuleMetadata]:
+        cls: Type[TModuleMetadata], source: str, new_version: str, version_tag: str = ""
+    ) -> Tuple[str, TModuleMetadata]:
         """
         Returns the source text with the version replaced by the new version.
         """
         metadata: TModuleMetadata = cls.parse(source)
         current_version = metadata.version
         if current_version == new_version:
             LOGGER.debug("Current version is the same as the new version: %s", current_version)
@@ -1276,15 +1301,15 @@
                 "the egg_info.tag_build field?"
             )
 
         return result, new_metadata
 
     @classmethod
     @abstractmethod
-    def _substitute_version(cls: type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
+    def _substitute_version(cls: Type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
         raise NotImplementedError()
 
     @abstractmethod
     def get_full_version(self) -> packaging.version.Version:
         """
         Return the full version (version + version tag) of this module.
         """
@@ -1316,23 +1341,23 @@
       set.
     :param freeze_operator: (Optional) This key determines the comparison operator used by the freeze command.
       Valid values are [==, ~=, >=]. *Default is '~='*
     """
 
     compiler_version: Optional[str] = None
 
-    _raw_parser: type[YamlParser] = YamlParser
+    _raw_parser: Type[YamlParser] = YamlParser
 
     @validator("compiler_version")
     @classmethod
     def is_pep440_version_v1(cls, v: str) -> str:
         return cls.is_pep440_version(v)
 
     @classmethod
-    def _substitute_version(cls: type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
+    def _substitute_version(cls: Type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
         new_version_obj: version.Version = cls._compose_full_version(new_version, version_tag)
         return re.sub(r"([\s]version\s*:\s*['\"\s]?)[^\"'}\s]+(['\"]?)", rf"\g<1>{new_version_obj}\g<2>", source)
 
     def get_full_version(self) -> packaging.version.Version:
         return version.Version(self.version)
 
     def to_v2(self) -> "ModuleV2Metadata":
@@ -1361,18 +1386,18 @@
       this module will be set in setup.cfg. If it is set to true, all modules imported in any of those modules will also be
       set.
     :param freeze_operator: (Optional) This key determines the comparison operator used by the freeze command.
       Valid values are [==, ~=, >=]. *Default is '~='*
     :param install_requires: The Python packages this module depends on.
     """
 
-    install_requires: list[str]
+    install_requires: List[str]
     version_tag: str = ""
 
-    _raw_parser: type[CfgParser] = CfgParser
+    _raw_parser: Type[CfgParser] = CfgParser
 
     @validator("version")
     @classmethod
     def is_base_version(cls, v: str) -> str:
         version_obj: version.Version = version.Version(v)
         if str(version_obj) != version_obj.base_version:
             raise ValueError(
@@ -1388,15 +1413,15 @@
 
         def get_version_tag(v: packaging.version.Version) -> str:
             if v.is_devrelease:
                 return f"dev{v.dev}"
             if v.is_prerelease:
                 # e.g. rc
                 assert v.pre is not None
-                return f"{v.pre[0]}{v.pre[1]}"
+                return "%s%s" % (v.pre[0], v.pre[1])
             if v.is_postrelease:
                 return f"post{v.post}"
             return ""
 
         return v.base_version, get_version_tag(v)
 
     @validator("version_tag")
@@ -1420,15 +1445,15 @@
             raise ValueError("Module names should not contain underscores, use '-' instead.")
         return v
 
     def get_full_version(self) -> packaging.version.Version:
         return self._compose_full_version(self.version, self.version_tag)
 
     @classmethod
-    def _substitute_version(cls: type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
+    def _substitute_version(cls: Type[TModuleMetadata], source: str, new_version: str, version_tag: str = "") -> str:
         result = re.sub(
             r"(\[metadata\][^\[]*[ \t\f\v]*version[ \t\f\v]*=[ \t\f\v]*)[\S]+(\n|$)",
             rf"\g<1>{new_version}\n",
             source,
         )
         if "[egg_info]" not in result:
             result = f"{result}\n[egg_info]\ntag_build = {version_tag}"
@@ -1458,15 +1483,15 @@
                 out.add_section("egg_info")
             out.set("egg_info", "tag_build", self.version_tag)
 
         return out
 
 
 @stable_api
-class ModuleRepoType(enum.Enum):
+class ModuleRepoType(Enum):
     git = "git"
     package = "package"
 
 
 @stable_api
 class ModuleRepoInfo(BaseModel):
     url: str
@@ -1506,14 +1531,31 @@
         )
 
     def __str__(self) -> str:
         return f"{self.first_type}.{self.first_relation_name} before {self.then_type}.{self.then_relation_name}"
 
 
 @stable_api
+class ProjectPipConfig(BaseModel):
+    """
+    :param use_config_file: Indicates whether the pip configuration files have to be taken into account when installing
+        Python packages.
+    :param index_urls: List of pip indexes to use project-wide. These repositories should be
+        `PEP 503 <https://www.python.org/dev/peps/pep-0503/>`_ (the simple repository API)
+        compliant. If more than one index url is configured, they will all be passed to pip. This is generally only
+        recommended if all configured indexes are under full control of the end user to protect against dependency
+        confusion attacks. See the `pip install documentation <https://pip.pypa.io/en/stable/cli/pip_install/>`_ and
+        `PEP 708 (draft) <https://peps.python.org/pep-0708/>`_ for more information.
+    """
+
+    use_config_file: bool = False
+    index_urls: List[str] = []
+
+
+@stable_api
 class ProjectMetadata(Metadata, MetadataFieldRequires):
     """
     :param name: The name of the project.
     :param description: (Optional) An optional description of the project
     :param author: (Optional) The author of the project
     :param author_email: (Optional) The contact email address of author
     :param license: (Optional) License the project is released under
@@ -1526,20 +1568,16 @@
     :param repo: (Optional) A list (a yaml list) of repositories where Inmanta can find modules. Inmanta tries each repository
         in the order they appear in the list. Each element of this list requires a ``type`` and a ``url`` field. The type field
         can have the following values:
 
         * git: When the type is set to git, the url field should contain a template of the Git repo URL. Inmanta creates the
           git repo url by formatting {} or {0} with the name of the module. If no formatter is present it appends the name
           of the module to the URL.
-        * package: When the type is set to package, the URL field should contain the URL of the Python package repository.
-          The repository should be `PEP 503 <https://www.python.org/dev/peps/pep-0503/>`_ (the simple repository API)
-          compliant. If more than one package url is configured, they will all be passed to pip. This is generally only
-          recommended if all configured indexes are under full control of the end user to protect against dependency
-          confusion attacks. See the `pip install documentation <https://pip.pypa.io/en/stable/cli/pip_install/>`_ and
-          `PEP 708 (draft) <https://peps.python.org/pep-0708/>`_ for more information.
+        * package: [DEPRECATED] Setting up pip indexes should be done via the ``index_urls`` option of the ``pip`` section. See
+          :py:class:`inmanta.module.ProjectPipConfig` for more details.
 
         The old syntax, which only defines a Git URL per list entry is maintained for backward compatibility.
     :param requires: (Optional) This key can contain a list (a yaml list) of version constraints for modules used in this
         project. Similar to the module, version constraints are defined using
         `PEP440 syntax <https://www.python.org/dev/peps/pep-0440/#version-specifiers>`_.
     :param freeze_recursive: (Optional) This key determined if the freeze command will behave recursively or not. If
         freeze_recursive is set to false or not set, the current version of all modules imported directly in the main.cf file
@@ -1570,61 +1608,74 @@
         account when making changes to handler code.
 
         Another caveat is that if the dependency module does contain code that is relevant for the agent, it will be loaded
         like any other handler code and it will be this code that is imported by any dependent modules (though depending on
         the load order the very first import may use the version installed by pip). If at some point this dependency module's
         handlers cease to be relevant for this agent, its code will remain stale. Therefore this feature should not be depended
         on in transient scenarios like this.
+    :param pip: A configuration section that holds information about the pip configuration that should be taken into account
+                when installing Python packages (See: :py:class:`inmanta.module.ProjectPipConfig` for more details).
     """
 
-    _raw_parser: type[YamlParser] = YamlParser
+    _raw_parser: Type[YamlParser] = YamlParser
     _re_relation_precedence_rule: str = r"^(?P<ft>[^\s.]+)\.(?P<fr>[^\s.]+)\s+before\s+(?P<tt>[^\s.]+)\.(?P<tr>[^\s.]+)$"
     _re_relation_precedence_rule_compiled: re.Pattern[str] = re.compile(_re_relation_precedence_rule)
 
     author: Optional[str] = None
     author_email: Optional[NameEmail] = None
     license: Optional[str] = None
     copyright: Optional[str] = None
-    modulepath: list[str] = []
-    repo: list[ModuleRepoInfo] = []
+    modulepath: List[str] = []
+    repo: List[ModuleRepoInfo] = []
     downloadpath: Optional[str] = None
     install_mode: InstallMode = InstallMode.release
-    requires: list[str] = []
-    relation_precedence_policy: list[constr(strip_whitespace=True, regex=_re_relation_precedence_rule, min_length=1)] = []
+    requires: List[str] = []
+    relation_precedence_policy: List[constr(strip_whitespace=True, regex=_re_relation_precedence_rule, min_length=1)] = []
     strict_deps_check: bool = True
     agent_install_dependency_modules: bool = False
+    pip: ProjectPipConfig = ProjectPipConfig()
 
     @validator("modulepath", pre=True)
     @classmethod
     def modulepath_to_list(cls, v: object) -> object:
         return cls.to_list(v)
 
     @validator("repo", pre=True)
     @classmethod
-    def validate_repo_field(cls, v: object) -> list[dict[Any, Any]]:
+    def validate_repo_field(cls, v: object) -> List[Dict[Any, Any]]:
         v_as_list = cls.to_list(v)
         result = []
         for elem in v_as_list:
             if isinstance(elem, str):
                 # Ensure backward compatibility with the version of Inmanta that didn't have support for the type field.
                 result.append({"url": elem, "type": ModuleRepoType.git})
             elif isinstance(elem, dict):
+                if elem["type"] == ModuleRepoType.package.value:
+                    LOGGER.warning(
+                        "Setting a pip index through the `repo -> url` option with type `package` in the project.yml file "
+                        "is deprecated. Please set the pip index url through the `pip -> index_urls` option instead."
+                    )
                 result.append(elem)
             else:
                 raise ValueError(f"Value should be either a string of a dict, got {elem}")
         return result
 
-    def get_relation_precedence_rules(self) -> list[RelationPrecedenceRule]:
+    def get_relation_precedence_rules(self) -> List[RelationPrecedenceRule]:
         """
         Return all RelationPrecedenceRules defined in the project.yml file.
         """
         return [RelationPrecedenceRule.from_string(rule_as_str) for rule_as_str in self.relation_precedence_policy]
 
-    def get_index_urls(self) -> list[str]:
-        return [repo.url for repo in self.repo if repo.type == ModuleRepoType.package]
+    def get_index_urls(self) -> List[str]:
+        # Once setting repos with type package is no longer supported, this method can return self.pip.index_urls alone.
+        index_urls_deprecated_option: List[str] = [repo.url for repo in self.repo if repo.type == ModuleRepoType.package]
+
+        # This ensures no duplicates are returned and insertion order is preserved.
+        # i.e. the left-most index will be passed to pip as --index-url and the others as --extra-index-url
+        return list({value: None for value in itertools.chain(self.pip.index_urls, index_urls_deprecated_option)})
 
 
 @stable_api
 class ModuleLike(ABC, Generic[TMetadata]):
     """
     Commons superclass for projects and modules, which are both versioned by git
 
@@ -1643,15 +1694,15 @@
     @abstractmethod
     # Union[Project, ModuleV1, ModuleV2] would be more strict than ModuleLike[Any] but very restrictive with potential stable
     # API extension in mind.
     def from_path(cls, path: str) -> Optional["ModuleLike"]:
         """
         Get a concrete module like instance from a path. Returns None when no project or module is present at the given path.
         """
-        subs: tuple[type[ModuleLike], ...] = (Project, Module)
+        subs: Tuple[Type[ModuleLike], ...] = (Project, Module)
         for sub in subs:
             instance: Optional[ModuleLike] = sub.from_path(path)
             if instance is not None:
                 return instance
         return None
 
     @classmethod
@@ -1672,22 +1723,22 @@
 
     def _get_metadata_from_disk(self) -> TMetadata:
         metadata_file_path = self.get_metadata_file_path()
 
         if not os.path.exists(metadata_file_path):
             raise ModuleMetadataFileNotFound(f"Metadata file {metadata_file_path} does not exist")
 
-        with open(metadata_file_path, encoding="utf-8") as fd:
+        with open(metadata_file_path, "r", encoding="utf-8") as fd:
             return self.get_metadata_from_source(source=fd)
 
     def get_metadata_from_source(self, source: Union[str, TextIO]) -> TMetadata:
         """
         :param source: Either the yaml content as a string or an input stream from the yaml file
         """
-        metadata_type: type[TMetadata] = self.get_metadata_file_schema_type()
+        metadata_type: Type[TMetadata] = self.get_metadata_file_schema_type()
         return metadata_type.parse(source)
 
     @property
     def path(self) -> str:
         return self._path
 
     @property
@@ -1704,15 +1755,15 @@
 
     @abstractmethod
     def get_metadata_file_path(self) -> str:
         raise NotImplementedError()
 
     @classmethod
     @abstractmethod
-    def get_metadata_file_schema_type(cls) -> type[TMetadata]:
+    def get_metadata_file_schema_type(cls) -> Type[TMetadata]:
         raise NotImplementedError()
 
     @classmethod
     @abstractmethod
     def get_name_from_metadata(cls, metadata: TMetadata) -> str:
         raise NotImplementedError()
 
@@ -1724,15 +1775,15 @@
 
         This operation may make this object invalid or outdated if the persisted metadata has been updated since creating this
         instance.
         """
         raise NotImplementedError()
 
     @abstractmethod
-    def get_module_requirements(self) -> list[str]:
+    def get_module_requirements(self) -> List[str]:
         """
         Returns all requirements this module has on other modules, regardless of module generation. Requirements should be on
         inmanta module names, not Python package names.
         """
         raise NotImplementedError()
 
     def has_module_requirement(self, module_name: str) -> bool:
@@ -1740,15 +1791,15 @@
         :param module_name: The module name in lower cases.
         :returns: True iff the module defines a dependency on the given module in one of the files that
                   declare dependencies module dependencies. This could include the requirements.txt file
                   next to the metadata file of the project or module.
         """
         return any(module_name == InmantaModuleRequirement.parse(req).key for req in self.get_module_requirements())
 
-    def _load_file(self, ns: Namespace, file: str) -> tuple[list[Statement], BasicBlock]:
+    def _load_file(self, ns: Namespace, file: str) -> Tuple[List[Statement], BasicBlock]:
         ns.location = Location(file, 1)
         statements = []  # type: List[Statement]
         stmts = plyInmantaParser.parse(ns, file)
         block = BasicBlock(ns)
         for s in stmts:
             if isinstance(s, BiStatement):
                 statements.append(s)
@@ -1759,39 +1810,39 @@
             elif isinstance(s, str) or isinstance(s, LocatableString):
                 pass
             else:
                 assert isinstance(s, DynamicStatement)
                 block.add(s)
         return (statements, block)
 
-    def _get_requirements_txt_as_list(self) -> list[str]:
+    def _get_requirements_txt_as_list(self) -> List[str]:
         """
         Returns the contents of the requirements.txt file as a list of requirements, if it exists.
         """
         file = os.path.join(self._path, "requirements.txt")
         if os.path.exists(file):
             return RequirementsTxtParser.parse_requirements_as_strs(file)
         else:
             return []
 
     @abstractmethod
-    def get_all_python_requirements_as_list(self) -> list[str]:
+    def get_all_python_requirements_as_list(self) -> List[str]:
         """
         Returns all Python requirements specified by this module like, including requirements on V2 modules.
         """
         raise NotImplementedError()
 
-    def get_strict_python_requirements_as_list(self) -> list[str]:
+    def get_strict_python_requirements_as_list(self) -> List[str]:
         """
         Returns the strict python requirements specified by this module like, meaning all Python requirements excluding those on
         inmanta modules.
         """
         return [req for req in self.get_all_python_requirements_as_list() if not req.startswith(ModuleV2.PKG_NAME_PREFIX)]
 
-    def get_module_v2_requirements(self) -> list[InmantaModuleRequirement]:
+    def get_module_v2_requirements(self) -> List[InmantaModuleRequirement]:
         """
         Returns all requirements this module like has on v2 modules.
         """
         return [
             InmantaModuleRequirement.parse(ModuleV2Source.get_inmanta_module_name(req))
             for req in self.get_all_python_requirements_as_list()
             if req.startswith(ModuleV2.PKG_NAME_PREFIX)
@@ -1808,16 +1859,16 @@
         Updates the metadata file of the given project or V1 module by adding the given requirement the `requires` section.
 
         :param requirement: The requirement to add.
         """
         # Parse cfg file
         content: CommentedMap = PreservativeYamlParser.parse(self.get_metadata_file_path())
         # Update requires
-        if "requires" in content and content["requires"]:
-            existing_matching_reqs: list[str] = [
+        if "requires" in content:
+            existing_matching_reqs: List[str] = [
                 r for r in content["requires"] if InmantaModuleRequirement.parse(r).key == requirement.key
             ]
             for r in existing_matching_reqs:
                 content["requires"].remove(r)
             content["requires"].append(str(requirement))
         else:
             content["requires"] = [str(requirement)]
@@ -1888,15 +1939,15 @@
         """
         if not os.path.exists(path):
             raise ProjectNotFoundException(f"Directory {path} doesn't exist")
         super().__init__(path)
         self.project_path = path
         self.main_file = main_file
 
-        self._ast_cache: Optional[tuple[list[Statement], BasicBlock]] = None  # Cache for expensive method calls
+        self._ast_cache: Optional[Tuple[List[Statement], BasicBlock]] = None  # Cache for expensive method calls
         self._metadata.modulepath = [os.path.abspath(os.path.join(path, x)) for x in self._metadata.modulepath]
         self.module_source: ModuleV2Source = ModuleV2Source(self.metadata.get_index_urls())
         self.module_source_v1: ModuleV1Source = ModuleV1Source(
             local_repo=CompositeModuleRepo([make_repo(x) for x in self.modulepath]),
             remote_repo=CompositeModuleRepo(
                 [make_repo(repo.url, root=path) for repo in self._metadata.repo if repo.type == ModuleRepoType.git]
             ),
@@ -1919,33 +1970,30 @@
             if isinstance(venv_path, env.VirtualEnv):
                 self.virtualenv = venv_path
             else:
                 venv_path = os.path.abspath(venv_path)
                 self.virtualenv = env.VirtualEnv(venv_path)
 
         self.loaded = False
-        self.modules: dict[str, Module] = {}
+        self.modules: Dict[str, Module] = {}
         self.root_ns = Namespace("__root__")
         self.autostd = autostd
         if attach_cf_cache:
             cache_manager.attach_to_project(path)
 
         if strict_deps_check is not None:
             self.strict_deps_check = strict_deps_check
         else:
             self.strict_deps_check = self._metadata.strict_deps_check
 
-        self._complete_ast: Optional[tuple[list[Statement], list[BasicBlock]]] = None
-        # Cache for the complete ast
-
-    def get_relation_precedence_policy(self) -> list[RelationPrecedenceRule]:
+    def get_relation_precedence_policy(self) -> List[RelationPrecedenceRule]:
         return self._metadata.get_relation_precedence_rules()
 
     @classmethod
-    def from_path(cls: type[TProject], path: str) -> Optional[TProject]:
+    def from_path(cls: Type[TProject], path: str) -> Optional[TProject]:
         return cls(path=path) if os.path.exists(os.path.join(path, cls.PROJECT_FILE)) else None
 
     def install_module(self, module_req: InmantaModuleRequirement, install_as_v1_module: bool) -> None:
         """
         Install the given module. If attempting to as v2, this method implicitly trusts any Python package with the
         corresponding name.
         Does not reinstall if the given module requirement is already met.
@@ -1966,26 +2014,26 @@
         return metadata.name
 
     @property
     def install_mode(self) -> InstallMode:
         return self._metadata.install_mode
 
     @property
-    def modulepath(self) -> list[str]:
+    def modulepath(self) -> List[str]:
         return self._metadata.modulepath
 
     @property
     def downloadpath(self) -> Optional[str]:
         return self._metadata.downloadpath
 
     def get_metadata_file_path(self) -> str:
         return os.path.join(self._path, Project.PROJECT_FILE)
 
     @classmethod
-    def get_metadata_file_schema_type(cls) -> type[ProjectMetadata]:
+    def get_metadata_file_schema_type(cls) -> Type[ProjectMetadata]:
         return ProjectMetadata
 
     @classmethod
     def get_project_dir(cls, cur_dir: str) -> str:
         """
         Find the project directory where we are working in. Traverse up until we find Project.PROJECT_FILE or reach /
         """
@@ -2027,29 +2075,30 @@
         :param update_dependencies: Update all Python dependencies (recursive) to their latest versions.
         """
         if not self.is_using_virtual_env():
             self.use_virtual_env()
 
         self.load_module_recursive(install=True, bypass_module_cache=bypass_module_cache)
 
-        indexes_urls: list[str] = self.metadata.get_index_urls()
+        indexes_urls: List[str] = self.metadata.get_index_urls()
         # Verify non-python part
         self.verify_modules_cache()
         self.verify_module_version_compatibility()
 
         # do python install
-        pyreq: list[Requirement] = [Requirement.parse(x) for x in self.collect_python_requirements()]
+        pyreq: List[Requirement] = [Requirement.parse(x) for x in self.collect_python_requirements()]
 
         if len(pyreq) > 0:
             # upgrade both direct and transitive module dependencies: eager upgrade strategy
             self.virtualenv.install_from_index(
                 pyreq,
                 upgrade=update_dependencies,
                 index_urls=indexes_urls if indexes_urls else None,
                 upgrade_strategy=env.PipUpgradeStrategy.EAGER,
+                use_pip_config=self.metadata.pip.use_config_file,
             )
 
         self.verify()
 
     def load(self, install: bool = False) -> None:
         """
         Load this project's AST and plugins.
@@ -2059,74 +2108,66 @@
         if not self.loaded:
             if not self.is_using_virtual_env():
                 self.use_virtual_env()
             if install:
                 self.install_modules()
             self.get_complete_ast()
             self.loaded = True
-            start = time()
             self.verify()
             self.load_plugins()
-            end = time()
-            LOGGER.debug("Plugin loading took %0.03f seconds", end - start)
 
     def invalidate_state(self, module: Optional[str] = None) -> None:
         """
         Invalidate this project's state, forcing a reload next time load is called.
 
         :param module: Invalidate the state for a single module. If omitted, invalidates the state for all modules.
         """
         if module is not None:
             if module in self.modules:
                 del self.modules[module]
         else:
             self.modules = {}
         self.loaded = False
-        self._ast_cache = None
-        self._complete_ast = None
 
-    def get_ast(self) -> tuple[list[Statement], BasicBlock]:
+    def get_ast(self) -> Tuple[List[Statement], BasicBlock]:
         if self._ast_cache is None:
             self._ast_cache = self.__load_ast()
         return self._ast_cache
 
-    def get_imports(self) -> list[DefineImport]:
+    def get_imports(self) -> List[DefineImport]:
         (statements, _) = self.get_ast()
         imports = [x for x in statements if isinstance(x, DefineImport)]
         if self.autostd:
             std_locatable = LocatableString("std", Range("__internal__", 1, 1, 1, 1), -1, self.root_ns)
             imp = DefineImport(std_locatable, std_locatable)
             imp.location = std_locatable.location
             imports.insert(0, imp)
         return imports
 
-    def get_complete_ast(self) -> tuple[list[Statement], list[BasicBlock]]:
-        if self._complete_ast is not None:
-            return self._complete_ast
+    def get_complete_ast(self) -> Tuple[List[Statement], List[BasicBlock]]:
         start = time()
         # load ast
         (statements, block) = self.get_ast()
         blocks = [block]
         statements = [x for x in statements]
 
         for _, nstmt, nb in self.load_module_recursive():
             statements.extend(nstmt)
             blocks.append(nb)
 
         end = time()
-        LOGGER.debug("Parsing took %0.03f seconds", end - start)
+        LOGGER.debug("Parsing took %f seconds", end - start)
         cache_manager.log_stats()
-        self._complete_ast = (statements, blocks)
-        return self._complete_ast
+        return (statements, blocks)
 
-    def __load_ast(self) -> tuple[list[Statement], BasicBlock]:
+    def __load_ast(self) -> Tuple[List[Statement], BasicBlock]:
         main_ns = Namespace("__config__", self.root_ns)
         return self._load_file(main_ns, os.path.join(self.project_path, self.main_file))
 
-    def get_modules(self) -> dict[str, "Module"]:
+    def get_modules(self) -> Dict[str, "Module"]:
         self.load()
         return self.modules
 
     def get_module(
         self,
         full_module_name: str,
         *,
@@ -2164,45 +2205,45 @@
 
         if use_module_cache():
             return self.modules[module_name]
         return self.load_module(module_name, allow_v1=allow_v1, install_v1=install_v1, install_v2=install_v2)
 
     def load_module_recursive(
         self, install: bool = False, bypass_module_cache: bool = False
-    ) -> list[tuple[str, list[Statement], BasicBlock]]:
+    ) -> List[Tuple[str, List[Statement], BasicBlock]]:
         """
         Loads this project's modules and submodules by recursively following import statements starting from the project's main
         file.
 
         For each imported submodule, return a triple of name, statements, basicblock
 
         :param install: Run in install mode, installing any modules that have not yet been installed. If install is False,
             all modules are expected to be preinstalled. For security reasons installation of v2 modules is based on explicit
             Python requirements rather than on imports.
         :param bypass_module_cache: Fetch the module data from disk even if a cache entry exists.
         """
-        ast_by_top_level_mod: dict[str, list[tuple[str, list[Statement], BasicBlock]]] = defaultdict(list)
+        ast_by_top_level_mod: Dict[str, List[Tuple[str, List[Statement], BasicBlock]]] = defaultdict(list)
 
         # List of imports that still have to be loaded.
         # get imports: don't use a set because this collection is used to drive control flow and we want to keep control flow as
         # deterministic as possible
-        imports: list[DefineImport] = [x for x in self.get_imports()]
+        imports: List[DefineImport] = [x for x in self.get_imports()]
 
         # All imports of the entire project
-        all_imports: set[DefineImport] = set(imports)
+        all_imports: Set[DefineImport] = set(imports)
 
-        v2_modules: set[str] = set()
+        v2_modules: Set[str] = set()
         """
         Set of modules that should be loaded as a V2 module.
         """
-        set_up: set[str] = set()
+        set_up: Set[str] = set()
         """
         Set of top level modules that have been set up (setup_module()).
         """
-        done: dict[str, dict[str, DefineImport]] = defaultdict(dict)
+        done: Dict[str, Dict[str, DefineImport]] = defaultdict(dict)
         """
         Submodules, grouped by top level that have been fully loaded: AST has been loaded into ast_by_top_level_mod and its
         imports have been added to the queue (load_sub_module()).
         """
 
         def require_v2(module_name: str) -> None:
             """
@@ -2256,26 +2297,26 @@
         def load_sub_module(module: Module, imp: DefineImport) -> None:
             """
             Loads a submodule's AST and processes its imports. Enforces dependency generation directionality (v1 can depend on
             v2 but not the other way around). If any modules have already been loaded with an incompatible generation, queues
             them for reload.
             Does not install any v2 modules.
             """
-            parts: list[str] = imp.name.split("::")
+            parts: List[str] = imp.name.split("::")
             for i in range(1, len(parts) + 1):
                 subs = "::".join(parts[0:i])
                 if subs in done[module.name]:
                     continue
                 (nstmt, nb) = module.get_ast(subs)
 
                 done[module.name][subs] = imp
                 ast_by_top_level_mod[module.name].append((subs, nstmt, nb))
 
                 # get imports and add to list
-                subs_imports: list[DefineImport] = module.get_imports(subs)
+                subs_imports: List[DefineImport] = module.get_imports(subs)
                 add_imports_to_be_loaded(subs_imports)
                 if isinstance(module, ModuleV2):
                     # A V2 module can only depend on V2 modules. Ensure that all dependencies
                     # of this module will be loaded as a V2 module.
                     for dep_module_name in (subs_imp.name.split("::")[0] for subs_imp in subs_imports):
                         require_v2(dep_module_name)
 
@@ -2313,16 +2354,16 @@
                 load_sub_module(module, imp)
             except (InvalidModuleException, ModuleNotFoundException) as e:
                 raise ModuleLoadingException(ns, imp, e)
 
         # Remove modules from self.modules that were not part of an import statement.
         # This happens when a module or a project defines a V2 module requirement in
         # its dependencies, but the requirement is never imported anywhere.
-        loaded_modules: set[str] = set(self.modules.keys())
-        imported_modules: set[str] = {i.name.split("::")[0] for i in all_imports}
+        loaded_modules: Set[str] = set(self.modules.keys())
+        imported_modules: Set[str] = set(i.name.split("::")[0] for i in all_imports)
         for module_to_unload in loaded_modules - imported_modules:
             self.invalidate_state(module_to_unload)
 
         return list(chain.from_iterable(ast_by_top_level_mod.values()))
 
     def load_module(
         self,
@@ -2341,19 +2382,18 @@
         :param install_v1: Allow installing this module as v1 if it has not yet been installed. This option is ignored if
             allow_v1=False.
         :param install_v2: Allow installing this module as v2 if it has not yet been installed, implicitly trusting any Python
             package with the corresponding name.
         """
         if not self.is_using_virtual_env():
             self.use_virtual_env()
-        reqs: Mapping[str, list[InmantaModuleRequirement]] = self.collect_requirements()
-        module_reqs: list[InmantaModuleRequirement] = (
+        reqs: Mapping[str, List[InmantaModuleRequirement]] = self.collect_requirements()
+        module_reqs: List[InmantaModuleRequirement] = (
             list(reqs[module_name]) if module_name in reqs else [InmantaModuleRequirement.parse(module_name)]
         )
-
         module: Optional[Union[ModuleV1, ModuleV2]]
         try:
             module = self.module_source.get_module(self, module_reqs, install=install_v2)
             if module is not None and self.module_source_v1.path_for(module_name) is not None:
                 LOGGER.warning("Module %s is installed as a V1 module and a V2 module: V1 will be ignored.", module_name)
             if module is None and allow_v1:
                 module = self.module_source_v1.get_module(self, module_reqs, install=install_v1)
@@ -2368,16 +2408,18 @@
             raise ModuleNotFoundException(
                 f"Could not find module {module_name}. Please make sure to add any module v2 requirements with"
                 " `inmanta module add --v2` and to install all the project's dependencies with `inmanta project install`."
             )
         if isinstance(module, ModuleV1):
             warnings.warn(
                 InmantaWarning(
-                    f"Loaded V1 module {module.name}. The use of V1 modules is deprecated."
-                    " Use the equivalent V2 module instead."
+                    (
+                        f"Loaded V1 module {module.name}. The use of V1 modules is deprecated."
+                        " Use the equivalent V2 module instead."
+                    )
                 )
             )
         self.modules[module_name] = module
         return module
 
     def load_plugins(self) -> None:
         """
@@ -2418,15 +2460,15 @@
 
     def verify_module_version_compatibility(self) -> None:
         """
         Check if all the required modules for this module have been loaded. Assumes the modules cache is valid and up to date.
 
         :raises CompilerException: When one or more of the requirements of the project is not satisfied.
         """
-        requirements: dict[str, list[InmantaModuleRequirement]] = self.collect_requirements()
+        requirements: Dict[str, List[InmantaModuleRequirement]] = self.collect_requirements()
 
         exc_message = ""
         for name, spec in requirements.items():
             if name not in self.modules:
                 # the module is in the project requirements but it is not part of the loaded AST so there is no need to verify
                 # its compatibility
                 LOGGER.warning("Module %s is present in requires but it is not used by the model.", name)
@@ -2450,15 +2492,15 @@
             raise CompilerException(exc_message)
 
     def verify_python_requires(self) -> None:
         """
         Verifies no incompatibilities exist within the Python environment with respect to installed module v2 requirements.
         """
         if self.strict_deps_check:
-            constraints: list[Requirement] = [Requirement.parse(item) for item in self.collect_python_requirements()]
+            constraints: List[Requirement] = [Requirement.parse(item) for item in self.collect_python_requirements()]
             env.ActiveEnv.check(strict_scope=re.compile(f"{ModuleV2.PKG_NAME_PREFIX}.*"), constraints=constraints)
         else:
             if not env.ActiveEnv.check_legacy(in_scope=re.compile(f"{ModuleV2.PKG_NAME_PREFIX}.*")):
                 raise CompilerException(
                     "Not all installed modules are compatible: requirements conflicts were found. Please resolve any conflicts"
                     " before attempting another compile. Run `pip check` to check for any incompatibilities."
                 )
@@ -2518,15 +2560,15 @@
 
     def use_virtual_env(self) -> None:
         """
         Use the virtual environment. This activates the environment for the current process.
         """
         self.virtualenv.use_virtual_env()
 
-    def sorted_modules(self) -> list["Module"]:
+    def sorted_modules(self) -> List["Module"]:
         """
         Return a list of all modules, sorted on their name
         """
         names = list(self.modules.keys())
         names = sorted(names)
 
         mod_list = []
@@ -2537,15 +2579,15 @@
 
     def log_installed_modules(self) -> None:
         """
         Log the name, version and generation (v1 or v2) of all installed modules.
         """
         LOGGER.info("The following modules are currently installed:")
 
-        sorted_modules: list["Module"] = self.sorted_modules()
+        sorted_modules: List["Module"] = self.sorted_modules()
 
         def get_modules_with_gen(gen: ModuleGeneration) -> Sequence["Module"]:
             return list(filter(lambda mod: mod.GENERATION == gen, sorted_modules))
 
         v1_modules: Sequence["ModuleV1"] = cast(list["ModuleV1"], get_modules_with_gen(ModuleGeneration.V1))
         v2_modules: Sequence["ModuleV2"] = cast(list["ModuleV2"], get_modules_with_gen(ModuleGeneration.V2))
 
@@ -2560,94 +2602,94 @@
                 LOGGER.info(f"  {v1_mod.name}: {v1_mod.version}")
 
     def add_module_requirement_persistent(self, requirement: InmantaModuleRequirement, add_as_v1_module: bool) -> None:
         # Add requirement to metadata file
         if add_as_v1_module:
             self.add_module_requirement_to_requires_and_write(requirement)
             # Refresh in-memory metadata
-            with open(self.get_metadata_file_path(), encoding="utf-8") as fd:
+            with open(self.get_metadata_file_path(), "r", encoding="utf-8") as fd:
                 self._metadata = ProjectMetadata.parse(fd)
         # Update requirements.txt file
         requirements_txt_file_path = os.path.join(self._path, "requirements.txt")
         if not add_as_v1_module:
             requirements_txt_file = RequirementsTxtFile(requirements_txt_file_path, create_file_if_not_exists=True)
             requirements_txt_file.set_requirement_and_write(requirement.get_python_package_requirement())
         elif os.path.exists(requirements_txt_file_path):
             requirements_txt_file = RequirementsTxtFile(requirements_txt_file_path)
             requirements_txt_file.remove_requirement_and_write(requirement.get_python_package_requirement().key)
 
-    def get_module_requirements(self) -> list[str]:
+    def get_module_requirements(self) -> List[str]:
         return [*self.metadata.requires, *(str(req) for req in self.get_module_v2_requirements())]
 
     def requires(self) -> "List[InmantaModuleRequirement]":
         """
         Get the requires for this project
         """
         # filter on import stmt
         reqs = []
         for spec in self._metadata.requires:
             req = [x for x in parse_requirements(spec)]
             if len(req) > 1:
-                print(f"Module file for {self._path} has bad line in requirements specification {spec}")
+                print("Module file for %s has bad line in requirements specification %s" % (self._path, spec))
             reqe = InmantaModuleRequirement(req[0])
             reqs.append(reqe)
         return [*reqs, *self.get_module_v2_requirements()]
 
     def collect_requirements(self) -> "Dict[str, List[InmantaModuleRequirement]]":
         """
         Collect the list of all module requirements of all modules in the project.
         """
-        specs: dict[str, list[InmantaModuleRequirement]] = {}
+        specs: Dict[str, List[InmantaModuleRequirement]] = {}
         merge_specs(specs, self.requires())
         for module in self.modules.values():
             reqs = module.requires()
             merge_specs(specs, reqs)
         return specs
 
     def collect_imported_requirements(self) -> "Dict[str, List[InmantaModuleRequirement]]":
-        imports = {x.name.split("::")[0] for x in self.get_complete_ast()[0] if isinstance(x, DefineImport)}
+        imports = set([x.name.split("::")[0] for x in self.get_complete_ast()[0] if isinstance(x, DefineImport)])
         if self.autostd:
             imports.add("std")
-        specs: dict[str, list[InmantaModuleRequirement]] = self.collect_requirements()
+        specs: Dict[str, List[InmantaModuleRequirement]] = self.collect_requirements()
 
         def get_spec(name: str) -> "List[InmantaModuleRequirement]":
             if name in specs:
                 return specs[name]
             return [InmantaModuleRequirement.parse(name)]
 
         return {name: get_spec(name) for name in imports}
 
-    def collect_python_requirements(self) -> list[str]:
+    def collect_python_requirements(self) -> List[str]:
         """
         Collect the list of all python requirements of all modules in this project, excluding those on inmanta modules.
         """
         reqs = chain(
             chain.from_iterable([mod.get_strict_python_requirements_as_list() for mod in self.modules.values()]),
             self.get_strict_python_requirements_as_list(),
         )
         return list(set(reqs))
 
     def get_root_namespace(self) -> Namespace:
         return self.root_ns
 
-    def get_freeze(self, mode: str = "==", recursive: bool = False) -> dict[str, str]:
+    def get_freeze(self, mode: str = "==", recursive: bool = False) -> Dict[str, str]:
         # collect in scope modules
         if not recursive:
             modules = {m.name: m for m in (self.get_module(imp.name, allow_v1=True) for imp in self.get_imports())}
         else:
             modules = self.get_modules()
 
         out = {}
         for name, mod in modules.items():
             version = str(mod.version)
             out[name] = mode + " " + version
 
         return out
 
-    def get_all_python_requirements_as_list(self) -> list[str]:
+    def get_all_python_requirements_as_list(self) -> List[str]:
         return self._get_requirements_txt_as_list()
 
     def module_v2_source_configured(self) -> bool:
         """
         Returns True iff this project has one or more module v2 sources configured.
         """
         return any(True for repo in self._metadata.repo if repo.type == ModuleRepoType.package)
@@ -2661,15 +2703,15 @@
         super().__init__(tempfile.gettempdir(), autostd=autostd, attach_cf_cache=False)
 
     def _get_metadata_from_disk(self) -> ProjectMetadata:
         return ProjectMetadata(name="DUMMY")
 
 
 @stable_api
-class ModuleGeneration(enum.Enum):
+class ModuleGeneration(Enum):
     """
     The generation of a module. This might affect the on-disk structure of a module as well as how it's distributed.
     """
 
     V1: int = 1
     V2: int = 2
 
@@ -2697,22 +2739,21 @@
 
         if self.metadata.deprecated:
             warnings.warn(ModuleDeprecationWarning(f"Module {self.name} has been deprecated"))
         self._project: Optional[Project] = project
         self.ensure_versioned()
         self.model_dir = os.path.join(self.path, Module.MODEL_DIR)
 
-        self._ast_cache: dict[str, tuple[list[Statement], BasicBlock]] = {}  # Cache for expensive method calls
-        self._import_cache: dict[str, list[DefineImport]] = {}  # Cache for expensive method calls
-        self._dir_cache: Dict[str, list[str]] = {}  # Cache containing all the filepaths present in a dir
+        self._ast_cache: Dict[str, Tuple[List[Statement], BasicBlock]] = {}  # Cache for expensive method calls
+        self._import_cache: Dict[str, List[DefineImport]] = {}  # Cache for expensive method calls
 
     @classmethod
     @abstractmethod
     def from_path(cls, path: str) -> Optional["Module"]:
-        subs: tuple[type[Module], ...] = (ModuleV1, ModuleV2)
+        subs: Tuple[Type[Module], ...] = (ModuleV1, ModuleV2)
         for sub in subs:
             instance: Optional[Module] = sub.from_path(path)
             if instance is not None:
                 return instance
         return None
 
     def requires(self) -> "List[InmantaModuleRequirement]":
@@ -2736,15 +2777,15 @@
         try:
             return cls.get_first_directory_containing_file(module_subdirectory, cls.MODULE_FILE)
         except FileNotFoundError:
             raise InvalidModuleException(f"Directory {module_subdirectory} is not part of a valid {cls.GENERATION.name} module")
 
     def rewrite_version(self, new_version: str, version_tag: str = "") -> None:
         new_version = str(new_version)  # make sure it is a string!
-        with open(self.get_metadata_file_path(), encoding="utf-8") as fd:
+        with open(self.get_metadata_file_path(), "r", encoding="utf-8") as fd:
             module_def = fd.read()
         new_module_def, new_metadata = self.get_metadata_file_schema_type().rewrite_version(
             module_def, new_version, version_tag
         )
         with open(self.get_metadata_file_path(), "w+", encoding="utf-8") as fd:
             fd.write(new_module_def)
         self._metadata = new_metadata
@@ -2761,15 +2802,15 @@
     def ensure_versioned(self) -> None:
         """
         Check if this module is versioned using Git. If not a warning is logged.
         """
         if not os.path.exists(os.path.join(self.path, ".git")):
             LOGGER.warning("Module %s is not version controlled, we recommend you do this as soon as possible.", self.name)
 
-    def get_ast(self, name: str) -> tuple[list[Statement], BasicBlock]:
+    def get_ast(self, name: str) -> Tuple[List[Statement], BasicBlock]:
         if self._project is None:
             raise ValueError("Can only get module's AST in the context of a project.")
 
         # Check local cache
         hit = self._ast_cache.get(name, None)
         if hit is not None:
             return hit
@@ -2791,38 +2832,38 @@
             out = self._load_file(ns, file)
             # Set local cache before returning
             self._ast_cache[name] = out
             return out
         except FileNotFoundError as e:
             raise InvalidModuleException("could not locate module with name: %s" % name) from e
 
-    def get_freeze(self, submodule: str, recursive: bool = False, mode: str = ">=") -> dict[str, str]:
+    def get_freeze(self, submodule: str, recursive: bool = False, mode: str = ">=") -> Dict[str, str]:
         if self._project is None:
             raise ValueError("Can only get module's freeze in the context of a project.")
 
         imports = [statement.name for statement in self.get_imports(submodule)]
 
-        out: dict[str, str] = {}
+        out: Dict[str, str] = {}
 
-        todo: list[str] = imports
+        todo: List[str] = imports
 
         for impor in todo:
             if impor not in out:
                 v1_mode: bool = self.GENERATION == ModuleGeneration.V1
                 mainmod = self._project.get_module(impor, install_v1=v1_mode, allow_v1=v1_mode)
                 vers: version.Version = mainmod.version
                 # track submodules for cycle avoidance
                 out[impor] = mode + " " + str(vers)
                 if recursive:
                     todo.extend([statement.name for statement in mainmod.get_imports(impor)])
 
         # drop submodules
         return {x: v for x, v in out.items() if "::" not in x}
 
-    def get_imports(self, name: str) -> list[DefineImport]:
+    def get_imports(self, name: str) -> List[DefineImport]:
         # Check local cache
         hit = self._import_cache.get(name, None)
         if hit is not None:
             return hit
 
         if self._project is None:
             raise ValueError("Can only get module's imports in the context of a project.")
@@ -2835,31 +2876,31 @@
             imp.location = std_locatable.location
             imports.insert(0, imp)
 
         # Set local cache before returning
         self._import_cache[name] = imports
         return imports
 
-    def _get_model_files(self, curdir: str) -> list[str]:
-        files: list[str] = []
+    def _get_model_files(self, curdir: str) -> List[str]:
+        files: List[str] = []
         init_cf = os.path.join(curdir, "_init.cf")
         if not os.path.exists(init_cf):
             return files
 
         for entry in os.listdir(curdir):
             entry = os.path.join(curdir, entry)
             if os.path.isdir(entry):
                 files.extend(self._get_model_files(entry))
 
             elif entry[-3:] == ".cf":
                 files.append(entry)
 
         return files
 
-    def get_all_submodules(self) -> list[str]:
+    def get_all_submodules(self) -> List[str]:
         """
         Get all submodules of this module
         """
         modules = []
         files = self._get_model_files(self.model_dir)
 
         for f in files:
@@ -2880,67 +2921,30 @@
         """
         Return directory containing the python files which define handlers and plugins.
         If no such directory is defined, this method returns None.
         """
         raise NotImplementedError()
 
     def _list_python_files(self, plugin_dir: str) -> list[str]:
-        """
-        Generate a list of all Python files in the given plugin directory.
-        This method prioritizes .pyc files over .py files, uses caching to avoid duplicate directory walks,
-        includes namespace packages and excludes the model directory.
-        """
-        # Return cached results if this directory has been processed before
-        if plugin_dir in self._dir_cache:
-            return self._dir_cache[plugin_dir]
-
-        files: dict[str, str] = {}
-        model_dir_path: str = os.path.join(plugin_dir, "inmanta_plugins", self.name, "model")
-
-        for dirpath, dirnames, filenames in os.walk(plugin_dir, topdown=True):
-            # Modify dirnames in-place to stop os.walk from descending into any more subdirectories of the model directory
-            if dirpath.startswith(model_dir_path):
-                dirnames[:] = []
-                continue
-
-            # Skip this directory if it's already in the cache
-            if dirpath in self._dir_cache:
-                cached_files = self._dir_cache[dirpath]
-                for file in cached_files:
-                    base_file_path = os.path.splitext(file)[0]
-                    files[base_file_path] = file
-                continue
-
-            current_path_files = []
-
-            for filename in filenames:
-                file_path = os.path.join(dirpath, filename)
-
-                # Skip files in the default cache directory
-                if "__pycache__" in file_path:
-                    continue
+        """Generate a list of all python files"""
+        files: Dict[str, str] = {}
 
-                base_file_path = os.path.splitext(file_path)[0]
+        for file_name in glob.iglob(os.path.join(plugin_dir, "**", "*.pyc"), recursive=True):
+            # Filter out pyc files in the default cache dir. Only support our compiled pyc files.
+            if "__pycache__" not in file_name:
+                files[file_name[:-3]] = file_name
+
+        for file_name in glob.iglob(os.path.join(plugin_dir, "**", "*.py"), recursive=True):
+            # store the python source file if we do not have a python file
+            if file_name[:-2] not in files:
+                files[file_name[:-2]] = file_name
 
-                # Prioritize .pyc files over .py files
-                if file_path.endswith(".pyc"):
-                    files[base_file_path] = file_path
-                    current_path_files.append(file_path)
-                elif file_path.endswith(".py") and base_file_path not in files:
-                    files[base_file_path] = file_path
-                    current_path_files.append(file_path)
-
-            # Update the cache with files found in the current directory
-            self._dir_cache[dirpath] = current_path_files
-
-        # Cache the final list of files for the root directory and return it
-        self._dir_cache[plugin_dir] = list(files.values())
-        return self._dir_cache[plugin_dir]
+        return list(files.values())
 
-    def get_plugin_files(self) -> Iterator[tuple[Path, ModuleName]]:
+    def get_plugin_files(self) -> Iterator[Tuple[Path, ModuleName]]:
         """
         Returns a tuple (absolute_path, fq_mod_name) of all python files in this module.
         """
         plugin_dir: Optional[str] = self.get_plugin_dir()
 
         if plugin_dir is None:
             return iter(())
@@ -2959,15 +2963,15 @@
         )
 
     def load_plugins(self) -> None:
         """
         Load all plug-ins from a configuration module
         """
         for path_to_file, fq_mod_name in self.get_plugin_files():
-            LOGGER.log(const.LOG_LEVEL_TRACE, "Loading Python module %s", fq_mod_name)
+            LOGGER.debug("Loading module %s", fq_mod_name)
             try:
                 importlib.import_module(fq_mod_name)
             except Exception as e:
                 tb: Optional[types.TracebackType] = sys.exc_info()[2]
                 stack: traceback.StackSummary = traceback.extract_tb(tb)
                 lineno: Optional[int] = more_itertools.first(
                     (frame.lineno for frame in reversed(stack) if frame.filename == path_to_file), None
@@ -2982,15 +2986,15 @@
         :param plugin_dir: The plugin directory relative to the inmanta module's root directory.
         :param mod_name: The top-level name of this module.
         """
         rel_py_file = os.path.relpath(py_file, start=plugin_dir)
         return loader.convert_relative_path_to_module(os.path.join(mod_name, loader.PLUGIN_DIR, rel_py_file))
 
     def execute_command(self, cmd: str) -> None:
-        print(f"executing {cmd} on {self.name} in {self._path}")
+        print("executing %s on %s in %s" % (cmd, self.name, self._path))
         print("=" * 10)
         subprocess.call(cmd, shell=True, cwd=self._path)
         print("=" * 10)
 
     def unload(self) -> None:
         """
         Unloads this module instance from the project, the registered plugins and the loaded Python modules.
@@ -3004,15 +3008,15 @@
 @stable_api
 class ModuleV1(Module[ModuleV1Metadata], ModuleLikeWithYmlMetadataFile):
     MODULE_FILE = "module.yml"
     GENERATION = ModuleGeneration.V1
 
     def __init__(self, project: Optional[Project], path: str):
         try:
-            super().__init__(project, path)
+            super(ModuleV1, self).__init__(project, path)
         except InvalidMetadata as e:
             raise InvalidModuleException(f"The module found at {path} is not a valid V1 module") from e
         except ModuleMetadataFileNotFound:
             if os.path.exists(os.path.join(path, ModuleV2.MODULE_FILE)):
                 raise ModuleV2InV1PathException(
                     project=project,
                     module=ModuleV2(project, path),
@@ -3027,15 +3031,15 @@
             LOGGER.warning(
                 "The name in the module file (%s) does not match the directory name (%s)",
                 self.name,
                 os.path.basename(self._path),
             )
 
     @classmethod
-    def from_path(cls: type[TModule], path: str) -> Optional[TModule]:
+    def from_path(cls: Type[TModule], path: str) -> Optional[TModule]:
         return cls(project=None, path=path) if os.path.exists(os.path.join(path, cls.MODULE_FILE)) else None
 
     def get_metadata_file_path(self) -> str:
         return os.path.join(self.path, self.MODULE_FILE)
 
     @classmethod
     def get_name_from_metadata(cls, metadata: ModuleV1Metadata) -> str:
@@ -3045,20 +3049,20 @@
     def compiler_version(self) -> Optional[str]:
         """
         Get the minimal compiler version required for this module version. Returns none is the compiler version is not
         constrained.
         """
         return str(self._metadata.compiler_version)
 
-    def get_all_requires(self) -> list[InmantaModuleRequirement]:
+    def get_all_requires(self) -> List[InmantaModuleRequirement]:
         """
         :return: all modules required by an import from any sub-modules, with all constraints applied
         """
         # get all constraints
-        spec: dict[str, InmantaModuleRequirement] = {req.project_name: req for req in self.requires()}
+        spec: Dict[str, InmantaModuleRequirement] = {req.project_name: req for req in self.requires()}
         # find all imports
         imports = {imp.name.split("::")[0] for subm in sorted(self.get_all_submodules()) for imp in self.get_imports(subm)}
         return [spec[r] if spec.get(r) else InmantaModuleRequirement.parse(r) for r in imports]
 
     @classmethod
     def update(
         cls,
@@ -3108,27 +3112,27 @@
 
         def try_parse(x: str) -> Optional[version.Version]:
             try:
                 return parse_version(x)
             except Exception:
                 return None
 
-        versions: list[version.Version] = [x for x in [try_parse(v) for v in versions_str] if x is not None]
+        versions: List[version.Version] = [x for x in [try_parse(v) for v in versions_str] if x is not None]
         versions = sorted(versions, reverse=True)
 
         for r in requirements:
             versions = [x for x in r.specifier.filter(versions, not release_only)]
 
         comp_version_raw = get_compiler_version()
         comp_version = parse_version(comp_version_raw)
         return cls.__best_for_compiler_version(modulename, versions, path, comp_version)
 
     @classmethod
     def __best_for_compiler_version(
-        cls, modulename: str, versions: list[version.Version], path: str, comp_version: version.Version
+        cls, modulename: str, versions: List[version.Version], path: str, comp_version: version.Version
     ) -> Optional[version.Version]:
         def get_cv_for(best: version.Version) -> Optional[version.Version]:
             cfg_text: str = gitprovider.get_file_for_version(path, str(best), cls.MODULE_FILE)
             metadata: ModuleV1Metadata = cls.get_metadata_file_schema_type().parse(cfg_text)
             if metadata.compiler_version is None:
                 return None
             v = metadata.compiler_version
@@ -3156,53 +3160,53 @@
                 hi = mid
         if hi == len(versions):
             LOGGER.warning("Could not find version of module %s suitable for this compiler, try a newer compiler" % modulename)
             return None
         return versions[lo]
 
     @classmethod
-    def get_metadata_file_schema_type(cls) -> type[ModuleV1Metadata]:
+    def get_metadata_file_schema_type(cls) -> Type[ModuleV1Metadata]:
         return ModuleV1Metadata
 
     def get_plugin_dir(self) -> Optional[str]:
         plugins_dir = os.path.join(self._path, loader.PLUGIN_DIR)
         if not os.path.exists(plugins_dir):
             return None
         return plugins_dir
 
-    def get_all_python_requirements_as_list(self) -> list[str]:
+    def get_all_python_requirements_as_list(self) -> List[str]:
         return self._get_requirements_txt_as_list()
 
-    def get_module_requirements(self) -> list[str]:
+    def get_module_requirements(self) -> List[str]:
         return [*self.metadata.requires, *(str(req) for req in self.get_module_v2_requirements())]
 
     def add_module_requirement_persistent(self, requirement: InmantaModuleRequirement, add_as_v1_module: bool) -> None:
         requirements_txt_file_path = os.path.join(self._path, "requirements.txt")
         if add_as_v1_module:
             # Add requirement to module.yml file
             self.add_module_requirement_to_requires_and_write(requirement)
             # Refresh in-memory metadata
-            with open(self.get_metadata_file_path(), encoding="utf-8") as fd:
+            with open(self.get_metadata_file_path(), "r", encoding="utf-8") as fd:
                 self._metadata = ModuleV1Metadata.parse(fd)
             # Remove requirement from requirements.txt file
             if os.path.exists(requirements_txt_file_path):
                 requirements_txt_file = RequirementsTxtFile(requirements_txt_file_path)
                 requirements_txt_file.remove_requirement_and_write(requirement.get_python_package_requirement().key)
         else:
             # Add requirement to requirements.txt
             requirements_txt_file = RequirementsTxtFile(requirements_txt_file_path, create_file_if_not_exists=True)
             requirements_txt_file.set_requirement_and_write(requirement.get_python_package_requirement())
             # Remove requirement from module.yml file
             self.remove_module_requirement_from_requires_and_write(requirement.key)
 
-    def versions(self) -> list[version.Version]:
+    def versions(self) -> List[version.Version]:
         """
         Provide a list of all versions available in the repository
         """
-        versions_str: list[str] = gitprovider.get_all_tags(self._path)
+        versions_str: List[str] = gitprovider.get_all_tags(self._path)
 
         def try_parse(x: str) -> Optional[version.Version]:
             try:
                 return parse_version(x)
             except Exception:
                 return None
 
@@ -3232,15 +3236,15 @@
             print("Failed to get status of module")
             LOGGER.exception("Failed to get status of module %s")
 
     def push(self) -> None:
         """
         Run a git push on this module
         """
-        sys.stdout.write(f"{self.name} ({self._path}) ")
+        sys.stdout.write("%s (%s) " % (self.name, self._path))
         sys.stdout.flush()
         try:
             print(gitprovider.push(self._path))
         except CalledProcessError:
             print("Cloud not push module %s" % self.name)
         else:
             print("done")
@@ -3258,25 +3262,25 @@
         project: Optional[Project],
         path: str,
         is_editable_install: bool = False,
         installed_version: Optional[version.Version] = None,
     ) -> None:
         self._is_editable_install = is_editable_install
         self._version: Optional[version.Version] = installed_version
-        super().__init__(project, path)
+        super(ModuleV2, self).__init__(project, path)
 
         if not os.path.exists(os.path.join(self.model_dir, "_init.cf")):
             raise InvalidModuleException(
                 f"The module at {path} contains no _init.cf file. This occurs when you install or build modules from source"
                 " incorrectly. Always use the `inmanta module install` and `inmanta module build` commands to respectively"
                 " install and build modules from source. Make sure to uninstall the broken package first."
             )
 
     @classmethod
-    def from_path(cls: type[TModule], path: str) -> Optional[TModule]:
+    def from_path(cls: Type[TModule], path: str) -> Optional[TModule]:
         try:
             return cls(project=None, path=path) if os.path.exists(os.path.join(path, cls.MODULE_FILE)) else None
         except InvalidModuleException:
             # setup.cfg is a generic Python config file: if the metadata does not match an inmanta module's, return None
             return None
 
     def get_version(self) -> version.Version:
@@ -3288,40 +3292,40 @@
         """
         Returns True iff this module has been installed in editable mode.
         """
         return self._is_editable_install
 
     def ensure_versioned(self) -> None:
         if self._is_editable_install:
-            super().ensure_versioned()
+            super(ModuleV2, self).ensure_versioned()
         else:
             # Only editable installs can be checked for versioning
             pass
 
     def get_metadata_file_path(self) -> str:
         return os.path.join(self.path, ModuleV2.MODULE_FILE)
 
     @classmethod
     def get_name_from_metadata(cls, metadata: ModuleV2Metadata) -> str:
         return metadata.name[len(cls.PKG_NAME_PREFIX) :].replace("-", "_")
 
     @classmethod
-    def get_metadata_file_schema_type(cls) -> type[ModuleV2Metadata]:
+    def get_metadata_file_schema_type(cls) -> Type[ModuleV2Metadata]:
         return ModuleV2Metadata
 
     def get_plugin_dir(self) -> str:
         if self._is_editable_install:
             return os.path.join(self.path, const.PLUGINS_PACKAGE, self.name)
         else:
             return self.path
 
-    def get_all_python_requirements_as_list(self) -> list[str]:
+    def get_all_python_requirements_as_list(self) -> List[str]:
         return list(self.metadata.install_requires)
 
-    def get_module_requirements(self) -> list[str]:
+    def get_module_requirements(self) -> List[str]:
         return [str(req) for req in self.get_module_v2_requirements()]
 
     def add_module_requirement_persistent(self, requirement: InmantaModuleRequirement, add_as_v1_module: bool) -> None:
         if add_as_v1_module:
             raise Exception("Cannot add V1 requirement to a V2 module")
         # Parse config file
         config_parser = ConfigParser()
@@ -3337,9 +3341,9 @@
         else:
             new_install_requires = [str(python_pkg_requirement)]
         config_parser.set("options", "install_requires", "\n".join(new_install_requires))
         # Write config back to disk
         with open(self.get_metadata_file_path(), "w", encoding="utf-8") as fd:
             config_parser.write(fd)
         # Reload in-memory state
-        with open(self.get_metadata_file_path(), encoding="utf-8") as fd:
+        with open(self.get_metadata_file_path(), "r", encoding="utf-8") as fd:
             self._metadata = ModuleV2Metadata.parse(fd)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/moduletool.py` & `inmanta-core-9.3.0/src/inmanta/moduletool.py`

 * *Files 1% similar despite different names*

```diff
@@ -31,29 +31,30 @@
 import tempfile
 import time
 import zipfile
 from argparse import ArgumentParser, RawTextHelpFormatter
 from collections import abc
 from configparser import ConfigParser
 from functools import total_ordering
-from re import Pattern
-from typing import TYPE_CHECKING, Any, Dict, List, Optional
+from types import TracebackType
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Pattern, Set, Type
 
 import click
 import more_itertools
 import texttable
 import yaml
 from cookiecutter.main import cookiecutter
 from pkg_resources import Requirement, parse_version
 
 import build
+import build.env
 import inmanta
 import inmanta.warnings
 import toml
-from build.env import DefaultIsolatedEnv
+from build.env import IsolatedEnvBuilder
 from inmanta import const, env
 from inmanta.ast import CompilerException
 from inmanta.command import CLIException, ShowUsageException
 from inmanta.const import CF_CACHE_DIR, MAX_UPDATE_ATTEMPT
 from inmanta.module import (
     DummyProject,
     FreezeOperator,
@@ -101,25 +102,25 @@
         "--no-strict-deps-check",
         dest="no_strict_deps_check",
         action="store_true",
         default=False,
         help=(
             "When this option is enabled, only version conflicts in the direct dependencies will result in an error. "
             "All other version conflicts will result in a warning. This option is mutually exclusive with the "
-            r"\--strict-deps-check option."
+            "\--strict-deps-check option."  # noqa: W605
         ),
     )
     parser.add_argument(
         "--strict-deps-check",
         dest="strict_deps_check",
         action="store_true",
         default=False,
         help=(
             "When this option is enabled, a version conflict in any (transitive) dependency will results in an error. "
-            r"This option is mutually exclusive with the \--no-strict-deps-check option."  # noqa: W605
+            "This option is mutually exclusive with the \--no-strict-deps-check option."  # noqa: W605
         ),
     )
 
 
 def get_strict_deps_check(no_strict_deps_check: bool, strict_deps_check: bool) -> Optional[bool]:
     """
     Perform input validation on the --no-strict-deps-check and --strict-deps-check options and
@@ -131,15 +132,15 @@
         # If none of the *strict_deps_check options are provided, use the value set in the project.yml file
         return None
     if no_strict_deps_check:
         return False
     return strict_deps_check
 
 
-class ModuleLikeTool:
+class ModuleLikeTool(object):
     """Shared code for modules and projects"""
 
     def execute(self, cmd: Optional[str], args: argparse.Namespace) -> None:
         """
         Execute the given subcommand
         """
         if cmd is not None and cmd != "" and hasattr(self, cmd):
@@ -204,30 +205,30 @@
                     outversion = str(VersionOperation.set_version_tag(old_version, version_tag=""))
 
             if dev:
                 outversion = "%s.dev%d" % (outversion, time.time())
 
         outversion = parse_version(outversion)
         if outversion <= old_version:
-            LOGGER.error(f"new versions ({outversion}) is not larger then old version ({old_version}), aborting")
+            LOGGER.error("new versions (%s) is not larger then old version (%s), aborting" % (outversion, old_version))
             return None
 
         return outversion
 
 
 @total_ordering
 @enum.unique
 class ChangeType(enum.Enum):
     MAJOR: str = "major"
     MINOR: str = "minor"
     PATCH: str = "patch"
     REVISION: str = "revision"
 
     def __lt__(self, other: "ChangeType") -> bool:
-        order: list[ChangeType] = [ChangeType.REVISION, ChangeType.PATCH, ChangeType.MINOR, ChangeType.MAJOR]
+        order: List[ChangeType] = [ChangeType.REVISION, ChangeType.PATCH, ChangeType.MINOR, ChangeType.MAJOR]
         if other not in order:
             return NotImplemented
         return order.index(self) < order.index(other)
 
     @classmethod
     def diff(cls, *, low: Version, high: Version) -> Optional["ChangeType"]:
         """
@@ -405,15 +406,15 @@
             recursive = project.freeze_recursive
 
         if operator is None:
             operator = project.freeze_operator
 
         freeze = project.get_freeze(mode=operator, recursive=recursive)
 
-        with open(project.get_metadata_file_path(), encoding="utf-8") as fd:
+        with open(project.get_metadata_file_path(), "r", encoding="utf-8") as fd:
             newconfig = yaml.safe_load(fd)
 
         requires = sorted([k + " " + v for k, v in freeze.items()])
         newconfig["requires"] = requires
 
         close = False
 
@@ -465,18 +466,18 @@
         strict = get_strict_deps_check(no_strict_deps_check, strict_deps_check)
         if project is None:
             # rename var to make mypy happy
             my_project = self.get_project(load=False, strict_deps_check=strict)
         else:
             my_project = project
 
-        def do_update(specs: "Dict[str, List[InmantaModuleRequirement]]", modules: list[str]) -> None:
+        def do_update(specs: "Dict[str, List[InmantaModuleRequirement]]", modules: List[str]) -> None:
             v2_modules = {module for module in modules if my_project.module_source.path_for(module) is not None}
 
-            v2_python_specs: list[Requirement] = [
+            v2_python_specs: List[Requirement] = [
                 module_spec.get_python_package_requirement()
                 for module, module_specs in specs.items()
                 for module_spec in module_specs
                 if module in v2_modules
             ]
             if v2_python_specs:
                 # Get known requires and add them to prevent invalidating constraints through updates
@@ -484,24 +485,21 @@
                 # Because for pip not every valid -r is a valid -c
                 current_requires = my_project.get_strict_python_requirements_as_list()
                 env.process_env.install_from_index(
                     v2_python_specs + [Requirement.parse(r) for r in current_requires],
                     my_project.module_source.urls,
                     upgrade=True,
                     allow_pre_releases=my_project.install_mode != InstallMode.release,
+                    use_pip_config=my_project.metadata.pip.use_config_file,
                 )
-                # Invalidate ast cache so that dependencies of installed modules can be updated as well
-                my_project.invalidate_state()
 
             for v1_module in set(modules).difference(v2_modules):
                 spec = specs.get(v1_module, [])
                 try:
                     ModuleV1.update(my_project, v1_module, spec, install_mode=my_project.install_mode)
-                    # Invalidate the state of the updated module
-                    my_project.invalidate_state(v1_module)
                 except Exception:
                     LOGGER.exception("Failed to update module %s", v1_module)
 
             # Load the newly installed modules into the modules cache
             my_project.install_modules(bypass_module_cache=True, update_dependencies=True)
 
         attempt = 0
@@ -512,15 +510,15 @@
             LOGGER.info("Performing update attempt %d of %d", attempt + 1, MAX_UPDATE_ATTEMPT)
             try:
                 loaded_mods_pre_update = {module_name: mod.version for module_name, mod in my_project.modules.items()}
 
                 # get AST
                 my_project.load_module_recursive(install=True)
                 # get current full set of requirements
-                specs: dict[str, list[InmantaModuleRequirement]] = my_project.collect_imported_requirements()
+                specs: Dict[str, List[InmantaModuleRequirement]] = my_project.collect_imported_requirements()
                 if module is None:
                     modules = list(specs.keys())
                 else:
                     modules = [module]
                 do_update(specs, modules)
 
                 loaded_mods_post_update = {module_name: mod.version for module_name, mod in my_project.modules.items()}
@@ -565,15 +563,15 @@
         subparser = parser.add_subparsers(title="subcommand", dest="cmd")
 
         add_help_msg = "Add a module dependency to an Inmanta module or project."
         add = subparser.add_parser(
             "add",
             help=add_help_msg,
             description=f"{add_help_msg} When executed on a project, the module is installed as well. "
-            r"Either \--v1 or \--v2 has to be set.",
+            f"Either \--v1 or \--v2 has to be set.",  # noqa: W605
             parents=parent_parsers,
         )
         add.add_argument(
             "module_req",
             help="The name of the module, optionally with a version constraint.",
         )
         add.add_argument("--v1", dest="v1", help="Add the given module as a v1 module", action="store_true")
@@ -732,15 +730,15 @@
             parents=parent_parsers,
         )
 
         release = subparser.add_parser(
             "release",
             parents=parent_parsers,
             help="Release a new stable or dev release for this module.",
-            description=r"""
+            description="""
 When a stable release is done, this command:
 
 * Does a commit that changes the current version to a stable version.
 * Adds Git release tag.
 * Does a commit that changes the current version to a development version that is one patch increment ahead of the released
   version.
 
@@ -889,15 +887,15 @@
             project = self.get_project_for_module(module)
             path: str = os.path.realpath(os.curdir)
             return self.construct_module(project, path)
         else:
             project = self.get_project(load=True)
             return project.get_module(module, allow_v1=True)
 
-    def get_modules(self, module: Optional[str] = None) -> list[Module]:
+    def get_modules(self, module: Optional[str] = None) -> List[Module]:
         if module is not None:
             return [self.get_module(module)]
         else:
             return self.get_project(load=True).sorted_modules()
 
     def create(self, name: str, v1: bool, no_input: bool = False) -> None:
         """
@@ -977,15 +975,15 @@
 
         table = []
 
         project = Project.get()
         project.get_complete_ast()
 
         names: abc.Sequence[str] = sorted(project.modules.keys())
-        specs: dict[str, list[InmantaModuleRequirement]] = project.collect_imported_requirements()
+        specs: Dict[str, List[InmantaModuleRequirement]] = project.collect_imported_requirements()
         for name in names:
             mod: Module = Project.get().modules[name]
             version = str(mod.version)
             if name not in specs:
                 specs[name] = []
 
             generation: str = str(mod.GENERATION.name).lower()
@@ -1137,15 +1135,15 @@
             LOGGER.warning("Operator %s is unknown, expecting one of ['==', '~=', '>=']", operator)
 
         freeze = {}
 
         for submodule in module_obj.get_all_submodules():
             freeze.update(module_obj.get_freeze(submodule=submodule, mode=operator, recursive=recursive))
 
-        with open(module_obj.get_metadata_file_path(), encoding="utf-8") as fd:
+        with open(module_obj.get_metadata_file_path(), "r", encoding="utf-8") as fd:
             newconfig = yaml.safe_load(fd)
 
         requires = sorted([k + " " + v for k, v in freeze.items()])
         newconfig["requires"] = requires
 
         close = False
         out_fd = None
@@ -1236,17 +1234,16 @@
 
         # Sanity checks
         versions_between_current_and_new_version = [
             v for v in all_existing_stable_version if current_version < v <= new_version
         ]
         if versions_between_current_and_new_version:
             raise click.ClickException(
-                f"Error: Stable release {versions_between_current_and_new_version[0]} exists between "
-                f"current version {current_version} and new version {new_version}. Make sure your branch is up-to-update "
-                f"with the remote repository."
+                f"Stable release {versions_between_current_and_new_version[0]} exists between "
+                f"current version {current_version} and new version {new_version}"
             )
 
         return new_version
 
     def release(
         self,
         dev: bool,
@@ -1261,33 +1258,35 @@
         """
         Execute the release command.
         """
 
         # Validate patch, minor, major
         nb_version_bump_arguments_set = sum([revision, patch, minor, major])
         if nb_version_bump_arguments_set > 1:
-            raise click.UsageError("Error: Only one of --revision, --patch, --minor and --major can be set at the same time.")
+            raise click.UsageError("Only one of --revision, --patch, --minor and --major can be set at the same time.")
 
         # Make module
         module_dir = os.path.abspath(os.getcwd())
         module: Module[ModuleMetadata] = self.construct_module(project=DummyProject(), path=module_dir)
         if not gitprovider.is_git_repository(repo=module_dir):
-            raise click.ClickException(f"Error: Directory {module_dir} is not a git repository.")
+            raise click.ClickException(f"Directory {module_dir} is not a git repository.")
 
         # Validate current state of the module
         current_version: Version = module.version
         if current_version.epoch != 0:
-            raise click.ClickException("Error: Version with an epoch value larger than zero are not supported by this tool.")
+            raise click.ClickException("Version with an epoch value larger than zero are not supported by this tool.")
         gitprovider.fetch(module_dir)
 
         # Get history
         stable_releases: list[Version] = gitprovider.get_version_tags(module_dir, only_return_stable_versions=True)
 
         path_changelog_file = os.path.join(module_dir, const.MODULE_CHANGELOG_FILE)
-        changelog: Optional[Changelog] = Changelog(path_changelog_file) if os.path.exists(path_changelog_file) else None
+        changelog: Optional[ModuleChangelog] = (
+            ModuleChangelog(path_changelog_file) if os.path.exists(path_changelog_file) else None
+        )
 
         requested_version_bump: Optional[ChangeType] = ChangeType.parse_from_bools(revision, patch, minor, major)
         if not requested_version_bump and dev:
             # Dev always bumps
             requested_version_bump = ChangeType.PATCH
 
         if requested_version_bump:
@@ -1295,15 +1294,15 @@
                 current_version, stable_releases, requested_version_bump
             )
         else:
             # Never happens for dev release
             new_version = current_version
 
         if not changelog and changelog_message:
-            changelog = Changelog.create_changelog_file(path_changelog_file, new_version, changelog_message)
+            changelog = ModuleChangelog.create_changelog_file(path_changelog_file, new_version, changelog_message)
         elif changelog:
             if current_version.is_devrelease:
                 # Update the existing dev version to the new dev version
                 changelog.rewrite_version_in_changelog_header(old_version=current_version, new_version=new_version)
             else:
                 changelog.add_section_for_version(current_version, new_version)
 
@@ -1321,15 +1320,15 @@
                 commit_all=commit_all,
                 add=[module.get_metadata_file_path()] + ([changelog.get_path()] if changelog else []),
                 raise_exc_when_nothing_to_commit=False,
             )
         else:
             release_tag: Version = VersionOperation.set_version_tag(new_version, version_tag="")
             if release_tag in stable_releases:
-                raise click.ClickException(f"Error: A Git version tag already exists for version {release_tag}")
+                raise click.ClickException(f"A Git version tag already exists for version {release_tag}")
             module.rewrite_version(new_version=str(release_tag), version_tag="")
             if changelog:
                 changelog.set_release_date_for_version(release_tag)
             gitprovider.commit(
                 repo=module_dir,
                 message=message if message else f"Release version {module.metadata.get_full_version()}",
                 commit_all=commit_all,
@@ -1338,17 +1337,17 @@
             )
             gitprovider.tag(repo=module_dir, tag=str(release_tag))
             print(f"Tag created successfully: {release_tag}")
             # bump to the next dev version
             self.release(dev=True, message="Bump version to next development version", patch=True)
 
 
-class Changelog:
+class ModuleChangelog:
     """
-    This class represent a changelog file e.g. in an Inmanta module or an Inmanta python package.
+    This class represent the changelog file in an Inmanta module.
 
     The expected format of the changelog is the following:
 
     ```
     # Changelog
 
     ## v1.2.1 - ?
@@ -1364,15 +1363,15 @@
 
     def __init__(self, path_changelog_file: str) -> None:
         if not os.path.isfile(path_changelog_file):
             raise Exception(f"{path_changelog_file} is not a file.")
         self.path_changelog_file = os.path.abspath(path_changelog_file)
 
     @classmethod
-    def create_changelog_file(cls, path: str, version: Version, changelog_message: str) -> "Changelog":
+    def create_changelog_file(cls, path: str, version: Version, changelog_message: str) -> "ModuleChangelog":
         """
         Create a new changelog file at the given path. Add a section for the given version and write the given
         changelog message to it.
         """
         if os.path.exists(path):
             raise Exception(f"File {path} already exists.")
         with open(path, "w", encoding="utf-8") as fh:
@@ -1446,15 +1445,15 @@
             fh.write(new_content_changelog)
             fh.truncate()
 
     def _has_section_for_version(self, version: Version) -> bool:
         """
         Return True iff this changelog contains a section of the given version.
         """
-        with open(self.path_changelog_file, encoding="utf-8") as fh:
+        with open(self.path_changelog_file, "r", encoding="utf-8") as fh:
             regex_version_header: re.Pattern[str] = self.regex_for_changelog_line(version)
             content = fh.read()
             return regex_version_header.search(content) is not None
 
     def rewrite_version_in_changelog_header(self, old_version: Version, new_version: Version) -> None:
         """
         Replaces the first occurrence of the given old_version in this changelog file with new_version.
@@ -1509,63 +1508,60 @@
             else:
                 LOGGER.warning(
                     "Failed to add changelog entry to section for version %s.",
                     str(version.base_version),
                 )
 
 
-ModuleChangelog = Changelog  # For backwards compatibility after class rename
-
-
 class ModuleBuildFailedError(Exception):
     def __init__(self, msg: str, *args: Any) -> None:
         self.msg = msg
-        super().__init__(msg, *args)
+        super(ModuleBuildFailedError, self).__init__(msg, *args)
 
     def __str__(self) -> str:
         return self.msg
 
 
 BUILD_FILE_IGNORE_PATTERN: Pattern[str] = re.compile("|".join(("__pycache__", "__cfcache__", r".*\.pyc", rf"{CF_CACHE_DIR}")))
 
 
-class DefaultIsolatedEnvCached(DefaultIsolatedEnv):
+class IsolatedEnvBuilderCached(IsolatedEnvBuilder):
     """
     An IsolatedEnvBuilder that maintains its build environment across invocations of the context manager.
     This class is only used by the test suite. It decreases the runtime of the test suite because the build
     environment is reused across test cases.
 
     This class is a singleton. The get_instance() method should be used to obtain an instance of this class.
     """
 
-    _instance: Optional["DefaultIsolatedEnvCached"] = None
+    _instance: Optional["IsolatedEnvBuilderCached"] = None
 
     def __init__(self) -> None:
         super().__init__()
-        self._isolated_env: Optional[DefaultIsolatedEnv] = None
+        self._isolated_env: Optional[build.env.IsolatedEnv] = None
 
     @classmethod
-    def get_instance(cls) -> "DefaultIsolatedEnvCached":
+    def get_instance(cls) -> "IsolatedEnvBuilderCached":
         """
         This method should be used to obtain an instance of this class, because this class is a singleton.
         """
         if not cls._instance:
             cls._instance = cls()
         return cls._instance
 
-    def __enter__(self) -> DefaultIsolatedEnv:
+    def __enter__(self) -> build.env.IsolatedEnv:
         if not self._isolated_env:
-            self._isolated_env = super().__enter__()
+            self._isolated_env = super(IsolatedEnvBuilderCached, self).__enter__()
             self._install_build_requirements(self._isolated_env)
             # All build dependencies are installed, so we can disable the install() method on self._isolated_env.
             # This prevents unnecessary pip processes from being spawned.
             setattr(self._isolated_env, "install", lambda *args, **kwargs: None)
         return self._isolated_env
 
-    def _install_build_requirements(self, isolated_env: DefaultIsolatedEnv) -> None:
+    def _install_build_requirements(self, isolated_env: build.env.IsolatedEnv) -> None:
         """
         Install the build requirements required to build the modules present in the tests/data/modules_v2 directory.
         """
         # Make mypy happy
         assert self._isolated_env is not None
         with tempfile.TemporaryDirectory() as tmp_python_project_dir:
             # All modules in the tests/data/modules_v2 directory have the same pyproject.toml file.
@@ -1576,35 +1572,38 @@
                     """
 [build-system]
 requires = ["setuptools", "wheel"]
 build-backend = "setuptools.build_meta"
                 """
                 )
             builder = build.ProjectBuilder(
-                source_dir=tmp_python_project_dir,
-                python_executable=self._isolated_env.python_executable,
+                srcdir=tmp_python_project_dir,
+                python_executable=self._isolated_env.executable,
+                scripts_dir=self._isolated_env.scripts_dir,
             )
             isolated_env.install(builder.build_system_requires)
             isolated_env.install(builder.get_requires_for_build(distribution="wheel"))
 
-    def __exit__(self, *args: object) -> None:
+    def __exit__(
+        self, exc_type: Optional[Type[BaseException]], exc_val: Optional[BaseException], exc_tb: Optional[TracebackType]
+    ) -> None:
         # Ignore implementation from the super class to keep the environment
         pass
 
     def destroy(self) -> None:
         """
         Cleanup the cached build environment. It should be called at the end of the test suite.
         """
         if self._isolated_env:
-            super().__exit__()
+            super(IsolatedEnvBuilderCached, self).__exit__(None, None, None)
             self._isolated_env = None
 
 
 class V2ModuleBuilder:
-    DISABLE_DEFAULT_ISOLATED_ENV_CACHED: bool = False
+    DISABLE_ISOLATED_ENV_BUILDER_CACHE: bool = False
 
     def __init__(self, module_path: str) -> None:
         """
         :raises InvalidModuleException: The given module_path doesn't reference a valid module.
         :raises ModuleBuildFailedError: Module build was unsuccessful.
         """
         self._module = ModuleV2(project=None, path=os.path.abspath(module_path))
@@ -1705,19 +1704,19 @@
         in the given wheel and log a warning if such a file exists.
         """
         rel_path_namespace_package = os.path.join("inmanta_plugins", self._module.name)
         abs_path_namespace_package = os.path.join(build_path, rel_path_namespace_package)
         files_in_python_package_dir = self._get_files_in_directory(abs_path_namespace_package, ignore=BUILD_FILE_IGNORE_PATTERN)
         with zipfile.ZipFile(path_to_wheel) as z:
             dir_prefix = f"{rel_path_namespace_package}/"
-            files_in_wheel = {
+            files_in_wheel = set(
                 info.filename[len(dir_prefix) :]
                 for info in z.infolist()
                 if not info.is_dir() and info.filename.startswith(dir_prefix)
-            }
+            )
         unpackaged_files = files_in_python_package_dir - files_in_wheel
         if unpackaged_files:
             LOGGER.warning(
                 f"The following files are present in the {rel_path_namespace_package} directory on disk, but were not "
                 f"packaged: {list(unpackaged_files)}. Update you MANIFEST.in file if they need to be packaged."
             )
 
@@ -1725,80 +1724,71 @@
         plugins_folder = os.path.join(build_path, "inmanta_plugins", self._module.name)
         if not os.path.exists(plugins_folder):
             os.makedirs(plugins_folder)
         init_file = os.path.join(plugins_folder, "__init__.py")
         if not os.path.exists(init_file):
             open(init_file, "w").close()
 
-    def _get_files_in_directory(self, directory: str, ignore: Optional[Pattern[str]] = None) -> set[str]:
+    def _get_files_in_directory(self, directory: str, ignore: Optional[Pattern[str]] = None) -> Set[str]:
         """
         Return the relative paths to all the files in all subdirectories of the given directory.
 
         :param directory: The directory to list the files of.
         :param ignore: Pattern for files and subdirectories to ignore, regardless of their relative depth. The pattern should
             match the full file or directory names.
         """
 
         def should_ignore(name: str) -> bool:
             return ignore is not None and ignore.fullmatch(name) is not None
 
         if not os.path.isdir(directory):
             raise Exception(f"{directory} is not a directory")
-        result: set[str] = set()
+        result: Set[str] = set()
         for dirpath, dirnames, filenames in os.walk(directory):
             if should_ignore(os.path.basename(dirpath)):
                 # ignore whole subdirectory
                 continue
-            relative_paths_to_filenames = {
+            relative_paths_to_filenames = set(
                 os.path.relpath(os.path.join(dirpath, f), directory) for f in filenames if not should_ignore(f)
-            }
+            )
             result = result | relative_paths_to_filenames
         return result
 
     def _move_data_files_into_namespace_package_dir(self, build_path: str) -> None:
         """
         Copy all files that have to be packaged into the Python package of the module
         """
-        python_pkg_dir: str = os.path.join(build_path, "inmanta_plugins", self._module.name)
-        model_dir: str = os.path.join(python_pkg_dir, "model")
-        if os.path.exists(model_dir):
-            raise ModuleBuildFailedError(
-                msg="There is already a model directory in %s. "
-                "The `inmanta_plugins.%s.model` package is reserved for bundling the inmanta model files. "
-                "Please use a different name for this Python package."
-                % (os.path.join(self._module.path, "inmanta_plugins", self._module.name), self._module.name)
-            )
-
+        python_pkg_dir = os.path.join(build_path, "inmanta_plugins", self._module.name)
         for dir_name in ["model", "files", "templates"]:
             fq_dir_name = os.path.join(build_path, dir_name)
             if os.path.exists(fq_dir_name):
                 shutil.move(fq_dir_name, python_pkg_dir)
         metadata_file = os.path.join(build_path, "setup.cfg")
         shutil.copy(metadata_file, python_pkg_dir)
 
-    def _get_isolated_env_builder(self) -> DefaultIsolatedEnv:
+    def _get_isolated_env_builder(self) -> IsolatedEnvBuilder:
         """
-        Returns the DefaultIsolatedEnv instance that should be used to build V2 modules. To speed to up the test
+        Returns the IsolatedEnvBuilder instance that should be used to build V2 modules. To speed to up the test
         suite, the build environment is cached when the tests are ran. This is possible because all modules, built
         by the test suite, have the same build requirements. For tests that need to test the code path used in
-        production, the V2ModuleBuilder.DISABLE_DEFAULT_ISOLATED_ENV_CACHED flag can be set to True.
+        production, the V2ModuleBuilder.DISABLE_ISOLATED_ENV_BUILDER_CACHE flag can be set to True.
         """
-        if inmanta.RUNNING_TESTS and not V2ModuleBuilder.DISABLE_DEFAULT_ISOLATED_ENV_CACHED:
-            return DefaultIsolatedEnvCached.get_instance()
+        if inmanta.RUNNING_TESTS and not V2ModuleBuilder.DISABLE_ISOLATED_ENV_BUILDER_CACHE:
+            return IsolatedEnvBuilderCached.get_instance()
         else:
-            return DefaultIsolatedEnv()
+            return IsolatedEnvBuilder()
 
     def _build_v2_module(self, build_path: str, output_directory: str) -> str:
         """
         Build v2 module using PEP517 package builder.
         """
         try:
             with self._get_isolated_env_builder() as env:
                 distribution = "wheel"
-                builder = build.ProjectBuilder(source_dir=build_path, python_executable=env.python_executable)
+                builder = build.ProjectBuilder(srcdir=build_path, python_executable=env.executable, scripts_dir=env.scripts_dir)
                 env.install(builder.build_system_requires)
                 env.install(builder.get_requires_for_build(distribution=distribution))
                 return builder.build(distribution=distribution, output_directory=output_directory)
         except Exception:
             raise ModuleBuildFailedError(msg="Module build failed")
 
 
@@ -1895,15 +1885,15 @@
         build-backend = "setuptools.build_meta"
         """
         if build_requires is None:
             build_requires = ["setuptools", "wheel"]
 
         config_in = {}
         if os.path.exists(os.path.join(in_folder, "pyproject.toml")):
-            with open(os.path.join(in_folder, "pyproject.toml")) as fh:
+            with open(os.path.join(in_folder, "pyproject.toml"), "r") as fh:
                 loglevel = logging.WARNING if warn_on_merge else logging.INFO
                 LOGGER.log(
                     level=loglevel,
                     msg="pyproject.toml file already exists, merging. This will remove all comments from the file",
                 )
                 config_in = toml.load(fh)
 
@@ -1946,20 +1936,20 @@
         # convert main config
         config = self._module.metadata.to_v2().to_config(config_in)
 
         config.add_section("options")
         config.add_section("options.packages.find")
 
         # add requirements
-        module_requirements: list[InmantaModuleRequirement] = [
+        module_requirements: List[InmantaModuleRequirement] = [
             req for req in self._module.get_all_requires() if req.project_name != self._module.name
         ]
-        python_requirements: list[str] = self._module.get_strict_python_requirements_as_list()
+        python_requirements: List[str] = self._module.get_strict_python_requirements_as_list()
         if module_requirements or python_requirements:
-            requires: list[str] = sorted([str(r.get_python_package_requirement()) for r in module_requirements])
+            requires: List[str] = sorted([str(r.get_python_package_requirement()) for r in module_requirements])
             requires += python_requirements
             config.set("options", "install_requires", "\n".join(requires))
 
         # Make setuptools work
         config["options"]["zip_safe"] = "False"
         config["options"]["include_package_data"] = "True"
         config["options"]["packages"] = "find_namespace:"
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/__init__.py` & `inmanta-core-9.3.0/src/inmanta/parser/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/cache.py` & `inmanta-core-9.3.0/src/inmanta/parser/cache.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,29 +13,29 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
 import os
-from typing import Optional
+from typing import List, Optional
 
 from inmanta.ast import Namespace
 from inmanta.ast.statements import Statement
 from inmanta.const import CF_CACHE_DIR, LogLevel
 from inmanta.parser.pickle import ASTPickler, ASTUnpickler
 from inmanta.util import get_compiler_version
 
 LOGGER = logging.getLogger(__name__)
 
 
 class CacheEnvelope:
     """Every cached file gets the exact modification time of the file it is caching, to have cheap, accurate invalidation"""
 
-    def __init__(self, timestamp: float, statements: list[Statement]) -> None:
+    def __init__(self, timestamp: float, statements: List[Statement]) -> None:
         self.timestamp = timestamp
         self.statements = statements
 
 
 class CacheManager:
     def __init__(self) -> None:
         self.hits = 0
@@ -80,15 +80,15 @@
 
     def is_attached_to_project(self) -> bool:
         return self.root_cache_dir is not None
 
     def detach_from_project(self) -> None:
         self.root_cache_dir = None
 
-    def un_cache(self, namespace: Namespace, filename: str) -> Optional[list[Statement]]:
+    def un_cache(self, namespace: Namespace, filename: str) -> Optional[List[Statement]]:
         if not self.cache_enabled.get():
             # cache not enabled
             return None
         if not self.is_attached_to_project():
             return None
         try:
             cache_filename = self._get_file_name(namespace, filename)
@@ -116,15 +116,15 @@
             LOGGER.warning(
                 "Compile cache loading failure, ignoring cache entry for %s",
                 filename,
                 exc_info=LOGGER.isEnabledFor(LogLevel.DEBUG.to_int),
             )
             return None
 
-    def cache(self, namespace: Namespace, filename: str, statements: list[Statement]) -> None:
+    def cache(self, namespace: Namespace, filename: str, statements: List[Statement]) -> None:
         if not self.cache_enabled.get():
             # cache not enabled
             return
         if not self.is_attached_to_project():
             return
         try:
             cache_filename = self._get_file_name(namespace, filename)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/parser.out` & `inmanta-core-9.3.0/src/inmanta/parser/parser.out`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 Created by PLY version 3.11 (http://www.dabeaz.com/ply)
 
 Grammar
 
 Rule 0     S' -> main
 Rule 1     main -> head body
-Rule 2     empty -> <empty>
-Rule 3     head -> empty
-Rule 4     head -> MLS
-Rule 5     body -> top_stmt body
-Rule 6     body -> empty
-Rule 7     top_stmt -> entity_def
-Rule 8     top_stmt -> implement_def
-Rule 9     top_stmt -> implementation_def
-Rule 10    top_stmt -> relation
-Rule 11    top_stmt -> statement
-Rule 12    top_stmt -> typedef
-Rule 13    top_stmt -> index
-Rule 14    top_stmt -> import
+Rule 2     head -> <empty>
+Rule 3     head -> MLS
+Rule 4     body -> top_stmt body
+Rule 5     body -> empty
+Rule 6     top_stmt -> entity_def
+Rule 7     top_stmt -> implement_def
+Rule 8     top_stmt -> implementation_def
+Rule 9     top_stmt -> relation
+Rule 10    top_stmt -> statement
+Rule 11    top_stmt -> typedef
+Rule 12    top_stmt -> index
+Rule 13    top_stmt -> import
+Rule 14    empty -> <empty>
 Rule 15    import -> IMPORT ns_ref
 Rule 16    import -> IMPORT ns_ref AS ID
 Rule 17    statement -> assign
 Rule 18    statement -> for
 Rule 19    statement -> if
-Rule 20    statement -> expression empty
+Rule 20    statement -> expression
 Rule 21    stmt_list -> statement stmt_list
 Rule 22    stmt_list -> empty
 Rule 23    assign -> var_ref = operand
 Rule 24    assign -> var_ref PEQ operand
 Rule 25    for -> FOR ID IN operand : block
 Rule 26    if -> IF if_body END
 Rule 27    if_body -> expression : stmt_list if_next
@@ -81,1202 +81,1159 @@
 Rule 76    implementation -> implementation_head block
 Rule 77    implementation_head -> :
 Rule 78    implementation_head -> : MLS
 Rule 79    block -> stmt_list END
 Rule 80    relation -> class_ref ID multi REL multi class_ref ID
 Rule 81    relation -> class_ref ID multi REL multi class_ref ID MLS
 Rule 82    relation -> relation_def MLS
-Rule 83    relation -> relation_def empty
+Rule 83    relation -> relation_def
 Rule 84    relation_def -> class_ref . ID multi REL class_ref . ID multi
 Rule 85    relation_def -> class_ref . ID multi REL class_ref
 Rule 86    relation_def -> class_ref . ID multi operand_list class_ref . ID multi
 Rule 87    relation_def -> class_ref . ID multi operand_list class_ref
 Rule 88    multi -> [ INT ]
 Rule 89    multi -> [ INT : ]
 Rule 90    multi -> [ INT : INT ]
 Rule 91    multi -> [ : INT ]
-Rule 92    typedef -> typedef_inner empty
+Rule 92    typedef -> typedef_inner
 Rule 93    typedef -> typedef_inner MLS
 Rule 94    typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression
 Rule 95    typedef_inner -> TYPEDEF CID AS constructor
 Rule 96    index -> INDEX class_ref ( id_list )
 Rule 97    expression -> boolean_expression
 Rule 98    expression -> constant
 Rule 99    expression -> function_call
-Rule 100   expression -> var_ref empty
+Rule 100   expression -> var_ref
 Rule 101   expression -> constructor
 Rule 102   expression -> list_def
 Rule 103   expression -> list_comprehension
 Rule 104   expression -> map_def
-Rule 105   expression -> map_lookup empty
+Rule 105   expression -> map_lookup
 Rule 106   expression -> index_lookup
 Rule 107   expression -> conditional_expression
 Rule 108   expression -> ( expression )
 Rule 109   boolean_expression -> expression CMP_OP expression
 Rule 110   boolean_expression -> expression IN expression
 Rule 111   boolean_expression -> expression AND expression
 Rule 112   boolean_expression -> expression OR expression
-Rule 113   boolean_expression -> expression NOT IN expression
-Rule 114   boolean_expression -> NOT expression
-Rule 115   boolean_expression -> var_ref . ID IS DEFINED
-Rule 116   boolean_expression -> ID IS DEFINED
-Rule 117   boolean_expression -> map_lookup IS DEFINED
-Rule 118   operand -> expression empty
-Rule 119   map_lookup -> attr_ref [ operand ]
-Rule 120   map_lookup -> var_ref [ operand ]
-Rule 121   map_lookup -> map_lookup [ operand ]
-Rule 122   constructor -> class_ref ( param_list )
-Rule 123   function_call -> ns_ref ( function_param_list )
-Rule 124   function_call -> attr_ref ( function_param_list )
-Rule 125   list_def -> [ operand_list ]
-Rule 126   list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ]
-Rule 127   list_comprehension_for_empty -> empty
-Rule 128   list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty
-Rule 129   list_comprehension_for -> FOR ID IN expression list_comprehension_for
-Rule 130   list_comprehension_guard -> empty
-Rule 131   list_comprehension_guard -> IF expression list_comprehension_guard
-Rule 132   dict_key -> RSTRING
-Rule 133   dict_key -> STRING
-Rule 134   pair_list -> dict_key : operand , pair_list
-Rule 135   pair_list -> dict_key : operand empty pair_list_empty
-Rule 136   pair_list -> pair_list_empty
-Rule 137   pair_list_empty -> empty
-Rule 138   map_def -> { pair_list }
-Rule 139   index_lookup -> class_ref [ param_list ]
-Rule 140   index_lookup -> attr_ref [ param_list ]
-Rule 141   conditional_expression -> expression ? expression : expression
-Rule 142   constant -> INT
-Rule 143   constant -> FLOAT
-Rule 144   constant -> NULL
-Rule 145   constant -> REGEX
-Rule 146   constant -> TRUE
-Rule 147   constant -> FALSE
-Rule 148   constant -> STRING
-Rule 149   constant -> FSTRING
-Rule 150   constant -> RSTRING
-Rule 151   constant -> MLS
-Rule 152   constant_list -> [ constants ]
-Rule 153   constants -> constant
-Rule 154   constants -> <empty>
-Rule 155   constants -> constant , constants
-Rule 156   wrapped_kwargs -> * * operand
-Rule 157   param_list_element -> ID = operand
-Rule 158   param_list_element -> wrapped_kwargs
-Rule 159   param_list -> param_list_empty
-Rule 160   param_list_empty -> empty
-Rule 161   param_list -> param_list_element empty param_list_empty
-Rule 162   param_list -> param_list_element , param_list
-Rule 163   function_param_list_element -> param_list_element
-Rule 164   function_param_list_element -> operand
-Rule 165   function_param_list -> function_param_list_empty
-Rule 166   function_param_list_empty -> empty
-Rule 167   function_param_list -> function_param_list_element empty function_param_list_empty
-Rule 168   function_param_list -> function_param_list_element , function_param_list
-Rule 169   operand_list -> operand , operand_list
-Rule 170   operand_list -> operand
-Rule 171   operand_list -> empty
-Rule 172   var_ref -> attr_ref empty
-Rule 173   attr_ref -> var_ref . ID
-Rule 174   var_ref -> ns_ref empty
-Rule 175   class_ref -> CID
-Rule 176   class_ref -> ns_ref SEP CID
-Rule 177   class_ref -> var_ref . CID
-Rule 178   class_ref_list -> class_ref , class_ref_list
-Rule 179   class_ref_list -> var_ref , class_ref_list
-Rule 180   class_ref_list -> class_ref
-Rule 181   class_ref_list -> var_ref
-Rule 182   ns_ref -> ns_ref SEP ID
-Rule 183   ns_ref -> ID
-Rule 184   id_list -> ID , id_list
-Rule 185   id_list -> ID
+Rule 113   boolean_expression -> NOT expression
+Rule 114   boolean_expression -> var_ref . ID IS DEFINED
+Rule 115   boolean_expression -> ID IS DEFINED
+Rule 116   boolean_expression -> map_lookup IS DEFINED
+Rule 117   operand -> expression
+Rule 118   map_lookup -> attr_ref [ operand ]
+Rule 119   map_lookup -> var_ref [ operand ]
+Rule 120   map_lookup -> map_lookup [ operand ]
+Rule 121   constructor -> class_ref ( param_list )
+Rule 122   function_call -> ns_ref ( function_param_list )
+Rule 123   function_call -> attr_ref ( function_param_list )
+Rule 124   list_def -> [ operand_list ]
+Rule 125   list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ]
+Rule 126   list_comprehension_for_empty -> empty
+Rule 127   list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty
+Rule 128   list_comprehension_for -> FOR ID IN expression list_comprehension_for
+Rule 129   list_comprehension_guard -> empty
+Rule 130   list_comprehension_guard -> IF expression list_comprehension_guard
+Rule 131   dict_key -> RSTRING
+Rule 132   dict_key -> STRING
+Rule 133   pair_list -> dict_key : operand , pair_list
+Rule 134   pair_list -> dict_key : operand empty pair_list_empty
+Rule 135   pair_list -> pair_list_empty
+Rule 136   pair_list_empty -> empty
+Rule 137   map_def -> { pair_list }
+Rule 138   index_lookup -> class_ref [ param_list ]
+Rule 139   index_lookup -> attr_ref [ param_list ]
+Rule 140   conditional_expression -> expression ? expression : expression
+Rule 141   constant -> INT
+Rule 142   constant -> FLOAT
+Rule 143   constant -> NULL
+Rule 144   constant -> REGEX
+Rule 145   constant -> TRUE
+Rule 146   constant -> FALSE
+Rule 147   constant -> STRING
+Rule 148   constant -> FSTRING
+Rule 149   constant -> RSTRING
+Rule 150   constant -> MLS
+Rule 151   constant_list -> [ constants ]
+Rule 152   constants -> constant
+Rule 153   constants -> <empty>
+Rule 154   constants -> constant , constants
+Rule 155   wrapped_kwargs -> * * operand
+Rule 156   param_list_element -> ID = operand
+Rule 157   param_list_element -> wrapped_kwargs
+Rule 158   param_list -> param_list_empty
+Rule 159   param_list_empty -> empty
+Rule 160   param_list -> param_list_element empty param_list_empty
+Rule 161   param_list -> param_list_element , param_list
+Rule 162   function_param_list_element -> param_list_element
+Rule 163   function_param_list_element -> operand
+Rule 164   function_param_list -> function_param_list_empty
+Rule 165   function_param_list_empty -> empty
+Rule 166   function_param_list -> function_param_list_element empty function_param_list_empty
+Rule 167   function_param_list -> function_param_list_element , function_param_list
+Rule 168   operand_list -> operand , operand_list
+Rule 169   operand_list -> operand
+Rule 170   operand_list -> <empty>
+Rule 171   var_ref -> attr_ref
+Rule 172   attr_ref -> var_ref . ID
+Rule 173   var_ref -> ns_ref
+Rule 174   class_ref -> CID
+Rule 175   class_ref -> ns_ref SEP CID
+Rule 176   class_ref -> var_ref . CID
+Rule 177   class_ref_list -> class_ref , class_ref_list
+Rule 178   class_ref_list -> var_ref , class_ref_list
+Rule 179   class_ref_list -> class_ref
+Rule 180   class_ref_list -> var_ref
+Rule 181   ns_ref -> ns_ref SEP ID
+Rule 182   ns_ref -> ID
+Rule 183   id_list -> ID , id_list
+Rule 184   id_list -> ID
 
 Terminals, with rules where they appear
 
-(                    : 96 108 122 123 124
-)                    : 96 108 122 123 124
-*                    : 156 156
-,                    : 70 134 155 162 168 169 178 179 184
-.                    : 84 84 85 86 86 87 115 173 177
-:                    : 25 27 29 31 32 33 34 77 78 89 90 91 134 135 141
-=                    : 23 49 50 51 53 54 55 57 58 60 61 63 64 66 67 157
-?                    : 43 44 59 60 61 65 66 67 141
+(                    : 96 108 121 122 123
+)                    : 96 108 121 122 123
+*                    : 155 155
+,                    : 70 133 154 161 167 168 177 178 183
+.                    : 84 84 85 86 86 87 114 172 176
+:                    : 25 27 29 31 32 33 34 77 78 89 90 91 133 134 140
+=                    : 23 49 50 51 53 54 55 57 58 60 61 63 64 66 67 156
+?                    : 43 44 59 60 61 65 66 67 140
 AND                  : 111
 AS                   : 16 94 95
-CID                  : 31 33 48 49 50 51 56 57 58 59 60 61 95 175 176 177
+CID                  : 31 33 48 49 50 51 56 57 58 59 60 61 95 174 175 176
 CMP_OP               : 109
-DEFINED              : 115 116 117
+DEFINED              : 114 115 116
 DICT                 : 56 57 58 59 60 61 62 63 64 65 66 67
 ELIF                 : 30
 ELSE                 : 29
 END                  : 26 35 36 37 38 79
 ENTITY               : 31 32 33 34
 EXTENDS              : 33 34
-FALSE                : 147
-FLOAT                : 143
-FOR                  : 25 75 128 129
-FSTRING              : 149
-ID                   : 16 25 32 34 52 53 54 55 62 63 64 65 66 67 75 80 80 81 81 84 84 85 86 86 87 94 115 116 128 129 157 173 182 183 184 185
-IF                   : 26 131
+FALSE                : 146
+FLOAT                : 142
+FOR                  : 25 75 127 128
+FSTRING              : 148
+ID                   : 16 25 32 34 52 53 54 55 62 63 64 65 66 67 75 80 80 81 81 84 84 85 86 86 87 94 114 115 127 128 156 172 181 182 183 184
+IF                   : 26 130
 IMPLEMENT            : 71 72 73 74
 IMPLEMENTATION       : 75
 IMPORT               : 15 16
-IN                   : 25 110 113 128 129
+IN                   : 25 110 127 128
 INDEX                : 96
-INT                  : 88 89 90 90 91 142
-IS                   : 115 116 117
+INT                  : 88 89 90 90 91 141
+IS                   : 114 115 116
 MATCHING             : 94
-MLS                  : 4 35 38 72 74 78 81 82 93 151
-NOT                  : 113 114
-NULL                 : 58 61 64 67 144
+MLS                  : 3 35 38 72 74 78 81 82 93 150
+NOT                  : 113
+NULL                 : 58 61 64 67 143
 OR                   : 112
 PARENTS              : 69
 PEQ                  : 24
-REGEX                : 145
+REGEX                : 144
 REL                  : 80 81 84 85
-RSTRING              : 132 150
-SEP                  : 176 182
-STRING               : 133 148
-TRUE                 : 146
+RSTRING              : 131 149
+SEP                  : 175 181
+STRING               : 132 147
+TRUE                 : 145
 TYPEDEF              : 94 95
 UNDEF                : 51 55
 USING                : 71 72 73 74
 WHEN                 : 73 74
-[                    : 42 88 89 90 91 119 120 121 125 126 139 140 152
-]                    : 42 88 89 90 91 119 120 121 125 126 139 140 152
+[                    : 42 88 89 90 91 118 119 120 124 125 138 139 151
+]                    : 42 88 89 90 91 118 119 120 124 125 138 139 151
 error                : 
-{                    : 138
-}                    : 138
+{                    : 137
+}                    : 137
 
 Nonterminals, with rules where they appear
 
 assign               : 17
 attr                 : 39 40
 attr_base_type       : 42 44 47
-attr_ref             : 119 124 140 172
+attr_ref             : 118 123 139 171
 attr_type            : 48 49 50 51 52 53 54 55
 attr_type_multi      : 43 46
 attr_type_opt        : 45
 block                : 25 76
-body                 : 1 5
+body                 : 1 4
 boolean_expression   : 97
-class_ref            : 71 72 73 74 75 80 80 81 81 84 84 85 85 86 86 87 87 96 122 139 178 180
-class_ref_list       : 33 34 178 179
+class_ref            : 71 72 73 74 75 80 80 81 81 84 84 85 85 86 86 87 87 96 121 138 177 179
+class_ref_list       : 33 34 177 178
 conditional_expression : 107
-constant             : 49 53 98 153 155
+constant             : 49 53 98 152 154
 constant_list        : 50 54
-constants            : 152 155
+constants            : 151 154
 constructor          : 95 101
-dict_key             : 134 135
-empty                : 3 6 20 22 28 48 56 56 57 58 59 71 73 83 92 100 105 118 127 130 135 137 160 161 166 167 171 172 174
+dict_key             : 133 134
+empty                : 5 22 28 48 56 56 57 58 59 71 73 126 129 134 136 159 160 165 166
 entity_body          : 35 36 39
 entity_body_outer    : 31 32 33 34
-entity_def           : 7
-expression           : 20 27 73 74 94 108 109 109 110 110 111 111 112 112 113 113 114 118 126 128 129 131 141 141 141
+entity_def           : 6
+expression           : 20 27 73 74 94 108 109 109 110 110 111 111 112 112 113 117 125 127 128 130 140 140 140
 for                  : 18
 function_call        : 99
-function_param_list  : 123 124 168
-function_param_list_element : 167 168
-function_param_list_empty : 165 167
+function_param_list  : 122 123 167
+function_param_list_element : 166 167
+function_param_list_empty : 164 166
 head                 : 1
-id_list              : 96 184
+id_list              : 96 183
 if                   : 19
 if_body              : 26 30
 if_next              : 27
-implement_def        : 8
+implement_def        : 7
 implement_ns_list    : 70 70 71 72 73 74
 implementation       : 75
-implementation_def   : 9
+implementation_def   : 8
 implementation_head  : 76
-import               : 14
-index                : 13
+import               : 13
+index                : 12
 index_lookup         : 106
 list_comprehension   : 103
-list_comprehension_for : 126 129
-list_comprehension_for_empty : 128
-list_comprehension_guard : 126 131
+list_comprehension_for : 125 128
+list_comprehension_for_empty : 127
+list_comprehension_guard : 125 130
 list_def             : 102
 main                 : 0
 map_def              : 57 60 63 66 104
-map_lookup           : 105 117 121
+map_lookup           : 105 116 120
 multi                : 80 80 81 81 84 84 85 86 86 87
-ns_ref               : 15 16 41 68 94 123 174 176 182
-operand              : 23 24 25 119 120 121 134 135 156 157 164 169 170
-operand_list         : 86 87 125 169
-pair_list            : 134 138
-pair_list_empty      : 135 136
-param_list           : 122 139 140 162
-param_list_element   : 161 162 163
-param_list_empty     : 159 161
-relation             : 10
+ns_ref               : 15 16 41 68 94 122 173 175 181
+operand              : 23 24 25 118 119 120 133 134 155 156 163 168 169
+operand_list         : 86 87 124 168
+pair_list            : 133 137
+pair_list_empty      : 134 135
+param_list           : 121 138 139 161
+param_list_element   : 160 161 162
+param_list_empty     : 158 160
+relation             : 9
 relation_def         : 82 83
-statement            : 11 21
+statement            : 10 21
 stmt_list            : 21 27 29 79
-top_stmt             : 5
-typedef              : 12
+top_stmt             : 4
+typedef              : 11
 typedef_inner        : 92 93
-var_ref              : 23 24 100 115 120 173 177 179 181
-wrapped_kwargs       : 158
+var_ref              : 23 24 100 114 119 172 176 178 180
+wrapped_kwargs       : 157
 
 Parsing method: LALR
 
 state 0
 
     (0) S' -> . main
     (1) main -> . head body
-    (3) head -> . empty
-    (4) head -> . MLS
-    (2) empty -> .
-
-    MLS             shift and go to state 4
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    (2) head -> .
+    (3) head -> . MLS
 
-  ! MLS             [ reduce using rule 2 (empty -> .) ]
+    ENTITY          reduce using rule 2 (head -> .)
+    IMPLEMENT       reduce using rule 2 (head -> .)
+    IMPLEMENTATION  reduce using rule 2 (head -> .)
+    INDEX           reduce using rule 2 (head -> .)
+    IMPORT          reduce using rule 2 (head -> .)
+    CID             reduce using rule 2 (head -> .)
+    FOR             reduce using rule 2 (head -> .)
+    IF              reduce using rule 2 (head -> .)
+    (               reduce using rule 2 (head -> .)
+    TYPEDEF         reduce using rule 2 (head -> .)
+    ID              reduce using rule 2 (head -> .)
+    NOT             reduce using rule 2 (head -> .)
+    INT             reduce using rule 2 (head -> .)
+    FLOAT           reduce using rule 2 (head -> .)
+    NULL            reduce using rule 2 (head -> .)
+    REGEX           reduce using rule 2 (head -> .)
+    TRUE            reduce using rule 2 (head -> .)
+    FALSE           reduce using rule 2 (head -> .)
+    STRING          reduce using rule 2 (head -> .)
+    FSTRING         reduce using rule 2 (head -> .)
+    RSTRING         reduce using rule 2 (head -> .)
+    [               reduce using rule 2 (head -> .)
+    {               reduce using rule 2 (head -> .)
+    $end            reduce using rule 2 (head -> .)
+    MLS             shift and go to state 3
+
+  ! MLS             [ reduce using rule 2 (head -> .) ]
 
     main                           shift and go to state 1
     head                           shift and go to state 2
-    empty                          shift and go to state 3
 
 state 1
 
     (0) S' -> main .
 
 
 
 state 2
 
     (1) main -> head . body
-    (5) body -> . top_stmt body
-    (6) body -> . empty
-    (7) top_stmt -> . entity_def
-    (8) top_stmt -> . implement_def
-    (9) top_stmt -> . implementation_def
-    (10) top_stmt -> . relation
-    (11) top_stmt -> . statement
-    (12) top_stmt -> . typedef
-    (13) top_stmt -> . index
-    (14) top_stmt -> . import
-    (2) empty -> .
+    (4) body -> . top_stmt body
+    (5) body -> . empty
+    (6) top_stmt -> . entity_def
+    (7) top_stmt -> . implement_def
+    (8) top_stmt -> . implementation_def
+    (9) top_stmt -> . relation
+    (10) top_stmt -> . statement
+    (11) top_stmt -> . typedef
+    (12) top_stmt -> . index
+    (13) top_stmt -> . import
+    (14) empty -> .
     (31) entity_def -> . ENTITY CID : entity_body_outer
     (32) entity_def -> . ENTITY ID : entity_body_outer
     (33) entity_def -> . ENTITY CID EXTENDS class_ref_list : entity_body_outer
     (34) entity_def -> . ENTITY ID EXTENDS class_ref_list : entity_body_outer
     (71) implement_def -> . IMPLEMENT class_ref USING implement_ns_list empty
     (72) implement_def -> . IMPLEMENT class_ref USING implement_ns_list MLS
     (73) implement_def -> . IMPLEMENT class_ref USING implement_ns_list WHEN expression empty
     (74) implement_def -> . IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS
     (75) implementation_def -> . IMPLEMENTATION ID FOR class_ref implementation
     (80) relation -> . class_ref ID multi REL multi class_ref ID
     (81) relation -> . class_ref ID multi REL multi class_ref ID MLS
     (82) relation -> . relation_def MLS
-    (83) relation -> . relation_def empty
+    (83) relation -> . relation_def
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (92) typedef -> . typedef_inner empty
+    (20) statement -> . expression
+    (92) typedef -> . typedef_inner
     (93) typedef -> . typedef_inner MLS
     (96) index -> . INDEX class_ref ( id_list )
     (15) import -> . IMPORT ns_ref
     (16) import -> . IMPORT ns_ref AS ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
     (84) relation_def -> . class_ref . ID multi REL class_ref . ID multi
     (85) relation_def -> . class_ref . ID multi REL class_ref
     (86) relation_def -> . class_ref . ID multi operand_list class_ref . ID multi
     (87) relation_def -> . class_ref . ID multi operand_list class_ref
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (94) typedef_inner -> . TYPEDEF ID AS ns_ref MATCHING expression
     (95) typedef_inner -> . TYPEDEF CID AS constructor
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-
-    $end            reduce using rule 2 (empty -> .)
-    ENTITY          shift and go to state 16
-    IMPLEMENT       shift and go to state 19
-    IMPLEMENTATION  shift and go to state 23
-    INDEX           shift and go to state 30
-    IMPORT          shift and go to state 32
-    CID             shift and go to state 17
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    TYPEDEF         shift and go to state 46
-    ID              shift and go to state 18
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-
-    body                           shift and go to state 5
-    top_stmt                       shift and go to state 6
-    empty                          shift and go to state 7
-    entity_def                     shift and go to state 8
-    implement_def                  shift and go to state 9
-    implementation_def             shift and go to state 10
-    relation                       shift and go to state 11
-    statement                      shift and go to state 12
-    typedef                        shift and go to state 13
-    index                          shift and go to state 14
-    import                         shift and go to state 15
-    class_ref                      shift and go to state 20
-    expression                     shift and go to state 22
-    relation_def                   shift and go to state 25
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    typedef_inner                  shift and go to state 29
-    ns_ref                         shift and go to state 33
-    var_ref                        shift and go to state 34
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+
+    $end            reduce using rule 14 (empty -> .)
+    ENTITY          shift and go to state 15
+    IMPLEMENT       shift and go to state 18
+    IMPLEMENTATION  shift and go to state 22
+    INDEX           shift and go to state 29
+    IMPORT          shift and go to state 31
+    CID             shift and go to state 16
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    TYPEDEF         shift and go to state 45
+    ID              shift and go to state 17
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+
+    body                           shift and go to state 4
+    top_stmt                       shift and go to state 5
+    empty                          shift and go to state 6
+    entity_def                     shift and go to state 7
+    implement_def                  shift and go to state 8
+    implementation_def             shift and go to state 9
+    relation                       shift and go to state 10
+    statement                      shift and go to state 11
+    typedef                        shift and go to state 12
+    index                          shift and go to state 13
+    import                         shift and go to state 14
+    class_ref                      shift and go to state 19
+    expression                     shift and go to state 21
+    relation_def                   shift and go to state 24
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    typedef_inner                  shift and go to state 28
+    ns_ref                         shift and go to state 32
+    var_ref                        shift and go to state 33
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
 
 state 3
 
-    (3) head -> empty .
+    (3) head -> MLS .
 
-    ENTITY          reduce using rule 3 (head -> empty .)
-    IMPLEMENT       reduce using rule 3 (head -> empty .)
-    IMPLEMENTATION  reduce using rule 3 (head -> empty .)
-    INDEX           reduce using rule 3 (head -> empty .)
-    IMPORT          reduce using rule 3 (head -> empty .)
-    CID             reduce using rule 3 (head -> empty .)
-    FOR             reduce using rule 3 (head -> empty .)
-    IF              reduce using rule 3 (head -> empty .)
-    (               reduce using rule 3 (head -> empty .)
-    TYPEDEF         reduce using rule 3 (head -> empty .)
-    ID              reduce using rule 3 (head -> empty .)
-    NOT             reduce using rule 3 (head -> empty .)
-    INT             reduce using rule 3 (head -> empty .)
-    FLOAT           reduce using rule 3 (head -> empty .)
-    NULL            reduce using rule 3 (head -> empty .)
-    REGEX           reduce using rule 3 (head -> empty .)
-    TRUE            reduce using rule 3 (head -> empty .)
-    FALSE           reduce using rule 3 (head -> empty .)
-    STRING          reduce using rule 3 (head -> empty .)
-    FSTRING         reduce using rule 3 (head -> empty .)
-    RSTRING         reduce using rule 3 (head -> empty .)
-    MLS             reduce using rule 3 (head -> empty .)
-    [               reduce using rule 3 (head -> empty .)
-    {               reduce using rule 3 (head -> empty .)
-    $end            reduce using rule 3 (head -> empty .)
+    ENTITY          reduce using rule 3 (head -> MLS .)
+    IMPLEMENT       reduce using rule 3 (head -> MLS .)
+    IMPLEMENTATION  reduce using rule 3 (head -> MLS .)
+    INDEX           reduce using rule 3 (head -> MLS .)
+    IMPORT          reduce using rule 3 (head -> MLS .)
+    CID             reduce using rule 3 (head -> MLS .)
+    FOR             reduce using rule 3 (head -> MLS .)
+    IF              reduce using rule 3 (head -> MLS .)
+    (               reduce using rule 3 (head -> MLS .)
+    TYPEDEF         reduce using rule 3 (head -> MLS .)
+    ID              reduce using rule 3 (head -> MLS .)
+    NOT             reduce using rule 3 (head -> MLS .)
+    INT             reduce using rule 3 (head -> MLS .)
+    FLOAT           reduce using rule 3 (head -> MLS .)
+    NULL            reduce using rule 3 (head -> MLS .)
+    REGEX           reduce using rule 3 (head -> MLS .)
+    TRUE            reduce using rule 3 (head -> MLS .)
+    FALSE           reduce using rule 3 (head -> MLS .)
+    STRING          reduce using rule 3 (head -> MLS .)
+    FSTRING         reduce using rule 3 (head -> MLS .)
+    RSTRING         reduce using rule 3 (head -> MLS .)
+    MLS             reduce using rule 3 (head -> MLS .)
+    [               reduce using rule 3 (head -> MLS .)
+    {               reduce using rule 3 (head -> MLS .)
+    $end            reduce using rule 3 (head -> MLS .)
 
 
 state 4
 
-    (4) head -> MLS .
-
-    ENTITY          reduce using rule 4 (head -> MLS .)
-    IMPLEMENT       reduce using rule 4 (head -> MLS .)
-    IMPLEMENTATION  reduce using rule 4 (head -> MLS .)
-    INDEX           reduce using rule 4 (head -> MLS .)
-    IMPORT          reduce using rule 4 (head -> MLS .)
-    CID             reduce using rule 4 (head -> MLS .)
-    FOR             reduce using rule 4 (head -> MLS .)
-    IF              reduce using rule 4 (head -> MLS .)
-    (               reduce using rule 4 (head -> MLS .)
-    TYPEDEF         reduce using rule 4 (head -> MLS .)
-    ID              reduce using rule 4 (head -> MLS .)
-    NOT             reduce using rule 4 (head -> MLS .)
-    INT             reduce using rule 4 (head -> MLS .)
-    FLOAT           reduce using rule 4 (head -> MLS .)
-    NULL            reduce using rule 4 (head -> MLS .)
-    REGEX           reduce using rule 4 (head -> MLS .)
-    TRUE            reduce using rule 4 (head -> MLS .)
-    FALSE           reduce using rule 4 (head -> MLS .)
-    STRING          reduce using rule 4 (head -> MLS .)
-    FSTRING         reduce using rule 4 (head -> MLS .)
-    RSTRING         reduce using rule 4 (head -> MLS .)
-    MLS             reduce using rule 4 (head -> MLS .)
-    [               reduce using rule 4 (head -> MLS .)
-    {               reduce using rule 4 (head -> MLS .)
-    $end            reduce using rule 4 (head -> MLS .)
-
-
-state 5
-
     (1) main -> head body .
 
     $end            reduce using rule 1 (main -> head body .)
 
 
-state 6
+state 5
 
-    (5) body -> top_stmt . body
-    (5) body -> . top_stmt body
-    (6) body -> . empty
-    (7) top_stmt -> . entity_def
-    (8) top_stmt -> . implement_def
-    (9) top_stmt -> . implementation_def
-    (10) top_stmt -> . relation
-    (11) top_stmt -> . statement
-    (12) top_stmt -> . typedef
-    (13) top_stmt -> . index
-    (14) top_stmt -> . import
-    (2) empty -> .
+    (4) body -> top_stmt . body
+    (4) body -> . top_stmt body
+    (5) body -> . empty
+    (6) top_stmt -> . entity_def
+    (7) top_stmt -> . implement_def
+    (8) top_stmt -> . implementation_def
+    (9) top_stmt -> . relation
+    (10) top_stmt -> . statement
+    (11) top_stmt -> . typedef
+    (12) top_stmt -> . index
+    (13) top_stmt -> . import
+    (14) empty -> .
     (31) entity_def -> . ENTITY CID : entity_body_outer
     (32) entity_def -> . ENTITY ID : entity_body_outer
     (33) entity_def -> . ENTITY CID EXTENDS class_ref_list : entity_body_outer
     (34) entity_def -> . ENTITY ID EXTENDS class_ref_list : entity_body_outer
     (71) implement_def -> . IMPLEMENT class_ref USING implement_ns_list empty
     (72) implement_def -> . IMPLEMENT class_ref USING implement_ns_list MLS
     (73) implement_def -> . IMPLEMENT class_ref USING implement_ns_list WHEN expression empty
     (74) implement_def -> . IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS
     (75) implementation_def -> . IMPLEMENTATION ID FOR class_ref implementation
     (80) relation -> . class_ref ID multi REL multi class_ref ID
     (81) relation -> . class_ref ID multi REL multi class_ref ID MLS
     (82) relation -> . relation_def MLS
-    (83) relation -> . relation_def empty
+    (83) relation -> . relation_def
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (92) typedef -> . typedef_inner empty
+    (20) statement -> . expression
+    (92) typedef -> . typedef_inner
     (93) typedef -> . typedef_inner MLS
     (96) index -> . INDEX class_ref ( id_list )
     (15) import -> . IMPORT ns_ref
     (16) import -> . IMPORT ns_ref AS ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
     (84) relation_def -> . class_ref . ID multi REL class_ref . ID multi
     (85) relation_def -> . class_ref . ID multi REL class_ref
     (86) relation_def -> . class_ref . ID multi operand_list class_ref . ID multi
     (87) relation_def -> . class_ref . ID multi operand_list class_ref
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (94) typedef_inner -> . TYPEDEF ID AS ns_ref MATCHING expression
     (95) typedef_inner -> . TYPEDEF CID AS constructor
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-
-    $end            reduce using rule 2 (empty -> .)
-    ENTITY          shift and go to state 16
-    IMPLEMENT       shift and go to state 19
-    IMPLEMENTATION  shift and go to state 23
-    INDEX           shift and go to state 30
-    IMPORT          shift and go to state 32
-    CID             shift and go to state 17
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    TYPEDEF         shift and go to state 46
-    ID              shift and go to state 18
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-
-    top_stmt                       shift and go to state 6
-    body                           shift and go to state 60
-    empty                          shift and go to state 7
-    entity_def                     shift and go to state 8
-    implement_def                  shift and go to state 9
-    implementation_def             shift and go to state 10
-    relation                       shift and go to state 11
-    statement                      shift and go to state 12
-    typedef                        shift and go to state 13
-    index                          shift and go to state 14
-    import                         shift and go to state 15
-    class_ref                      shift and go to state 20
-    expression                     shift and go to state 22
-    relation_def                   shift and go to state 25
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    typedef_inner                  shift and go to state 29
-    ns_ref                         shift and go to state 33
-    var_ref                        shift and go to state 34
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+
+    $end            reduce using rule 14 (empty -> .)
+    ENTITY          shift and go to state 15
+    IMPLEMENT       shift and go to state 18
+    IMPLEMENTATION  shift and go to state 22
+    INDEX           shift and go to state 29
+    IMPORT          shift and go to state 31
+    CID             shift and go to state 16
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    TYPEDEF         shift and go to state 45
+    ID              shift and go to state 17
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+
+    top_stmt                       shift and go to state 5
+    body                           shift and go to state 59
+    empty                          shift and go to state 6
+    entity_def                     shift and go to state 7
+    implement_def                  shift and go to state 8
+    implementation_def             shift and go to state 9
+    relation                       shift and go to state 10
+    statement                      shift and go to state 11
+    typedef                        shift and go to state 12
+    index                          shift and go to state 13
+    import                         shift and go to state 14
+    class_ref                      shift and go to state 19
+    expression                     shift and go to state 21
+    relation_def                   shift and go to state 24
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    typedef_inner                  shift and go to state 28
+    ns_ref                         shift and go to state 32
+    var_ref                        shift and go to state 33
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+
+state 6
+
+    (5) body -> empty .
+
+    $end            reduce using rule 5 (body -> empty .)
+
 
 state 7
 
-    (6) body -> empty .
+    (6) top_stmt -> entity_def .
 
-    $end            reduce using rule 6 (body -> empty .)
+    ENTITY          reduce using rule 6 (top_stmt -> entity_def .)
+    IMPLEMENT       reduce using rule 6 (top_stmt -> entity_def .)
+    IMPLEMENTATION  reduce using rule 6 (top_stmt -> entity_def .)
+    INDEX           reduce using rule 6 (top_stmt -> entity_def .)
+    IMPORT          reduce using rule 6 (top_stmt -> entity_def .)
+    CID             reduce using rule 6 (top_stmt -> entity_def .)
+    FOR             reduce using rule 6 (top_stmt -> entity_def .)
+    IF              reduce using rule 6 (top_stmt -> entity_def .)
+    (               reduce using rule 6 (top_stmt -> entity_def .)
+    TYPEDEF         reduce using rule 6 (top_stmt -> entity_def .)
+    ID              reduce using rule 6 (top_stmt -> entity_def .)
+    NOT             reduce using rule 6 (top_stmt -> entity_def .)
+    INT             reduce using rule 6 (top_stmt -> entity_def .)
+    FLOAT           reduce using rule 6 (top_stmt -> entity_def .)
+    NULL            reduce using rule 6 (top_stmt -> entity_def .)
+    REGEX           reduce using rule 6 (top_stmt -> entity_def .)
+    TRUE            reduce using rule 6 (top_stmt -> entity_def .)
+    FALSE           reduce using rule 6 (top_stmt -> entity_def .)
+    STRING          reduce using rule 6 (top_stmt -> entity_def .)
+    FSTRING         reduce using rule 6 (top_stmt -> entity_def .)
+    RSTRING         reduce using rule 6 (top_stmt -> entity_def .)
+    MLS             reduce using rule 6 (top_stmt -> entity_def .)
+    [               reduce using rule 6 (top_stmt -> entity_def .)
+    {               reduce using rule 6 (top_stmt -> entity_def .)
+    $end            reduce using rule 6 (top_stmt -> entity_def .)
 
 
 state 8
 
-    (7) top_stmt -> entity_def .
+    (7) top_stmt -> implement_def .
 
-    ENTITY          reduce using rule 7 (top_stmt -> entity_def .)
-    IMPLEMENT       reduce using rule 7 (top_stmt -> entity_def .)
-    IMPLEMENTATION  reduce using rule 7 (top_stmt -> entity_def .)
-    INDEX           reduce using rule 7 (top_stmt -> entity_def .)
-    IMPORT          reduce using rule 7 (top_stmt -> entity_def .)
-    CID             reduce using rule 7 (top_stmt -> entity_def .)
-    FOR             reduce using rule 7 (top_stmt -> entity_def .)
-    IF              reduce using rule 7 (top_stmt -> entity_def .)
-    (               reduce using rule 7 (top_stmt -> entity_def .)
-    TYPEDEF         reduce using rule 7 (top_stmt -> entity_def .)
-    ID              reduce using rule 7 (top_stmt -> entity_def .)
-    NOT             reduce using rule 7 (top_stmt -> entity_def .)
-    INT             reduce using rule 7 (top_stmt -> entity_def .)
-    FLOAT           reduce using rule 7 (top_stmt -> entity_def .)
-    NULL            reduce using rule 7 (top_stmt -> entity_def .)
-    REGEX           reduce using rule 7 (top_stmt -> entity_def .)
-    TRUE            reduce using rule 7 (top_stmt -> entity_def .)
-    FALSE           reduce using rule 7 (top_stmt -> entity_def .)
-    STRING          reduce using rule 7 (top_stmt -> entity_def .)
-    FSTRING         reduce using rule 7 (top_stmt -> entity_def .)
-    RSTRING         reduce using rule 7 (top_stmt -> entity_def .)
-    MLS             reduce using rule 7 (top_stmt -> entity_def .)
-    [               reduce using rule 7 (top_stmt -> entity_def .)
-    {               reduce using rule 7 (top_stmt -> entity_def .)
-    $end            reduce using rule 7 (top_stmt -> entity_def .)
+    ENTITY          reduce using rule 7 (top_stmt -> implement_def .)
+    IMPLEMENT       reduce using rule 7 (top_stmt -> implement_def .)
+    IMPLEMENTATION  reduce using rule 7 (top_stmt -> implement_def .)
+    INDEX           reduce using rule 7 (top_stmt -> implement_def .)
+    IMPORT          reduce using rule 7 (top_stmt -> implement_def .)
+    CID             reduce using rule 7 (top_stmt -> implement_def .)
+    FOR             reduce using rule 7 (top_stmt -> implement_def .)
+    IF              reduce using rule 7 (top_stmt -> implement_def .)
+    (               reduce using rule 7 (top_stmt -> implement_def .)
+    TYPEDEF         reduce using rule 7 (top_stmt -> implement_def .)
+    ID              reduce using rule 7 (top_stmt -> implement_def .)
+    NOT             reduce using rule 7 (top_stmt -> implement_def .)
+    INT             reduce using rule 7 (top_stmt -> implement_def .)
+    FLOAT           reduce using rule 7 (top_stmt -> implement_def .)
+    NULL            reduce using rule 7 (top_stmt -> implement_def .)
+    REGEX           reduce using rule 7 (top_stmt -> implement_def .)
+    TRUE            reduce using rule 7 (top_stmt -> implement_def .)
+    FALSE           reduce using rule 7 (top_stmt -> implement_def .)
+    STRING          reduce using rule 7 (top_stmt -> implement_def .)
+    FSTRING         reduce using rule 7 (top_stmt -> implement_def .)
+    RSTRING         reduce using rule 7 (top_stmt -> implement_def .)
+    MLS             reduce using rule 7 (top_stmt -> implement_def .)
+    [               reduce using rule 7 (top_stmt -> implement_def .)
+    {               reduce using rule 7 (top_stmt -> implement_def .)
+    $end            reduce using rule 7 (top_stmt -> implement_def .)
 
 
 state 9
 
-    (8) top_stmt -> implement_def .
+    (8) top_stmt -> implementation_def .
 
-    ENTITY          reduce using rule 8 (top_stmt -> implement_def .)
-    IMPLEMENT       reduce using rule 8 (top_stmt -> implement_def .)
-    IMPLEMENTATION  reduce using rule 8 (top_stmt -> implement_def .)
-    INDEX           reduce using rule 8 (top_stmt -> implement_def .)
-    IMPORT          reduce using rule 8 (top_stmt -> implement_def .)
-    CID             reduce using rule 8 (top_stmt -> implement_def .)
-    FOR             reduce using rule 8 (top_stmt -> implement_def .)
-    IF              reduce using rule 8 (top_stmt -> implement_def .)
-    (               reduce using rule 8 (top_stmt -> implement_def .)
-    TYPEDEF         reduce using rule 8 (top_stmt -> implement_def .)
-    ID              reduce using rule 8 (top_stmt -> implement_def .)
-    NOT             reduce using rule 8 (top_stmt -> implement_def .)
-    INT             reduce using rule 8 (top_stmt -> implement_def .)
-    FLOAT           reduce using rule 8 (top_stmt -> implement_def .)
-    NULL            reduce using rule 8 (top_stmt -> implement_def .)
-    REGEX           reduce using rule 8 (top_stmt -> implement_def .)
-    TRUE            reduce using rule 8 (top_stmt -> implement_def .)
-    FALSE           reduce using rule 8 (top_stmt -> implement_def .)
-    STRING          reduce using rule 8 (top_stmt -> implement_def .)
-    FSTRING         reduce using rule 8 (top_stmt -> implement_def .)
-    RSTRING         reduce using rule 8 (top_stmt -> implement_def .)
-    MLS             reduce using rule 8 (top_stmt -> implement_def .)
-    [               reduce using rule 8 (top_stmt -> implement_def .)
-    {               reduce using rule 8 (top_stmt -> implement_def .)
-    $end            reduce using rule 8 (top_stmt -> implement_def .)
+    ENTITY          reduce using rule 8 (top_stmt -> implementation_def .)
+    IMPLEMENT       reduce using rule 8 (top_stmt -> implementation_def .)
+    IMPLEMENTATION  reduce using rule 8 (top_stmt -> implementation_def .)
+    INDEX           reduce using rule 8 (top_stmt -> implementation_def .)
+    IMPORT          reduce using rule 8 (top_stmt -> implementation_def .)
+    CID             reduce using rule 8 (top_stmt -> implementation_def .)
+    FOR             reduce using rule 8 (top_stmt -> implementation_def .)
+    IF              reduce using rule 8 (top_stmt -> implementation_def .)
+    (               reduce using rule 8 (top_stmt -> implementation_def .)
+    TYPEDEF         reduce using rule 8 (top_stmt -> implementation_def .)
+    ID              reduce using rule 8 (top_stmt -> implementation_def .)
+    NOT             reduce using rule 8 (top_stmt -> implementation_def .)
+    INT             reduce using rule 8 (top_stmt -> implementation_def .)
+    FLOAT           reduce using rule 8 (top_stmt -> implementation_def .)
+    NULL            reduce using rule 8 (top_stmt -> implementation_def .)
+    REGEX           reduce using rule 8 (top_stmt -> implementation_def .)
+    TRUE            reduce using rule 8 (top_stmt -> implementation_def .)
+    FALSE           reduce using rule 8 (top_stmt -> implementation_def .)
+    STRING          reduce using rule 8 (top_stmt -> implementation_def .)
+    FSTRING         reduce using rule 8 (top_stmt -> implementation_def .)
+    RSTRING         reduce using rule 8 (top_stmt -> implementation_def .)
+    MLS             reduce using rule 8 (top_stmt -> implementation_def .)
+    [               reduce using rule 8 (top_stmt -> implementation_def .)
+    {               reduce using rule 8 (top_stmt -> implementation_def .)
+    $end            reduce using rule 8 (top_stmt -> implementation_def .)
 
 
 state 10
 
-    (9) top_stmt -> implementation_def .
+    (9) top_stmt -> relation .
 
-    ENTITY          reduce using rule 9 (top_stmt -> implementation_def .)
-    IMPLEMENT       reduce using rule 9 (top_stmt -> implementation_def .)
-    IMPLEMENTATION  reduce using rule 9 (top_stmt -> implementation_def .)
-    INDEX           reduce using rule 9 (top_stmt -> implementation_def .)
-    IMPORT          reduce using rule 9 (top_stmt -> implementation_def .)
-    CID             reduce using rule 9 (top_stmt -> implementation_def .)
-    FOR             reduce using rule 9 (top_stmt -> implementation_def .)
-    IF              reduce using rule 9 (top_stmt -> implementation_def .)
-    (               reduce using rule 9 (top_stmt -> implementation_def .)
-    TYPEDEF         reduce using rule 9 (top_stmt -> implementation_def .)
-    ID              reduce using rule 9 (top_stmt -> implementation_def .)
-    NOT             reduce using rule 9 (top_stmt -> implementation_def .)
-    INT             reduce using rule 9 (top_stmt -> implementation_def .)
-    FLOAT           reduce using rule 9 (top_stmt -> implementation_def .)
-    NULL            reduce using rule 9 (top_stmt -> implementation_def .)
-    REGEX           reduce using rule 9 (top_stmt -> implementation_def .)
-    TRUE            reduce using rule 9 (top_stmt -> implementation_def .)
-    FALSE           reduce using rule 9 (top_stmt -> implementation_def .)
-    STRING          reduce using rule 9 (top_stmt -> implementation_def .)
-    FSTRING         reduce using rule 9 (top_stmt -> implementation_def .)
-    RSTRING         reduce using rule 9 (top_stmt -> implementation_def .)
-    MLS             reduce using rule 9 (top_stmt -> implementation_def .)
-    [               reduce using rule 9 (top_stmt -> implementation_def .)
-    {               reduce using rule 9 (top_stmt -> implementation_def .)
-    $end            reduce using rule 9 (top_stmt -> implementation_def .)
+    ENTITY          reduce using rule 9 (top_stmt -> relation .)
+    IMPLEMENT       reduce using rule 9 (top_stmt -> relation .)
+    IMPLEMENTATION  reduce using rule 9 (top_stmt -> relation .)
+    INDEX           reduce using rule 9 (top_stmt -> relation .)
+    IMPORT          reduce using rule 9 (top_stmt -> relation .)
+    CID             reduce using rule 9 (top_stmt -> relation .)
+    FOR             reduce using rule 9 (top_stmt -> relation .)
+    IF              reduce using rule 9 (top_stmt -> relation .)
+    (               reduce using rule 9 (top_stmt -> relation .)
+    TYPEDEF         reduce using rule 9 (top_stmt -> relation .)
+    ID              reduce using rule 9 (top_stmt -> relation .)
+    NOT             reduce using rule 9 (top_stmt -> relation .)
+    INT             reduce using rule 9 (top_stmt -> relation .)
+    FLOAT           reduce using rule 9 (top_stmt -> relation .)
+    NULL            reduce using rule 9 (top_stmt -> relation .)
+    REGEX           reduce using rule 9 (top_stmt -> relation .)
+    TRUE            reduce using rule 9 (top_stmt -> relation .)
+    FALSE           reduce using rule 9 (top_stmt -> relation .)
+    STRING          reduce using rule 9 (top_stmt -> relation .)
+    FSTRING         reduce using rule 9 (top_stmt -> relation .)
+    RSTRING         reduce using rule 9 (top_stmt -> relation .)
+    MLS             reduce using rule 9 (top_stmt -> relation .)
+    [               reduce using rule 9 (top_stmt -> relation .)
+    {               reduce using rule 9 (top_stmt -> relation .)
+    $end            reduce using rule 9 (top_stmt -> relation .)
 
 
 state 11
 
-    (10) top_stmt -> relation .
+    (10) top_stmt -> statement .
 
-    ENTITY          reduce using rule 10 (top_stmt -> relation .)
-    IMPLEMENT       reduce using rule 10 (top_stmt -> relation .)
-    IMPLEMENTATION  reduce using rule 10 (top_stmt -> relation .)
-    INDEX           reduce using rule 10 (top_stmt -> relation .)
-    IMPORT          reduce using rule 10 (top_stmt -> relation .)
-    CID             reduce using rule 10 (top_stmt -> relation .)
-    FOR             reduce using rule 10 (top_stmt -> relation .)
-    IF              reduce using rule 10 (top_stmt -> relation .)
-    (               reduce using rule 10 (top_stmt -> relation .)
-    TYPEDEF         reduce using rule 10 (top_stmt -> relation .)
-    ID              reduce using rule 10 (top_stmt -> relation .)
-    NOT             reduce using rule 10 (top_stmt -> relation .)
-    INT             reduce using rule 10 (top_stmt -> relation .)
-    FLOAT           reduce using rule 10 (top_stmt -> relation .)
-    NULL            reduce using rule 10 (top_stmt -> relation .)
-    REGEX           reduce using rule 10 (top_stmt -> relation .)
-    TRUE            reduce using rule 10 (top_stmt -> relation .)
-    FALSE           reduce using rule 10 (top_stmt -> relation .)
-    STRING          reduce using rule 10 (top_stmt -> relation .)
-    FSTRING         reduce using rule 10 (top_stmt -> relation .)
-    RSTRING         reduce using rule 10 (top_stmt -> relation .)
-    MLS             reduce using rule 10 (top_stmt -> relation .)
-    [               reduce using rule 10 (top_stmt -> relation .)
-    {               reduce using rule 10 (top_stmt -> relation .)
-    $end            reduce using rule 10 (top_stmt -> relation .)
+    ENTITY          reduce using rule 10 (top_stmt -> statement .)
+    IMPLEMENT       reduce using rule 10 (top_stmt -> statement .)
+    IMPLEMENTATION  reduce using rule 10 (top_stmt -> statement .)
+    INDEX           reduce using rule 10 (top_stmt -> statement .)
+    IMPORT          reduce using rule 10 (top_stmt -> statement .)
+    CID             reduce using rule 10 (top_stmt -> statement .)
+    FOR             reduce using rule 10 (top_stmt -> statement .)
+    IF              reduce using rule 10 (top_stmt -> statement .)
+    (               reduce using rule 10 (top_stmt -> statement .)
+    TYPEDEF         reduce using rule 10 (top_stmt -> statement .)
+    ID              reduce using rule 10 (top_stmt -> statement .)
+    NOT             reduce using rule 10 (top_stmt -> statement .)
+    INT             reduce using rule 10 (top_stmt -> statement .)
+    FLOAT           reduce using rule 10 (top_stmt -> statement .)
+    NULL            reduce using rule 10 (top_stmt -> statement .)
+    REGEX           reduce using rule 10 (top_stmt -> statement .)
+    TRUE            reduce using rule 10 (top_stmt -> statement .)
+    FALSE           reduce using rule 10 (top_stmt -> statement .)
+    STRING          reduce using rule 10 (top_stmt -> statement .)
+    FSTRING         reduce using rule 10 (top_stmt -> statement .)
+    RSTRING         reduce using rule 10 (top_stmt -> statement .)
+    MLS             reduce using rule 10 (top_stmt -> statement .)
+    [               reduce using rule 10 (top_stmt -> statement .)
+    {               reduce using rule 10 (top_stmt -> statement .)
+    $end            reduce using rule 10 (top_stmt -> statement .)
 
 
 state 12
 
-    (11) top_stmt -> statement .
+    (11) top_stmt -> typedef .
 
-    ENTITY          reduce using rule 11 (top_stmt -> statement .)
-    IMPLEMENT       reduce using rule 11 (top_stmt -> statement .)
-    IMPLEMENTATION  reduce using rule 11 (top_stmt -> statement .)
-    INDEX           reduce using rule 11 (top_stmt -> statement .)
-    IMPORT          reduce using rule 11 (top_stmt -> statement .)
-    CID             reduce using rule 11 (top_stmt -> statement .)
-    FOR             reduce using rule 11 (top_stmt -> statement .)
-    IF              reduce using rule 11 (top_stmt -> statement .)
-    (               reduce using rule 11 (top_stmt -> statement .)
-    TYPEDEF         reduce using rule 11 (top_stmt -> statement .)
-    ID              reduce using rule 11 (top_stmt -> statement .)
-    NOT             reduce using rule 11 (top_stmt -> statement .)
-    INT             reduce using rule 11 (top_stmt -> statement .)
-    FLOAT           reduce using rule 11 (top_stmt -> statement .)
-    NULL            reduce using rule 11 (top_stmt -> statement .)
-    REGEX           reduce using rule 11 (top_stmt -> statement .)
-    TRUE            reduce using rule 11 (top_stmt -> statement .)
-    FALSE           reduce using rule 11 (top_stmt -> statement .)
-    STRING          reduce using rule 11 (top_stmt -> statement .)
-    FSTRING         reduce using rule 11 (top_stmt -> statement .)
-    RSTRING         reduce using rule 11 (top_stmt -> statement .)
-    MLS             reduce using rule 11 (top_stmt -> statement .)
-    [               reduce using rule 11 (top_stmt -> statement .)
-    {               reduce using rule 11 (top_stmt -> statement .)
-    $end            reduce using rule 11 (top_stmt -> statement .)
+    ENTITY          reduce using rule 11 (top_stmt -> typedef .)
+    IMPLEMENT       reduce using rule 11 (top_stmt -> typedef .)
+    IMPLEMENTATION  reduce using rule 11 (top_stmt -> typedef .)
+    INDEX           reduce using rule 11 (top_stmt -> typedef .)
+    IMPORT          reduce using rule 11 (top_stmt -> typedef .)
+    CID             reduce using rule 11 (top_stmt -> typedef .)
+    FOR             reduce using rule 11 (top_stmt -> typedef .)
+    IF              reduce using rule 11 (top_stmt -> typedef .)
+    (               reduce using rule 11 (top_stmt -> typedef .)
+    TYPEDEF         reduce using rule 11 (top_stmt -> typedef .)
+    ID              reduce using rule 11 (top_stmt -> typedef .)
+    NOT             reduce using rule 11 (top_stmt -> typedef .)
+    INT             reduce using rule 11 (top_stmt -> typedef .)
+    FLOAT           reduce using rule 11 (top_stmt -> typedef .)
+    NULL            reduce using rule 11 (top_stmt -> typedef .)
+    REGEX           reduce using rule 11 (top_stmt -> typedef .)
+    TRUE            reduce using rule 11 (top_stmt -> typedef .)
+    FALSE           reduce using rule 11 (top_stmt -> typedef .)
+    STRING          reduce using rule 11 (top_stmt -> typedef .)
+    FSTRING         reduce using rule 11 (top_stmt -> typedef .)
+    RSTRING         reduce using rule 11 (top_stmt -> typedef .)
+    MLS             reduce using rule 11 (top_stmt -> typedef .)
+    [               reduce using rule 11 (top_stmt -> typedef .)
+    {               reduce using rule 11 (top_stmt -> typedef .)
+    $end            reduce using rule 11 (top_stmt -> typedef .)
 
 
 state 13
 
-    (12) top_stmt -> typedef .
+    (12) top_stmt -> index .
 
-    ENTITY          reduce using rule 12 (top_stmt -> typedef .)
-    IMPLEMENT       reduce using rule 12 (top_stmt -> typedef .)
-    IMPLEMENTATION  reduce using rule 12 (top_stmt -> typedef .)
-    INDEX           reduce using rule 12 (top_stmt -> typedef .)
-    IMPORT          reduce using rule 12 (top_stmt -> typedef .)
-    CID             reduce using rule 12 (top_stmt -> typedef .)
-    FOR             reduce using rule 12 (top_stmt -> typedef .)
-    IF              reduce using rule 12 (top_stmt -> typedef .)
-    (               reduce using rule 12 (top_stmt -> typedef .)
-    TYPEDEF         reduce using rule 12 (top_stmt -> typedef .)
-    ID              reduce using rule 12 (top_stmt -> typedef .)
-    NOT             reduce using rule 12 (top_stmt -> typedef .)
-    INT             reduce using rule 12 (top_stmt -> typedef .)
-    FLOAT           reduce using rule 12 (top_stmt -> typedef .)
-    NULL            reduce using rule 12 (top_stmt -> typedef .)
-    REGEX           reduce using rule 12 (top_stmt -> typedef .)
-    TRUE            reduce using rule 12 (top_stmt -> typedef .)
-    FALSE           reduce using rule 12 (top_stmt -> typedef .)
-    STRING          reduce using rule 12 (top_stmt -> typedef .)
-    FSTRING         reduce using rule 12 (top_stmt -> typedef .)
-    RSTRING         reduce using rule 12 (top_stmt -> typedef .)
-    MLS             reduce using rule 12 (top_stmt -> typedef .)
-    [               reduce using rule 12 (top_stmt -> typedef .)
-    {               reduce using rule 12 (top_stmt -> typedef .)
-    $end            reduce using rule 12 (top_stmt -> typedef .)
+    ENTITY          reduce using rule 12 (top_stmt -> index .)
+    IMPLEMENT       reduce using rule 12 (top_stmt -> index .)
+    IMPLEMENTATION  reduce using rule 12 (top_stmt -> index .)
+    INDEX           reduce using rule 12 (top_stmt -> index .)
+    IMPORT          reduce using rule 12 (top_stmt -> index .)
+    CID             reduce using rule 12 (top_stmt -> index .)
+    FOR             reduce using rule 12 (top_stmt -> index .)
+    IF              reduce using rule 12 (top_stmt -> index .)
+    (               reduce using rule 12 (top_stmt -> index .)
+    TYPEDEF         reduce using rule 12 (top_stmt -> index .)
+    ID              reduce using rule 12 (top_stmt -> index .)
+    NOT             reduce using rule 12 (top_stmt -> index .)
+    INT             reduce using rule 12 (top_stmt -> index .)
+    FLOAT           reduce using rule 12 (top_stmt -> index .)
+    NULL            reduce using rule 12 (top_stmt -> index .)
+    REGEX           reduce using rule 12 (top_stmt -> index .)
+    TRUE            reduce using rule 12 (top_stmt -> index .)
+    FALSE           reduce using rule 12 (top_stmt -> index .)
+    STRING          reduce using rule 12 (top_stmt -> index .)
+    FSTRING         reduce using rule 12 (top_stmt -> index .)
+    RSTRING         reduce using rule 12 (top_stmt -> index .)
+    MLS             reduce using rule 12 (top_stmt -> index .)
+    [               reduce using rule 12 (top_stmt -> index .)
+    {               reduce using rule 12 (top_stmt -> index .)
+    $end            reduce using rule 12 (top_stmt -> index .)
 
 
 state 14
 
-    (13) top_stmt -> index .
+    (13) top_stmt -> import .
 
-    ENTITY          reduce using rule 13 (top_stmt -> index .)
-    IMPLEMENT       reduce using rule 13 (top_stmt -> index .)
-    IMPLEMENTATION  reduce using rule 13 (top_stmt -> index .)
-    INDEX           reduce using rule 13 (top_stmt -> index .)
-    IMPORT          reduce using rule 13 (top_stmt -> index .)
-    CID             reduce using rule 13 (top_stmt -> index .)
-    FOR             reduce using rule 13 (top_stmt -> index .)
-    IF              reduce using rule 13 (top_stmt -> index .)
-    (               reduce using rule 13 (top_stmt -> index .)
-    TYPEDEF         reduce using rule 13 (top_stmt -> index .)
-    ID              reduce using rule 13 (top_stmt -> index .)
-    NOT             reduce using rule 13 (top_stmt -> index .)
-    INT             reduce using rule 13 (top_stmt -> index .)
-    FLOAT           reduce using rule 13 (top_stmt -> index .)
-    NULL            reduce using rule 13 (top_stmt -> index .)
-    REGEX           reduce using rule 13 (top_stmt -> index .)
-    TRUE            reduce using rule 13 (top_stmt -> index .)
-    FALSE           reduce using rule 13 (top_stmt -> index .)
-    STRING          reduce using rule 13 (top_stmt -> index .)
-    FSTRING         reduce using rule 13 (top_stmt -> index .)
-    RSTRING         reduce using rule 13 (top_stmt -> index .)
-    MLS             reduce using rule 13 (top_stmt -> index .)
-    [               reduce using rule 13 (top_stmt -> index .)
-    {               reduce using rule 13 (top_stmt -> index .)
-    $end            reduce using rule 13 (top_stmt -> index .)
+    ENTITY          reduce using rule 13 (top_stmt -> import .)
+    IMPLEMENT       reduce using rule 13 (top_stmt -> import .)
+    IMPLEMENTATION  reduce using rule 13 (top_stmt -> import .)
+    INDEX           reduce using rule 13 (top_stmt -> import .)
+    IMPORT          reduce using rule 13 (top_stmt -> import .)
+    CID             reduce using rule 13 (top_stmt -> import .)
+    FOR             reduce using rule 13 (top_stmt -> import .)
+    IF              reduce using rule 13 (top_stmt -> import .)
+    (               reduce using rule 13 (top_stmt -> import .)
+    TYPEDEF         reduce using rule 13 (top_stmt -> import .)
+    ID              reduce using rule 13 (top_stmt -> import .)
+    NOT             reduce using rule 13 (top_stmt -> import .)
+    INT             reduce using rule 13 (top_stmt -> import .)
+    FLOAT           reduce using rule 13 (top_stmt -> import .)
+    NULL            reduce using rule 13 (top_stmt -> import .)
+    REGEX           reduce using rule 13 (top_stmt -> import .)
+    TRUE            reduce using rule 13 (top_stmt -> import .)
+    FALSE           reduce using rule 13 (top_stmt -> import .)
+    STRING          reduce using rule 13 (top_stmt -> import .)
+    FSTRING         reduce using rule 13 (top_stmt -> import .)
+    RSTRING         reduce using rule 13 (top_stmt -> import .)
+    MLS             reduce using rule 13 (top_stmt -> import .)
+    [               reduce using rule 13 (top_stmt -> import .)
+    {               reduce using rule 13 (top_stmt -> import .)
+    $end            reduce using rule 13 (top_stmt -> import .)
 
 
 state 15
 
-    (14) top_stmt -> import .
-
-    ENTITY          reduce using rule 14 (top_stmt -> import .)
-    IMPLEMENT       reduce using rule 14 (top_stmt -> import .)
-    IMPLEMENTATION  reduce using rule 14 (top_stmt -> import .)
-    INDEX           reduce using rule 14 (top_stmt -> import .)
-    IMPORT          reduce using rule 14 (top_stmt -> import .)
-    CID             reduce using rule 14 (top_stmt -> import .)
-    FOR             reduce using rule 14 (top_stmt -> import .)
-    IF              reduce using rule 14 (top_stmt -> import .)
-    (               reduce using rule 14 (top_stmt -> import .)
-    TYPEDEF         reduce using rule 14 (top_stmt -> import .)
-    ID              reduce using rule 14 (top_stmt -> import .)
-    NOT             reduce using rule 14 (top_stmt -> import .)
-    INT             reduce using rule 14 (top_stmt -> import .)
-    FLOAT           reduce using rule 14 (top_stmt -> import .)
-    NULL            reduce using rule 14 (top_stmt -> import .)
-    REGEX           reduce using rule 14 (top_stmt -> import .)
-    TRUE            reduce using rule 14 (top_stmt -> import .)
-    FALSE           reduce using rule 14 (top_stmt -> import .)
-    STRING          reduce using rule 14 (top_stmt -> import .)
-    FSTRING         reduce using rule 14 (top_stmt -> import .)
-    RSTRING         reduce using rule 14 (top_stmt -> import .)
-    MLS             reduce using rule 14 (top_stmt -> import .)
-    [               reduce using rule 14 (top_stmt -> import .)
-    {               reduce using rule 14 (top_stmt -> import .)
-    $end            reduce using rule 14 (top_stmt -> import .)
-
-
-state 16
-
     (31) entity_def -> ENTITY . CID : entity_body_outer
     (32) entity_def -> ENTITY . ID : entity_body_outer
     (33) entity_def -> ENTITY . CID EXTENDS class_ref_list : entity_body_outer
     (34) entity_def -> ENTITY . ID EXTENDS class_ref_list : entity_body_outer
 
-    CID             shift and go to state 61
-    ID              shift and go to state 62
+    CID             shift and go to state 60
+    ID              shift and go to state 61
 
 
-state 17
+state 16
 
-    (175) class_ref -> CID .
+    (174) class_ref -> CID .
 
-    ID              reduce using rule 175 (class_ref -> CID .)
-    .               reduce using rule 175 (class_ref -> CID .)
-    (               reduce using rule 175 (class_ref -> CID .)
-    [               reduce using rule 175 (class_ref -> CID .)
-    USING           reduce using rule 175 (class_ref -> CID .)
-    ,               reduce using rule 175 (class_ref -> CID .)
-    :               reduce using rule 175 (class_ref -> CID .)
-    MLS             reduce using rule 175 (class_ref -> CID .)
-    ENTITY          reduce using rule 175 (class_ref -> CID .)
-    IMPLEMENT       reduce using rule 175 (class_ref -> CID .)
-    IMPLEMENTATION  reduce using rule 175 (class_ref -> CID .)
-    INDEX           reduce using rule 175 (class_ref -> CID .)
-    IMPORT          reduce using rule 175 (class_ref -> CID .)
-    CID             reduce using rule 175 (class_ref -> CID .)
-    FOR             reduce using rule 175 (class_ref -> CID .)
-    IF              reduce using rule 175 (class_ref -> CID .)
-    TYPEDEF         reduce using rule 175 (class_ref -> CID .)
-    NOT             reduce using rule 175 (class_ref -> CID .)
-    INT             reduce using rule 175 (class_ref -> CID .)
-    FLOAT           reduce using rule 175 (class_ref -> CID .)
-    NULL            reduce using rule 175 (class_ref -> CID .)
-    REGEX           reduce using rule 175 (class_ref -> CID .)
-    TRUE            reduce using rule 175 (class_ref -> CID .)
-    FALSE           reduce using rule 175 (class_ref -> CID .)
-    STRING          reduce using rule 175 (class_ref -> CID .)
-    FSTRING         reduce using rule 175 (class_ref -> CID .)
-    RSTRING         reduce using rule 175 (class_ref -> CID .)
-    {               reduce using rule 175 (class_ref -> CID .)
-    $end            reduce using rule 175 (class_ref -> CID .)
+    ID              reduce using rule 174 (class_ref -> CID .)
+    .               reduce using rule 174 (class_ref -> CID .)
+    (               reduce using rule 174 (class_ref -> CID .)
+    [               reduce using rule 174 (class_ref -> CID .)
+    USING           reduce using rule 174 (class_ref -> CID .)
+    ,               reduce using rule 174 (class_ref -> CID .)
+    :               reduce using rule 174 (class_ref -> CID .)
+    MLS             reduce using rule 174 (class_ref -> CID .)
+    ENTITY          reduce using rule 174 (class_ref -> CID .)
+    IMPLEMENT       reduce using rule 174 (class_ref -> CID .)
+    IMPLEMENTATION  reduce using rule 174 (class_ref -> CID .)
+    INDEX           reduce using rule 174 (class_ref -> CID .)
+    IMPORT          reduce using rule 174 (class_ref -> CID .)
+    CID             reduce using rule 174 (class_ref -> CID .)
+    FOR             reduce using rule 174 (class_ref -> CID .)
+    IF              reduce using rule 174 (class_ref -> CID .)
+    TYPEDEF         reduce using rule 174 (class_ref -> CID .)
+    NOT             reduce using rule 174 (class_ref -> CID .)
+    INT             reduce using rule 174 (class_ref -> CID .)
+    FLOAT           reduce using rule 174 (class_ref -> CID .)
+    NULL            reduce using rule 174 (class_ref -> CID .)
+    REGEX           reduce using rule 174 (class_ref -> CID .)
+    TRUE            reduce using rule 174 (class_ref -> CID .)
+    FALSE           reduce using rule 174 (class_ref -> CID .)
+    STRING          reduce using rule 174 (class_ref -> CID .)
+    FSTRING         reduce using rule 174 (class_ref -> CID .)
+    RSTRING         reduce using rule 174 (class_ref -> CID .)
+    {               reduce using rule 174 (class_ref -> CID .)
+    $end            reduce using rule 174 (class_ref -> CID .)
 
 
-state 18
+state 17
 
-    (183) ns_ref -> ID .
-    (116) boolean_expression -> ID . IS DEFINED
+    (182) ns_ref -> ID .
+    (115) boolean_expression -> ID . IS DEFINED
 
-    SEP             reduce using rule 183 (ns_ref -> ID .)
-    (               reduce using rule 183 (ns_ref -> ID .)
-    .               reduce using rule 183 (ns_ref -> ID .)
-    =               reduce using rule 183 (ns_ref -> ID .)
-    PEQ             reduce using rule 183 (ns_ref -> ID .)
-    [               reduce using rule 183 (ns_ref -> ID .)
-    CMP_OP          reduce using rule 183 (ns_ref -> ID .)
-    IN              reduce using rule 183 (ns_ref -> ID .)
-    AND             reduce using rule 183 (ns_ref -> ID .)
-    OR              reduce using rule 183 (ns_ref -> ID .)
-    NOT             reduce using rule 183 (ns_ref -> ID .)
-    ?               reduce using rule 183 (ns_ref -> ID .)
-    ENTITY          reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENT       reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENTATION  reduce using rule 183 (ns_ref -> ID .)
-    INDEX           reduce using rule 183 (ns_ref -> ID .)
-    IMPORT          reduce using rule 183 (ns_ref -> ID .)
-    CID             reduce using rule 183 (ns_ref -> ID .)
-    FOR             reduce using rule 183 (ns_ref -> ID .)
-    IF              reduce using rule 183 (ns_ref -> ID .)
-    TYPEDEF         reduce using rule 183 (ns_ref -> ID .)
-    ID              reduce using rule 183 (ns_ref -> ID .)
-    INT             reduce using rule 183 (ns_ref -> ID .)
-    FLOAT           reduce using rule 183 (ns_ref -> ID .)
-    NULL            reduce using rule 183 (ns_ref -> ID .)
-    REGEX           reduce using rule 183 (ns_ref -> ID .)
-    TRUE            reduce using rule 183 (ns_ref -> ID .)
-    FALSE           reduce using rule 183 (ns_ref -> ID .)
-    STRING          reduce using rule 183 (ns_ref -> ID .)
-    FSTRING         reduce using rule 183 (ns_ref -> ID .)
-    RSTRING         reduce using rule 183 (ns_ref -> ID .)
-    MLS             reduce using rule 183 (ns_ref -> ID .)
-    {               reduce using rule 183 (ns_ref -> ID .)
-    $end            reduce using rule 183 (ns_ref -> ID .)
-    IS              shift and go to state 63
+    SEP             reduce using rule 182 (ns_ref -> ID .)
+    (               reduce using rule 182 (ns_ref -> ID .)
+    .               reduce using rule 182 (ns_ref -> ID .)
+    =               reduce using rule 182 (ns_ref -> ID .)
+    PEQ             reduce using rule 182 (ns_ref -> ID .)
+    [               reduce using rule 182 (ns_ref -> ID .)
+    CMP_OP          reduce using rule 182 (ns_ref -> ID .)
+    IN              reduce using rule 182 (ns_ref -> ID .)
+    AND             reduce using rule 182 (ns_ref -> ID .)
+    OR              reduce using rule 182 (ns_ref -> ID .)
+    ?               reduce using rule 182 (ns_ref -> ID .)
+    ENTITY          reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENT       reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENTATION  reduce using rule 182 (ns_ref -> ID .)
+    INDEX           reduce using rule 182 (ns_ref -> ID .)
+    IMPORT          reduce using rule 182 (ns_ref -> ID .)
+    CID             reduce using rule 182 (ns_ref -> ID .)
+    FOR             reduce using rule 182 (ns_ref -> ID .)
+    IF              reduce using rule 182 (ns_ref -> ID .)
+    TYPEDEF         reduce using rule 182 (ns_ref -> ID .)
+    ID              reduce using rule 182 (ns_ref -> ID .)
+    NOT             reduce using rule 182 (ns_ref -> ID .)
+    INT             reduce using rule 182 (ns_ref -> ID .)
+    FLOAT           reduce using rule 182 (ns_ref -> ID .)
+    NULL            reduce using rule 182 (ns_ref -> ID .)
+    REGEX           reduce using rule 182 (ns_ref -> ID .)
+    TRUE            reduce using rule 182 (ns_ref -> ID .)
+    FALSE           reduce using rule 182 (ns_ref -> ID .)
+    STRING          reduce using rule 182 (ns_ref -> ID .)
+    FSTRING         reduce using rule 182 (ns_ref -> ID .)
+    RSTRING         reduce using rule 182 (ns_ref -> ID .)
+    MLS             reduce using rule 182 (ns_ref -> ID .)
+    {               reduce using rule 182 (ns_ref -> ID .)
+    $end            reduce using rule 182 (ns_ref -> ID .)
+    IS              shift and go to state 62
 
 
-state 19
+state 18
 
     (71) implement_def -> IMPLEMENT . class_ref USING implement_ns_list empty
     (72) implement_def -> IMPLEMENT . class_ref USING implement_ns_list MLS
     (73) implement_def -> IMPLEMENT . class_ref USING implement_ns_list WHEN expression empty
     (74) implement_def -> IMPLEMENT . class_ref USING implement_ns_list WHEN expression MLS
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 64
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 63
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 20
+state 19
 
     (80) relation -> class_ref . ID multi REL multi class_ref ID
     (81) relation -> class_ref . ID multi REL multi class_ref ID MLS
     (84) relation_def -> class_ref . . ID multi REL class_ref . ID multi
     (85) relation_def -> class_ref . . ID multi REL class_ref
     (86) relation_def -> class_ref . . ID multi operand_list class_ref . ID multi
     (87) relation_def -> class_ref . . ID multi operand_list class_ref
-    (122) constructor -> class_ref . ( param_list )
-    (139) index_lookup -> class_ref . [ param_list ]
+    (121) constructor -> class_ref . ( param_list )
+    (138) index_lookup -> class_ref . [ param_list ]
 
-    ID              shift and go to state 69
-    .               shift and go to state 70
-    (               shift and go to state 71
-    [               shift and go to state 72
+    ID              shift and go to state 68
+    .               shift and go to state 69
+    (               shift and go to state 70
+    [               shift and go to state 71
 
 
-state 21
+state 20
 
-    (151) constant -> MLS .
+    (150) constant -> MLS .
 
-    CMP_OP          reduce using rule 151 (constant -> MLS .)
-    IN              reduce using rule 151 (constant -> MLS .)
-    AND             reduce using rule 151 (constant -> MLS .)
-    OR              reduce using rule 151 (constant -> MLS .)
-    NOT             reduce using rule 151 (constant -> MLS .)
-    ?               reduce using rule 151 (constant -> MLS .)
-    ENTITY          reduce using rule 151 (constant -> MLS .)
-    IMPLEMENT       reduce using rule 151 (constant -> MLS .)
-    IMPLEMENTATION  reduce using rule 151 (constant -> MLS .)
-    INDEX           reduce using rule 151 (constant -> MLS .)
-    IMPORT          reduce using rule 151 (constant -> MLS .)
-    CID             reduce using rule 151 (constant -> MLS .)
-    FOR             reduce using rule 151 (constant -> MLS .)
-    IF              reduce using rule 151 (constant -> MLS .)
-    (               reduce using rule 151 (constant -> MLS .)
-    TYPEDEF         reduce using rule 151 (constant -> MLS .)
-    ID              reduce using rule 151 (constant -> MLS .)
-    INT             reduce using rule 151 (constant -> MLS .)
-    FLOAT           reduce using rule 151 (constant -> MLS .)
-    NULL            reduce using rule 151 (constant -> MLS .)
-    REGEX           reduce using rule 151 (constant -> MLS .)
-    TRUE            reduce using rule 151 (constant -> MLS .)
-    FALSE           reduce using rule 151 (constant -> MLS .)
-    STRING          reduce using rule 151 (constant -> MLS .)
-    FSTRING         reduce using rule 151 (constant -> MLS .)
-    RSTRING         reduce using rule 151 (constant -> MLS .)
-    MLS             reduce using rule 151 (constant -> MLS .)
-    [               reduce using rule 151 (constant -> MLS .)
-    {               reduce using rule 151 (constant -> MLS .)
-    $end            reduce using rule 151 (constant -> MLS .)
-    )               reduce using rule 151 (constant -> MLS .)
-    :               reduce using rule 151 (constant -> MLS .)
-    ,               reduce using rule 151 (constant -> MLS .)
-    ]               reduce using rule 151 (constant -> MLS .)
-    ELSE            reduce using rule 151 (constant -> MLS .)
-    ELIF            reduce using rule 151 (constant -> MLS .)
-    END             reduce using rule 151 (constant -> MLS .)
-    }               reduce using rule 151 (constant -> MLS .)
-    DICT            reduce using rule 151 (constant -> MLS .)
+    CMP_OP          reduce using rule 150 (constant -> MLS .)
+    IN              reduce using rule 150 (constant -> MLS .)
+    AND             reduce using rule 150 (constant -> MLS .)
+    OR              reduce using rule 150 (constant -> MLS .)
+    ?               reduce using rule 150 (constant -> MLS .)
+    ENTITY          reduce using rule 150 (constant -> MLS .)
+    IMPLEMENT       reduce using rule 150 (constant -> MLS .)
+    IMPLEMENTATION  reduce using rule 150 (constant -> MLS .)
+    INDEX           reduce using rule 150 (constant -> MLS .)
+    IMPORT          reduce using rule 150 (constant -> MLS .)
+    CID             reduce using rule 150 (constant -> MLS .)
+    FOR             reduce using rule 150 (constant -> MLS .)
+    IF              reduce using rule 150 (constant -> MLS .)
+    (               reduce using rule 150 (constant -> MLS .)
+    TYPEDEF         reduce using rule 150 (constant -> MLS .)
+    ID              reduce using rule 150 (constant -> MLS .)
+    NOT             reduce using rule 150 (constant -> MLS .)
+    INT             reduce using rule 150 (constant -> MLS .)
+    FLOAT           reduce using rule 150 (constant -> MLS .)
+    NULL            reduce using rule 150 (constant -> MLS .)
+    REGEX           reduce using rule 150 (constant -> MLS .)
+    TRUE            reduce using rule 150 (constant -> MLS .)
+    FALSE           reduce using rule 150 (constant -> MLS .)
+    STRING          reduce using rule 150 (constant -> MLS .)
+    FSTRING         reduce using rule 150 (constant -> MLS .)
+    RSTRING         reduce using rule 150 (constant -> MLS .)
+    MLS             reduce using rule 150 (constant -> MLS .)
+    [               reduce using rule 150 (constant -> MLS .)
+    {               reduce using rule 150 (constant -> MLS .)
+    $end            reduce using rule 150 (constant -> MLS .)
+    )               reduce using rule 150 (constant -> MLS .)
+    :               reduce using rule 150 (constant -> MLS .)
+    ,               reduce using rule 150 (constant -> MLS .)
+    ]               reduce using rule 150 (constant -> MLS .)
+    ELSE            reduce using rule 150 (constant -> MLS .)
+    ELIF            reduce using rule 150 (constant -> MLS .)
+    END             reduce using rule 150 (constant -> MLS .)
+    }               reduce using rule 150 (constant -> MLS .)
+    DICT            reduce using rule 150 (constant -> MLS .)
 
 
-state 22
+state 21
 
-    (20) statement -> expression . empty
+    (20) statement -> expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (2) empty -> .
-
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
+    (140) conditional_expression -> expression . ? expression : expression
 
-  ! NOT             [ reduce using rule 2 (empty -> .) ]
+    ENTITY          reduce using rule 20 (statement -> expression .)
+    IMPLEMENT       reduce using rule 20 (statement -> expression .)
+    IMPLEMENTATION  reduce using rule 20 (statement -> expression .)
+    INDEX           reduce using rule 20 (statement -> expression .)
+    IMPORT          reduce using rule 20 (statement -> expression .)
+    CID             reduce using rule 20 (statement -> expression .)
+    FOR             reduce using rule 20 (statement -> expression .)
+    IF              reduce using rule 20 (statement -> expression .)
+    (               reduce using rule 20 (statement -> expression .)
+    TYPEDEF         reduce using rule 20 (statement -> expression .)
+    ID              reduce using rule 20 (statement -> expression .)
+    NOT             reduce using rule 20 (statement -> expression .)
+    INT             reduce using rule 20 (statement -> expression .)
+    FLOAT           reduce using rule 20 (statement -> expression .)
+    NULL            reduce using rule 20 (statement -> expression .)
+    REGEX           reduce using rule 20 (statement -> expression .)
+    TRUE            reduce using rule 20 (statement -> expression .)
+    FALSE           reduce using rule 20 (statement -> expression .)
+    STRING          reduce using rule 20 (statement -> expression .)
+    FSTRING         reduce using rule 20 (statement -> expression .)
+    RSTRING         reduce using rule 20 (statement -> expression .)
+    MLS             reduce using rule 20 (statement -> expression .)
+    [               reduce using rule 20 (statement -> expression .)
+    {               reduce using rule 20 (statement -> expression .)
+    $end            reduce using rule 20 (statement -> expression .)
+    ELSE            reduce using rule 20 (statement -> expression .)
+    ELIF            reduce using rule 20 (statement -> expression .)
+    END             reduce using rule 20 (statement -> expression .)
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
-    empty                          shift and go to state 73
 
-state 23
+state 22
 
     (75) implementation_def -> IMPLEMENTATION . ID FOR class_ref implementation
 
-    ID              shift and go to state 80
+    ID              shift and go to state 77
 
 
-state 24
+state 23
 
     (25) for -> FOR . ID IN operand : block
 
-    ID              shift and go to state 81
+    ID              shift and go to state 78
 
 
-state 25
+state 24
 
     (82) relation -> relation_def . MLS
-    (83) relation -> relation_def . empty
-    (2) empty -> .
+    (83) relation -> relation_def .
 
-    MLS             shift and go to state 82
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    MLS             shift and go to state 79
+    ENTITY          reduce using rule 83 (relation -> relation_def .)
+    IMPLEMENT       reduce using rule 83 (relation -> relation_def .)
+    IMPLEMENTATION  reduce using rule 83 (relation -> relation_def .)
+    INDEX           reduce using rule 83 (relation -> relation_def .)
+    IMPORT          reduce using rule 83 (relation -> relation_def .)
+    CID             reduce using rule 83 (relation -> relation_def .)
+    FOR             reduce using rule 83 (relation -> relation_def .)
+    IF              reduce using rule 83 (relation -> relation_def .)
+    (               reduce using rule 83 (relation -> relation_def .)
+    TYPEDEF         reduce using rule 83 (relation -> relation_def .)
+    ID              reduce using rule 83 (relation -> relation_def .)
+    NOT             reduce using rule 83 (relation -> relation_def .)
+    INT             reduce using rule 83 (relation -> relation_def .)
+    FLOAT           reduce using rule 83 (relation -> relation_def .)
+    NULL            reduce using rule 83 (relation -> relation_def .)
+    REGEX           reduce using rule 83 (relation -> relation_def .)
+    TRUE            reduce using rule 83 (relation -> relation_def .)
+    FALSE           reduce using rule 83 (relation -> relation_def .)
+    STRING          reduce using rule 83 (relation -> relation_def .)
+    FSTRING         reduce using rule 83 (relation -> relation_def .)
+    RSTRING         reduce using rule 83 (relation -> relation_def .)
+    [               reduce using rule 83 (relation -> relation_def .)
+    {               reduce using rule 83 (relation -> relation_def .)
+    $end            reduce using rule 83 (relation -> relation_def .)
 
-  ! MLS             [ reduce using rule 2 (empty -> .) ]
+  ! MLS             [ reduce using rule 83 (relation -> relation_def .) ]
 
-    empty                          shift and go to state 83
 
-state 26
+state 25
 
     (17) statement -> assign .
 
     ENTITY          reduce using rule 17 (statement -> assign .)
     IMPLEMENT       reduce using rule 17 (statement -> assign .)
     IMPLEMENTATION  reduce using rule 17 (statement -> assign .)
     INDEX           reduce using rule 17 (statement -> assign .)
@@ -1302,15 +1259,15 @@
     {               reduce using rule 17 (statement -> assign .)
     $end            reduce using rule 17 (statement -> assign .)
     ELSE            reduce using rule 17 (statement -> assign .)
     ELIF            reduce using rule 17 (statement -> assign .)
     END             reduce using rule 17 (statement -> assign .)
 
 
-state 27
+state 26
 
     (18) statement -> for .
 
     ENTITY          reduce using rule 18 (statement -> for .)
     IMPLEMENT       reduce using rule 18 (statement -> for .)
     IMPLEMENTATION  reduce using rule 18 (statement -> for .)
     INDEX           reduce using rule 18 (statement -> for .)
@@ -1336,15 +1293,15 @@
     {               reduce using rule 18 (statement -> for .)
     $end            reduce using rule 18 (statement -> for .)
     ELSE            reduce using rule 18 (statement -> for .)
     ELIF            reduce using rule 18 (statement -> for .)
     END             reduce using rule 18 (statement -> for .)
 
 
-state 28
+state 27
 
     (19) statement -> if .
 
     ENTITY          reduce using rule 19 (statement -> if .)
     IMPLEMENT       reduce using rule 19 (statement -> if .)
     IMPLEMENTATION  reduce using rule 19 (statement -> if .)
     INDEX           reduce using rule 19 (statement -> if .)
@@ -1370,376 +1327,368 @@
     {               reduce using rule 19 (statement -> if .)
     $end            reduce using rule 19 (statement -> if .)
     ELSE            reduce using rule 19 (statement -> if .)
     ELIF            reduce using rule 19 (statement -> if .)
     END             reduce using rule 19 (statement -> if .)
 
 
-state 29
+state 28
 
-    (92) typedef -> typedef_inner . empty
+    (92) typedef -> typedef_inner .
     (93) typedef -> typedef_inner . MLS
-    (2) empty -> .
 
-    MLS             shift and go to state 85
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    ENTITY          reduce using rule 92 (typedef -> typedef_inner .)
+    IMPLEMENT       reduce using rule 92 (typedef -> typedef_inner .)
+    IMPLEMENTATION  reduce using rule 92 (typedef -> typedef_inner .)
+    INDEX           reduce using rule 92 (typedef -> typedef_inner .)
+    IMPORT          reduce using rule 92 (typedef -> typedef_inner .)
+    CID             reduce using rule 92 (typedef -> typedef_inner .)
+    FOR             reduce using rule 92 (typedef -> typedef_inner .)
+    IF              reduce using rule 92 (typedef -> typedef_inner .)
+    (               reduce using rule 92 (typedef -> typedef_inner .)
+    TYPEDEF         reduce using rule 92 (typedef -> typedef_inner .)
+    ID              reduce using rule 92 (typedef -> typedef_inner .)
+    NOT             reduce using rule 92 (typedef -> typedef_inner .)
+    INT             reduce using rule 92 (typedef -> typedef_inner .)
+    FLOAT           reduce using rule 92 (typedef -> typedef_inner .)
+    NULL            reduce using rule 92 (typedef -> typedef_inner .)
+    REGEX           reduce using rule 92 (typedef -> typedef_inner .)
+    TRUE            reduce using rule 92 (typedef -> typedef_inner .)
+    FALSE           reduce using rule 92 (typedef -> typedef_inner .)
+    STRING          reduce using rule 92 (typedef -> typedef_inner .)
+    FSTRING         reduce using rule 92 (typedef -> typedef_inner .)
+    RSTRING         reduce using rule 92 (typedef -> typedef_inner .)
+    [               reduce using rule 92 (typedef -> typedef_inner .)
+    {               reduce using rule 92 (typedef -> typedef_inner .)
+    $end            reduce using rule 92 (typedef -> typedef_inner .)
+    MLS             shift and go to state 80
 
-  ! MLS             [ reduce using rule 2 (empty -> .) ]
+  ! MLS             [ reduce using rule 92 (typedef -> typedef_inner .) ]
 
-    empty                          shift and go to state 84
 
-state 30
+state 29
 
     (96) index -> INDEX . class_ref ( id_list )
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 86
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 81
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 31
+state 30
 
     (108) expression -> ( . expression )
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 87
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 82
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 32
+state 31
 
     (15) import -> IMPORT . ns_ref
     (16) import -> IMPORT . ns_ref AS ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    ID              shift and go to state 67
+    ID              shift and go to state 66
 
-    ns_ref                         shift and go to state 93
+    ns_ref                         shift and go to state 88
 
-state 33
+state 32
 
-    (176) class_ref -> ns_ref . SEP CID
-    (182) ns_ref -> ns_ref . SEP ID
-    (174) var_ref -> ns_ref . empty
-    (123) function_call -> ns_ref . ( function_param_list )
-    (2) empty -> .
-
-    SEP             shift and go to state 94
-    (               shift and go to state 96
-    .               reduce using rule 2 (empty -> .)
-    =               reduce using rule 2 (empty -> .)
-    PEQ             reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    (175) class_ref -> ns_ref . SEP CID
+    (181) ns_ref -> ns_ref . SEP ID
+    (173) var_ref -> ns_ref .
+    (122) function_call -> ns_ref . ( function_param_list )
+
+    SEP             shift and go to state 89
+    .               reduce using rule 173 (var_ref -> ns_ref .)
+    =               reduce using rule 173 (var_ref -> ns_ref .)
+    PEQ             reduce using rule 173 (var_ref -> ns_ref .)
+    [               reduce using rule 173 (var_ref -> ns_ref .)
+    CMP_OP          reduce using rule 173 (var_ref -> ns_ref .)
+    IN              reduce using rule 173 (var_ref -> ns_ref .)
+    AND             reduce using rule 173 (var_ref -> ns_ref .)
+    OR              reduce using rule 173 (var_ref -> ns_ref .)
+    ?               reduce using rule 173 (var_ref -> ns_ref .)
+    ENTITY          reduce using rule 173 (var_ref -> ns_ref .)
+    IMPLEMENT       reduce using rule 173 (var_ref -> ns_ref .)
+    IMPLEMENTATION  reduce using rule 173 (var_ref -> ns_ref .)
+    INDEX           reduce using rule 173 (var_ref -> ns_ref .)
+    IMPORT          reduce using rule 173 (var_ref -> ns_ref .)
+    CID             reduce using rule 173 (var_ref -> ns_ref .)
+    FOR             reduce using rule 173 (var_ref -> ns_ref .)
+    IF              reduce using rule 173 (var_ref -> ns_ref .)
+    TYPEDEF         reduce using rule 173 (var_ref -> ns_ref .)
+    ID              reduce using rule 173 (var_ref -> ns_ref .)
+    NOT             reduce using rule 173 (var_ref -> ns_ref .)
+    INT             reduce using rule 173 (var_ref -> ns_ref .)
+    FLOAT           reduce using rule 173 (var_ref -> ns_ref .)
+    NULL            reduce using rule 173 (var_ref -> ns_ref .)
+    REGEX           reduce using rule 173 (var_ref -> ns_ref .)
+    TRUE            reduce using rule 173 (var_ref -> ns_ref .)
+    FALSE           reduce using rule 173 (var_ref -> ns_ref .)
+    STRING          reduce using rule 173 (var_ref -> ns_ref .)
+    FSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    RSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    MLS             reduce using rule 173 (var_ref -> ns_ref .)
+    {               reduce using rule 173 (var_ref -> ns_ref .)
+    $end            reduce using rule 173 (var_ref -> ns_ref .)
+    (               shift and go to state 90
 
-  ! (               [ reduce using rule 2 (empty -> .) ]
+  ! (               [ reduce using rule 173 (var_ref -> ns_ref .) ]
 
-    empty                          shift and go to state 95
 
-state 34
+state 33
 
-    (177) class_ref -> var_ref . . CID
+    (176) class_ref -> var_ref . . CID
     (23) assign -> var_ref . = operand
     (24) assign -> var_ref . PEQ operand
-    (100) expression -> var_ref . empty
-    (115) boolean_expression -> var_ref . . ID IS DEFINED
-    (120) map_lookup -> var_ref . [ operand ]
-    (173) attr_ref -> var_ref . . ID
-    (2) empty -> .
-
-    .               shift and go to state 97
-    =               shift and go to state 98
-    PEQ             shift and go to state 99
-    [               shift and go to state 101
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    (100) expression -> var_ref .
+    (114) boolean_expression -> var_ref . . ID IS DEFINED
+    (119) map_lookup -> var_ref . [ operand ]
+    (172) attr_ref -> var_ref . . ID
+
+    .               shift and go to state 91
+    =               shift and go to state 92
+    PEQ             shift and go to state 93
+    CMP_OP          reduce using rule 100 (expression -> var_ref .)
+    IN              reduce using rule 100 (expression -> var_ref .)
+    AND             reduce using rule 100 (expression -> var_ref .)
+    OR              reduce using rule 100 (expression -> var_ref .)
+    ?               reduce using rule 100 (expression -> var_ref .)
+    ENTITY          reduce using rule 100 (expression -> var_ref .)
+    IMPLEMENT       reduce using rule 100 (expression -> var_ref .)
+    IMPLEMENTATION  reduce using rule 100 (expression -> var_ref .)
+    INDEX           reduce using rule 100 (expression -> var_ref .)
+    IMPORT          reduce using rule 100 (expression -> var_ref .)
+    CID             reduce using rule 100 (expression -> var_ref .)
+    FOR             reduce using rule 100 (expression -> var_ref .)
+    IF              reduce using rule 100 (expression -> var_ref .)
+    (               reduce using rule 100 (expression -> var_ref .)
+    TYPEDEF         reduce using rule 100 (expression -> var_ref .)
+    ID              reduce using rule 100 (expression -> var_ref .)
+    NOT             reduce using rule 100 (expression -> var_ref .)
+    INT             reduce using rule 100 (expression -> var_ref .)
+    FLOAT           reduce using rule 100 (expression -> var_ref .)
+    NULL            reduce using rule 100 (expression -> var_ref .)
+    REGEX           reduce using rule 100 (expression -> var_ref .)
+    TRUE            reduce using rule 100 (expression -> var_ref .)
+    FALSE           reduce using rule 100 (expression -> var_ref .)
+    STRING          reduce using rule 100 (expression -> var_ref .)
+    FSTRING         reduce using rule 100 (expression -> var_ref .)
+    RSTRING         reduce using rule 100 (expression -> var_ref .)
+    MLS             reduce using rule 100 (expression -> var_ref .)
+    {               reduce using rule 100 (expression -> var_ref .)
+    $end            reduce using rule 100 (expression -> var_ref .)
+    [               shift and go to state 94
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 100 (expression -> var_ref .) ]
 
-    empty                          shift and go to state 100
 
-state 35
+state 34
 
     (26) if -> IF . if_body END
     (27) if_body -> . expression : stmt_list if_next
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    if_body                        shift and go to state 102
-    expression                     shift and go to state 103
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    if_body                        shift and go to state 95
+    expression                     shift and go to state 96
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 36
+state 35
 
     (97) expression -> boolean_expression .
 
     CMP_OP          reduce using rule 97 (expression -> boolean_expression .)
     IN              reduce using rule 97 (expression -> boolean_expression .)
     AND             reduce using rule 97 (expression -> boolean_expression .)
     OR              reduce using rule 97 (expression -> boolean_expression .)
-    NOT             reduce using rule 97 (expression -> boolean_expression .)
     ?               reduce using rule 97 (expression -> boolean_expression .)
     ENTITY          reduce using rule 97 (expression -> boolean_expression .)
     IMPLEMENT       reduce using rule 97 (expression -> boolean_expression .)
     IMPLEMENTATION  reduce using rule 97 (expression -> boolean_expression .)
     INDEX           reduce using rule 97 (expression -> boolean_expression .)
     IMPORT          reduce using rule 97 (expression -> boolean_expression .)
     CID             reduce using rule 97 (expression -> boolean_expression .)
     FOR             reduce using rule 97 (expression -> boolean_expression .)
     IF              reduce using rule 97 (expression -> boolean_expression .)
     (               reduce using rule 97 (expression -> boolean_expression .)
     TYPEDEF         reduce using rule 97 (expression -> boolean_expression .)
     ID              reduce using rule 97 (expression -> boolean_expression .)
+    NOT             reduce using rule 97 (expression -> boolean_expression .)
     INT             reduce using rule 97 (expression -> boolean_expression .)
     FLOAT           reduce using rule 97 (expression -> boolean_expression .)
     NULL            reduce using rule 97 (expression -> boolean_expression .)
     REGEX           reduce using rule 97 (expression -> boolean_expression .)
     TRUE            reduce using rule 97 (expression -> boolean_expression .)
     FALSE           reduce using rule 97 (expression -> boolean_expression .)
     STRING          reduce using rule 97 (expression -> boolean_expression .)
@@ -1755,35 +1704,35 @@
     ]               reduce using rule 97 (expression -> boolean_expression .)
     ELSE            reduce using rule 97 (expression -> boolean_expression .)
     ELIF            reduce using rule 97 (expression -> boolean_expression .)
     END             reduce using rule 97 (expression -> boolean_expression .)
     }               reduce using rule 97 (expression -> boolean_expression .)
 
 
-state 37
+state 36
 
     (98) expression -> constant .
 
     CMP_OP          reduce using rule 98 (expression -> constant .)
     IN              reduce using rule 98 (expression -> constant .)
     AND             reduce using rule 98 (expression -> constant .)
     OR              reduce using rule 98 (expression -> constant .)
-    NOT             reduce using rule 98 (expression -> constant .)
     ?               reduce using rule 98 (expression -> constant .)
     ENTITY          reduce using rule 98 (expression -> constant .)
     IMPLEMENT       reduce using rule 98 (expression -> constant .)
     IMPLEMENTATION  reduce using rule 98 (expression -> constant .)
     INDEX           reduce using rule 98 (expression -> constant .)
     IMPORT          reduce using rule 98 (expression -> constant .)
     CID             reduce using rule 98 (expression -> constant .)
     FOR             reduce using rule 98 (expression -> constant .)
     IF              reduce using rule 98 (expression -> constant .)
     (               reduce using rule 98 (expression -> constant .)
     TYPEDEF         reduce using rule 98 (expression -> constant .)
     ID              reduce using rule 98 (expression -> constant .)
+    NOT             reduce using rule 98 (expression -> constant .)
     INT             reduce using rule 98 (expression -> constant .)
     FLOAT           reduce using rule 98 (expression -> constant .)
     NULL            reduce using rule 98 (expression -> constant .)
     REGEX           reduce using rule 98 (expression -> constant .)
     TRUE            reduce using rule 98 (expression -> constant .)
     FALSE           reduce using rule 98 (expression -> constant .)
     STRING          reduce using rule 98 (expression -> constant .)
@@ -1799,35 +1748,35 @@
     ]               reduce using rule 98 (expression -> constant .)
     ELSE            reduce using rule 98 (expression -> constant .)
     ELIF            reduce using rule 98 (expression -> constant .)
     END             reduce using rule 98 (expression -> constant .)
     }               reduce using rule 98 (expression -> constant .)
 
 
-state 38
+state 37
 
     (99) expression -> function_call .
 
     CMP_OP          reduce using rule 99 (expression -> function_call .)
     IN              reduce using rule 99 (expression -> function_call .)
     AND             reduce using rule 99 (expression -> function_call .)
     OR              reduce using rule 99 (expression -> function_call .)
-    NOT             reduce using rule 99 (expression -> function_call .)
     ?               reduce using rule 99 (expression -> function_call .)
     ENTITY          reduce using rule 99 (expression -> function_call .)
     IMPLEMENT       reduce using rule 99 (expression -> function_call .)
     IMPLEMENTATION  reduce using rule 99 (expression -> function_call .)
     INDEX           reduce using rule 99 (expression -> function_call .)
     IMPORT          reduce using rule 99 (expression -> function_call .)
     CID             reduce using rule 99 (expression -> function_call .)
     FOR             reduce using rule 99 (expression -> function_call .)
     IF              reduce using rule 99 (expression -> function_call .)
     (               reduce using rule 99 (expression -> function_call .)
     TYPEDEF         reduce using rule 99 (expression -> function_call .)
     ID              reduce using rule 99 (expression -> function_call .)
+    NOT             reduce using rule 99 (expression -> function_call .)
     INT             reduce using rule 99 (expression -> function_call .)
     FLOAT           reduce using rule 99 (expression -> function_call .)
     NULL            reduce using rule 99 (expression -> function_call .)
     REGEX           reduce using rule 99 (expression -> function_call .)
     TRUE            reduce using rule 99 (expression -> function_call .)
     FALSE           reduce using rule 99 (expression -> function_call .)
     STRING          reduce using rule 99 (expression -> function_call .)
@@ -1843,35 +1792,35 @@
     ]               reduce using rule 99 (expression -> function_call .)
     ELSE            reduce using rule 99 (expression -> function_call .)
     ELIF            reduce using rule 99 (expression -> function_call .)
     END             reduce using rule 99 (expression -> function_call .)
     }               reduce using rule 99 (expression -> function_call .)
 
 
-state 39
+state 38
 
     (101) expression -> constructor .
 
     CMP_OP          reduce using rule 101 (expression -> constructor .)
     IN              reduce using rule 101 (expression -> constructor .)
     AND             reduce using rule 101 (expression -> constructor .)
     OR              reduce using rule 101 (expression -> constructor .)
-    NOT             reduce using rule 101 (expression -> constructor .)
     ?               reduce using rule 101 (expression -> constructor .)
     ENTITY          reduce using rule 101 (expression -> constructor .)
     IMPLEMENT       reduce using rule 101 (expression -> constructor .)
     IMPLEMENTATION  reduce using rule 101 (expression -> constructor .)
     INDEX           reduce using rule 101 (expression -> constructor .)
     IMPORT          reduce using rule 101 (expression -> constructor .)
     CID             reduce using rule 101 (expression -> constructor .)
     FOR             reduce using rule 101 (expression -> constructor .)
     IF              reduce using rule 101 (expression -> constructor .)
     (               reduce using rule 101 (expression -> constructor .)
     TYPEDEF         reduce using rule 101 (expression -> constructor .)
     ID              reduce using rule 101 (expression -> constructor .)
+    NOT             reduce using rule 101 (expression -> constructor .)
     INT             reduce using rule 101 (expression -> constructor .)
     FLOAT           reduce using rule 101 (expression -> constructor .)
     NULL            reduce using rule 101 (expression -> constructor .)
     REGEX           reduce using rule 101 (expression -> constructor .)
     TRUE            reduce using rule 101 (expression -> constructor .)
     FALSE           reduce using rule 101 (expression -> constructor .)
     STRING          reduce using rule 101 (expression -> constructor .)
@@ -1887,35 +1836,35 @@
     ]               reduce using rule 101 (expression -> constructor .)
     ELSE            reduce using rule 101 (expression -> constructor .)
     ELIF            reduce using rule 101 (expression -> constructor .)
     END             reduce using rule 101 (expression -> constructor .)
     }               reduce using rule 101 (expression -> constructor .)
 
 
-state 40
+state 39
 
     (102) expression -> list_def .
 
     CMP_OP          reduce using rule 102 (expression -> list_def .)
     IN              reduce using rule 102 (expression -> list_def .)
     AND             reduce using rule 102 (expression -> list_def .)
     OR              reduce using rule 102 (expression -> list_def .)
-    NOT             reduce using rule 102 (expression -> list_def .)
     ?               reduce using rule 102 (expression -> list_def .)
     ENTITY          reduce using rule 102 (expression -> list_def .)
     IMPLEMENT       reduce using rule 102 (expression -> list_def .)
     IMPLEMENTATION  reduce using rule 102 (expression -> list_def .)
     INDEX           reduce using rule 102 (expression -> list_def .)
     IMPORT          reduce using rule 102 (expression -> list_def .)
     CID             reduce using rule 102 (expression -> list_def .)
     FOR             reduce using rule 102 (expression -> list_def .)
     IF              reduce using rule 102 (expression -> list_def .)
     (               reduce using rule 102 (expression -> list_def .)
     TYPEDEF         reduce using rule 102 (expression -> list_def .)
     ID              reduce using rule 102 (expression -> list_def .)
+    NOT             reduce using rule 102 (expression -> list_def .)
     INT             reduce using rule 102 (expression -> list_def .)
     FLOAT           reduce using rule 102 (expression -> list_def .)
     NULL            reduce using rule 102 (expression -> list_def .)
     REGEX           reduce using rule 102 (expression -> list_def .)
     TRUE            reduce using rule 102 (expression -> list_def .)
     FALSE           reduce using rule 102 (expression -> list_def .)
     STRING          reduce using rule 102 (expression -> list_def .)
@@ -1931,35 +1880,35 @@
     ]               reduce using rule 102 (expression -> list_def .)
     ELSE            reduce using rule 102 (expression -> list_def .)
     ELIF            reduce using rule 102 (expression -> list_def .)
     END             reduce using rule 102 (expression -> list_def .)
     }               reduce using rule 102 (expression -> list_def .)
 
 
-state 41
+state 40
 
     (103) expression -> list_comprehension .
 
     CMP_OP          reduce using rule 103 (expression -> list_comprehension .)
     IN              reduce using rule 103 (expression -> list_comprehension .)
     AND             reduce using rule 103 (expression -> list_comprehension .)
     OR              reduce using rule 103 (expression -> list_comprehension .)
-    NOT             reduce using rule 103 (expression -> list_comprehension .)
     ?               reduce using rule 103 (expression -> list_comprehension .)
     ENTITY          reduce using rule 103 (expression -> list_comprehension .)
     IMPLEMENT       reduce using rule 103 (expression -> list_comprehension .)
     IMPLEMENTATION  reduce using rule 103 (expression -> list_comprehension .)
     INDEX           reduce using rule 103 (expression -> list_comprehension .)
     IMPORT          reduce using rule 103 (expression -> list_comprehension .)
     CID             reduce using rule 103 (expression -> list_comprehension .)
     FOR             reduce using rule 103 (expression -> list_comprehension .)
     IF              reduce using rule 103 (expression -> list_comprehension .)
     (               reduce using rule 103 (expression -> list_comprehension .)
     TYPEDEF         reduce using rule 103 (expression -> list_comprehension .)
     ID              reduce using rule 103 (expression -> list_comprehension .)
+    NOT             reduce using rule 103 (expression -> list_comprehension .)
     INT             reduce using rule 103 (expression -> list_comprehension .)
     FLOAT           reduce using rule 103 (expression -> list_comprehension .)
     NULL            reduce using rule 103 (expression -> list_comprehension .)
     REGEX           reduce using rule 103 (expression -> list_comprehension .)
     TRUE            reduce using rule 103 (expression -> list_comprehension .)
     FALSE           reduce using rule 103 (expression -> list_comprehension .)
     STRING          reduce using rule 103 (expression -> list_comprehension .)
@@ -1975,35 +1924,35 @@
     ]               reduce using rule 103 (expression -> list_comprehension .)
     ELSE            reduce using rule 103 (expression -> list_comprehension .)
     ELIF            reduce using rule 103 (expression -> list_comprehension .)
     END             reduce using rule 103 (expression -> list_comprehension .)
     }               reduce using rule 103 (expression -> list_comprehension .)
 
 
-state 42
+state 41
 
     (104) expression -> map_def .
 
     CMP_OP          reduce using rule 104 (expression -> map_def .)
     IN              reduce using rule 104 (expression -> map_def .)
     AND             reduce using rule 104 (expression -> map_def .)
     OR              reduce using rule 104 (expression -> map_def .)
-    NOT             reduce using rule 104 (expression -> map_def .)
     ?               reduce using rule 104 (expression -> map_def .)
     ENTITY          reduce using rule 104 (expression -> map_def .)
     IMPLEMENT       reduce using rule 104 (expression -> map_def .)
     IMPLEMENTATION  reduce using rule 104 (expression -> map_def .)
     INDEX           reduce using rule 104 (expression -> map_def .)
     IMPORT          reduce using rule 104 (expression -> map_def .)
     CID             reduce using rule 104 (expression -> map_def .)
     FOR             reduce using rule 104 (expression -> map_def .)
     IF              reduce using rule 104 (expression -> map_def .)
     (               reduce using rule 104 (expression -> map_def .)
     TYPEDEF         reduce using rule 104 (expression -> map_def .)
     ID              reduce using rule 104 (expression -> map_def .)
+    NOT             reduce using rule 104 (expression -> map_def .)
     INT             reduce using rule 104 (expression -> map_def .)
     FLOAT           reduce using rule 104 (expression -> map_def .)
     NULL            reduce using rule 104 (expression -> map_def .)
     REGEX           reduce using rule 104 (expression -> map_def .)
     TRUE            reduce using rule 104 (expression -> map_def .)
     FALSE           reduce using rule 104 (expression -> map_def .)
     STRING          reduce using rule 104 (expression -> map_def .)
@@ -2019,86 +1968,84 @@
     ]               reduce using rule 104 (expression -> map_def .)
     ELSE            reduce using rule 104 (expression -> map_def .)
     ELIF            reduce using rule 104 (expression -> map_def .)
     END             reduce using rule 104 (expression -> map_def .)
     }               reduce using rule 104 (expression -> map_def .)
 
 
-state 43
+state 42
 
-    (105) expression -> map_lookup . empty
-    (117) boolean_expression -> map_lookup . IS DEFINED
-    (121) map_lookup -> map_lookup . [ operand ]
-    (2) empty -> .
-
-    IS              shift and go to state 105
-    [               shift and go to state 106
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    )               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
-    ,               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    }               reduce using rule 2 (empty -> .)
+    (105) expression -> map_lookup .
+    (116) boolean_expression -> map_lookup . IS DEFINED
+    (120) map_lookup -> map_lookup . [ operand ]
+
+    CMP_OP          reduce using rule 105 (expression -> map_lookup .)
+    IN              reduce using rule 105 (expression -> map_lookup .)
+    AND             reduce using rule 105 (expression -> map_lookup .)
+    OR              reduce using rule 105 (expression -> map_lookup .)
+    ?               reduce using rule 105 (expression -> map_lookup .)
+    ENTITY          reduce using rule 105 (expression -> map_lookup .)
+    IMPLEMENT       reduce using rule 105 (expression -> map_lookup .)
+    IMPLEMENTATION  reduce using rule 105 (expression -> map_lookup .)
+    INDEX           reduce using rule 105 (expression -> map_lookup .)
+    IMPORT          reduce using rule 105 (expression -> map_lookup .)
+    CID             reduce using rule 105 (expression -> map_lookup .)
+    FOR             reduce using rule 105 (expression -> map_lookup .)
+    IF              reduce using rule 105 (expression -> map_lookup .)
+    (               reduce using rule 105 (expression -> map_lookup .)
+    TYPEDEF         reduce using rule 105 (expression -> map_lookup .)
+    ID              reduce using rule 105 (expression -> map_lookup .)
+    NOT             reduce using rule 105 (expression -> map_lookup .)
+    INT             reduce using rule 105 (expression -> map_lookup .)
+    FLOAT           reduce using rule 105 (expression -> map_lookup .)
+    NULL            reduce using rule 105 (expression -> map_lookup .)
+    REGEX           reduce using rule 105 (expression -> map_lookup .)
+    TRUE            reduce using rule 105 (expression -> map_lookup .)
+    FALSE           reduce using rule 105 (expression -> map_lookup .)
+    STRING          reduce using rule 105 (expression -> map_lookup .)
+    FSTRING         reduce using rule 105 (expression -> map_lookup .)
+    RSTRING         reduce using rule 105 (expression -> map_lookup .)
+    MLS             reduce using rule 105 (expression -> map_lookup .)
+    {               reduce using rule 105 (expression -> map_lookup .)
+    $end            reduce using rule 105 (expression -> map_lookup .)
+    )               reduce using rule 105 (expression -> map_lookup .)
+    :               reduce using rule 105 (expression -> map_lookup .)
+    ,               reduce using rule 105 (expression -> map_lookup .)
+    ]               reduce using rule 105 (expression -> map_lookup .)
+    ELSE            reduce using rule 105 (expression -> map_lookup .)
+    ELIF            reduce using rule 105 (expression -> map_lookup .)
+    END             reduce using rule 105 (expression -> map_lookup .)
+    }               reduce using rule 105 (expression -> map_lookup .)
+    IS              shift and go to state 97
+    [               shift and go to state 98
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 105 (expression -> map_lookup .) ]
 
-    empty                          shift and go to state 104
 
-state 44
+state 43
 
     (106) expression -> index_lookup .
 
     CMP_OP          reduce using rule 106 (expression -> index_lookup .)
     IN              reduce using rule 106 (expression -> index_lookup .)
     AND             reduce using rule 106 (expression -> index_lookup .)
     OR              reduce using rule 106 (expression -> index_lookup .)
-    NOT             reduce using rule 106 (expression -> index_lookup .)
     ?               reduce using rule 106 (expression -> index_lookup .)
     ENTITY          reduce using rule 106 (expression -> index_lookup .)
     IMPLEMENT       reduce using rule 106 (expression -> index_lookup .)
     IMPLEMENTATION  reduce using rule 106 (expression -> index_lookup .)
     INDEX           reduce using rule 106 (expression -> index_lookup .)
     IMPORT          reduce using rule 106 (expression -> index_lookup .)
     CID             reduce using rule 106 (expression -> index_lookup .)
     FOR             reduce using rule 106 (expression -> index_lookup .)
     IF              reduce using rule 106 (expression -> index_lookup .)
     (               reduce using rule 106 (expression -> index_lookup .)
     TYPEDEF         reduce using rule 106 (expression -> index_lookup .)
     ID              reduce using rule 106 (expression -> index_lookup .)
+    NOT             reduce using rule 106 (expression -> index_lookup .)
     INT             reduce using rule 106 (expression -> index_lookup .)
     FLOAT           reduce using rule 106 (expression -> index_lookup .)
     NULL            reduce using rule 106 (expression -> index_lookup .)
     REGEX           reduce using rule 106 (expression -> index_lookup .)
     TRUE            reduce using rule 106 (expression -> index_lookup .)
     FALSE           reduce using rule 106 (expression -> index_lookup .)
     STRING          reduce using rule 106 (expression -> index_lookup .)
@@ -2114,35 +2061,35 @@
     ]               reduce using rule 106 (expression -> index_lookup .)
     ELSE            reduce using rule 106 (expression -> index_lookup .)
     ELIF            reduce using rule 106 (expression -> index_lookup .)
     END             reduce using rule 106 (expression -> index_lookup .)
     }               reduce using rule 106 (expression -> index_lookup .)
 
 
-state 45
+state 44
 
     (107) expression -> conditional_expression .
 
     CMP_OP          reduce using rule 107 (expression -> conditional_expression .)
     IN              reduce using rule 107 (expression -> conditional_expression .)
     AND             reduce using rule 107 (expression -> conditional_expression .)
     OR              reduce using rule 107 (expression -> conditional_expression .)
-    NOT             reduce using rule 107 (expression -> conditional_expression .)
     ?               reduce using rule 107 (expression -> conditional_expression .)
     ENTITY          reduce using rule 107 (expression -> conditional_expression .)
     IMPLEMENT       reduce using rule 107 (expression -> conditional_expression .)
     IMPLEMENTATION  reduce using rule 107 (expression -> conditional_expression .)
     INDEX           reduce using rule 107 (expression -> conditional_expression .)
     IMPORT          reduce using rule 107 (expression -> conditional_expression .)
     CID             reduce using rule 107 (expression -> conditional_expression .)
     FOR             reduce using rule 107 (expression -> conditional_expression .)
     IF              reduce using rule 107 (expression -> conditional_expression .)
     (               reduce using rule 107 (expression -> conditional_expression .)
     TYPEDEF         reduce using rule 107 (expression -> conditional_expression .)
     ID              reduce using rule 107 (expression -> conditional_expression .)
+    NOT             reduce using rule 107 (expression -> conditional_expression .)
     INT             reduce using rule 107 (expression -> conditional_expression .)
     FLOAT           reduce using rule 107 (expression -> conditional_expression .)
     NULL            reduce using rule 107 (expression -> conditional_expression .)
     REGEX           reduce using rule 107 (expression -> conditional_expression .)
     TRUE            reduce using rule 107 (expression -> conditional_expression .)
     FALSE           reduce using rule 107 (expression -> conditional_expression .)
     STRING          reduce using rule 107 (expression -> conditional_expression .)
@@ -2158,1359 +2105,1303 @@
     ]               reduce using rule 107 (expression -> conditional_expression .)
     ELSE            reduce using rule 107 (expression -> conditional_expression .)
     ELIF            reduce using rule 107 (expression -> conditional_expression .)
     END             reduce using rule 107 (expression -> conditional_expression .)
     }               reduce using rule 107 (expression -> conditional_expression .)
 
 
-state 46
+state 45
 
     (94) typedef_inner -> TYPEDEF . ID AS ns_ref MATCHING expression
     (95) typedef_inner -> TYPEDEF . CID AS constructor
 
-    ID              shift and go to state 107
-    CID             shift and go to state 108
+    ID              shift and go to state 99
+    CID             shift and go to state 100
 
 
-state 47
+state 46
 
-    (172) var_ref -> attr_ref . empty
-    (124) function_call -> attr_ref . ( function_param_list )
-    (119) map_lookup -> attr_ref . [ operand ]
-    (140) index_lookup -> attr_ref . [ param_list ]
-    (2) empty -> .
-
-    (               shift and go to state 110
-    [               shift and go to state 111
-    .               reduce using rule 2 (empty -> .)
-    =               reduce using rule 2 (empty -> .)
-    PEQ             reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
+    (171) var_ref -> attr_ref .
+    (123) function_call -> attr_ref . ( function_param_list )
+    (118) map_lookup -> attr_ref . [ operand ]
+    (139) index_lookup -> attr_ref . [ param_list ]
+
+    .               reduce using rule 171 (var_ref -> attr_ref .)
+    =               reduce using rule 171 (var_ref -> attr_ref .)
+    PEQ             reduce using rule 171 (var_ref -> attr_ref .)
+    CMP_OP          reduce using rule 171 (var_ref -> attr_ref .)
+    IN              reduce using rule 171 (var_ref -> attr_ref .)
+    AND             reduce using rule 171 (var_ref -> attr_ref .)
+    OR              reduce using rule 171 (var_ref -> attr_ref .)
+    ?               reduce using rule 171 (var_ref -> attr_ref .)
+    ENTITY          reduce using rule 171 (var_ref -> attr_ref .)
+    IMPLEMENT       reduce using rule 171 (var_ref -> attr_ref .)
+    IMPLEMENTATION  reduce using rule 171 (var_ref -> attr_ref .)
+    INDEX           reduce using rule 171 (var_ref -> attr_ref .)
+    IMPORT          reduce using rule 171 (var_ref -> attr_ref .)
+    CID             reduce using rule 171 (var_ref -> attr_ref .)
+    FOR             reduce using rule 171 (var_ref -> attr_ref .)
+    IF              reduce using rule 171 (var_ref -> attr_ref .)
+    TYPEDEF         reduce using rule 171 (var_ref -> attr_ref .)
+    ID              reduce using rule 171 (var_ref -> attr_ref .)
+    NOT             reduce using rule 171 (var_ref -> attr_ref .)
+    INT             reduce using rule 171 (var_ref -> attr_ref .)
+    FLOAT           reduce using rule 171 (var_ref -> attr_ref .)
+    NULL            reduce using rule 171 (var_ref -> attr_ref .)
+    REGEX           reduce using rule 171 (var_ref -> attr_ref .)
+    TRUE            reduce using rule 171 (var_ref -> attr_ref .)
+    FALSE           reduce using rule 171 (var_ref -> attr_ref .)
+    STRING          reduce using rule 171 (var_ref -> attr_ref .)
+    FSTRING         reduce using rule 171 (var_ref -> attr_ref .)
+    RSTRING         reduce using rule 171 (var_ref -> attr_ref .)
+    MLS             reduce using rule 171 (var_ref -> attr_ref .)
+    {               reduce using rule 171 (var_ref -> attr_ref .)
+    $end            reduce using rule 171 (var_ref -> attr_ref .)
+    ELSE            reduce using rule 171 (var_ref -> attr_ref .)
+    ELIF            reduce using rule 171 (var_ref -> attr_ref .)
+    END             reduce using rule 171 (var_ref -> attr_ref .)
+    (               shift and go to state 101
+    [               shift and go to state 102
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
-  ! (               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 171 (var_ref -> attr_ref .) ]
+  ! (               [ reduce using rule 171 (var_ref -> attr_ref .) ]
 
-    empty                          shift and go to state 109
 
-state 48
+state 47
 
-    (114) boolean_expression -> NOT . expression
+    (113) boolean_expression -> NOT . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 112
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 103
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
+
+state 48
+
+    (141) constant -> INT .
+
+    CMP_OP          reduce using rule 141 (constant -> INT .)
+    IN              reduce using rule 141 (constant -> INT .)
+    AND             reduce using rule 141 (constant -> INT .)
+    OR              reduce using rule 141 (constant -> INT .)
+    ?               reduce using rule 141 (constant -> INT .)
+    ENTITY          reduce using rule 141 (constant -> INT .)
+    IMPLEMENT       reduce using rule 141 (constant -> INT .)
+    IMPLEMENTATION  reduce using rule 141 (constant -> INT .)
+    INDEX           reduce using rule 141 (constant -> INT .)
+    IMPORT          reduce using rule 141 (constant -> INT .)
+    CID             reduce using rule 141 (constant -> INT .)
+    FOR             reduce using rule 141 (constant -> INT .)
+    IF              reduce using rule 141 (constant -> INT .)
+    (               reduce using rule 141 (constant -> INT .)
+    TYPEDEF         reduce using rule 141 (constant -> INT .)
+    ID              reduce using rule 141 (constant -> INT .)
+    NOT             reduce using rule 141 (constant -> INT .)
+    INT             reduce using rule 141 (constant -> INT .)
+    FLOAT           reduce using rule 141 (constant -> INT .)
+    NULL            reduce using rule 141 (constant -> INT .)
+    REGEX           reduce using rule 141 (constant -> INT .)
+    TRUE            reduce using rule 141 (constant -> INT .)
+    FALSE           reduce using rule 141 (constant -> INT .)
+    STRING          reduce using rule 141 (constant -> INT .)
+    FSTRING         reduce using rule 141 (constant -> INT .)
+    RSTRING         reduce using rule 141 (constant -> INT .)
+    MLS             reduce using rule 141 (constant -> INT .)
+    [               reduce using rule 141 (constant -> INT .)
+    {               reduce using rule 141 (constant -> INT .)
+    $end            reduce using rule 141 (constant -> INT .)
+    )               reduce using rule 141 (constant -> INT .)
+    :               reduce using rule 141 (constant -> INT .)
+    ,               reduce using rule 141 (constant -> INT .)
+    ]               reduce using rule 141 (constant -> INT .)
+    ELSE            reduce using rule 141 (constant -> INT .)
+    ELIF            reduce using rule 141 (constant -> INT .)
+    END             reduce using rule 141 (constant -> INT .)
+    }               reduce using rule 141 (constant -> INT .)
+    DICT            reduce using rule 141 (constant -> INT .)
+
 
 state 49
 
-    (142) constant -> INT .
+    (142) constant -> FLOAT .
 
-    CMP_OP          reduce using rule 142 (constant -> INT .)
-    IN              reduce using rule 142 (constant -> INT .)
-    AND             reduce using rule 142 (constant -> INT .)
-    OR              reduce using rule 142 (constant -> INT .)
-    NOT             reduce using rule 142 (constant -> INT .)
-    ?               reduce using rule 142 (constant -> INT .)
-    ENTITY          reduce using rule 142 (constant -> INT .)
-    IMPLEMENT       reduce using rule 142 (constant -> INT .)
-    IMPLEMENTATION  reduce using rule 142 (constant -> INT .)
-    INDEX           reduce using rule 142 (constant -> INT .)
-    IMPORT          reduce using rule 142 (constant -> INT .)
-    CID             reduce using rule 142 (constant -> INT .)
-    FOR             reduce using rule 142 (constant -> INT .)
-    IF              reduce using rule 142 (constant -> INT .)
-    (               reduce using rule 142 (constant -> INT .)
-    TYPEDEF         reduce using rule 142 (constant -> INT .)
-    ID              reduce using rule 142 (constant -> INT .)
-    INT             reduce using rule 142 (constant -> INT .)
-    FLOAT           reduce using rule 142 (constant -> INT .)
-    NULL            reduce using rule 142 (constant -> INT .)
-    REGEX           reduce using rule 142 (constant -> INT .)
-    TRUE            reduce using rule 142 (constant -> INT .)
-    FALSE           reduce using rule 142 (constant -> INT .)
-    STRING          reduce using rule 142 (constant -> INT .)
-    FSTRING         reduce using rule 142 (constant -> INT .)
-    RSTRING         reduce using rule 142 (constant -> INT .)
-    MLS             reduce using rule 142 (constant -> INT .)
-    [               reduce using rule 142 (constant -> INT .)
-    {               reduce using rule 142 (constant -> INT .)
-    $end            reduce using rule 142 (constant -> INT .)
-    )               reduce using rule 142 (constant -> INT .)
-    :               reduce using rule 142 (constant -> INT .)
-    ,               reduce using rule 142 (constant -> INT .)
-    ]               reduce using rule 142 (constant -> INT .)
-    ELSE            reduce using rule 142 (constant -> INT .)
-    ELIF            reduce using rule 142 (constant -> INT .)
-    END             reduce using rule 142 (constant -> INT .)
-    }               reduce using rule 142 (constant -> INT .)
-    DICT            reduce using rule 142 (constant -> INT .)
+    CMP_OP          reduce using rule 142 (constant -> FLOAT .)
+    IN              reduce using rule 142 (constant -> FLOAT .)
+    AND             reduce using rule 142 (constant -> FLOAT .)
+    OR              reduce using rule 142 (constant -> FLOAT .)
+    ?               reduce using rule 142 (constant -> FLOAT .)
+    ENTITY          reduce using rule 142 (constant -> FLOAT .)
+    IMPLEMENT       reduce using rule 142 (constant -> FLOAT .)
+    IMPLEMENTATION  reduce using rule 142 (constant -> FLOAT .)
+    INDEX           reduce using rule 142 (constant -> FLOAT .)
+    IMPORT          reduce using rule 142 (constant -> FLOAT .)
+    CID             reduce using rule 142 (constant -> FLOAT .)
+    FOR             reduce using rule 142 (constant -> FLOAT .)
+    IF              reduce using rule 142 (constant -> FLOAT .)
+    (               reduce using rule 142 (constant -> FLOAT .)
+    TYPEDEF         reduce using rule 142 (constant -> FLOAT .)
+    ID              reduce using rule 142 (constant -> FLOAT .)
+    NOT             reduce using rule 142 (constant -> FLOAT .)
+    INT             reduce using rule 142 (constant -> FLOAT .)
+    FLOAT           reduce using rule 142 (constant -> FLOAT .)
+    NULL            reduce using rule 142 (constant -> FLOAT .)
+    REGEX           reduce using rule 142 (constant -> FLOAT .)
+    TRUE            reduce using rule 142 (constant -> FLOAT .)
+    FALSE           reduce using rule 142 (constant -> FLOAT .)
+    STRING          reduce using rule 142 (constant -> FLOAT .)
+    FSTRING         reduce using rule 142 (constant -> FLOAT .)
+    RSTRING         reduce using rule 142 (constant -> FLOAT .)
+    MLS             reduce using rule 142 (constant -> FLOAT .)
+    [               reduce using rule 142 (constant -> FLOAT .)
+    {               reduce using rule 142 (constant -> FLOAT .)
+    $end            reduce using rule 142 (constant -> FLOAT .)
+    )               reduce using rule 142 (constant -> FLOAT .)
+    :               reduce using rule 142 (constant -> FLOAT .)
+    ,               reduce using rule 142 (constant -> FLOAT .)
+    ]               reduce using rule 142 (constant -> FLOAT .)
+    ELSE            reduce using rule 142 (constant -> FLOAT .)
+    ELIF            reduce using rule 142 (constant -> FLOAT .)
+    END             reduce using rule 142 (constant -> FLOAT .)
+    }               reduce using rule 142 (constant -> FLOAT .)
+    DICT            reduce using rule 142 (constant -> FLOAT .)
 
 
 state 50
 
-    (143) constant -> FLOAT .
+    (143) constant -> NULL .
 
-    CMP_OP          reduce using rule 143 (constant -> FLOAT .)
-    IN              reduce using rule 143 (constant -> FLOAT .)
-    AND             reduce using rule 143 (constant -> FLOAT .)
-    OR              reduce using rule 143 (constant -> FLOAT .)
-    NOT             reduce using rule 143 (constant -> FLOAT .)
-    ?               reduce using rule 143 (constant -> FLOAT .)
-    ENTITY          reduce using rule 143 (constant -> FLOAT .)
-    IMPLEMENT       reduce using rule 143 (constant -> FLOAT .)
-    IMPLEMENTATION  reduce using rule 143 (constant -> FLOAT .)
-    INDEX           reduce using rule 143 (constant -> FLOAT .)
-    IMPORT          reduce using rule 143 (constant -> FLOAT .)
-    CID             reduce using rule 143 (constant -> FLOAT .)
-    FOR             reduce using rule 143 (constant -> FLOAT .)
-    IF              reduce using rule 143 (constant -> FLOAT .)
-    (               reduce using rule 143 (constant -> FLOAT .)
-    TYPEDEF         reduce using rule 143 (constant -> FLOAT .)
-    ID              reduce using rule 143 (constant -> FLOAT .)
-    INT             reduce using rule 143 (constant -> FLOAT .)
-    FLOAT           reduce using rule 143 (constant -> FLOAT .)
-    NULL            reduce using rule 143 (constant -> FLOAT .)
-    REGEX           reduce using rule 143 (constant -> FLOAT .)
-    TRUE            reduce using rule 143 (constant -> FLOAT .)
-    FALSE           reduce using rule 143 (constant -> FLOAT .)
-    STRING          reduce using rule 143 (constant -> FLOAT .)
-    FSTRING         reduce using rule 143 (constant -> FLOAT .)
-    RSTRING         reduce using rule 143 (constant -> FLOAT .)
-    MLS             reduce using rule 143 (constant -> FLOAT .)
-    [               reduce using rule 143 (constant -> FLOAT .)
-    {               reduce using rule 143 (constant -> FLOAT .)
-    $end            reduce using rule 143 (constant -> FLOAT .)
-    )               reduce using rule 143 (constant -> FLOAT .)
-    :               reduce using rule 143 (constant -> FLOAT .)
-    ,               reduce using rule 143 (constant -> FLOAT .)
-    ]               reduce using rule 143 (constant -> FLOAT .)
-    ELSE            reduce using rule 143 (constant -> FLOAT .)
-    ELIF            reduce using rule 143 (constant -> FLOAT .)
-    END             reduce using rule 143 (constant -> FLOAT .)
-    }               reduce using rule 143 (constant -> FLOAT .)
-    DICT            reduce using rule 143 (constant -> FLOAT .)
+    CMP_OP          reduce using rule 143 (constant -> NULL .)
+    IN              reduce using rule 143 (constant -> NULL .)
+    AND             reduce using rule 143 (constant -> NULL .)
+    OR              reduce using rule 143 (constant -> NULL .)
+    ?               reduce using rule 143 (constant -> NULL .)
+    ENTITY          reduce using rule 143 (constant -> NULL .)
+    IMPLEMENT       reduce using rule 143 (constant -> NULL .)
+    IMPLEMENTATION  reduce using rule 143 (constant -> NULL .)
+    INDEX           reduce using rule 143 (constant -> NULL .)
+    IMPORT          reduce using rule 143 (constant -> NULL .)
+    CID             reduce using rule 143 (constant -> NULL .)
+    FOR             reduce using rule 143 (constant -> NULL .)
+    IF              reduce using rule 143 (constant -> NULL .)
+    (               reduce using rule 143 (constant -> NULL .)
+    TYPEDEF         reduce using rule 143 (constant -> NULL .)
+    ID              reduce using rule 143 (constant -> NULL .)
+    NOT             reduce using rule 143 (constant -> NULL .)
+    INT             reduce using rule 143 (constant -> NULL .)
+    FLOAT           reduce using rule 143 (constant -> NULL .)
+    NULL            reduce using rule 143 (constant -> NULL .)
+    REGEX           reduce using rule 143 (constant -> NULL .)
+    TRUE            reduce using rule 143 (constant -> NULL .)
+    FALSE           reduce using rule 143 (constant -> NULL .)
+    STRING          reduce using rule 143 (constant -> NULL .)
+    FSTRING         reduce using rule 143 (constant -> NULL .)
+    RSTRING         reduce using rule 143 (constant -> NULL .)
+    MLS             reduce using rule 143 (constant -> NULL .)
+    [               reduce using rule 143 (constant -> NULL .)
+    {               reduce using rule 143 (constant -> NULL .)
+    $end            reduce using rule 143 (constant -> NULL .)
+    )               reduce using rule 143 (constant -> NULL .)
+    :               reduce using rule 143 (constant -> NULL .)
+    ,               reduce using rule 143 (constant -> NULL .)
+    ]               reduce using rule 143 (constant -> NULL .)
+    ELSE            reduce using rule 143 (constant -> NULL .)
+    ELIF            reduce using rule 143 (constant -> NULL .)
+    END             reduce using rule 143 (constant -> NULL .)
+    }               reduce using rule 143 (constant -> NULL .)
+    DICT            reduce using rule 143 (constant -> NULL .)
 
 
 state 51
 
-    (144) constant -> NULL .
+    (144) constant -> REGEX .
 
-    CMP_OP          reduce using rule 144 (constant -> NULL .)
-    IN              reduce using rule 144 (constant -> NULL .)
-    AND             reduce using rule 144 (constant -> NULL .)
-    OR              reduce using rule 144 (constant -> NULL .)
-    NOT             reduce using rule 144 (constant -> NULL .)
-    ?               reduce using rule 144 (constant -> NULL .)
-    ENTITY          reduce using rule 144 (constant -> NULL .)
-    IMPLEMENT       reduce using rule 144 (constant -> NULL .)
-    IMPLEMENTATION  reduce using rule 144 (constant -> NULL .)
-    INDEX           reduce using rule 144 (constant -> NULL .)
-    IMPORT          reduce using rule 144 (constant -> NULL .)
-    CID             reduce using rule 144 (constant -> NULL .)
-    FOR             reduce using rule 144 (constant -> NULL .)
-    IF              reduce using rule 144 (constant -> NULL .)
-    (               reduce using rule 144 (constant -> NULL .)
-    TYPEDEF         reduce using rule 144 (constant -> NULL .)
-    ID              reduce using rule 144 (constant -> NULL .)
-    INT             reduce using rule 144 (constant -> NULL .)
-    FLOAT           reduce using rule 144 (constant -> NULL .)
-    NULL            reduce using rule 144 (constant -> NULL .)
-    REGEX           reduce using rule 144 (constant -> NULL .)
-    TRUE            reduce using rule 144 (constant -> NULL .)
-    FALSE           reduce using rule 144 (constant -> NULL .)
-    STRING          reduce using rule 144 (constant -> NULL .)
-    FSTRING         reduce using rule 144 (constant -> NULL .)
-    RSTRING         reduce using rule 144 (constant -> NULL .)
-    MLS             reduce using rule 144 (constant -> NULL .)
-    [               reduce using rule 144 (constant -> NULL .)
-    {               reduce using rule 144 (constant -> NULL .)
-    $end            reduce using rule 144 (constant -> NULL .)
-    )               reduce using rule 144 (constant -> NULL .)
-    :               reduce using rule 144 (constant -> NULL .)
-    ,               reduce using rule 144 (constant -> NULL .)
-    ]               reduce using rule 144 (constant -> NULL .)
-    ELSE            reduce using rule 144 (constant -> NULL .)
-    ELIF            reduce using rule 144 (constant -> NULL .)
-    END             reduce using rule 144 (constant -> NULL .)
-    }               reduce using rule 144 (constant -> NULL .)
-    DICT            reduce using rule 144 (constant -> NULL .)
+    CMP_OP          reduce using rule 144 (constant -> REGEX .)
+    IN              reduce using rule 144 (constant -> REGEX .)
+    AND             reduce using rule 144 (constant -> REGEX .)
+    OR              reduce using rule 144 (constant -> REGEX .)
+    ?               reduce using rule 144 (constant -> REGEX .)
+    ENTITY          reduce using rule 144 (constant -> REGEX .)
+    IMPLEMENT       reduce using rule 144 (constant -> REGEX .)
+    IMPLEMENTATION  reduce using rule 144 (constant -> REGEX .)
+    INDEX           reduce using rule 144 (constant -> REGEX .)
+    IMPORT          reduce using rule 144 (constant -> REGEX .)
+    CID             reduce using rule 144 (constant -> REGEX .)
+    FOR             reduce using rule 144 (constant -> REGEX .)
+    IF              reduce using rule 144 (constant -> REGEX .)
+    (               reduce using rule 144 (constant -> REGEX .)
+    TYPEDEF         reduce using rule 144 (constant -> REGEX .)
+    ID              reduce using rule 144 (constant -> REGEX .)
+    NOT             reduce using rule 144 (constant -> REGEX .)
+    INT             reduce using rule 144 (constant -> REGEX .)
+    FLOAT           reduce using rule 144 (constant -> REGEX .)
+    NULL            reduce using rule 144 (constant -> REGEX .)
+    REGEX           reduce using rule 144 (constant -> REGEX .)
+    TRUE            reduce using rule 144 (constant -> REGEX .)
+    FALSE           reduce using rule 144 (constant -> REGEX .)
+    STRING          reduce using rule 144 (constant -> REGEX .)
+    FSTRING         reduce using rule 144 (constant -> REGEX .)
+    RSTRING         reduce using rule 144 (constant -> REGEX .)
+    MLS             reduce using rule 144 (constant -> REGEX .)
+    [               reduce using rule 144 (constant -> REGEX .)
+    {               reduce using rule 144 (constant -> REGEX .)
+    $end            reduce using rule 144 (constant -> REGEX .)
+    )               reduce using rule 144 (constant -> REGEX .)
+    :               reduce using rule 144 (constant -> REGEX .)
+    ,               reduce using rule 144 (constant -> REGEX .)
+    ]               reduce using rule 144 (constant -> REGEX .)
+    ELSE            reduce using rule 144 (constant -> REGEX .)
+    ELIF            reduce using rule 144 (constant -> REGEX .)
+    END             reduce using rule 144 (constant -> REGEX .)
+    }               reduce using rule 144 (constant -> REGEX .)
+    DICT            reduce using rule 144 (constant -> REGEX .)
 
 
 state 52
 
-    (145) constant -> REGEX .
+    (145) constant -> TRUE .
 
-    CMP_OP          reduce using rule 145 (constant -> REGEX .)
-    IN              reduce using rule 145 (constant -> REGEX .)
-    AND             reduce using rule 145 (constant -> REGEX .)
-    OR              reduce using rule 145 (constant -> REGEX .)
-    NOT             reduce using rule 145 (constant -> REGEX .)
-    ?               reduce using rule 145 (constant -> REGEX .)
-    ENTITY          reduce using rule 145 (constant -> REGEX .)
-    IMPLEMENT       reduce using rule 145 (constant -> REGEX .)
-    IMPLEMENTATION  reduce using rule 145 (constant -> REGEX .)
-    INDEX           reduce using rule 145 (constant -> REGEX .)
-    IMPORT          reduce using rule 145 (constant -> REGEX .)
-    CID             reduce using rule 145 (constant -> REGEX .)
-    FOR             reduce using rule 145 (constant -> REGEX .)
-    IF              reduce using rule 145 (constant -> REGEX .)
-    (               reduce using rule 145 (constant -> REGEX .)
-    TYPEDEF         reduce using rule 145 (constant -> REGEX .)
-    ID              reduce using rule 145 (constant -> REGEX .)
-    INT             reduce using rule 145 (constant -> REGEX .)
-    FLOAT           reduce using rule 145 (constant -> REGEX .)
-    NULL            reduce using rule 145 (constant -> REGEX .)
-    REGEX           reduce using rule 145 (constant -> REGEX .)
-    TRUE            reduce using rule 145 (constant -> REGEX .)
-    FALSE           reduce using rule 145 (constant -> REGEX .)
-    STRING          reduce using rule 145 (constant -> REGEX .)
-    FSTRING         reduce using rule 145 (constant -> REGEX .)
-    RSTRING         reduce using rule 145 (constant -> REGEX .)
-    MLS             reduce using rule 145 (constant -> REGEX .)
-    [               reduce using rule 145 (constant -> REGEX .)
-    {               reduce using rule 145 (constant -> REGEX .)
-    $end            reduce using rule 145 (constant -> REGEX .)
-    )               reduce using rule 145 (constant -> REGEX .)
-    :               reduce using rule 145 (constant -> REGEX .)
-    ,               reduce using rule 145 (constant -> REGEX .)
-    ]               reduce using rule 145 (constant -> REGEX .)
-    ELSE            reduce using rule 145 (constant -> REGEX .)
-    ELIF            reduce using rule 145 (constant -> REGEX .)
-    END             reduce using rule 145 (constant -> REGEX .)
-    }               reduce using rule 145 (constant -> REGEX .)
-    DICT            reduce using rule 145 (constant -> REGEX .)
+    CMP_OP          reduce using rule 145 (constant -> TRUE .)
+    IN              reduce using rule 145 (constant -> TRUE .)
+    AND             reduce using rule 145 (constant -> TRUE .)
+    OR              reduce using rule 145 (constant -> TRUE .)
+    ?               reduce using rule 145 (constant -> TRUE .)
+    ENTITY          reduce using rule 145 (constant -> TRUE .)
+    IMPLEMENT       reduce using rule 145 (constant -> TRUE .)
+    IMPLEMENTATION  reduce using rule 145 (constant -> TRUE .)
+    INDEX           reduce using rule 145 (constant -> TRUE .)
+    IMPORT          reduce using rule 145 (constant -> TRUE .)
+    CID             reduce using rule 145 (constant -> TRUE .)
+    FOR             reduce using rule 145 (constant -> TRUE .)
+    IF              reduce using rule 145 (constant -> TRUE .)
+    (               reduce using rule 145 (constant -> TRUE .)
+    TYPEDEF         reduce using rule 145 (constant -> TRUE .)
+    ID              reduce using rule 145 (constant -> TRUE .)
+    NOT             reduce using rule 145 (constant -> TRUE .)
+    INT             reduce using rule 145 (constant -> TRUE .)
+    FLOAT           reduce using rule 145 (constant -> TRUE .)
+    NULL            reduce using rule 145 (constant -> TRUE .)
+    REGEX           reduce using rule 145 (constant -> TRUE .)
+    TRUE            reduce using rule 145 (constant -> TRUE .)
+    FALSE           reduce using rule 145 (constant -> TRUE .)
+    STRING          reduce using rule 145 (constant -> TRUE .)
+    FSTRING         reduce using rule 145 (constant -> TRUE .)
+    RSTRING         reduce using rule 145 (constant -> TRUE .)
+    MLS             reduce using rule 145 (constant -> TRUE .)
+    [               reduce using rule 145 (constant -> TRUE .)
+    {               reduce using rule 145 (constant -> TRUE .)
+    $end            reduce using rule 145 (constant -> TRUE .)
+    )               reduce using rule 145 (constant -> TRUE .)
+    :               reduce using rule 145 (constant -> TRUE .)
+    ,               reduce using rule 145 (constant -> TRUE .)
+    ]               reduce using rule 145 (constant -> TRUE .)
+    ELSE            reduce using rule 145 (constant -> TRUE .)
+    ELIF            reduce using rule 145 (constant -> TRUE .)
+    END             reduce using rule 145 (constant -> TRUE .)
+    }               reduce using rule 145 (constant -> TRUE .)
+    DICT            reduce using rule 145 (constant -> TRUE .)
 
 
 state 53
 
-    (146) constant -> TRUE .
+    (146) constant -> FALSE .
 
-    CMP_OP          reduce using rule 146 (constant -> TRUE .)
-    IN              reduce using rule 146 (constant -> TRUE .)
-    AND             reduce using rule 146 (constant -> TRUE .)
-    OR              reduce using rule 146 (constant -> TRUE .)
-    NOT             reduce using rule 146 (constant -> TRUE .)
-    ?               reduce using rule 146 (constant -> TRUE .)
-    ENTITY          reduce using rule 146 (constant -> TRUE .)
-    IMPLEMENT       reduce using rule 146 (constant -> TRUE .)
-    IMPLEMENTATION  reduce using rule 146 (constant -> TRUE .)
-    INDEX           reduce using rule 146 (constant -> TRUE .)
-    IMPORT          reduce using rule 146 (constant -> TRUE .)
-    CID             reduce using rule 146 (constant -> TRUE .)
-    FOR             reduce using rule 146 (constant -> TRUE .)
-    IF              reduce using rule 146 (constant -> TRUE .)
-    (               reduce using rule 146 (constant -> TRUE .)
-    TYPEDEF         reduce using rule 146 (constant -> TRUE .)
-    ID              reduce using rule 146 (constant -> TRUE .)
-    INT             reduce using rule 146 (constant -> TRUE .)
-    FLOAT           reduce using rule 146 (constant -> TRUE .)
-    NULL            reduce using rule 146 (constant -> TRUE .)
-    REGEX           reduce using rule 146 (constant -> TRUE .)
-    TRUE            reduce using rule 146 (constant -> TRUE .)
-    FALSE           reduce using rule 146 (constant -> TRUE .)
-    STRING          reduce using rule 146 (constant -> TRUE .)
-    FSTRING         reduce using rule 146 (constant -> TRUE .)
-    RSTRING         reduce using rule 146 (constant -> TRUE .)
-    MLS             reduce using rule 146 (constant -> TRUE .)
-    [               reduce using rule 146 (constant -> TRUE .)
-    {               reduce using rule 146 (constant -> TRUE .)
-    $end            reduce using rule 146 (constant -> TRUE .)
-    )               reduce using rule 146 (constant -> TRUE .)
-    :               reduce using rule 146 (constant -> TRUE .)
-    ,               reduce using rule 146 (constant -> TRUE .)
-    ]               reduce using rule 146 (constant -> TRUE .)
-    ELSE            reduce using rule 146 (constant -> TRUE .)
-    ELIF            reduce using rule 146 (constant -> TRUE .)
-    END             reduce using rule 146 (constant -> TRUE .)
-    }               reduce using rule 146 (constant -> TRUE .)
-    DICT            reduce using rule 146 (constant -> TRUE .)
+    CMP_OP          reduce using rule 146 (constant -> FALSE .)
+    IN              reduce using rule 146 (constant -> FALSE .)
+    AND             reduce using rule 146 (constant -> FALSE .)
+    OR              reduce using rule 146 (constant -> FALSE .)
+    ?               reduce using rule 146 (constant -> FALSE .)
+    ENTITY          reduce using rule 146 (constant -> FALSE .)
+    IMPLEMENT       reduce using rule 146 (constant -> FALSE .)
+    IMPLEMENTATION  reduce using rule 146 (constant -> FALSE .)
+    INDEX           reduce using rule 146 (constant -> FALSE .)
+    IMPORT          reduce using rule 146 (constant -> FALSE .)
+    CID             reduce using rule 146 (constant -> FALSE .)
+    FOR             reduce using rule 146 (constant -> FALSE .)
+    IF              reduce using rule 146 (constant -> FALSE .)
+    (               reduce using rule 146 (constant -> FALSE .)
+    TYPEDEF         reduce using rule 146 (constant -> FALSE .)
+    ID              reduce using rule 146 (constant -> FALSE .)
+    NOT             reduce using rule 146 (constant -> FALSE .)
+    INT             reduce using rule 146 (constant -> FALSE .)
+    FLOAT           reduce using rule 146 (constant -> FALSE .)
+    NULL            reduce using rule 146 (constant -> FALSE .)
+    REGEX           reduce using rule 146 (constant -> FALSE .)
+    TRUE            reduce using rule 146 (constant -> FALSE .)
+    FALSE           reduce using rule 146 (constant -> FALSE .)
+    STRING          reduce using rule 146 (constant -> FALSE .)
+    FSTRING         reduce using rule 146 (constant -> FALSE .)
+    RSTRING         reduce using rule 146 (constant -> FALSE .)
+    MLS             reduce using rule 146 (constant -> FALSE .)
+    [               reduce using rule 146 (constant -> FALSE .)
+    {               reduce using rule 146 (constant -> FALSE .)
+    $end            reduce using rule 146 (constant -> FALSE .)
+    )               reduce using rule 146 (constant -> FALSE .)
+    :               reduce using rule 146 (constant -> FALSE .)
+    ,               reduce using rule 146 (constant -> FALSE .)
+    ]               reduce using rule 146 (constant -> FALSE .)
+    ELSE            reduce using rule 146 (constant -> FALSE .)
+    ELIF            reduce using rule 146 (constant -> FALSE .)
+    END             reduce using rule 146 (constant -> FALSE .)
+    }               reduce using rule 146 (constant -> FALSE .)
+    DICT            reduce using rule 146 (constant -> FALSE .)
 
 
 state 54
 
-    (147) constant -> FALSE .
+    (147) constant -> STRING .
 
-    CMP_OP          reduce using rule 147 (constant -> FALSE .)
-    IN              reduce using rule 147 (constant -> FALSE .)
-    AND             reduce using rule 147 (constant -> FALSE .)
-    OR              reduce using rule 147 (constant -> FALSE .)
-    NOT             reduce using rule 147 (constant -> FALSE .)
-    ?               reduce using rule 147 (constant -> FALSE .)
-    ENTITY          reduce using rule 147 (constant -> FALSE .)
-    IMPLEMENT       reduce using rule 147 (constant -> FALSE .)
-    IMPLEMENTATION  reduce using rule 147 (constant -> FALSE .)
-    INDEX           reduce using rule 147 (constant -> FALSE .)
-    IMPORT          reduce using rule 147 (constant -> FALSE .)
-    CID             reduce using rule 147 (constant -> FALSE .)
-    FOR             reduce using rule 147 (constant -> FALSE .)
-    IF              reduce using rule 147 (constant -> FALSE .)
-    (               reduce using rule 147 (constant -> FALSE .)
-    TYPEDEF         reduce using rule 147 (constant -> FALSE .)
-    ID              reduce using rule 147 (constant -> FALSE .)
-    INT             reduce using rule 147 (constant -> FALSE .)
-    FLOAT           reduce using rule 147 (constant -> FALSE .)
-    NULL            reduce using rule 147 (constant -> FALSE .)
-    REGEX           reduce using rule 147 (constant -> FALSE .)
-    TRUE            reduce using rule 147 (constant -> FALSE .)
-    FALSE           reduce using rule 147 (constant -> FALSE .)
-    STRING          reduce using rule 147 (constant -> FALSE .)
-    FSTRING         reduce using rule 147 (constant -> FALSE .)
-    RSTRING         reduce using rule 147 (constant -> FALSE .)
-    MLS             reduce using rule 147 (constant -> FALSE .)
-    [               reduce using rule 147 (constant -> FALSE .)
-    {               reduce using rule 147 (constant -> FALSE .)
-    $end            reduce using rule 147 (constant -> FALSE .)
-    )               reduce using rule 147 (constant -> FALSE .)
-    :               reduce using rule 147 (constant -> FALSE .)
-    ,               reduce using rule 147 (constant -> FALSE .)
-    ]               reduce using rule 147 (constant -> FALSE .)
-    ELSE            reduce using rule 147 (constant -> FALSE .)
-    ELIF            reduce using rule 147 (constant -> FALSE .)
-    END             reduce using rule 147 (constant -> FALSE .)
-    }               reduce using rule 147 (constant -> FALSE .)
-    DICT            reduce using rule 147 (constant -> FALSE .)
+    CMP_OP          reduce using rule 147 (constant -> STRING .)
+    IN              reduce using rule 147 (constant -> STRING .)
+    AND             reduce using rule 147 (constant -> STRING .)
+    OR              reduce using rule 147 (constant -> STRING .)
+    ?               reduce using rule 147 (constant -> STRING .)
+    ENTITY          reduce using rule 147 (constant -> STRING .)
+    IMPLEMENT       reduce using rule 147 (constant -> STRING .)
+    IMPLEMENTATION  reduce using rule 147 (constant -> STRING .)
+    INDEX           reduce using rule 147 (constant -> STRING .)
+    IMPORT          reduce using rule 147 (constant -> STRING .)
+    CID             reduce using rule 147 (constant -> STRING .)
+    FOR             reduce using rule 147 (constant -> STRING .)
+    IF              reduce using rule 147 (constant -> STRING .)
+    (               reduce using rule 147 (constant -> STRING .)
+    TYPEDEF         reduce using rule 147 (constant -> STRING .)
+    ID              reduce using rule 147 (constant -> STRING .)
+    NOT             reduce using rule 147 (constant -> STRING .)
+    INT             reduce using rule 147 (constant -> STRING .)
+    FLOAT           reduce using rule 147 (constant -> STRING .)
+    NULL            reduce using rule 147 (constant -> STRING .)
+    REGEX           reduce using rule 147 (constant -> STRING .)
+    TRUE            reduce using rule 147 (constant -> STRING .)
+    FALSE           reduce using rule 147 (constant -> STRING .)
+    STRING          reduce using rule 147 (constant -> STRING .)
+    FSTRING         reduce using rule 147 (constant -> STRING .)
+    RSTRING         reduce using rule 147 (constant -> STRING .)
+    MLS             reduce using rule 147 (constant -> STRING .)
+    [               reduce using rule 147 (constant -> STRING .)
+    {               reduce using rule 147 (constant -> STRING .)
+    $end            reduce using rule 147 (constant -> STRING .)
+    )               reduce using rule 147 (constant -> STRING .)
+    :               reduce using rule 147 (constant -> STRING .)
+    ,               reduce using rule 147 (constant -> STRING .)
+    ]               reduce using rule 147 (constant -> STRING .)
+    ELSE            reduce using rule 147 (constant -> STRING .)
+    ELIF            reduce using rule 147 (constant -> STRING .)
+    END             reduce using rule 147 (constant -> STRING .)
+    }               reduce using rule 147 (constant -> STRING .)
+    DICT            reduce using rule 147 (constant -> STRING .)
 
 
 state 55
 
-    (148) constant -> STRING .
+    (148) constant -> FSTRING .
 
-    CMP_OP          reduce using rule 148 (constant -> STRING .)
-    IN              reduce using rule 148 (constant -> STRING .)
-    AND             reduce using rule 148 (constant -> STRING .)
-    OR              reduce using rule 148 (constant -> STRING .)
-    NOT             reduce using rule 148 (constant -> STRING .)
-    ?               reduce using rule 148 (constant -> STRING .)
-    ENTITY          reduce using rule 148 (constant -> STRING .)
-    IMPLEMENT       reduce using rule 148 (constant -> STRING .)
-    IMPLEMENTATION  reduce using rule 148 (constant -> STRING .)
-    INDEX           reduce using rule 148 (constant -> STRING .)
-    IMPORT          reduce using rule 148 (constant -> STRING .)
-    CID             reduce using rule 148 (constant -> STRING .)
-    FOR             reduce using rule 148 (constant -> STRING .)
-    IF              reduce using rule 148 (constant -> STRING .)
-    (               reduce using rule 148 (constant -> STRING .)
-    TYPEDEF         reduce using rule 148 (constant -> STRING .)
-    ID              reduce using rule 148 (constant -> STRING .)
-    INT             reduce using rule 148 (constant -> STRING .)
-    FLOAT           reduce using rule 148 (constant -> STRING .)
-    NULL            reduce using rule 148 (constant -> STRING .)
-    REGEX           reduce using rule 148 (constant -> STRING .)
-    TRUE            reduce using rule 148 (constant -> STRING .)
-    FALSE           reduce using rule 148 (constant -> STRING .)
-    STRING          reduce using rule 148 (constant -> STRING .)
-    FSTRING         reduce using rule 148 (constant -> STRING .)
-    RSTRING         reduce using rule 148 (constant -> STRING .)
-    MLS             reduce using rule 148 (constant -> STRING .)
-    [               reduce using rule 148 (constant -> STRING .)
-    {               reduce using rule 148 (constant -> STRING .)
-    $end            reduce using rule 148 (constant -> STRING .)
-    )               reduce using rule 148 (constant -> STRING .)
-    :               reduce using rule 148 (constant -> STRING .)
-    ,               reduce using rule 148 (constant -> STRING .)
-    ]               reduce using rule 148 (constant -> STRING .)
-    ELSE            reduce using rule 148 (constant -> STRING .)
-    ELIF            reduce using rule 148 (constant -> STRING .)
-    END             reduce using rule 148 (constant -> STRING .)
-    }               reduce using rule 148 (constant -> STRING .)
-    DICT            reduce using rule 148 (constant -> STRING .)
+    CMP_OP          reduce using rule 148 (constant -> FSTRING .)
+    IN              reduce using rule 148 (constant -> FSTRING .)
+    AND             reduce using rule 148 (constant -> FSTRING .)
+    OR              reduce using rule 148 (constant -> FSTRING .)
+    ?               reduce using rule 148 (constant -> FSTRING .)
+    ENTITY          reduce using rule 148 (constant -> FSTRING .)
+    IMPLEMENT       reduce using rule 148 (constant -> FSTRING .)
+    IMPLEMENTATION  reduce using rule 148 (constant -> FSTRING .)
+    INDEX           reduce using rule 148 (constant -> FSTRING .)
+    IMPORT          reduce using rule 148 (constant -> FSTRING .)
+    CID             reduce using rule 148 (constant -> FSTRING .)
+    FOR             reduce using rule 148 (constant -> FSTRING .)
+    IF              reduce using rule 148 (constant -> FSTRING .)
+    (               reduce using rule 148 (constant -> FSTRING .)
+    TYPEDEF         reduce using rule 148 (constant -> FSTRING .)
+    ID              reduce using rule 148 (constant -> FSTRING .)
+    NOT             reduce using rule 148 (constant -> FSTRING .)
+    INT             reduce using rule 148 (constant -> FSTRING .)
+    FLOAT           reduce using rule 148 (constant -> FSTRING .)
+    NULL            reduce using rule 148 (constant -> FSTRING .)
+    REGEX           reduce using rule 148 (constant -> FSTRING .)
+    TRUE            reduce using rule 148 (constant -> FSTRING .)
+    FALSE           reduce using rule 148 (constant -> FSTRING .)
+    STRING          reduce using rule 148 (constant -> FSTRING .)
+    FSTRING         reduce using rule 148 (constant -> FSTRING .)
+    RSTRING         reduce using rule 148 (constant -> FSTRING .)
+    MLS             reduce using rule 148 (constant -> FSTRING .)
+    [               reduce using rule 148 (constant -> FSTRING .)
+    {               reduce using rule 148 (constant -> FSTRING .)
+    $end            reduce using rule 148 (constant -> FSTRING .)
+    )               reduce using rule 148 (constant -> FSTRING .)
+    :               reduce using rule 148 (constant -> FSTRING .)
+    ,               reduce using rule 148 (constant -> FSTRING .)
+    ]               reduce using rule 148 (constant -> FSTRING .)
+    ELSE            reduce using rule 148 (constant -> FSTRING .)
+    ELIF            reduce using rule 148 (constant -> FSTRING .)
+    END             reduce using rule 148 (constant -> FSTRING .)
+    }               reduce using rule 148 (constant -> FSTRING .)
+    DICT            reduce using rule 148 (constant -> FSTRING .)
 
 
 state 56
 
-    (149) constant -> FSTRING .
+    (149) constant -> RSTRING .
 
-    CMP_OP          reduce using rule 149 (constant -> FSTRING .)
-    IN              reduce using rule 149 (constant -> FSTRING .)
-    AND             reduce using rule 149 (constant -> FSTRING .)
-    OR              reduce using rule 149 (constant -> FSTRING .)
-    NOT             reduce using rule 149 (constant -> FSTRING .)
-    ?               reduce using rule 149 (constant -> FSTRING .)
-    ENTITY          reduce using rule 149 (constant -> FSTRING .)
-    IMPLEMENT       reduce using rule 149 (constant -> FSTRING .)
-    IMPLEMENTATION  reduce using rule 149 (constant -> FSTRING .)
-    INDEX           reduce using rule 149 (constant -> FSTRING .)
-    IMPORT          reduce using rule 149 (constant -> FSTRING .)
-    CID             reduce using rule 149 (constant -> FSTRING .)
-    FOR             reduce using rule 149 (constant -> FSTRING .)
-    IF              reduce using rule 149 (constant -> FSTRING .)
-    (               reduce using rule 149 (constant -> FSTRING .)
-    TYPEDEF         reduce using rule 149 (constant -> FSTRING .)
-    ID              reduce using rule 149 (constant -> FSTRING .)
-    INT             reduce using rule 149 (constant -> FSTRING .)
-    FLOAT           reduce using rule 149 (constant -> FSTRING .)
-    NULL            reduce using rule 149 (constant -> FSTRING .)
-    REGEX           reduce using rule 149 (constant -> FSTRING .)
-    TRUE            reduce using rule 149 (constant -> FSTRING .)
-    FALSE           reduce using rule 149 (constant -> FSTRING .)
-    STRING          reduce using rule 149 (constant -> FSTRING .)
-    FSTRING         reduce using rule 149 (constant -> FSTRING .)
-    RSTRING         reduce using rule 149 (constant -> FSTRING .)
-    MLS             reduce using rule 149 (constant -> FSTRING .)
-    [               reduce using rule 149 (constant -> FSTRING .)
-    {               reduce using rule 149 (constant -> FSTRING .)
-    $end            reduce using rule 149 (constant -> FSTRING .)
-    )               reduce using rule 149 (constant -> FSTRING .)
-    :               reduce using rule 149 (constant -> FSTRING .)
-    ,               reduce using rule 149 (constant -> FSTRING .)
-    ]               reduce using rule 149 (constant -> FSTRING .)
-    ELSE            reduce using rule 149 (constant -> FSTRING .)
-    ELIF            reduce using rule 149 (constant -> FSTRING .)
-    END             reduce using rule 149 (constant -> FSTRING .)
-    }               reduce using rule 149 (constant -> FSTRING .)
-    DICT            reduce using rule 149 (constant -> FSTRING .)
+    CMP_OP          reduce using rule 149 (constant -> RSTRING .)
+    IN              reduce using rule 149 (constant -> RSTRING .)
+    AND             reduce using rule 149 (constant -> RSTRING .)
+    OR              reduce using rule 149 (constant -> RSTRING .)
+    ?               reduce using rule 149 (constant -> RSTRING .)
+    ENTITY          reduce using rule 149 (constant -> RSTRING .)
+    IMPLEMENT       reduce using rule 149 (constant -> RSTRING .)
+    IMPLEMENTATION  reduce using rule 149 (constant -> RSTRING .)
+    INDEX           reduce using rule 149 (constant -> RSTRING .)
+    IMPORT          reduce using rule 149 (constant -> RSTRING .)
+    CID             reduce using rule 149 (constant -> RSTRING .)
+    FOR             reduce using rule 149 (constant -> RSTRING .)
+    IF              reduce using rule 149 (constant -> RSTRING .)
+    (               reduce using rule 149 (constant -> RSTRING .)
+    TYPEDEF         reduce using rule 149 (constant -> RSTRING .)
+    ID              reduce using rule 149 (constant -> RSTRING .)
+    NOT             reduce using rule 149 (constant -> RSTRING .)
+    INT             reduce using rule 149 (constant -> RSTRING .)
+    FLOAT           reduce using rule 149 (constant -> RSTRING .)
+    NULL            reduce using rule 149 (constant -> RSTRING .)
+    REGEX           reduce using rule 149 (constant -> RSTRING .)
+    TRUE            reduce using rule 149 (constant -> RSTRING .)
+    FALSE           reduce using rule 149 (constant -> RSTRING .)
+    STRING          reduce using rule 149 (constant -> RSTRING .)
+    FSTRING         reduce using rule 149 (constant -> RSTRING .)
+    RSTRING         reduce using rule 149 (constant -> RSTRING .)
+    MLS             reduce using rule 149 (constant -> RSTRING .)
+    [               reduce using rule 149 (constant -> RSTRING .)
+    {               reduce using rule 149 (constant -> RSTRING .)
+    $end            reduce using rule 149 (constant -> RSTRING .)
+    )               reduce using rule 149 (constant -> RSTRING .)
+    :               reduce using rule 149 (constant -> RSTRING .)
+    ,               reduce using rule 149 (constant -> RSTRING .)
+    ]               reduce using rule 149 (constant -> RSTRING .)
+    ELSE            reduce using rule 149 (constant -> RSTRING .)
+    ELIF            reduce using rule 149 (constant -> RSTRING .)
+    END             reduce using rule 149 (constant -> RSTRING .)
+    }               reduce using rule 149 (constant -> RSTRING .)
+    DICT            reduce using rule 149 (constant -> RSTRING .)
 
 
 state 57
 
-    (150) constant -> RSTRING .
-
-    CMP_OP          reduce using rule 150 (constant -> RSTRING .)
-    IN              reduce using rule 150 (constant -> RSTRING .)
-    AND             reduce using rule 150 (constant -> RSTRING .)
-    OR              reduce using rule 150 (constant -> RSTRING .)
-    NOT             reduce using rule 150 (constant -> RSTRING .)
-    ?               reduce using rule 150 (constant -> RSTRING .)
-    ENTITY          reduce using rule 150 (constant -> RSTRING .)
-    IMPLEMENT       reduce using rule 150 (constant -> RSTRING .)
-    IMPLEMENTATION  reduce using rule 150 (constant -> RSTRING .)
-    INDEX           reduce using rule 150 (constant -> RSTRING .)
-    IMPORT          reduce using rule 150 (constant -> RSTRING .)
-    CID             reduce using rule 150 (constant -> RSTRING .)
-    FOR             reduce using rule 150 (constant -> RSTRING .)
-    IF              reduce using rule 150 (constant -> RSTRING .)
-    (               reduce using rule 150 (constant -> RSTRING .)
-    TYPEDEF         reduce using rule 150 (constant -> RSTRING .)
-    ID              reduce using rule 150 (constant -> RSTRING .)
-    INT             reduce using rule 150 (constant -> RSTRING .)
-    FLOAT           reduce using rule 150 (constant -> RSTRING .)
-    NULL            reduce using rule 150 (constant -> RSTRING .)
-    REGEX           reduce using rule 150 (constant -> RSTRING .)
-    TRUE            reduce using rule 150 (constant -> RSTRING .)
-    FALSE           reduce using rule 150 (constant -> RSTRING .)
-    STRING          reduce using rule 150 (constant -> RSTRING .)
-    FSTRING         reduce using rule 150 (constant -> RSTRING .)
-    RSTRING         reduce using rule 150 (constant -> RSTRING .)
-    MLS             reduce using rule 150 (constant -> RSTRING .)
-    [               reduce using rule 150 (constant -> RSTRING .)
-    {               reduce using rule 150 (constant -> RSTRING .)
-    $end            reduce using rule 150 (constant -> RSTRING .)
-    )               reduce using rule 150 (constant -> RSTRING .)
-    :               reduce using rule 150 (constant -> RSTRING .)
-    ,               reduce using rule 150 (constant -> RSTRING .)
-    ]               reduce using rule 150 (constant -> RSTRING .)
-    ELSE            reduce using rule 150 (constant -> RSTRING .)
-    ELIF            reduce using rule 150 (constant -> RSTRING .)
-    END             reduce using rule 150 (constant -> RSTRING .)
-    }               reduce using rule 150 (constant -> RSTRING .)
-    DICT            reduce using rule 150 (constant -> RSTRING .)
-
-
-state 58
-
-    (125) list_def -> [ . operand_list ]
-    (126) list_comprehension -> [ . expression list_comprehension_for list_comprehension_guard ]
-    (169) operand_list -> . operand , operand_list
-    (170) operand_list -> . operand
-    (171) operand_list -> . empty
+    (124) list_def -> [ . operand_list ]
+    (125) list_comprehension -> [ . expression list_comprehension_for list_comprehension_guard ]
+    (168) operand_list -> . operand , operand_list
+    (169) operand_list -> . operand
+    (170) operand_list -> .
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (118) operand -> . expression empty
-    (2) empty -> .
+    (117) operand -> . expression
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    ]               reduce using rule 2 (empty -> .)
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    operand_list                   shift and go to state 113
-    expression                     shift and go to state 114
-    operand                        shift and go to state 115
-    empty                          shift and go to state 116
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    ]               reduce using rule 170 (operand_list -> .)
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    operand_list                   shift and go to state 104
+    expression                     shift and go to state 105
+    operand                        shift and go to state 106
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 59
+state 58
 
-    (138) map_def -> { . pair_list }
-    (134) pair_list -> . dict_key : operand , pair_list
-    (135) pair_list -> . dict_key : operand empty pair_list_empty
-    (136) pair_list -> . pair_list_empty
-    (132) dict_key -> . RSTRING
-    (133) dict_key -> . STRING
-    (137) pair_list_empty -> . empty
-    (2) empty -> .
-
-    RSTRING         shift and go to state 121
-    STRING          shift and go to state 122
-    }               reduce using rule 2 (empty -> .)
-
-    pair_list                      shift and go to state 117
-    dict_key                       shift and go to state 118
-    empty                          shift and go to state 119
-    pair_list_empty                shift and go to state 120
+    (137) map_def -> { . pair_list }
+    (133) pair_list -> . dict_key : operand , pair_list
+    (134) pair_list -> . dict_key : operand empty pair_list_empty
+    (135) pair_list -> . pair_list_empty
+    (131) dict_key -> . RSTRING
+    (132) dict_key -> . STRING
+    (136) pair_list_empty -> . empty
+    (14) empty -> .
+
+    RSTRING         shift and go to state 111
+    STRING          shift and go to state 112
+    }               reduce using rule 14 (empty -> .)
 
-state 60
+    pair_list                      shift and go to state 107
+    dict_key                       shift and go to state 108
+    empty                          shift and go to state 109
+    pair_list_empty                shift and go to state 110
 
-    (5) body -> top_stmt body .
+state 59
 
-    $end            reduce using rule 5 (body -> top_stmt body .)
+    (4) body -> top_stmt body .
 
+    $end            reduce using rule 4 (body -> top_stmt body .)
 
-state 61
+
+state 60
 
     (31) entity_def -> ENTITY CID . : entity_body_outer
     (33) entity_def -> ENTITY CID . EXTENDS class_ref_list : entity_body_outer
 
-    :               shift and go to state 123
-    EXTENDS         shift and go to state 124
+    :               shift and go to state 113
+    EXTENDS         shift and go to state 114
 
 
-state 62
+state 61
 
     (32) entity_def -> ENTITY ID . : entity_body_outer
     (34) entity_def -> ENTITY ID . EXTENDS class_ref_list : entity_body_outer
 
-    :               shift and go to state 125
-    EXTENDS         shift and go to state 126
+    :               shift and go to state 115
+    EXTENDS         shift and go to state 116
 
 
-state 63
+state 62
 
-    (116) boolean_expression -> ID IS . DEFINED
+    (115) boolean_expression -> ID IS . DEFINED
 
-    DEFINED         shift and go to state 127
+    DEFINED         shift and go to state 117
 
 
-state 64
+state 63
 
     (71) implement_def -> IMPLEMENT class_ref . USING implement_ns_list empty
     (72) implement_def -> IMPLEMENT class_ref . USING implement_ns_list MLS
     (73) implement_def -> IMPLEMENT class_ref . USING implement_ns_list WHEN expression empty
     (74) implement_def -> IMPLEMENT class_ref . USING implement_ns_list WHEN expression MLS
 
-    USING           shift and go to state 128
+    USING           shift and go to state 118
 
 
-state 65
+state 64
 
-    (176) class_ref -> ns_ref . SEP CID
-    (182) ns_ref -> ns_ref . SEP ID
-    (174) var_ref -> ns_ref . empty
-    (2) empty -> .
+    (175) class_ref -> ns_ref . SEP CID
+    (181) ns_ref -> ns_ref . SEP ID
+    (173) var_ref -> ns_ref .
 
-    SEP             shift and go to state 94
-    .               reduce using rule 2 (empty -> .)
+    SEP             shift and go to state 89
+    .               reduce using rule 173 (var_ref -> ns_ref .)
 
-    empty                          shift and go to state 95
 
-state 66
+state 65
 
-    (177) class_ref -> var_ref . . CID
-    (173) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
+    (172) attr_ref -> var_ref . . ID
 
-    .               shift and go to state 129
+    .               shift and go to state 119
 
 
-state 67
+state 66
 
-    (183) ns_ref -> ID .
+    (182) ns_ref -> ID .
 
-    SEP             reduce using rule 183 (ns_ref -> ID .)
-    .               reduce using rule 183 (ns_ref -> ID .)
-    AS              reduce using rule 183 (ns_ref -> ID .)
-    ENTITY          reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENT       reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENTATION  reduce using rule 183 (ns_ref -> ID .)
-    INDEX           reduce using rule 183 (ns_ref -> ID .)
-    IMPORT          reduce using rule 183 (ns_ref -> ID .)
-    CID             reduce using rule 183 (ns_ref -> ID .)
-    FOR             reduce using rule 183 (ns_ref -> ID .)
-    IF              reduce using rule 183 (ns_ref -> ID .)
-    (               reduce using rule 183 (ns_ref -> ID .)
-    TYPEDEF         reduce using rule 183 (ns_ref -> ID .)
-    ID              reduce using rule 183 (ns_ref -> ID .)
-    NOT             reduce using rule 183 (ns_ref -> ID .)
-    INT             reduce using rule 183 (ns_ref -> ID .)
-    FLOAT           reduce using rule 183 (ns_ref -> ID .)
-    NULL            reduce using rule 183 (ns_ref -> ID .)
-    REGEX           reduce using rule 183 (ns_ref -> ID .)
-    TRUE            reduce using rule 183 (ns_ref -> ID .)
-    FALSE           reduce using rule 183 (ns_ref -> ID .)
-    STRING          reduce using rule 183 (ns_ref -> ID .)
-    FSTRING         reduce using rule 183 (ns_ref -> ID .)
-    RSTRING         reduce using rule 183 (ns_ref -> ID .)
-    MLS             reduce using rule 183 (ns_ref -> ID .)
-    [               reduce using rule 183 (ns_ref -> ID .)
-    {               reduce using rule 183 (ns_ref -> ID .)
-    $end            reduce using rule 183 (ns_ref -> ID .)
-    ?               reduce using rule 183 (ns_ref -> ID .)
-    ,               reduce using rule 183 (ns_ref -> ID .)
-    :               reduce using rule 183 (ns_ref -> ID .)
-    WHEN            reduce using rule 183 (ns_ref -> ID .)
-    MATCHING        reduce using rule 183 (ns_ref -> ID .)
+    SEP             reduce using rule 182 (ns_ref -> ID .)
+    .               reduce using rule 182 (ns_ref -> ID .)
+    AS              reduce using rule 182 (ns_ref -> ID .)
+    ENTITY          reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENT       reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENTATION  reduce using rule 182 (ns_ref -> ID .)
+    INDEX           reduce using rule 182 (ns_ref -> ID .)
+    IMPORT          reduce using rule 182 (ns_ref -> ID .)
+    CID             reduce using rule 182 (ns_ref -> ID .)
+    FOR             reduce using rule 182 (ns_ref -> ID .)
+    IF              reduce using rule 182 (ns_ref -> ID .)
+    (               reduce using rule 182 (ns_ref -> ID .)
+    TYPEDEF         reduce using rule 182 (ns_ref -> ID .)
+    ID              reduce using rule 182 (ns_ref -> ID .)
+    NOT             reduce using rule 182 (ns_ref -> ID .)
+    INT             reduce using rule 182 (ns_ref -> ID .)
+    FLOAT           reduce using rule 182 (ns_ref -> ID .)
+    NULL            reduce using rule 182 (ns_ref -> ID .)
+    REGEX           reduce using rule 182 (ns_ref -> ID .)
+    TRUE            reduce using rule 182 (ns_ref -> ID .)
+    FALSE           reduce using rule 182 (ns_ref -> ID .)
+    STRING          reduce using rule 182 (ns_ref -> ID .)
+    FSTRING         reduce using rule 182 (ns_ref -> ID .)
+    RSTRING         reduce using rule 182 (ns_ref -> ID .)
+    MLS             reduce using rule 182 (ns_ref -> ID .)
+    [               reduce using rule 182 (ns_ref -> ID .)
+    {               reduce using rule 182 (ns_ref -> ID .)
+    $end            reduce using rule 182 (ns_ref -> ID .)
+    ?               reduce using rule 182 (ns_ref -> ID .)
+    ,               reduce using rule 182 (ns_ref -> ID .)
+    :               reduce using rule 182 (ns_ref -> ID .)
+    WHEN            reduce using rule 182 (ns_ref -> ID .)
+    MATCHING        reduce using rule 182 (ns_ref -> ID .)
 
 
-state 68
+state 67
 
-    (172) var_ref -> attr_ref . empty
-    (2) empty -> .
+    (171) var_ref -> attr_ref .
 
-    .               reduce using rule 2 (empty -> .)
-    ,               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
+    .               reduce using rule 171 (var_ref -> attr_ref .)
+    ,               reduce using rule 171 (var_ref -> attr_ref .)
+    :               reduce using rule 171 (var_ref -> attr_ref .)
 
-    empty                          shift and go to state 109
 
-state 69
+state 68
 
     (80) relation -> class_ref ID . multi REL multi class_ref ID
     (81) relation -> class_ref ID . multi REL multi class_ref ID MLS
     (88) multi -> . [ INT ]
     (89) multi -> . [ INT : ]
     (90) multi -> . [ INT : INT ]
     (91) multi -> . [ : INT ]
 
-    [               shift and go to state 131
+    [               shift and go to state 121
 
-    multi                          shift and go to state 130
+    multi                          shift and go to state 120
 
-state 70
+state 69
 
     (84) relation_def -> class_ref . . ID multi REL class_ref . ID multi
     (85) relation_def -> class_ref . . ID multi REL class_ref
     (86) relation_def -> class_ref . . ID multi operand_list class_ref . ID multi
     (87) relation_def -> class_ref . . ID multi operand_list class_ref
 
-    ID              shift and go to state 132
-
-
-state 71
-
-    (122) constructor -> class_ref ( . param_list )
-    (159) param_list -> . param_list_empty
-    (161) param_list -> . param_list_element empty param_list_empty
-    (162) param_list -> . param_list_element , param_list
-    (160) param_list_empty -> . empty
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (2) empty -> .
-    (156) wrapped_kwargs -> . * * operand
-
-    ID              shift and go to state 137
-    )               reduce using rule 2 (empty -> .)
-    *               shift and go to state 139
-
-    param_list                     shift and go to state 133
-    param_list_empty               shift and go to state 134
-    param_list_element             shift and go to state 135
-    empty                          shift and go to state 136
-    wrapped_kwargs                 shift and go to state 138
-
-state 72
+    ID              shift and go to state 122
 
-    (139) index_lookup -> class_ref [ . param_list ]
-    (159) param_list -> . param_list_empty
-    (161) param_list -> . param_list_element empty param_list_empty
-    (162) param_list -> . param_list_element , param_list
-    (160) param_list_empty -> . empty
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (2) empty -> .
-    (156) wrapped_kwargs -> . * * operand
-
-    ID              shift and go to state 137
-    ]               reduce using rule 2 (empty -> .)
-    *               shift and go to state 139
-
-    param_list                     shift and go to state 140
-    param_list_empty               shift and go to state 134
-    param_list_element             shift and go to state 135
-    empty                          shift and go to state 136
-    wrapped_kwargs                 shift and go to state 138
 
-state 73
+state 70
 
-    (20) statement -> expression empty .
+    (121) constructor -> class_ref ( . param_list )
+    (158) param_list -> . param_list_empty
+    (160) param_list -> . param_list_element empty param_list_empty
+    (161) param_list -> . param_list_element , param_list
+    (159) param_list_empty -> . empty
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (14) empty -> .
+    (155) wrapped_kwargs -> . * * operand
+
+    ID              shift and go to state 127
+    )               reduce using rule 14 (empty -> .)
+    *               shift and go to state 129
+
+    param_list                     shift and go to state 123
+    param_list_empty               shift and go to state 124
+    param_list_element             shift and go to state 125
+    empty                          shift and go to state 126
+    wrapped_kwargs                 shift and go to state 128
 
-    ENTITY          reduce using rule 20 (statement -> expression empty .)
-    IMPLEMENT       reduce using rule 20 (statement -> expression empty .)
-    IMPLEMENTATION  reduce using rule 20 (statement -> expression empty .)
-    INDEX           reduce using rule 20 (statement -> expression empty .)
-    IMPORT          reduce using rule 20 (statement -> expression empty .)
-    CID             reduce using rule 20 (statement -> expression empty .)
-    FOR             reduce using rule 20 (statement -> expression empty .)
-    IF              reduce using rule 20 (statement -> expression empty .)
-    (               reduce using rule 20 (statement -> expression empty .)
-    TYPEDEF         reduce using rule 20 (statement -> expression empty .)
-    ID              reduce using rule 20 (statement -> expression empty .)
-    NOT             reduce using rule 20 (statement -> expression empty .)
-    INT             reduce using rule 20 (statement -> expression empty .)
-    FLOAT           reduce using rule 20 (statement -> expression empty .)
-    NULL            reduce using rule 20 (statement -> expression empty .)
-    REGEX           reduce using rule 20 (statement -> expression empty .)
-    TRUE            reduce using rule 20 (statement -> expression empty .)
-    FALSE           reduce using rule 20 (statement -> expression empty .)
-    STRING          reduce using rule 20 (statement -> expression empty .)
-    FSTRING         reduce using rule 20 (statement -> expression empty .)
-    RSTRING         reduce using rule 20 (statement -> expression empty .)
-    MLS             reduce using rule 20 (statement -> expression empty .)
-    [               reduce using rule 20 (statement -> expression empty .)
-    {               reduce using rule 20 (statement -> expression empty .)
-    $end            reduce using rule 20 (statement -> expression empty .)
-    ELSE            reduce using rule 20 (statement -> expression empty .)
-    ELIF            reduce using rule 20 (statement -> expression empty .)
-    END             reduce using rule 20 (statement -> expression empty .)
+state 71
 
+    (138) index_lookup -> class_ref [ . param_list ]
+    (158) param_list -> . param_list_empty
+    (160) param_list -> . param_list_element empty param_list_empty
+    (161) param_list -> . param_list_element , param_list
+    (159) param_list_empty -> . empty
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (14) empty -> .
+    (155) wrapped_kwargs -> . * * operand
+
+    ID              shift and go to state 127
+    ]               reduce using rule 14 (empty -> .)
+    *               shift and go to state 129
+
+    param_list                     shift and go to state 130
+    param_list_empty               shift and go to state 124
+    param_list_element             shift and go to state 125
+    empty                          shift and go to state 126
+    wrapped_kwargs                 shift and go to state 128
 
-state 74
+state 72
 
     (109) boolean_expression -> expression CMP_OP . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 141
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 131
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 75
+state 73
 
     (110) boolean_expression -> expression IN . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 142
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 132
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 76
+state 74
 
     (111) boolean_expression -> expression AND . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 143
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 133
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 77
+state 75
 
     (112) boolean_expression -> expression OR . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 144
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 134
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 78
-
-    (113) boolean_expression -> expression NOT . IN expression
-
-    IN              shift and go to state 145
-
-
-state 79
+state 76
 
-    (141) conditional_expression -> expression ? . expression : expression
+    (140) conditional_expression -> expression ? . expression : expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 146
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 135
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 80
+state 77
 
     (75) implementation_def -> IMPLEMENTATION ID . FOR class_ref implementation
 
-    FOR             shift and go to state 147
+    FOR             shift and go to state 136
 
 
-state 81
+state 78
 
     (25) for -> FOR ID . IN operand : block
 
-    IN              shift and go to state 148
+    IN              shift and go to state 137
 
 
-state 82
+state 79
 
     (82) relation -> relation_def MLS .
 
     ENTITY          reduce using rule 82 (relation -> relation_def MLS .)
     IMPLEMENT       reduce using rule 82 (relation -> relation_def MLS .)
     IMPLEMENTATION  reduce using rule 82 (relation -> relation_def MLS .)
     INDEX           reduce using rule 82 (relation -> relation_def MLS .)
@@ -3533,77 +3424,15 @@
     RSTRING         reduce using rule 82 (relation -> relation_def MLS .)
     MLS             reduce using rule 82 (relation -> relation_def MLS .)
     [               reduce using rule 82 (relation -> relation_def MLS .)
     {               reduce using rule 82 (relation -> relation_def MLS .)
     $end            reduce using rule 82 (relation -> relation_def MLS .)
 
 
-state 83
-
-    (83) relation -> relation_def empty .
-
-    ENTITY          reduce using rule 83 (relation -> relation_def empty .)
-    IMPLEMENT       reduce using rule 83 (relation -> relation_def empty .)
-    IMPLEMENTATION  reduce using rule 83 (relation -> relation_def empty .)
-    INDEX           reduce using rule 83 (relation -> relation_def empty .)
-    IMPORT          reduce using rule 83 (relation -> relation_def empty .)
-    CID             reduce using rule 83 (relation -> relation_def empty .)
-    FOR             reduce using rule 83 (relation -> relation_def empty .)
-    IF              reduce using rule 83 (relation -> relation_def empty .)
-    (               reduce using rule 83 (relation -> relation_def empty .)
-    TYPEDEF         reduce using rule 83 (relation -> relation_def empty .)
-    ID              reduce using rule 83 (relation -> relation_def empty .)
-    NOT             reduce using rule 83 (relation -> relation_def empty .)
-    INT             reduce using rule 83 (relation -> relation_def empty .)
-    FLOAT           reduce using rule 83 (relation -> relation_def empty .)
-    NULL            reduce using rule 83 (relation -> relation_def empty .)
-    REGEX           reduce using rule 83 (relation -> relation_def empty .)
-    TRUE            reduce using rule 83 (relation -> relation_def empty .)
-    FALSE           reduce using rule 83 (relation -> relation_def empty .)
-    STRING          reduce using rule 83 (relation -> relation_def empty .)
-    FSTRING         reduce using rule 83 (relation -> relation_def empty .)
-    RSTRING         reduce using rule 83 (relation -> relation_def empty .)
-    MLS             reduce using rule 83 (relation -> relation_def empty .)
-    [               reduce using rule 83 (relation -> relation_def empty .)
-    {               reduce using rule 83 (relation -> relation_def empty .)
-    $end            reduce using rule 83 (relation -> relation_def empty .)
-
-
-state 84
-
-    (92) typedef -> typedef_inner empty .
-
-    ENTITY          reduce using rule 92 (typedef -> typedef_inner empty .)
-    IMPLEMENT       reduce using rule 92 (typedef -> typedef_inner empty .)
-    IMPLEMENTATION  reduce using rule 92 (typedef -> typedef_inner empty .)
-    INDEX           reduce using rule 92 (typedef -> typedef_inner empty .)
-    IMPORT          reduce using rule 92 (typedef -> typedef_inner empty .)
-    CID             reduce using rule 92 (typedef -> typedef_inner empty .)
-    FOR             reduce using rule 92 (typedef -> typedef_inner empty .)
-    IF              reduce using rule 92 (typedef -> typedef_inner empty .)
-    (               reduce using rule 92 (typedef -> typedef_inner empty .)
-    TYPEDEF         reduce using rule 92 (typedef -> typedef_inner empty .)
-    ID              reduce using rule 92 (typedef -> typedef_inner empty .)
-    NOT             reduce using rule 92 (typedef -> typedef_inner empty .)
-    INT             reduce using rule 92 (typedef -> typedef_inner empty .)
-    FLOAT           reduce using rule 92 (typedef -> typedef_inner empty .)
-    NULL            reduce using rule 92 (typedef -> typedef_inner empty .)
-    REGEX           reduce using rule 92 (typedef -> typedef_inner empty .)
-    TRUE            reduce using rule 92 (typedef -> typedef_inner empty .)
-    FALSE           reduce using rule 92 (typedef -> typedef_inner empty .)
-    STRING          reduce using rule 92 (typedef -> typedef_inner empty .)
-    FSTRING         reduce using rule 92 (typedef -> typedef_inner empty .)
-    RSTRING         reduce using rule 92 (typedef -> typedef_inner empty .)
-    MLS             reduce using rule 92 (typedef -> typedef_inner empty .)
-    [               reduce using rule 92 (typedef -> typedef_inner empty .)
-    {               reduce using rule 92 (typedef -> typedef_inner empty .)
-    $end            reduce using rule 92 (typedef -> typedef_inner empty .)
-
-
-state 85
+state 80
 
     (93) typedef -> typedef_inner MLS .
 
     ENTITY          reduce using rule 93 (typedef -> typedef_inner MLS .)
     IMPLEMENT       reduce using rule 93 (typedef -> typedef_inner MLS .)
     IMPLEMENTATION  reduce using rule 93 (typedef -> typedef_inner MLS .)
     INDEX           reduce using rule 93 (typedef -> typedef_inner MLS .)
@@ -3626,263 +3455,255 @@
     RSTRING         reduce using rule 93 (typedef -> typedef_inner MLS .)
     MLS             reduce using rule 93 (typedef -> typedef_inner MLS .)
     [               reduce using rule 93 (typedef -> typedef_inner MLS .)
     {               reduce using rule 93 (typedef -> typedef_inner MLS .)
     $end            reduce using rule 93 (typedef -> typedef_inner MLS .)
 
 
-state 86
+state 81
 
     (96) index -> INDEX class_ref . ( id_list )
 
-    (               shift and go to state 149
+    (               shift and go to state 138
 
 
-state 87
+state 82
 
     (108) expression -> ( expression . )
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
-    )               shift and go to state 150
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
+    )               shift and go to state 139
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
 
-state 88
+state 83
 
-    (100) expression -> var_ref . empty
-    (115) boolean_expression -> var_ref . . ID IS DEFINED
-    (120) map_lookup -> var_ref . [ operand ]
-    (173) attr_ref -> var_ref . . ID
-    (177) class_ref -> var_ref . . CID
-    (2) empty -> .
-
-    .               shift and go to state 151
-    [               shift and go to state 101
-    )               reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ,               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    }               reduce using rule 2 (empty -> .)
+    (100) expression -> var_ref .
+    (114) boolean_expression -> var_ref . . ID IS DEFINED
+    (119) map_lookup -> var_ref . [ operand ]
+    (172) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
+
+    )               reduce using rule 100 (expression -> var_ref .)
+    CMP_OP          reduce using rule 100 (expression -> var_ref .)
+    IN              reduce using rule 100 (expression -> var_ref .)
+    AND             reduce using rule 100 (expression -> var_ref .)
+    OR              reduce using rule 100 (expression -> var_ref .)
+    ?               reduce using rule 100 (expression -> var_ref .)
+    :               reduce using rule 100 (expression -> var_ref .)
+    ENTITY          reduce using rule 100 (expression -> var_ref .)
+    IMPLEMENT       reduce using rule 100 (expression -> var_ref .)
+    IMPLEMENTATION  reduce using rule 100 (expression -> var_ref .)
+    INDEX           reduce using rule 100 (expression -> var_ref .)
+    IMPORT          reduce using rule 100 (expression -> var_ref .)
+    CID             reduce using rule 100 (expression -> var_ref .)
+    FOR             reduce using rule 100 (expression -> var_ref .)
+    IF              reduce using rule 100 (expression -> var_ref .)
+    (               reduce using rule 100 (expression -> var_ref .)
+    TYPEDEF         reduce using rule 100 (expression -> var_ref .)
+    ID              reduce using rule 100 (expression -> var_ref .)
+    NOT             reduce using rule 100 (expression -> var_ref .)
+    INT             reduce using rule 100 (expression -> var_ref .)
+    FLOAT           reduce using rule 100 (expression -> var_ref .)
+    NULL            reduce using rule 100 (expression -> var_ref .)
+    REGEX           reduce using rule 100 (expression -> var_ref .)
+    TRUE            reduce using rule 100 (expression -> var_ref .)
+    FALSE           reduce using rule 100 (expression -> var_ref .)
+    STRING          reduce using rule 100 (expression -> var_ref .)
+    FSTRING         reduce using rule 100 (expression -> var_ref .)
+    RSTRING         reduce using rule 100 (expression -> var_ref .)
+    MLS             reduce using rule 100 (expression -> var_ref .)
+    {               reduce using rule 100 (expression -> var_ref .)
+    $end            reduce using rule 100 (expression -> var_ref .)
+    ,               reduce using rule 100 (expression -> var_ref .)
+    ]               reduce using rule 100 (expression -> var_ref .)
+    ELSE            reduce using rule 100 (expression -> var_ref .)
+    ELIF            reduce using rule 100 (expression -> var_ref .)
+    END             reduce using rule 100 (expression -> var_ref .)
+    }               reduce using rule 100 (expression -> var_ref .)
+    .               shift and go to state 140
+    [               shift and go to state 94
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 100 (expression -> var_ref .) ]
 
-    empty                          shift and go to state 100
 
-state 89
+state 84
 
-    (116) boolean_expression -> ID . IS DEFINED
-    (183) ns_ref -> ID .
+    (115) boolean_expression -> ID . IS DEFINED
+    (182) ns_ref -> ID .
 
-    IS              shift and go to state 63
-    (               reduce using rule 183 (ns_ref -> ID .)
-    SEP             reduce using rule 183 (ns_ref -> ID .)
-    .               reduce using rule 183 (ns_ref -> ID .)
-    [               reduce using rule 183 (ns_ref -> ID .)
-    )               reduce using rule 183 (ns_ref -> ID .)
-    CMP_OP          reduce using rule 183 (ns_ref -> ID .)
-    IN              reduce using rule 183 (ns_ref -> ID .)
-    AND             reduce using rule 183 (ns_ref -> ID .)
-    OR              reduce using rule 183 (ns_ref -> ID .)
-    NOT             reduce using rule 183 (ns_ref -> ID .)
-    ?               reduce using rule 183 (ns_ref -> ID .)
-    :               reduce using rule 183 (ns_ref -> ID .)
-    ENTITY          reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENT       reduce using rule 183 (ns_ref -> ID .)
-    IMPLEMENTATION  reduce using rule 183 (ns_ref -> ID .)
-    INDEX           reduce using rule 183 (ns_ref -> ID .)
-    IMPORT          reduce using rule 183 (ns_ref -> ID .)
-    CID             reduce using rule 183 (ns_ref -> ID .)
-    FOR             reduce using rule 183 (ns_ref -> ID .)
-    IF              reduce using rule 183 (ns_ref -> ID .)
-    TYPEDEF         reduce using rule 183 (ns_ref -> ID .)
-    ID              reduce using rule 183 (ns_ref -> ID .)
-    INT             reduce using rule 183 (ns_ref -> ID .)
-    FLOAT           reduce using rule 183 (ns_ref -> ID .)
-    NULL            reduce using rule 183 (ns_ref -> ID .)
-    REGEX           reduce using rule 183 (ns_ref -> ID .)
-    TRUE            reduce using rule 183 (ns_ref -> ID .)
-    FALSE           reduce using rule 183 (ns_ref -> ID .)
-    STRING          reduce using rule 183 (ns_ref -> ID .)
-    FSTRING         reduce using rule 183 (ns_ref -> ID .)
-    RSTRING         reduce using rule 183 (ns_ref -> ID .)
-    MLS             reduce using rule 183 (ns_ref -> ID .)
-    {               reduce using rule 183 (ns_ref -> ID .)
-    $end            reduce using rule 183 (ns_ref -> ID .)
-    ,               reduce using rule 183 (ns_ref -> ID .)
-    ]               reduce using rule 183 (ns_ref -> ID .)
-    ELSE            reduce using rule 183 (ns_ref -> ID .)
-    ELIF            reduce using rule 183 (ns_ref -> ID .)
-    END             reduce using rule 183 (ns_ref -> ID .)
-    }               reduce using rule 183 (ns_ref -> ID .)
-    =               reduce using rule 183 (ns_ref -> ID .)
-    PEQ             reduce using rule 183 (ns_ref -> ID .)
+    IS              shift and go to state 62
+    (               reduce using rule 182 (ns_ref -> ID .)
+    SEP             reduce using rule 182 (ns_ref -> ID .)
+    .               reduce using rule 182 (ns_ref -> ID .)
+    [               reduce using rule 182 (ns_ref -> ID .)
+    )               reduce using rule 182 (ns_ref -> ID .)
+    CMP_OP          reduce using rule 182 (ns_ref -> ID .)
+    IN              reduce using rule 182 (ns_ref -> ID .)
+    AND             reduce using rule 182 (ns_ref -> ID .)
+    OR              reduce using rule 182 (ns_ref -> ID .)
+    ?               reduce using rule 182 (ns_ref -> ID .)
+    :               reduce using rule 182 (ns_ref -> ID .)
+    ENTITY          reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENT       reduce using rule 182 (ns_ref -> ID .)
+    IMPLEMENTATION  reduce using rule 182 (ns_ref -> ID .)
+    INDEX           reduce using rule 182 (ns_ref -> ID .)
+    IMPORT          reduce using rule 182 (ns_ref -> ID .)
+    CID             reduce using rule 182 (ns_ref -> ID .)
+    FOR             reduce using rule 182 (ns_ref -> ID .)
+    IF              reduce using rule 182 (ns_ref -> ID .)
+    TYPEDEF         reduce using rule 182 (ns_ref -> ID .)
+    ID              reduce using rule 182 (ns_ref -> ID .)
+    NOT             reduce using rule 182 (ns_ref -> ID .)
+    INT             reduce using rule 182 (ns_ref -> ID .)
+    FLOAT           reduce using rule 182 (ns_ref -> ID .)
+    NULL            reduce using rule 182 (ns_ref -> ID .)
+    REGEX           reduce using rule 182 (ns_ref -> ID .)
+    TRUE            reduce using rule 182 (ns_ref -> ID .)
+    FALSE           reduce using rule 182 (ns_ref -> ID .)
+    STRING          reduce using rule 182 (ns_ref -> ID .)
+    FSTRING         reduce using rule 182 (ns_ref -> ID .)
+    RSTRING         reduce using rule 182 (ns_ref -> ID .)
+    MLS             reduce using rule 182 (ns_ref -> ID .)
+    {               reduce using rule 182 (ns_ref -> ID .)
+    $end            reduce using rule 182 (ns_ref -> ID .)
+    ,               reduce using rule 182 (ns_ref -> ID .)
+    ]               reduce using rule 182 (ns_ref -> ID .)
+    ELSE            reduce using rule 182 (ns_ref -> ID .)
+    ELIF            reduce using rule 182 (ns_ref -> ID .)
+    END             reduce using rule 182 (ns_ref -> ID .)
+    }               reduce using rule 182 (ns_ref -> ID .)
+    =               reduce using rule 182 (ns_ref -> ID .)
+    PEQ             reduce using rule 182 (ns_ref -> ID .)
 
 
-state 90
+state 85
 
-    (123) function_call -> ns_ref . ( function_param_list )
-    (174) var_ref -> ns_ref . empty
-    (182) ns_ref -> ns_ref . SEP ID
-    (176) class_ref -> ns_ref . SEP CID
-    (2) empty -> .
-
-    (               shift and go to state 96
-    SEP             shift and go to state 152
-    .               reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    )               reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ,               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    }               reduce using rule 2 (empty -> .)
+    (122) function_call -> ns_ref . ( function_param_list )
+    (173) var_ref -> ns_ref .
+    (181) ns_ref -> ns_ref . SEP ID
+    (175) class_ref -> ns_ref . SEP CID
+
+    (               shift and go to state 90
+    .               reduce using rule 173 (var_ref -> ns_ref .)
+    [               reduce using rule 173 (var_ref -> ns_ref .)
+    )               reduce using rule 173 (var_ref -> ns_ref .)
+    CMP_OP          reduce using rule 173 (var_ref -> ns_ref .)
+    IN              reduce using rule 173 (var_ref -> ns_ref .)
+    AND             reduce using rule 173 (var_ref -> ns_ref .)
+    OR              reduce using rule 173 (var_ref -> ns_ref .)
+    ?               reduce using rule 173 (var_ref -> ns_ref .)
+    :               reduce using rule 173 (var_ref -> ns_ref .)
+    ENTITY          reduce using rule 173 (var_ref -> ns_ref .)
+    IMPLEMENT       reduce using rule 173 (var_ref -> ns_ref .)
+    IMPLEMENTATION  reduce using rule 173 (var_ref -> ns_ref .)
+    INDEX           reduce using rule 173 (var_ref -> ns_ref .)
+    IMPORT          reduce using rule 173 (var_ref -> ns_ref .)
+    CID             reduce using rule 173 (var_ref -> ns_ref .)
+    FOR             reduce using rule 173 (var_ref -> ns_ref .)
+    IF              reduce using rule 173 (var_ref -> ns_ref .)
+    TYPEDEF         reduce using rule 173 (var_ref -> ns_ref .)
+    ID              reduce using rule 173 (var_ref -> ns_ref .)
+    NOT             reduce using rule 173 (var_ref -> ns_ref .)
+    INT             reduce using rule 173 (var_ref -> ns_ref .)
+    FLOAT           reduce using rule 173 (var_ref -> ns_ref .)
+    NULL            reduce using rule 173 (var_ref -> ns_ref .)
+    REGEX           reduce using rule 173 (var_ref -> ns_ref .)
+    TRUE            reduce using rule 173 (var_ref -> ns_ref .)
+    FALSE           reduce using rule 173 (var_ref -> ns_ref .)
+    STRING          reduce using rule 173 (var_ref -> ns_ref .)
+    FSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    RSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    MLS             reduce using rule 173 (var_ref -> ns_ref .)
+    {               reduce using rule 173 (var_ref -> ns_ref .)
+    $end            reduce using rule 173 (var_ref -> ns_ref .)
+    ,               reduce using rule 173 (var_ref -> ns_ref .)
+    ]               reduce using rule 173 (var_ref -> ns_ref .)
+    ELSE            reduce using rule 173 (var_ref -> ns_ref .)
+    ELIF            reduce using rule 173 (var_ref -> ns_ref .)
+    END             reduce using rule 173 (var_ref -> ns_ref .)
+    }               reduce using rule 173 (var_ref -> ns_ref .)
+    SEP             shift and go to state 141
 
-  ! (               [ reduce using rule 2 (empty -> .) ]
+  ! (               [ reduce using rule 173 (var_ref -> ns_ref .) ]
 
-    empty                          shift and go to state 95
 
-state 91
+state 86
 
-    (124) function_call -> attr_ref . ( function_param_list )
-    (172) var_ref -> attr_ref . empty
-    (119) map_lookup -> attr_ref . [ operand ]
-    (140) index_lookup -> attr_ref . [ param_list ]
-    (2) empty -> .
-
-    (               shift and go to state 110
-    [               shift and go to state 111
-    .               reduce using rule 2 (empty -> .)
-    )               reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ,               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    }               reduce using rule 2 (empty -> .)
+    (123) function_call -> attr_ref . ( function_param_list )
+    (171) var_ref -> attr_ref .
+    (118) map_lookup -> attr_ref . [ operand ]
+    (139) index_lookup -> attr_ref . [ param_list ]
+
+    (               shift and go to state 101
+    .               reduce using rule 171 (var_ref -> attr_ref .)
+    )               reduce using rule 171 (var_ref -> attr_ref .)
+    CMP_OP          reduce using rule 171 (var_ref -> attr_ref .)
+    IN              reduce using rule 171 (var_ref -> attr_ref .)
+    AND             reduce using rule 171 (var_ref -> attr_ref .)
+    OR              reduce using rule 171 (var_ref -> attr_ref .)
+    ?               reduce using rule 171 (var_ref -> attr_ref .)
+    :               reduce using rule 171 (var_ref -> attr_ref .)
+    ENTITY          reduce using rule 171 (var_ref -> attr_ref .)
+    IMPLEMENT       reduce using rule 171 (var_ref -> attr_ref .)
+    IMPLEMENTATION  reduce using rule 171 (var_ref -> attr_ref .)
+    INDEX           reduce using rule 171 (var_ref -> attr_ref .)
+    IMPORT          reduce using rule 171 (var_ref -> attr_ref .)
+    CID             reduce using rule 171 (var_ref -> attr_ref .)
+    FOR             reduce using rule 171 (var_ref -> attr_ref .)
+    IF              reduce using rule 171 (var_ref -> attr_ref .)
+    TYPEDEF         reduce using rule 171 (var_ref -> attr_ref .)
+    ID              reduce using rule 171 (var_ref -> attr_ref .)
+    NOT             reduce using rule 171 (var_ref -> attr_ref .)
+    INT             reduce using rule 171 (var_ref -> attr_ref .)
+    FLOAT           reduce using rule 171 (var_ref -> attr_ref .)
+    NULL            reduce using rule 171 (var_ref -> attr_ref .)
+    REGEX           reduce using rule 171 (var_ref -> attr_ref .)
+    TRUE            reduce using rule 171 (var_ref -> attr_ref .)
+    FALSE           reduce using rule 171 (var_ref -> attr_ref .)
+    STRING          reduce using rule 171 (var_ref -> attr_ref .)
+    FSTRING         reduce using rule 171 (var_ref -> attr_ref .)
+    RSTRING         reduce using rule 171 (var_ref -> attr_ref .)
+    MLS             reduce using rule 171 (var_ref -> attr_ref .)
+    {               reduce using rule 171 (var_ref -> attr_ref .)
+    $end            reduce using rule 171 (var_ref -> attr_ref .)
+    ,               reduce using rule 171 (var_ref -> attr_ref .)
+    ]               reduce using rule 171 (var_ref -> attr_ref .)
+    ELSE            reduce using rule 171 (var_ref -> attr_ref .)
+    ELIF            reduce using rule 171 (var_ref -> attr_ref .)
+    END             reduce using rule 171 (var_ref -> attr_ref .)
+    }               reduce using rule 171 (var_ref -> attr_ref .)
+    [               shift and go to state 102
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
-  ! (               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 171 (var_ref -> attr_ref .) ]
+  ! (               [ reduce using rule 171 (var_ref -> attr_ref .) ]
 
-    empty                          shift and go to state 109
 
-state 92
+state 87
 
-    (122) constructor -> class_ref . ( param_list )
-    (139) index_lookup -> class_ref . [ param_list ]
+    (121) constructor -> class_ref . ( param_list )
+    (138) index_lookup -> class_ref . [ param_list ]
 
-    (               shift and go to state 71
-    [               shift and go to state 72
+    (               shift and go to state 70
+    [               shift and go to state 71
 
 
-state 93
+state 88
 
     (15) import -> IMPORT ns_ref .
     (16) import -> IMPORT ns_ref . AS ID
-    (182) ns_ref -> ns_ref . SEP ID
+    (181) ns_ref -> ns_ref . SEP ID
 
     ENTITY          reduce using rule 15 (import -> IMPORT ns_ref .)
     IMPLEMENT       reduce using rule 15 (import -> IMPORT ns_ref .)
     IMPLEMENTATION  reduce using rule 15 (import -> IMPORT ns_ref .)
     INDEX           reduce using rule 15 (import -> IMPORT ns_ref .)
     IMPORT          reduce using rule 15 (import -> IMPORT ns_ref .)
     CID             reduce using rule 15 (import -> IMPORT ns_ref .)
@@ -3901,1103 +3722,897 @@
     STRING          reduce using rule 15 (import -> IMPORT ns_ref .)
     FSTRING         reduce using rule 15 (import -> IMPORT ns_ref .)
     RSTRING         reduce using rule 15 (import -> IMPORT ns_ref .)
     MLS             reduce using rule 15 (import -> IMPORT ns_ref .)
     [               reduce using rule 15 (import -> IMPORT ns_ref .)
     {               reduce using rule 15 (import -> IMPORT ns_ref .)
     $end            reduce using rule 15 (import -> IMPORT ns_ref .)
-    AS              shift and go to state 153
-    SEP             shift and go to state 154
-
-
-state 94
+    AS              shift and go to state 142
+    SEP             shift and go to state 143
 
-    (176) class_ref -> ns_ref SEP . CID
-    (182) ns_ref -> ns_ref SEP . ID
 
-    CID             shift and go to state 155
-    ID              shift and go to state 156
-
-
-state 95
+state 89
 
-    (174) var_ref -> ns_ref empty .
+    (175) class_ref -> ns_ref SEP . CID
+    (181) ns_ref -> ns_ref SEP . ID
 
-    .               reduce using rule 174 (var_ref -> ns_ref empty .)
-    =               reduce using rule 174 (var_ref -> ns_ref empty .)
-    PEQ             reduce using rule 174 (var_ref -> ns_ref empty .)
-    [               reduce using rule 174 (var_ref -> ns_ref empty .)
-    CMP_OP          reduce using rule 174 (var_ref -> ns_ref empty .)
-    IN              reduce using rule 174 (var_ref -> ns_ref empty .)
-    AND             reduce using rule 174 (var_ref -> ns_ref empty .)
-    OR              reduce using rule 174 (var_ref -> ns_ref empty .)
-    NOT             reduce using rule 174 (var_ref -> ns_ref empty .)
-    ?               reduce using rule 174 (var_ref -> ns_ref empty .)
-    ENTITY          reduce using rule 174 (var_ref -> ns_ref empty .)
-    IMPLEMENT       reduce using rule 174 (var_ref -> ns_ref empty .)
-    IMPLEMENTATION  reduce using rule 174 (var_ref -> ns_ref empty .)
-    INDEX           reduce using rule 174 (var_ref -> ns_ref empty .)
-    IMPORT          reduce using rule 174 (var_ref -> ns_ref empty .)
-    CID             reduce using rule 174 (var_ref -> ns_ref empty .)
-    FOR             reduce using rule 174 (var_ref -> ns_ref empty .)
-    IF              reduce using rule 174 (var_ref -> ns_ref empty .)
-    (               reduce using rule 174 (var_ref -> ns_ref empty .)
-    TYPEDEF         reduce using rule 174 (var_ref -> ns_ref empty .)
-    ID              reduce using rule 174 (var_ref -> ns_ref empty .)
-    INT             reduce using rule 174 (var_ref -> ns_ref empty .)
-    FLOAT           reduce using rule 174 (var_ref -> ns_ref empty .)
-    NULL            reduce using rule 174 (var_ref -> ns_ref empty .)
-    REGEX           reduce using rule 174 (var_ref -> ns_ref empty .)
-    TRUE            reduce using rule 174 (var_ref -> ns_ref empty .)
-    FALSE           reduce using rule 174 (var_ref -> ns_ref empty .)
-    STRING          reduce using rule 174 (var_ref -> ns_ref empty .)
-    FSTRING         reduce using rule 174 (var_ref -> ns_ref empty .)
-    RSTRING         reduce using rule 174 (var_ref -> ns_ref empty .)
-    MLS             reduce using rule 174 (var_ref -> ns_ref empty .)
-    {               reduce using rule 174 (var_ref -> ns_ref empty .)
-    $end            reduce using rule 174 (var_ref -> ns_ref empty .)
-    )               reduce using rule 174 (var_ref -> ns_ref empty .)
-    :               reduce using rule 174 (var_ref -> ns_ref empty .)
-    ,               reduce using rule 174 (var_ref -> ns_ref empty .)
-    ]               reduce using rule 174 (var_ref -> ns_ref empty .)
-    ELSE            reduce using rule 174 (var_ref -> ns_ref empty .)
-    ELIF            reduce using rule 174 (var_ref -> ns_ref empty .)
-    END             reduce using rule 174 (var_ref -> ns_ref empty .)
-    }               reduce using rule 174 (var_ref -> ns_ref empty .)
+    CID             shift and go to state 144
+    ID              shift and go to state 145
 
 
-state 96
+state 90
 
-    (123) function_call -> ns_ref ( . function_param_list )
-    (165) function_param_list -> . function_param_list_empty
-    (167) function_param_list -> . function_param_list_element empty function_param_list_empty
-    (168) function_param_list -> . function_param_list_element , function_param_list
-    (166) function_param_list_empty -> . empty
-    (163) function_param_list_element -> . param_list_element
-    (164) function_param_list_element -> . operand
-    (2) empty -> .
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (118) operand -> . expression empty
-    (156) wrapped_kwargs -> . * * operand
+    (122) function_call -> ns_ref ( . function_param_list )
+    (164) function_param_list -> . function_param_list_empty
+    (166) function_param_list -> . function_param_list_element empty function_param_list_empty
+    (167) function_param_list -> . function_param_list_element , function_param_list
+    (165) function_param_list_empty -> . empty
+    (162) function_param_list_element -> . param_list_element
+    (163) function_param_list_element -> . operand
+    (14) empty -> .
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (117) operand -> . expression
+    (155) wrapped_kwargs -> . * * operand
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    )               reduce using rule 2 (empty -> .)
-    ID              shift and go to state 163
-    *               shift and go to state 139
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    ns_ref                         shift and go to state 90
-    function_param_list            shift and go to state 157
-    function_param_list_empty      shift and go to state 158
-    function_param_list_element    shift and go to state 159
-    empty                          shift and go to state 160
-    param_list_element             shift and go to state 161
-    operand                        shift and go to state 162
-    wrapped_kwargs                 shift and go to state 138
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    )               reduce using rule 14 (empty -> .)
+    ID              shift and go to state 152
+    *               shift and go to state 129
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    ns_ref                         shift and go to state 85
+    function_param_list            shift and go to state 146
+    function_param_list_empty      shift and go to state 147
+    function_param_list_element    shift and go to state 148
+    empty                          shift and go to state 149
+    param_list_element             shift and go to state 150
+    operand                        shift and go to state 151
+    wrapped_kwargs                 shift and go to state 128
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 97
+state 91
 
-    (177) class_ref -> var_ref . . CID
-    (115) boolean_expression -> var_ref . . ID IS DEFINED
-    (173) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
+    (114) boolean_expression -> var_ref . . ID IS DEFINED
+    (172) attr_ref -> var_ref . . ID
 
-    CID             shift and go to state 165
-    ID              shift and go to state 166
+    CID             shift and go to state 154
+    ID              shift and go to state 155
 
 
-state 98
+state 92
 
     (23) assign -> var_ref = . operand
-    (118) operand -> . expression empty
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    var_ref                        shift and go to state 88
-    operand                        shift and go to state 167
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    var_ref                        shift and go to state 83
+    operand                        shift and go to state 156
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 99
+state 93
 
     (24) assign -> var_ref PEQ . operand
-    (118) operand -> . expression empty
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    var_ref                        shift and go to state 88
-    operand                        shift and go to state 168
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    var_ref                        shift and go to state 83
+    operand                        shift and go to state 157
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 100
-
-    (100) expression -> var_ref empty .
-
-    CMP_OP          reduce using rule 100 (expression -> var_ref empty .)
-    IN              reduce using rule 100 (expression -> var_ref empty .)
-    AND             reduce using rule 100 (expression -> var_ref empty .)
-    OR              reduce using rule 100 (expression -> var_ref empty .)
-    NOT             reduce using rule 100 (expression -> var_ref empty .)
-    ?               reduce using rule 100 (expression -> var_ref empty .)
-    ENTITY          reduce using rule 100 (expression -> var_ref empty .)
-    IMPLEMENT       reduce using rule 100 (expression -> var_ref empty .)
-    IMPLEMENTATION  reduce using rule 100 (expression -> var_ref empty .)
-    INDEX           reduce using rule 100 (expression -> var_ref empty .)
-    IMPORT          reduce using rule 100 (expression -> var_ref empty .)
-    CID             reduce using rule 100 (expression -> var_ref empty .)
-    FOR             reduce using rule 100 (expression -> var_ref empty .)
-    IF              reduce using rule 100 (expression -> var_ref empty .)
-    (               reduce using rule 100 (expression -> var_ref empty .)
-    TYPEDEF         reduce using rule 100 (expression -> var_ref empty .)
-    ID              reduce using rule 100 (expression -> var_ref empty .)
-    INT             reduce using rule 100 (expression -> var_ref empty .)
-    FLOAT           reduce using rule 100 (expression -> var_ref empty .)
-    NULL            reduce using rule 100 (expression -> var_ref empty .)
-    REGEX           reduce using rule 100 (expression -> var_ref empty .)
-    TRUE            reduce using rule 100 (expression -> var_ref empty .)
-    FALSE           reduce using rule 100 (expression -> var_ref empty .)
-    STRING          reduce using rule 100 (expression -> var_ref empty .)
-    FSTRING         reduce using rule 100 (expression -> var_ref empty .)
-    RSTRING         reduce using rule 100 (expression -> var_ref empty .)
-    MLS             reduce using rule 100 (expression -> var_ref empty .)
-    [               reduce using rule 100 (expression -> var_ref empty .)
-    {               reduce using rule 100 (expression -> var_ref empty .)
-    $end            reduce using rule 100 (expression -> var_ref empty .)
-    )               reduce using rule 100 (expression -> var_ref empty .)
-    :               reduce using rule 100 (expression -> var_ref empty .)
-    ,               reduce using rule 100 (expression -> var_ref empty .)
-    ]               reduce using rule 100 (expression -> var_ref empty .)
-    ELSE            reduce using rule 100 (expression -> var_ref empty .)
-    ELIF            reduce using rule 100 (expression -> var_ref empty .)
-    END             reduce using rule 100 (expression -> var_ref empty .)
-    }               reduce using rule 100 (expression -> var_ref empty .)
-
-
-state 101
+state 94
 
-    (120) map_lookup -> var_ref [ . operand ]
-    (118) operand -> . expression empty
+    (119) map_lookup -> var_ref [ . operand ]
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    var_ref                        shift and go to state 88
-    operand                        shift and go to state 169
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    var_ref                        shift and go to state 83
+    operand                        shift and go to state 158
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 102
+state 95
 
     (26) if -> IF if_body . END
 
-    END             shift and go to state 170
+    END             shift and go to state 159
 
 
-state 103
+state 96
 
     (27) if_body -> expression . : stmt_list if_next
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-
-    :               shift and go to state 171
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
+    (140) conditional_expression -> expression . ? expression : expression
 
+    :               shift and go to state 160
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
-state 104
 
-    (105) expression -> map_lookup empty .
-
-    CMP_OP          reduce using rule 105 (expression -> map_lookup empty .)
-    IN              reduce using rule 105 (expression -> map_lookup empty .)
-    AND             reduce using rule 105 (expression -> map_lookup empty .)
-    OR              reduce using rule 105 (expression -> map_lookup empty .)
-    NOT             reduce using rule 105 (expression -> map_lookup empty .)
-    ?               reduce using rule 105 (expression -> map_lookup empty .)
-    ENTITY          reduce using rule 105 (expression -> map_lookup empty .)
-    IMPLEMENT       reduce using rule 105 (expression -> map_lookup empty .)
-    IMPLEMENTATION  reduce using rule 105 (expression -> map_lookup empty .)
-    INDEX           reduce using rule 105 (expression -> map_lookup empty .)
-    IMPORT          reduce using rule 105 (expression -> map_lookup empty .)
-    CID             reduce using rule 105 (expression -> map_lookup empty .)
-    FOR             reduce using rule 105 (expression -> map_lookup empty .)
-    IF              reduce using rule 105 (expression -> map_lookup empty .)
-    (               reduce using rule 105 (expression -> map_lookup empty .)
-    TYPEDEF         reduce using rule 105 (expression -> map_lookup empty .)
-    ID              reduce using rule 105 (expression -> map_lookup empty .)
-    INT             reduce using rule 105 (expression -> map_lookup empty .)
-    FLOAT           reduce using rule 105 (expression -> map_lookup empty .)
-    NULL            reduce using rule 105 (expression -> map_lookup empty .)
-    REGEX           reduce using rule 105 (expression -> map_lookup empty .)
-    TRUE            reduce using rule 105 (expression -> map_lookup empty .)
-    FALSE           reduce using rule 105 (expression -> map_lookup empty .)
-    STRING          reduce using rule 105 (expression -> map_lookup empty .)
-    FSTRING         reduce using rule 105 (expression -> map_lookup empty .)
-    RSTRING         reduce using rule 105 (expression -> map_lookup empty .)
-    MLS             reduce using rule 105 (expression -> map_lookup empty .)
-    [               reduce using rule 105 (expression -> map_lookup empty .)
-    {               reduce using rule 105 (expression -> map_lookup empty .)
-    $end            reduce using rule 105 (expression -> map_lookup empty .)
-    )               reduce using rule 105 (expression -> map_lookup empty .)
-    :               reduce using rule 105 (expression -> map_lookup empty .)
-    ,               reduce using rule 105 (expression -> map_lookup empty .)
-    ]               reduce using rule 105 (expression -> map_lookup empty .)
-    ELSE            reduce using rule 105 (expression -> map_lookup empty .)
-    ELIF            reduce using rule 105 (expression -> map_lookup empty .)
-    END             reduce using rule 105 (expression -> map_lookup empty .)
-    }               reduce using rule 105 (expression -> map_lookup empty .)
-
-
-state 105
+state 97
 
-    (117) boolean_expression -> map_lookup IS . DEFINED
+    (116) boolean_expression -> map_lookup IS . DEFINED
 
-    DEFINED         shift and go to state 172
+    DEFINED         shift and go to state 161
 
 
-state 106
+state 98
 
-    (121) map_lookup -> map_lookup [ . operand ]
-    (118) operand -> . expression empty
+    (120) map_lookup -> map_lookup [ . operand ]
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    map_lookup                     shift and go to state 43
-    operand                        shift and go to state 173
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
 
-state 107
+    map_lookup                     shift and go to state 42
+    operand                        shift and go to state 162
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
+
+state 99
 
     (94) typedef_inner -> TYPEDEF ID . AS ns_ref MATCHING expression
 
-    AS              shift and go to state 174
+    AS              shift and go to state 163
 
 
-state 108
+state 100
 
     (95) typedef_inner -> TYPEDEF CID . AS constructor
 
-    AS              shift and go to state 175
+    AS              shift and go to state 164
 
 
-state 109
-
-    (172) var_ref -> attr_ref empty .
-
-    .               reduce using rule 172 (var_ref -> attr_ref empty .)
-    =               reduce using rule 172 (var_ref -> attr_ref empty .)
-    PEQ             reduce using rule 172 (var_ref -> attr_ref empty .)
-    [               reduce using rule 172 (var_ref -> attr_ref empty .)
-    CMP_OP          reduce using rule 172 (var_ref -> attr_ref empty .)
-    IN              reduce using rule 172 (var_ref -> attr_ref empty .)
-    AND             reduce using rule 172 (var_ref -> attr_ref empty .)
-    OR              reduce using rule 172 (var_ref -> attr_ref empty .)
-    NOT             reduce using rule 172 (var_ref -> attr_ref empty .)
-    ?               reduce using rule 172 (var_ref -> attr_ref empty .)
-    ENTITY          reduce using rule 172 (var_ref -> attr_ref empty .)
-    IMPLEMENT       reduce using rule 172 (var_ref -> attr_ref empty .)
-    IMPLEMENTATION  reduce using rule 172 (var_ref -> attr_ref empty .)
-    INDEX           reduce using rule 172 (var_ref -> attr_ref empty .)
-    IMPORT          reduce using rule 172 (var_ref -> attr_ref empty .)
-    CID             reduce using rule 172 (var_ref -> attr_ref empty .)
-    FOR             reduce using rule 172 (var_ref -> attr_ref empty .)
-    IF              reduce using rule 172 (var_ref -> attr_ref empty .)
-    (               reduce using rule 172 (var_ref -> attr_ref empty .)
-    TYPEDEF         reduce using rule 172 (var_ref -> attr_ref empty .)
-    ID              reduce using rule 172 (var_ref -> attr_ref empty .)
-    INT             reduce using rule 172 (var_ref -> attr_ref empty .)
-    FLOAT           reduce using rule 172 (var_ref -> attr_ref empty .)
-    NULL            reduce using rule 172 (var_ref -> attr_ref empty .)
-    REGEX           reduce using rule 172 (var_ref -> attr_ref empty .)
-    TRUE            reduce using rule 172 (var_ref -> attr_ref empty .)
-    FALSE           reduce using rule 172 (var_ref -> attr_ref empty .)
-    STRING          reduce using rule 172 (var_ref -> attr_ref empty .)
-    FSTRING         reduce using rule 172 (var_ref -> attr_ref empty .)
-    RSTRING         reduce using rule 172 (var_ref -> attr_ref empty .)
-    MLS             reduce using rule 172 (var_ref -> attr_ref empty .)
-    {               reduce using rule 172 (var_ref -> attr_ref empty .)
-    $end            reduce using rule 172 (var_ref -> attr_ref empty .)
-    )               reduce using rule 172 (var_ref -> attr_ref empty .)
-    :               reduce using rule 172 (var_ref -> attr_ref empty .)
-    ,               reduce using rule 172 (var_ref -> attr_ref empty .)
-    ]               reduce using rule 172 (var_ref -> attr_ref empty .)
-    ELSE            reduce using rule 172 (var_ref -> attr_ref empty .)
-    ELIF            reduce using rule 172 (var_ref -> attr_ref empty .)
-    END             reduce using rule 172 (var_ref -> attr_ref empty .)
-    }               reduce using rule 172 (var_ref -> attr_ref empty .)
-
-
-state 110
+state 101
 
-    (124) function_call -> attr_ref ( . function_param_list )
-    (165) function_param_list -> . function_param_list_empty
-    (167) function_param_list -> . function_param_list_element empty function_param_list_empty
-    (168) function_param_list -> . function_param_list_element , function_param_list
-    (166) function_param_list_empty -> . empty
-    (163) function_param_list_element -> . param_list_element
-    (164) function_param_list_element -> . operand
-    (2) empty -> .
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (118) operand -> . expression empty
-    (156) wrapped_kwargs -> . * * operand
+    (123) function_call -> attr_ref ( . function_param_list )
+    (164) function_param_list -> . function_param_list_empty
+    (166) function_param_list -> . function_param_list_element empty function_param_list_empty
+    (167) function_param_list -> . function_param_list_element , function_param_list
+    (165) function_param_list_empty -> . empty
+    (162) function_param_list_element -> . param_list_element
+    (163) function_param_list_element -> . operand
+    (14) empty -> .
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (117) operand -> . expression
+    (155) wrapped_kwargs -> . * * operand
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    )               reduce using rule 2 (empty -> .)
-    ID              shift and go to state 163
-    *               shift and go to state 139
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    attr_ref                       shift and go to state 91
-    function_param_list            shift and go to state 176
-    function_param_list_empty      shift and go to state 158
-    function_param_list_element    shift and go to state 159
-    empty                          shift and go to state 160
-    param_list_element             shift and go to state 161
-    operand                        shift and go to state 162
-    wrapped_kwargs                 shift and go to state 138
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    )               reduce using rule 14 (empty -> .)
+    ID              shift and go to state 152
+    *               shift and go to state 129
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    attr_ref                       shift and go to state 86
+    function_param_list            shift and go to state 165
+    function_param_list_empty      shift and go to state 147
+    function_param_list_element    shift and go to state 148
+    empty                          shift and go to state 149
+    param_list_element             shift and go to state 150
+    operand                        shift and go to state 151
+    wrapped_kwargs                 shift and go to state 128
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    class_ref                      shift and go to state 87
 
-state 111
+state 102
 
-    (119) map_lookup -> attr_ref [ . operand ]
-    (140) index_lookup -> attr_ref [ . param_list ]
-    (118) operand -> . expression empty
-    (159) param_list -> . param_list_empty
-    (161) param_list -> . param_list_element empty param_list_empty
-    (162) param_list -> . param_list_element , param_list
+    (118) map_lookup -> attr_ref [ . operand ]
+    (139) index_lookup -> attr_ref [ . param_list ]
+    (117) operand -> . expression
+    (158) param_list -> . param_list_empty
+    (160) param_list -> . param_list_element empty param_list_empty
+    (161) param_list -> . param_list_element , param_list
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (160) param_list_empty -> . empty
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
+    (159) param_list_empty -> . empty
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (2) empty -> .
-    (156) wrapped_kwargs -> . * * operand
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    ID              shift and go to state 163
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    ]               reduce using rule 2 (empty -> .)
-    *               shift and go to state 139
-    CID             shift and go to state 17
-
-    attr_ref                       shift and go to state 91
-    operand                        shift and go to state 177
-    param_list                     shift and go to state 178
-    expression                     shift and go to state 164
-    empty                          shift and go to state 136
-    param_list_empty               shift and go to state 134
-    param_list_element             shift and go to state 135
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    wrapped_kwargs                 shift and go to state 138
-    ns_ref                         shift and go to state 90
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (14) empty -> .
+    (155) wrapped_kwargs -> . * * operand
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    ID              shift and go to state 152
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    ]               reduce using rule 14 (empty -> .)
+    *               shift and go to state 129
+    CID             shift and go to state 16
+
+    attr_ref                       shift and go to state 86
+    operand                        shift and go to state 166
+    param_list                     shift and go to state 167
+    expression                     shift and go to state 153
+    param_list_empty               shift and go to state 124
+    param_list_element             shift and go to state 125
+    empty                          shift and go to state 126
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    wrapped_kwargs                 shift and go to state 128
+    ns_ref                         shift and go to state 85
+    class_ref                      shift and go to state 87
 
-state 112
+state 103
 
-    (114) boolean_expression -> NOT expression .
+    (113) boolean_expression -> NOT expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
-    CMP_OP          reduce using rule 114 (boolean_expression -> NOT expression .)
-    AND             reduce using rule 114 (boolean_expression -> NOT expression .)
-    OR              reduce using rule 114 (boolean_expression -> NOT expression .)
-    NOT             reduce using rule 114 (boolean_expression -> NOT expression .)
-    ?               reduce using rule 114 (boolean_expression -> NOT expression .)
-    ENTITY          reduce using rule 114 (boolean_expression -> NOT expression .)
-    IMPLEMENT       reduce using rule 114 (boolean_expression -> NOT expression .)
-    IMPLEMENTATION  reduce using rule 114 (boolean_expression -> NOT expression .)
-    INDEX           reduce using rule 114 (boolean_expression -> NOT expression .)
-    IMPORT          reduce using rule 114 (boolean_expression -> NOT expression .)
-    CID             reduce using rule 114 (boolean_expression -> NOT expression .)
-    FOR             reduce using rule 114 (boolean_expression -> NOT expression .)
-    IF              reduce using rule 114 (boolean_expression -> NOT expression .)
-    (               reduce using rule 114 (boolean_expression -> NOT expression .)
-    TYPEDEF         reduce using rule 114 (boolean_expression -> NOT expression .)
-    ID              reduce using rule 114 (boolean_expression -> NOT expression .)
-    INT             reduce using rule 114 (boolean_expression -> NOT expression .)
-    FLOAT           reduce using rule 114 (boolean_expression -> NOT expression .)
-    NULL            reduce using rule 114 (boolean_expression -> NOT expression .)
-    REGEX           reduce using rule 114 (boolean_expression -> NOT expression .)
-    TRUE            reduce using rule 114 (boolean_expression -> NOT expression .)
-    FALSE           reduce using rule 114 (boolean_expression -> NOT expression .)
-    STRING          reduce using rule 114 (boolean_expression -> NOT expression .)
-    FSTRING         reduce using rule 114 (boolean_expression -> NOT expression .)
-    RSTRING         reduce using rule 114 (boolean_expression -> NOT expression .)
-    MLS             reduce using rule 114 (boolean_expression -> NOT expression .)
-    [               reduce using rule 114 (boolean_expression -> NOT expression .)
-    {               reduce using rule 114 (boolean_expression -> NOT expression .)
-    $end            reduce using rule 114 (boolean_expression -> NOT expression .)
-    )               reduce using rule 114 (boolean_expression -> NOT expression .)
-    :               reduce using rule 114 (boolean_expression -> NOT expression .)
-    ,               reduce using rule 114 (boolean_expression -> NOT expression .)
-    ]               reduce using rule 114 (boolean_expression -> NOT expression .)
-    ELSE            reduce using rule 114 (boolean_expression -> NOT expression .)
-    ELIF            reduce using rule 114 (boolean_expression -> NOT expression .)
-    END             reduce using rule 114 (boolean_expression -> NOT expression .)
-    }               reduce using rule 114 (boolean_expression -> NOT expression .)
-    IN              shift and go to state 75
-
-  ! IN              [ reduce using rule 114 (boolean_expression -> NOT expression .) ]
-  ! CMP_OP          [ shift and go to state 74 ]
-  ! AND             [ shift and go to state 76 ]
-  ! OR              [ shift and go to state 77 ]
-  ! NOT             [ shift and go to state 78 ]
-  ! ?               [ shift and go to state 79 ]
+    CMP_OP          reduce using rule 113 (boolean_expression -> NOT expression .)
+    AND             reduce using rule 113 (boolean_expression -> NOT expression .)
+    OR              reduce using rule 113 (boolean_expression -> NOT expression .)
+    ?               reduce using rule 113 (boolean_expression -> NOT expression .)
+    ENTITY          reduce using rule 113 (boolean_expression -> NOT expression .)
+    IMPLEMENT       reduce using rule 113 (boolean_expression -> NOT expression .)
+    IMPLEMENTATION  reduce using rule 113 (boolean_expression -> NOT expression .)
+    INDEX           reduce using rule 113 (boolean_expression -> NOT expression .)
+    IMPORT          reduce using rule 113 (boolean_expression -> NOT expression .)
+    CID             reduce using rule 113 (boolean_expression -> NOT expression .)
+    FOR             reduce using rule 113 (boolean_expression -> NOT expression .)
+    IF              reduce using rule 113 (boolean_expression -> NOT expression .)
+    (               reduce using rule 113 (boolean_expression -> NOT expression .)
+    TYPEDEF         reduce using rule 113 (boolean_expression -> NOT expression .)
+    ID              reduce using rule 113 (boolean_expression -> NOT expression .)
+    NOT             reduce using rule 113 (boolean_expression -> NOT expression .)
+    INT             reduce using rule 113 (boolean_expression -> NOT expression .)
+    FLOAT           reduce using rule 113 (boolean_expression -> NOT expression .)
+    NULL            reduce using rule 113 (boolean_expression -> NOT expression .)
+    REGEX           reduce using rule 113 (boolean_expression -> NOT expression .)
+    TRUE            reduce using rule 113 (boolean_expression -> NOT expression .)
+    FALSE           reduce using rule 113 (boolean_expression -> NOT expression .)
+    STRING          reduce using rule 113 (boolean_expression -> NOT expression .)
+    FSTRING         reduce using rule 113 (boolean_expression -> NOT expression .)
+    RSTRING         reduce using rule 113 (boolean_expression -> NOT expression .)
+    MLS             reduce using rule 113 (boolean_expression -> NOT expression .)
+    [               reduce using rule 113 (boolean_expression -> NOT expression .)
+    {               reduce using rule 113 (boolean_expression -> NOT expression .)
+    $end            reduce using rule 113 (boolean_expression -> NOT expression .)
+    )               reduce using rule 113 (boolean_expression -> NOT expression .)
+    :               reduce using rule 113 (boolean_expression -> NOT expression .)
+    ,               reduce using rule 113 (boolean_expression -> NOT expression .)
+    ]               reduce using rule 113 (boolean_expression -> NOT expression .)
+    ELSE            reduce using rule 113 (boolean_expression -> NOT expression .)
+    ELIF            reduce using rule 113 (boolean_expression -> NOT expression .)
+    END             reduce using rule 113 (boolean_expression -> NOT expression .)
+    }               reduce using rule 113 (boolean_expression -> NOT expression .)
+    IN              shift and go to state 73
+
+  ! IN              [ reduce using rule 113 (boolean_expression -> NOT expression .) ]
+  ! CMP_OP          [ shift and go to state 72 ]
+  ! AND             [ shift and go to state 74 ]
+  ! OR              [ shift and go to state 75 ]
+  ! ?               [ shift and go to state 76 ]
 
 
-state 113
+state 104
 
-    (125) list_def -> [ operand_list . ]
+    (124) list_def -> [ operand_list . ]
 
-    ]               shift and go to state 179
+    ]               shift and go to state 168
 
 
-state 114
+state 105
 
-    (126) list_comprehension -> [ expression . list_comprehension_for list_comprehension_guard ]
-    (118) operand -> expression . empty
+    (125) list_comprehension -> [ expression . list_comprehension_for list_comprehension_guard ]
+    (117) operand -> expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (128) list_comprehension_for -> . FOR ID IN expression list_comprehension_for_empty
-    (129) list_comprehension_for -> . FOR ID IN expression list_comprehension_for
-    (2) empty -> .
-
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    FOR             shift and go to state 182
-    ,               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-
-    list_comprehension_for         shift and go to state 180
-    empty                          shift and go to state 181
-
-state 115
+    (140) conditional_expression -> expression . ? expression : expression
+    (127) list_comprehension_for -> . FOR ID IN expression list_comprehension_for_empty
+    (128) list_comprehension_for -> . FOR ID IN expression list_comprehension_for
+
+    ,               reduce using rule 117 (operand -> expression .)
+    ]               reduce using rule 117 (operand -> expression .)
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
+    FOR             shift and go to state 170
 
-    (169) operand_list -> operand . , operand_list
-    (170) operand_list -> operand .
+    list_comprehension_for         shift and go to state 169
 
-    ,               shift and go to state 183
-    ]               reduce using rule 170 (operand_list -> operand .)
-    CID             reduce using rule 170 (operand_list -> operand .)
-    ID              reduce using rule 170 (operand_list -> operand .)
-
-
-state 116
+state 106
 
-    (171) operand_list -> empty .
+    (168) operand_list -> operand . , operand_list
+    (169) operand_list -> operand .
 
-    ]               reduce using rule 171 (operand_list -> empty .)
-    CID             reduce using rule 171 (operand_list -> empty .)
-    ID              reduce using rule 171 (operand_list -> empty .)
+    ,               shift and go to state 171
+    ]               reduce using rule 169 (operand_list -> operand .)
+    CID             reduce using rule 169 (operand_list -> operand .)
+    ID              reduce using rule 169 (operand_list -> operand .)
 
 
-state 117
+state 107
 
-    (138) map_def -> { pair_list . }
+    (137) map_def -> { pair_list . }
 
-    }               shift and go to state 184
+    }               shift and go to state 172
 
 
-state 118
+state 108
 
-    (134) pair_list -> dict_key . : operand , pair_list
-    (135) pair_list -> dict_key . : operand empty pair_list_empty
+    (133) pair_list -> dict_key . : operand , pair_list
+    (134) pair_list -> dict_key . : operand empty pair_list_empty
 
-    :               shift and go to state 185
+    :               shift and go to state 173
 
 
-state 119
+state 109
 
-    (137) pair_list_empty -> empty .
+    (136) pair_list_empty -> empty .
 
-    }               reduce using rule 137 (pair_list_empty -> empty .)
+    }               reduce using rule 136 (pair_list_empty -> empty .)
 
 
-state 120
+state 110
 
-    (136) pair_list -> pair_list_empty .
+    (135) pair_list -> pair_list_empty .
 
-    }               reduce using rule 136 (pair_list -> pair_list_empty .)
+    }               reduce using rule 135 (pair_list -> pair_list_empty .)
 
 
-state 121
+state 111
 
-    (132) dict_key -> RSTRING .
+    (131) dict_key -> RSTRING .
 
-    :               reduce using rule 132 (dict_key -> RSTRING .)
+    :               reduce using rule 131 (dict_key -> RSTRING .)
 
 
-state 122
+state 112
 
-    (133) dict_key -> STRING .
+    (132) dict_key -> STRING .
 
-    :               reduce using rule 133 (dict_key -> STRING .)
+    :               reduce using rule 132 (dict_key -> STRING .)
 
 
-state 123
+state 113
 
     (31) entity_def -> ENTITY CID : . entity_body_outer
     (35) entity_body_outer -> . MLS entity_body END
     (36) entity_body_outer -> . entity_body END
     (37) entity_body_outer -> . END
     (38) entity_body_outer -> . MLS END
     (39) entity_body -> . entity_body attr
@@ -5025,57 +4640,57 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    MLS             shift and go to state 187
-    END             shift and go to state 189
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    entity_body_outer              shift and go to state 186
-    entity_body                    shift and go to state 188
-    attr                           shift and go to state 190
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    MLS             shift and go to state 175
+    END             shift and go to state 177
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    entity_body_outer              shift and go to state 174
+    entity_body                    shift and go to state 176
+    attr                           shift and go to state 178
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 124
+state 114
 
     (33) entity_def -> ENTITY CID EXTENDS . class_ref_list : entity_body_outer
-    (178) class_ref_list -> . class_ref , class_ref_list
-    (179) class_ref_list -> . var_ref , class_ref_list
-    (180) class_ref_list -> . class_ref
-    (181) class_ref_list -> . var_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref_list                 shift and go to state 197
-    class_ref                      shift and go to state 198
-    var_ref                        shift and go to state 199
-    ns_ref                         shift and go to state 200
-    attr_ref                       shift and go to state 68
+    (177) class_ref_list -> . class_ref , class_ref_list
+    (178) class_ref_list -> . var_ref , class_ref_list
+    (179) class_ref_list -> . class_ref
+    (180) class_ref_list -> . var_ref
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref_list                 shift and go to state 185
+    class_ref                      shift and go to state 186
+    var_ref                        shift and go to state 187
+    ns_ref                         shift and go to state 188
+    attr_ref                       shift and go to state 67
 
-state 125
+state 115
 
     (32) entity_def -> ENTITY ID : . entity_body_outer
     (35) entity_body_outer -> . MLS entity_body END
     (36) entity_body_outer -> . entity_body END
     (37) entity_body_outer -> . END
     (38) entity_body_outer -> . MLS END
     (39) entity_body -> . entity_body attr
@@ -5103,235 +4718,234 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    MLS             shift and go to state 187
-    END             shift and go to state 189
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    entity_body_outer              shift and go to state 201
-    entity_body                    shift and go to state 188
-    attr                           shift and go to state 190
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    MLS             shift and go to state 175
+    END             shift and go to state 177
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    entity_body_outer              shift and go to state 189
+    entity_body                    shift and go to state 176
+    attr                           shift and go to state 178
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 126
+state 116
 
     (34) entity_def -> ENTITY ID EXTENDS . class_ref_list : entity_body_outer
-    (178) class_ref_list -> . class_ref , class_ref_list
-    (179) class_ref_list -> . var_ref , class_ref_list
-    (180) class_ref_list -> . class_ref
-    (181) class_ref_list -> . var_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref_list                 shift and go to state 202
-    class_ref                      shift and go to state 198
-    var_ref                        shift and go to state 199
-    ns_ref                         shift and go to state 200
-    attr_ref                       shift and go to state 68
+    (177) class_ref_list -> . class_ref , class_ref_list
+    (178) class_ref_list -> . var_ref , class_ref_list
+    (179) class_ref_list -> . class_ref
+    (180) class_ref_list -> . var_ref
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref_list                 shift and go to state 190
+    class_ref                      shift and go to state 186
+    var_ref                        shift and go to state 187
+    ns_ref                         shift and go to state 188
+    attr_ref                       shift and go to state 67
 
-state 127
+state 117
 
-    (116) boolean_expression -> ID IS DEFINED .
+    (115) boolean_expression -> ID IS DEFINED .
 
-    CMP_OP          reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    IN              reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    AND             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    OR              reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    NOT             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ?               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ENTITY          reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    IMPLEMENT       reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    IMPLEMENTATION  reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    INDEX           reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    IMPORT          reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    CID             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    FOR             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    IF              reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    (               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    TYPEDEF         reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ID              reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    INT             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    FLOAT           reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    NULL            reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    REGEX           reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    TRUE            reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    FALSE           reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    STRING          reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    FSTRING         reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    RSTRING         reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    MLS             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    [               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    {               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    $end            reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    )               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    :               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ,               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ]               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ELSE            reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    ELIF            reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    END             reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
-    }               reduce using rule 116 (boolean_expression -> ID IS DEFINED .)
+    CMP_OP          reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    IN              reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    AND             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    OR              reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ?               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ENTITY          reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    IMPLEMENT       reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    IMPLEMENTATION  reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    INDEX           reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    IMPORT          reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    CID             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    FOR             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    IF              reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    (               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    TYPEDEF         reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ID              reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    NOT             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    INT             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    FLOAT           reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    NULL            reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    REGEX           reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    TRUE            reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    FALSE           reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    STRING          reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    FSTRING         reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    RSTRING         reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    MLS             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    [               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    {               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    $end            reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    )               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    :               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ,               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ]               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ELSE            reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    ELIF            reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    END             reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
+    }               reduce using rule 115 (boolean_expression -> ID IS DEFINED .)
 
 
-state 128
+state 118
 
     (71) implement_def -> IMPLEMENT class_ref USING . implement_ns_list empty
     (72) implement_def -> IMPLEMENT class_ref USING . implement_ns_list MLS
     (73) implement_def -> IMPLEMENT class_ref USING . implement_ns_list WHEN expression empty
     (74) implement_def -> IMPLEMENT class_ref USING . implement_ns_list WHEN expression MLS
     (68) implement_ns_list -> . ns_ref
     (69) implement_ns_list -> . PARENTS
     (70) implement_ns_list -> . implement_ns_list , implement_ns_list
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    PARENTS         shift and go to state 205
-    ID              shift and go to state 67
+    PARENTS         shift and go to state 193
+    ID              shift and go to state 66
 
-    implement_ns_list              shift and go to state 203
-    ns_ref                         shift and go to state 204
+    implement_ns_list              shift and go to state 191
+    ns_ref                         shift and go to state 192
 
-state 129
+state 119
 
-    (177) class_ref -> var_ref . . CID
-    (173) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
+    (172) attr_ref -> var_ref . . ID
 
-    CID             shift and go to state 165
-    ID              shift and go to state 206
+    CID             shift and go to state 154
+    ID              shift and go to state 194
 
 
-state 130
+state 120
 
     (80) relation -> class_ref ID multi . REL multi class_ref ID
     (81) relation -> class_ref ID multi . REL multi class_ref ID MLS
 
-    REL             shift and go to state 207
+    REL             shift and go to state 195
 
 
-state 131
+state 121
 
     (88) multi -> [ . INT ]
     (89) multi -> [ . INT : ]
     (90) multi -> [ . INT : INT ]
     (91) multi -> [ . : INT ]
 
-    INT             shift and go to state 208
-    :               shift and go to state 209
+    INT             shift and go to state 196
+    :               shift and go to state 197
 
 
-state 132
+state 122
 
     (84) relation_def -> class_ref . ID . multi REL class_ref . ID multi
     (85) relation_def -> class_ref . ID . multi REL class_ref
     (86) relation_def -> class_ref . ID . multi operand_list class_ref . ID multi
     (87) relation_def -> class_ref . ID . multi operand_list class_ref
     (88) multi -> . [ INT ]
     (89) multi -> . [ INT : ]
     (90) multi -> . [ INT : INT ]
     (91) multi -> . [ : INT ]
 
-    [               shift and go to state 131
+    [               shift and go to state 121
 
-    multi                          shift and go to state 210
+    multi                          shift and go to state 198
 
-state 133
+state 123
 
-    (122) constructor -> class_ref ( param_list . )
+    (121) constructor -> class_ref ( param_list . )
 
-    )               shift and go to state 211
+    )               shift and go to state 199
 
 
-state 134
+state 124
 
-    (159) param_list -> param_list_empty .
+    (158) param_list -> param_list_empty .
 
-    )               reduce using rule 159 (param_list -> param_list_empty .)
-    ]               reduce using rule 159 (param_list -> param_list_empty .)
+    )               reduce using rule 158 (param_list -> param_list_empty .)
+    ]               reduce using rule 158 (param_list -> param_list_empty .)
 
 
-state 135
+state 125
 
-    (161) param_list -> param_list_element . empty param_list_empty
-    (162) param_list -> param_list_element . , param_list
-    (2) empty -> .
+    (160) param_list -> param_list_element . empty param_list_empty
+    (161) param_list -> param_list_element . , param_list
+    (14) empty -> .
+
+    ,               shift and go to state 201
+    )               reduce using rule 14 (empty -> .)
+    ]               reduce using rule 14 (empty -> .)
 
-    ,               shift and go to state 213
-    )               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
+    empty                          shift and go to state 200
 
-    empty                          shift and go to state 212
-
-state 136
+state 126
 
-    (160) param_list_empty -> empty .
+    (159) param_list_empty -> empty .
 
-    )               reduce using rule 160 (param_list_empty -> empty .)
-    ]               reduce using rule 160 (param_list_empty -> empty .)
+    )               reduce using rule 159 (param_list_empty -> empty .)
+    ]               reduce using rule 159 (param_list_empty -> empty .)
 
 
-state 137
+state 127
 
-    (157) param_list_element -> ID . = operand
+    (156) param_list_element -> ID . = operand
 
-    =               shift and go to state 214
+    =               shift and go to state 202
 
 
-state 138
+state 128
 
-    (158) param_list_element -> wrapped_kwargs .
+    (157) param_list_element -> wrapped_kwargs .
 
-    ,               reduce using rule 158 (param_list_element -> wrapped_kwargs .)
-    )               reduce using rule 158 (param_list_element -> wrapped_kwargs .)
-    ]               reduce using rule 158 (param_list_element -> wrapped_kwargs .)
+    ,               reduce using rule 157 (param_list_element -> wrapped_kwargs .)
+    )               reduce using rule 157 (param_list_element -> wrapped_kwargs .)
+    ]               reduce using rule 157 (param_list_element -> wrapped_kwargs .)
 
 
-state 139
+state 129
 
-    (156) wrapped_kwargs -> * . * operand
+    (155) wrapped_kwargs -> * . * operand
 
-    *               shift and go to state 215
+    *               shift and go to state 203
 
 
-state 140
+state 130
 
-    (139) index_lookup -> class_ref [ param_list . ]
+    (138) index_lookup -> class_ref [ param_list . ]
 
-    ]               shift and go to state 216
+    ]               shift and go to state 204
 
 
-state 141
+state 131
 
     (109) boolean_expression -> expression CMP_OP expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
     CMP_OP          reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     AND             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     OR              reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ?               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ENTITY          reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     IMPLEMENT       reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
@@ -5340,14 +4954,15 @@
     IMPORT          reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     CID             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     FOR             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     IF              reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     (               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     TYPEDEF         reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ID              reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
+    NOT             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     INT             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     FLOAT           reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     NULL            reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     REGEX           reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     TRUE            reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     FALSE           reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     STRING          reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
@@ -5361,52 +4976,49 @@
     :               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ,               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ]               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ELSE            reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     ELIF            reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     END             reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
     }               reduce using rule 109 (boolean_expression -> expression CMP_OP expression .)
-    IN              shift and go to state 75
-    NOT             shift and go to state 78
+    IN              shift and go to state 73
 
   ! IN              [ reduce using rule 109 (boolean_expression -> expression CMP_OP expression .) ]
-  ! NOT             [ reduce using rule 109 (boolean_expression -> expression CMP_OP expression .) ]
-  ! CMP_OP          [ shift and go to state 74 ]
-  ! AND             [ shift and go to state 76 ]
-  ! OR              [ shift and go to state 77 ]
-  ! ?               [ shift and go to state 79 ]
+  ! CMP_OP          [ shift and go to state 72 ]
+  ! AND             [ shift and go to state 74 ]
+  ! OR              [ shift and go to state 75 ]
+  ! ?               [ shift and go to state 76 ]
 
 
-state 142
+state 132
 
     (110) boolean_expression -> expression IN expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
     CMP_OP          reduce using rule 110 (boolean_expression -> expression IN expression .)
     IN              reduce using rule 110 (boolean_expression -> expression IN expression .)
     AND             reduce using rule 110 (boolean_expression -> expression IN expression .)
     OR              reduce using rule 110 (boolean_expression -> expression IN expression .)
-    NOT             reduce using rule 110 (boolean_expression -> expression IN expression .)
     ?               reduce using rule 110 (boolean_expression -> expression IN expression .)
     ENTITY          reduce using rule 110 (boolean_expression -> expression IN expression .)
     IMPLEMENT       reduce using rule 110 (boolean_expression -> expression IN expression .)
     IMPLEMENTATION  reduce using rule 110 (boolean_expression -> expression IN expression .)
     INDEX           reduce using rule 110 (boolean_expression -> expression IN expression .)
     IMPORT          reduce using rule 110 (boolean_expression -> expression IN expression .)
     CID             reduce using rule 110 (boolean_expression -> expression IN expression .)
     FOR             reduce using rule 110 (boolean_expression -> expression IN expression .)
     IF              reduce using rule 110 (boolean_expression -> expression IN expression .)
     (               reduce using rule 110 (boolean_expression -> expression IN expression .)
     TYPEDEF         reduce using rule 110 (boolean_expression -> expression IN expression .)
     ID              reduce using rule 110 (boolean_expression -> expression IN expression .)
+    NOT             reduce using rule 110 (boolean_expression -> expression IN expression .)
     INT             reduce using rule 110 (boolean_expression -> expression IN expression .)
     FLOAT           reduce using rule 110 (boolean_expression -> expression IN expression .)
     NULL            reduce using rule 110 (boolean_expression -> expression IN expression .)
     REGEX           reduce using rule 110 (boolean_expression -> expression IN expression .)
     TRUE            reduce using rule 110 (boolean_expression -> expression IN expression .)
     FALSE           reduce using rule 110 (boolean_expression -> expression IN expression .)
     STRING          reduce using rule 110 (boolean_expression -> expression IN expression .)
@@ -5421,31 +5033,29 @@
     ,               reduce using rule 110 (boolean_expression -> expression IN expression .)
     ]               reduce using rule 110 (boolean_expression -> expression IN expression .)
     ELSE            reduce using rule 110 (boolean_expression -> expression IN expression .)
     ELIF            reduce using rule 110 (boolean_expression -> expression IN expression .)
     END             reduce using rule 110 (boolean_expression -> expression IN expression .)
     }               reduce using rule 110 (boolean_expression -> expression IN expression .)
 
-  ! CMP_OP          [ shift and go to state 74 ]
-  ! IN              [ shift and go to state 75 ]
-  ! AND             [ shift and go to state 76 ]
-  ! OR              [ shift and go to state 77 ]
-  ! NOT             [ shift and go to state 78 ]
-  ! ?               [ shift and go to state 79 ]
+  ! CMP_OP          [ shift and go to state 72 ]
+  ! IN              [ shift and go to state 73 ]
+  ! AND             [ shift and go to state 74 ]
+  ! OR              [ shift and go to state 75 ]
+  ! ?               [ shift and go to state 76 ]
 
 
-state 143
+state 133
 
     (111) boolean_expression -> expression AND expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
     AND             reduce using rule 111 (boolean_expression -> expression AND expression .)
     OR              reduce using rule 111 (boolean_expression -> expression AND expression .)
     ?               reduce using rule 111 (boolean_expression -> expression AND expression .)
     ENTITY          reduce using rule 111 (boolean_expression -> expression AND expression .)
     IMPLEMENT       reduce using rule 111 (boolean_expression -> expression AND expression .)
     IMPLEMENTATION  reduce using rule 111 (boolean_expression -> expression AND expression .)
@@ -5453,14 +5063,15 @@
     IMPORT          reduce using rule 111 (boolean_expression -> expression AND expression .)
     CID             reduce using rule 111 (boolean_expression -> expression AND expression .)
     FOR             reduce using rule 111 (boolean_expression -> expression AND expression .)
     IF              reduce using rule 111 (boolean_expression -> expression AND expression .)
     (               reduce using rule 111 (boolean_expression -> expression AND expression .)
     TYPEDEF         reduce using rule 111 (boolean_expression -> expression AND expression .)
     ID              reduce using rule 111 (boolean_expression -> expression AND expression .)
+    NOT             reduce using rule 111 (boolean_expression -> expression AND expression .)
     INT             reduce using rule 111 (boolean_expression -> expression AND expression .)
     FLOAT           reduce using rule 111 (boolean_expression -> expression AND expression .)
     NULL            reduce using rule 111 (boolean_expression -> expression AND expression .)
     REGEX           reduce using rule 111 (boolean_expression -> expression AND expression .)
     TRUE            reduce using rule 111 (boolean_expression -> expression AND expression .)
     FALSE           reduce using rule 111 (boolean_expression -> expression AND expression .)
     STRING          reduce using rule 111 (boolean_expression -> expression AND expression .)
@@ -5474,49 +5085,47 @@
     :               reduce using rule 111 (boolean_expression -> expression AND expression .)
     ,               reduce using rule 111 (boolean_expression -> expression AND expression .)
     ]               reduce using rule 111 (boolean_expression -> expression AND expression .)
     ELSE            reduce using rule 111 (boolean_expression -> expression AND expression .)
     ELIF            reduce using rule 111 (boolean_expression -> expression AND expression .)
     END             reduce using rule 111 (boolean_expression -> expression AND expression .)
     }               reduce using rule 111 (boolean_expression -> expression AND expression .)
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    NOT             shift and go to state 78
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
 
   ! CMP_OP          [ reduce using rule 111 (boolean_expression -> expression AND expression .) ]
   ! IN              [ reduce using rule 111 (boolean_expression -> expression AND expression .) ]
-  ! NOT             [ reduce using rule 111 (boolean_expression -> expression AND expression .) ]
-  ! AND             [ shift and go to state 76 ]
-  ! OR              [ shift and go to state 77 ]
-  ! ?               [ shift and go to state 79 ]
+  ! AND             [ shift and go to state 74 ]
+  ! OR              [ shift and go to state 75 ]
+  ! ?               [ shift and go to state 76 ]
 
 
-state 144
+state 134
 
     (112) boolean_expression -> expression OR expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
     OR              reduce using rule 112 (boolean_expression -> expression OR expression .)
     ?               reduce using rule 112 (boolean_expression -> expression OR expression .)
     ENTITY          reduce using rule 112 (boolean_expression -> expression OR expression .)
     IMPLEMENT       reduce using rule 112 (boolean_expression -> expression OR expression .)
     IMPLEMENTATION  reduce using rule 112 (boolean_expression -> expression OR expression .)
     INDEX           reduce using rule 112 (boolean_expression -> expression OR expression .)
     IMPORT          reduce using rule 112 (boolean_expression -> expression OR expression .)
     CID             reduce using rule 112 (boolean_expression -> expression OR expression .)
     FOR             reduce using rule 112 (boolean_expression -> expression OR expression .)
     IF              reduce using rule 112 (boolean_expression -> expression OR expression .)
     (               reduce using rule 112 (boolean_expression -> expression OR expression .)
     TYPEDEF         reduce using rule 112 (boolean_expression -> expression OR expression .)
     ID              reduce using rule 112 (boolean_expression -> expression OR expression .)
+    NOT             reduce using rule 112 (boolean_expression -> expression OR expression .)
     INT             reduce using rule 112 (boolean_expression -> expression OR expression .)
     FLOAT           reduce using rule 112 (boolean_expression -> expression OR expression .)
     NULL            reduce using rule 112 (boolean_expression -> expression OR expression .)
     REGEX           reduce using rule 112 (boolean_expression -> expression OR expression .)
     TRUE            reduce using rule 112 (boolean_expression -> expression OR expression .)
     FALSE           reduce using rule 112 (boolean_expression -> expression OR expression .)
     STRING          reduce using rule 112 (boolean_expression -> expression OR expression .)
@@ -5530,275 +5139,182 @@
     :               reduce using rule 112 (boolean_expression -> expression OR expression .)
     ,               reduce using rule 112 (boolean_expression -> expression OR expression .)
     ]               reduce using rule 112 (boolean_expression -> expression OR expression .)
     ELSE            reduce using rule 112 (boolean_expression -> expression OR expression .)
     ELIF            reduce using rule 112 (boolean_expression -> expression OR expression .)
     END             reduce using rule 112 (boolean_expression -> expression OR expression .)
     }               reduce using rule 112 (boolean_expression -> expression OR expression .)
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    NOT             shift and go to state 78
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
 
   ! CMP_OP          [ reduce using rule 112 (boolean_expression -> expression OR expression .) ]
   ! IN              [ reduce using rule 112 (boolean_expression -> expression OR expression .) ]
   ! AND             [ reduce using rule 112 (boolean_expression -> expression OR expression .) ]
-  ! NOT             [ reduce using rule 112 (boolean_expression -> expression OR expression .) ]
-  ! OR              [ shift and go to state 77 ]
-  ! ?               [ shift and go to state 79 ]
-
+  ! OR              [ shift and go to state 75 ]
+  ! ?               [ shift and go to state 76 ]
 
-state 145
 
-    (113) boolean_expression -> expression NOT IN . expression
-    (97) expression -> . boolean_expression
-    (98) expression -> . constant
-    (99) expression -> . function_call
-    (100) expression -> . var_ref empty
-    (101) expression -> . constructor
-    (102) expression -> . list_def
-    (103) expression -> . list_comprehension
-    (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
-    (106) expression -> . index_lookup
-    (107) expression -> . conditional_expression
-    (108) expression -> . ( expression )
-    (109) boolean_expression -> . expression CMP_OP expression
-    (110) boolean_expression -> . expression IN expression
-    (111) boolean_expression -> . expression AND expression
-    (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 217
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
-
-state 146
+state 135
 
-    (141) conditional_expression -> expression ? expression . : expression
+    (140) conditional_expression -> expression ? expression . : expression
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
-    :               shift and go to state 218
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
+    :               shift and go to state 205
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
 
-state 147
+state 136
 
     (75) implementation_def -> IMPLEMENTATION ID FOR . class_ref implementation
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 219
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 206
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 148
+state 137
 
     (25) for -> FOR ID IN . operand : block
-    (118) operand -> . expression empty
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    operand                        shift and go to state 220
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    operand                        shift and go to state 207
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 149
+state 138
 
     (96) index -> INDEX class_ref ( . id_list )
-    (184) id_list -> . ID , id_list
-    (185) id_list -> . ID
+    (183) id_list -> . ID , id_list
+    (184) id_list -> . ID
 
-    ID              shift and go to state 222
+    ID              shift and go to state 209
 
-    id_list                        shift and go to state 221
+    id_list                        shift and go to state 208
 
-state 150
+state 139
 
     (108) expression -> ( expression ) .
 
     CMP_OP          reduce using rule 108 (expression -> ( expression ) .)
     IN              reduce using rule 108 (expression -> ( expression ) .)
     AND             reduce using rule 108 (expression -> ( expression ) .)
     OR              reduce using rule 108 (expression -> ( expression ) .)
-    NOT             reduce using rule 108 (expression -> ( expression ) .)
     ?               reduce using rule 108 (expression -> ( expression ) .)
     ENTITY          reduce using rule 108 (expression -> ( expression ) .)
     IMPLEMENT       reduce using rule 108 (expression -> ( expression ) .)
     IMPLEMENTATION  reduce using rule 108 (expression -> ( expression ) .)
     INDEX           reduce using rule 108 (expression -> ( expression ) .)
     IMPORT          reduce using rule 108 (expression -> ( expression ) .)
     CID             reduce using rule 108 (expression -> ( expression ) .)
     FOR             reduce using rule 108 (expression -> ( expression ) .)
     IF              reduce using rule 108 (expression -> ( expression ) .)
     (               reduce using rule 108 (expression -> ( expression ) .)
     TYPEDEF         reduce using rule 108 (expression -> ( expression ) .)
     ID              reduce using rule 108 (expression -> ( expression ) .)
+    NOT             reduce using rule 108 (expression -> ( expression ) .)
     INT             reduce using rule 108 (expression -> ( expression ) .)
     FLOAT           reduce using rule 108 (expression -> ( expression ) .)
     NULL            reduce using rule 108 (expression -> ( expression ) .)
     REGEX           reduce using rule 108 (expression -> ( expression ) .)
     TRUE            reduce using rule 108 (expression -> ( expression ) .)
     FALSE           reduce using rule 108 (expression -> ( expression ) .)
     STRING          reduce using rule 108 (expression -> ( expression ) .)
@@ -5814,343 +5330,337 @@
     ]               reduce using rule 108 (expression -> ( expression ) .)
     ELSE            reduce using rule 108 (expression -> ( expression ) .)
     ELIF            reduce using rule 108 (expression -> ( expression ) .)
     END             reduce using rule 108 (expression -> ( expression ) .)
     }               reduce using rule 108 (expression -> ( expression ) .)
 
 
-state 151
+state 140
 
-    (115) boolean_expression -> var_ref . . ID IS DEFINED
-    (173) attr_ref -> var_ref . . ID
-    (177) class_ref -> var_ref . . CID
+    (114) boolean_expression -> var_ref . . ID IS DEFINED
+    (172) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
 
-    ID              shift and go to state 166
-    CID             shift and go to state 165
+    ID              shift and go to state 155
+    CID             shift and go to state 154
 
 
-state 152
+state 141
 
-    (182) ns_ref -> ns_ref SEP . ID
-    (176) class_ref -> ns_ref SEP . CID
+    (181) ns_ref -> ns_ref SEP . ID
+    (175) class_ref -> ns_ref SEP . CID
 
-    ID              shift and go to state 156
-    CID             shift and go to state 155
+    ID              shift and go to state 145
+    CID             shift and go to state 144
 
 
-state 153
+state 142
 
     (16) import -> IMPORT ns_ref AS . ID
 
-    ID              shift and go to state 223
+    ID              shift and go to state 210
 
 
-state 154
+state 143
 
-    (182) ns_ref -> ns_ref SEP . ID
+    (181) ns_ref -> ns_ref SEP . ID
 
-    ID              shift and go to state 156
+    ID              shift and go to state 145
 
 
-state 155
+state 144
 
-    (176) class_ref -> ns_ref SEP CID .
+    (175) class_ref -> ns_ref SEP CID .
 
-    ID              reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    .               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    (               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    [               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    USING           reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    ,               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    :               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    MLS             reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    ENTITY          reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    IMPLEMENT       reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    IMPLEMENTATION  reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    INDEX           reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    IMPORT          reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    CID             reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    FOR             reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    IF              reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    TYPEDEF         reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    NOT             reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    INT             reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    FLOAT           reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    NULL            reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    REGEX           reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    TRUE            reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    FALSE           reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    STRING          reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    FSTRING         reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    RSTRING         reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    {               reduce using rule 176 (class_ref -> ns_ref SEP CID .)
-    $end            reduce using rule 176 (class_ref -> ns_ref SEP CID .)
+    ID              reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    .               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    (               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    [               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    USING           reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    ,               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    :               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    MLS             reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    ENTITY          reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    IMPLEMENT       reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    IMPLEMENTATION  reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    INDEX           reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    IMPORT          reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    CID             reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    FOR             reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    IF              reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    TYPEDEF         reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    NOT             reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    INT             reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    FLOAT           reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    NULL            reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    REGEX           reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    TRUE            reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    FALSE           reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    STRING          reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    FSTRING         reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    RSTRING         reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    {               reduce using rule 175 (class_ref -> ns_ref SEP CID .)
+    $end            reduce using rule 175 (class_ref -> ns_ref SEP CID .)
 
 
-state 156
+state 145
 
-    (182) ns_ref -> ns_ref SEP ID .
+    (181) ns_ref -> ns_ref SEP ID .
 
-    SEP             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    (               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    .               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    =               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    PEQ             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    [               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    CMP_OP          reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    IN              reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    AND             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    OR              reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    NOT             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ?               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ENTITY          reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    IMPLEMENT       reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    IMPLEMENTATION  reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    INDEX           reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    IMPORT          reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    CID             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    FOR             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    IF              reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    TYPEDEF         reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ID              reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    INT             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    FLOAT           reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    NULL            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    REGEX           reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    TRUE            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    FALSE           reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    STRING          reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    FSTRING         reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    RSTRING         reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    MLS             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    {               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    $end            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    )               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    AS              reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    :               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ,               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ]               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ELSE            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    ELIF            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    END             reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    }               reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    WHEN            reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
-    MATCHING        reduce using rule 182 (ns_ref -> ns_ref SEP ID .)
+    SEP             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    (               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    .               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    =               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    PEQ             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    [               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    CMP_OP          reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    IN              reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    AND             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    OR              reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ?               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ENTITY          reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    IMPLEMENT       reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    IMPLEMENTATION  reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    INDEX           reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    IMPORT          reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    CID             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    FOR             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    IF              reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    TYPEDEF         reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ID              reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    NOT             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    INT             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    FLOAT           reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    NULL            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    REGEX           reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    TRUE            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    FALSE           reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    STRING          reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    FSTRING         reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    RSTRING         reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    MLS             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    {               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    $end            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    )               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    AS              reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    :               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ,               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ]               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ELSE            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    ELIF            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    END             reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    }               reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    WHEN            reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
+    MATCHING        reduce using rule 181 (ns_ref -> ns_ref SEP ID .)
 
 
-state 157
+state 146
 
-    (123) function_call -> ns_ref ( function_param_list . )
+    (122) function_call -> ns_ref ( function_param_list . )
 
-    )               shift and go to state 224
+    )               shift and go to state 211
 
 
-state 158
+state 147
 
-    (165) function_param_list -> function_param_list_empty .
+    (164) function_param_list -> function_param_list_empty .
 
-    )               reduce using rule 165 (function_param_list -> function_param_list_empty .)
+    )               reduce using rule 164 (function_param_list -> function_param_list_empty .)
 
 
-state 159
+state 148
 
-    (167) function_param_list -> function_param_list_element . empty function_param_list_empty
-    (168) function_param_list -> function_param_list_element . , function_param_list
-    (2) empty -> .
+    (166) function_param_list -> function_param_list_element . empty function_param_list_empty
+    (167) function_param_list -> function_param_list_element . , function_param_list
+    (14) empty -> .
 
-    ,               shift and go to state 226
-    )               reduce using rule 2 (empty -> .)
+    ,               shift and go to state 213
+    )               reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 225
+    empty                          shift and go to state 212
 
-state 160
+state 149
 
-    (166) function_param_list_empty -> empty .
+    (165) function_param_list_empty -> empty .
 
-    )               reduce using rule 166 (function_param_list_empty -> empty .)
+    )               reduce using rule 165 (function_param_list_empty -> empty .)
 
 
-state 161
+state 150
 
-    (163) function_param_list_element -> param_list_element .
+    (162) function_param_list_element -> param_list_element .
 
-    ,               reduce using rule 163 (function_param_list_element -> param_list_element .)
-    )               reduce using rule 163 (function_param_list_element -> param_list_element .)
+    ,               reduce using rule 162 (function_param_list_element -> param_list_element .)
+    )               reduce using rule 162 (function_param_list_element -> param_list_element .)
 
 
-state 162
+state 151
 
-    (164) function_param_list_element -> operand .
+    (163) function_param_list_element -> operand .
 
-    ,               reduce using rule 164 (function_param_list_element -> operand .)
-    )               reduce using rule 164 (function_param_list_element -> operand .)
+    ,               reduce using rule 163 (function_param_list_element -> operand .)
+    )               reduce using rule 163 (function_param_list_element -> operand .)
 
 
-state 163
+state 152
 
-    (157) param_list_element -> ID . = operand
-    (116) boolean_expression -> ID . IS DEFINED
-    (183) ns_ref -> ID .
-
-    =               shift and go to state 214
-    IS              shift and go to state 63
-    (               reduce using rule 183 (ns_ref -> ID .)
-    SEP             reduce using rule 183 (ns_ref -> ID .)
-    .               reduce using rule 183 (ns_ref -> ID .)
-    [               reduce using rule 183 (ns_ref -> ID .)
-    CMP_OP          reduce using rule 183 (ns_ref -> ID .)
-    IN              reduce using rule 183 (ns_ref -> ID .)
-    AND             reduce using rule 183 (ns_ref -> ID .)
-    OR              reduce using rule 183 (ns_ref -> ID .)
-    NOT             reduce using rule 183 (ns_ref -> ID .)
-    ?               reduce using rule 183 (ns_ref -> ID .)
-    ,               reduce using rule 183 (ns_ref -> ID .)
-    )               reduce using rule 183 (ns_ref -> ID .)
-    ]               reduce using rule 183 (ns_ref -> ID .)
+    (156) param_list_element -> ID . = operand
+    (115) boolean_expression -> ID . IS DEFINED
+    (182) ns_ref -> ID .
+
+    =               shift and go to state 202
+    IS              shift and go to state 62
+    (               reduce using rule 182 (ns_ref -> ID .)
+    SEP             reduce using rule 182 (ns_ref -> ID .)
+    .               reduce using rule 182 (ns_ref -> ID .)
+    [               reduce using rule 182 (ns_ref -> ID .)
+    CMP_OP          reduce using rule 182 (ns_ref -> ID .)
+    IN              reduce using rule 182 (ns_ref -> ID .)
+    AND             reduce using rule 182 (ns_ref -> ID .)
+    OR              reduce using rule 182 (ns_ref -> ID .)
+    ?               reduce using rule 182 (ns_ref -> ID .)
+    ,               reduce using rule 182 (ns_ref -> ID .)
+    )               reduce using rule 182 (ns_ref -> ID .)
+    ]               reduce using rule 182 (ns_ref -> ID .)
 
 
-state 164
+state 153
 
-    (118) operand -> expression . empty
+    (117) operand -> expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (2) empty -> .
-
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    ,               reduce using rule 2 (empty -> .)
-    )               reduce using rule 2 (empty -> .)
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
-    }               reduce using rule 2 (empty -> .)
+    (140) conditional_expression -> expression . ? expression : expression
 
-  ! NOT             [ reduce using rule 2 (empty -> .) ]
+    ,               reduce using rule 117 (operand -> expression .)
+    )               reduce using rule 117 (operand -> expression .)
+    ENTITY          reduce using rule 117 (operand -> expression .)
+    IMPLEMENT       reduce using rule 117 (operand -> expression .)
+    IMPLEMENTATION  reduce using rule 117 (operand -> expression .)
+    INDEX           reduce using rule 117 (operand -> expression .)
+    IMPORT          reduce using rule 117 (operand -> expression .)
+    CID             reduce using rule 117 (operand -> expression .)
+    FOR             reduce using rule 117 (operand -> expression .)
+    IF              reduce using rule 117 (operand -> expression .)
+    (               reduce using rule 117 (operand -> expression .)
+    TYPEDEF         reduce using rule 117 (operand -> expression .)
+    ID              reduce using rule 117 (operand -> expression .)
+    NOT             reduce using rule 117 (operand -> expression .)
+    INT             reduce using rule 117 (operand -> expression .)
+    FLOAT           reduce using rule 117 (operand -> expression .)
+    NULL            reduce using rule 117 (operand -> expression .)
+    REGEX           reduce using rule 117 (operand -> expression .)
+    TRUE            reduce using rule 117 (operand -> expression .)
+    FALSE           reduce using rule 117 (operand -> expression .)
+    STRING          reduce using rule 117 (operand -> expression .)
+    FSTRING         reduce using rule 117 (operand -> expression .)
+    RSTRING         reduce using rule 117 (operand -> expression .)
+    MLS             reduce using rule 117 (operand -> expression .)
+    [               reduce using rule 117 (operand -> expression .)
+    {               reduce using rule 117 (operand -> expression .)
+    $end            reduce using rule 117 (operand -> expression .)
+    ELSE            reduce using rule 117 (operand -> expression .)
+    ELIF            reduce using rule 117 (operand -> expression .)
+    END             reduce using rule 117 (operand -> expression .)
+    ]               reduce using rule 117 (operand -> expression .)
+    :               reduce using rule 117 (operand -> expression .)
+    }               reduce using rule 117 (operand -> expression .)
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
-    empty                          shift and go to state 181
 
-state 165
+state 154
 
-    (177) class_ref -> var_ref . CID .
+    (176) class_ref -> var_ref . CID .
 
-    ID              reduce using rule 177 (class_ref -> var_ref . CID .)
-    .               reduce using rule 177 (class_ref -> var_ref . CID .)
-    (               reduce using rule 177 (class_ref -> var_ref . CID .)
-    [               reduce using rule 177 (class_ref -> var_ref . CID .)
-    USING           reduce using rule 177 (class_ref -> var_ref . CID .)
-    ,               reduce using rule 177 (class_ref -> var_ref . CID .)
-    :               reduce using rule 177 (class_ref -> var_ref . CID .)
-    MLS             reduce using rule 177 (class_ref -> var_ref . CID .)
-    ENTITY          reduce using rule 177 (class_ref -> var_ref . CID .)
-    IMPLEMENT       reduce using rule 177 (class_ref -> var_ref . CID .)
-    IMPLEMENTATION  reduce using rule 177 (class_ref -> var_ref . CID .)
-    INDEX           reduce using rule 177 (class_ref -> var_ref . CID .)
-    IMPORT          reduce using rule 177 (class_ref -> var_ref . CID .)
-    CID             reduce using rule 177 (class_ref -> var_ref . CID .)
-    FOR             reduce using rule 177 (class_ref -> var_ref . CID .)
-    IF              reduce using rule 177 (class_ref -> var_ref . CID .)
-    TYPEDEF         reduce using rule 177 (class_ref -> var_ref . CID .)
-    NOT             reduce using rule 177 (class_ref -> var_ref . CID .)
-    INT             reduce using rule 177 (class_ref -> var_ref . CID .)
-    FLOAT           reduce using rule 177 (class_ref -> var_ref . CID .)
-    NULL            reduce using rule 177 (class_ref -> var_ref . CID .)
-    REGEX           reduce using rule 177 (class_ref -> var_ref . CID .)
-    TRUE            reduce using rule 177 (class_ref -> var_ref . CID .)
-    FALSE           reduce using rule 177 (class_ref -> var_ref . CID .)
-    STRING          reduce using rule 177 (class_ref -> var_ref . CID .)
-    FSTRING         reduce using rule 177 (class_ref -> var_ref . CID .)
-    RSTRING         reduce using rule 177 (class_ref -> var_ref . CID .)
-    {               reduce using rule 177 (class_ref -> var_ref . CID .)
-    $end            reduce using rule 177 (class_ref -> var_ref . CID .)
+    ID              reduce using rule 176 (class_ref -> var_ref . CID .)
+    .               reduce using rule 176 (class_ref -> var_ref . CID .)
+    (               reduce using rule 176 (class_ref -> var_ref . CID .)
+    [               reduce using rule 176 (class_ref -> var_ref . CID .)
+    USING           reduce using rule 176 (class_ref -> var_ref . CID .)
+    ,               reduce using rule 176 (class_ref -> var_ref . CID .)
+    :               reduce using rule 176 (class_ref -> var_ref . CID .)
+    MLS             reduce using rule 176 (class_ref -> var_ref . CID .)
+    ENTITY          reduce using rule 176 (class_ref -> var_ref . CID .)
+    IMPLEMENT       reduce using rule 176 (class_ref -> var_ref . CID .)
+    IMPLEMENTATION  reduce using rule 176 (class_ref -> var_ref . CID .)
+    INDEX           reduce using rule 176 (class_ref -> var_ref . CID .)
+    IMPORT          reduce using rule 176 (class_ref -> var_ref . CID .)
+    CID             reduce using rule 176 (class_ref -> var_ref . CID .)
+    FOR             reduce using rule 176 (class_ref -> var_ref . CID .)
+    IF              reduce using rule 176 (class_ref -> var_ref . CID .)
+    TYPEDEF         reduce using rule 176 (class_ref -> var_ref . CID .)
+    NOT             reduce using rule 176 (class_ref -> var_ref . CID .)
+    INT             reduce using rule 176 (class_ref -> var_ref . CID .)
+    FLOAT           reduce using rule 176 (class_ref -> var_ref . CID .)
+    NULL            reduce using rule 176 (class_ref -> var_ref . CID .)
+    REGEX           reduce using rule 176 (class_ref -> var_ref . CID .)
+    TRUE            reduce using rule 176 (class_ref -> var_ref . CID .)
+    FALSE           reduce using rule 176 (class_ref -> var_ref . CID .)
+    STRING          reduce using rule 176 (class_ref -> var_ref . CID .)
+    FSTRING         reduce using rule 176 (class_ref -> var_ref . CID .)
+    RSTRING         reduce using rule 176 (class_ref -> var_ref . CID .)
+    {               reduce using rule 176 (class_ref -> var_ref . CID .)
+    $end            reduce using rule 176 (class_ref -> var_ref . CID .)
 
 
-state 166
+state 155
 
-    (115) boolean_expression -> var_ref . ID . IS DEFINED
-    (173) attr_ref -> var_ref . ID .
+    (114) boolean_expression -> var_ref . ID . IS DEFINED
+    (172) attr_ref -> var_ref . ID .
 
-    IS              shift and go to state 227
-    (               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    [               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    .               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    =               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    PEQ             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    CMP_OP          reduce using rule 173 (attr_ref -> var_ref . ID .)
-    IN              reduce using rule 173 (attr_ref -> var_ref . ID .)
-    AND             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    OR              reduce using rule 173 (attr_ref -> var_ref . ID .)
-    NOT             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ?               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ENTITY          reduce using rule 173 (attr_ref -> var_ref . ID .)
-    IMPLEMENT       reduce using rule 173 (attr_ref -> var_ref . ID .)
-    IMPLEMENTATION  reduce using rule 173 (attr_ref -> var_ref . ID .)
-    INDEX           reduce using rule 173 (attr_ref -> var_ref . ID .)
-    IMPORT          reduce using rule 173 (attr_ref -> var_ref . ID .)
-    CID             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    FOR             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    IF              reduce using rule 173 (attr_ref -> var_ref . ID .)
-    TYPEDEF         reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ID              reduce using rule 173 (attr_ref -> var_ref . ID .)
-    INT             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    FLOAT           reduce using rule 173 (attr_ref -> var_ref . ID .)
-    NULL            reduce using rule 173 (attr_ref -> var_ref . ID .)
-    REGEX           reduce using rule 173 (attr_ref -> var_ref . ID .)
-    TRUE            reduce using rule 173 (attr_ref -> var_ref . ID .)
-    FALSE           reduce using rule 173 (attr_ref -> var_ref . ID .)
-    STRING          reduce using rule 173 (attr_ref -> var_ref . ID .)
-    FSTRING         reduce using rule 173 (attr_ref -> var_ref . ID .)
-    RSTRING         reduce using rule 173 (attr_ref -> var_ref . ID .)
-    MLS             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    {               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    $end            reduce using rule 173 (attr_ref -> var_ref . ID .)
-    )               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    :               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ,               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ]               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ELSE            reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ELIF            reduce using rule 173 (attr_ref -> var_ref . ID .)
-    END             reduce using rule 173 (attr_ref -> var_ref . ID .)
-    }               reduce using rule 173 (attr_ref -> var_ref . ID .)
+    IS              shift and go to state 214
+    (               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    [               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    .               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    =               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    PEQ             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    CMP_OP          reduce using rule 172 (attr_ref -> var_ref . ID .)
+    IN              reduce using rule 172 (attr_ref -> var_ref . ID .)
+    AND             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    OR              reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ?               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ENTITY          reduce using rule 172 (attr_ref -> var_ref . ID .)
+    IMPLEMENT       reduce using rule 172 (attr_ref -> var_ref . ID .)
+    IMPLEMENTATION  reduce using rule 172 (attr_ref -> var_ref . ID .)
+    INDEX           reduce using rule 172 (attr_ref -> var_ref . ID .)
+    IMPORT          reduce using rule 172 (attr_ref -> var_ref . ID .)
+    CID             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    FOR             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    IF              reduce using rule 172 (attr_ref -> var_ref . ID .)
+    TYPEDEF         reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ID              reduce using rule 172 (attr_ref -> var_ref . ID .)
+    NOT             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    INT             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    FLOAT           reduce using rule 172 (attr_ref -> var_ref . ID .)
+    NULL            reduce using rule 172 (attr_ref -> var_ref . ID .)
+    REGEX           reduce using rule 172 (attr_ref -> var_ref . ID .)
+    TRUE            reduce using rule 172 (attr_ref -> var_ref . ID .)
+    FALSE           reduce using rule 172 (attr_ref -> var_ref . ID .)
+    STRING          reduce using rule 172 (attr_ref -> var_ref . ID .)
+    FSTRING         reduce using rule 172 (attr_ref -> var_ref . ID .)
+    RSTRING         reduce using rule 172 (attr_ref -> var_ref . ID .)
+    MLS             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    {               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    $end            reduce using rule 172 (attr_ref -> var_ref . ID .)
+    )               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    :               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ,               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ]               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ELSE            reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ELIF            reduce using rule 172 (attr_ref -> var_ref . ID .)
+    END             reduce using rule 172 (attr_ref -> var_ref . ID .)
+    }               reduce using rule 172 (attr_ref -> var_ref . ID .)
 
 
-state 167
+state 156
 
     (23) assign -> var_ref = operand .
 
     ENTITY          reduce using rule 23 (assign -> var_ref = operand .)
     IMPLEMENT       reduce using rule 23 (assign -> var_ref = operand .)
     IMPLEMENTATION  reduce using rule 23 (assign -> var_ref = operand .)
     INDEX           reduce using rule 23 (assign -> var_ref = operand .)
@@ -6176,15 +5686,15 @@
     {               reduce using rule 23 (assign -> var_ref = operand .)
     $end            reduce using rule 23 (assign -> var_ref = operand .)
     ELSE            reduce using rule 23 (assign -> var_ref = operand .)
     ELIF            reduce using rule 23 (assign -> var_ref = operand .)
     END             reduce using rule 23 (assign -> var_ref = operand .)
 
 
-state 168
+state 157
 
     (24) assign -> var_ref PEQ operand .
 
     ENTITY          reduce using rule 24 (assign -> var_ref PEQ operand .)
     IMPLEMENT       reduce using rule 24 (assign -> var_ref PEQ operand .)
     IMPLEMENTATION  reduce using rule 24 (assign -> var_ref PEQ operand .)
     INDEX           reduce using rule 24 (assign -> var_ref PEQ operand .)
@@ -6210,22 +5720,22 @@
     {               reduce using rule 24 (assign -> var_ref PEQ operand .)
     $end            reduce using rule 24 (assign -> var_ref PEQ operand .)
     ELSE            reduce using rule 24 (assign -> var_ref PEQ operand .)
     ELIF            reduce using rule 24 (assign -> var_ref PEQ operand .)
     END             reduce using rule 24 (assign -> var_ref PEQ operand .)
 
 
-state 169
+state 158
 
-    (120) map_lookup -> var_ref [ operand . ]
+    (119) map_lookup -> var_ref [ operand . ]
 
-    ]               shift and go to state 228
+    ]               shift and go to state 215
 
 
-state 170
+state 159
 
     (26) if -> IF if_body END .
 
     ENTITY          reduce using rule 26 (if -> IF if_body END .)
     IMPLEMENT       reduce using rule 26 (if -> IF if_body END .)
     IMPLEMENTATION  reduce using rule 26 (if -> IF if_body END .)
     INDEX           reduce using rule 26 (if -> IF if_body END .)
@@ -6251,569 +5761,525 @@
     {               reduce using rule 26 (if -> IF if_body END .)
     $end            reduce using rule 26 (if -> IF if_body END .)
     ELSE            reduce using rule 26 (if -> IF if_body END .)
     ELIF            reduce using rule 26 (if -> IF if_body END .)
     END             reduce using rule 26 (if -> IF if_body END .)
 
 
-state 171
+state 160
 
     (27) if_body -> expression : . stmt_list if_next
     (21) stmt_list -> . statement stmt_list
     (22) stmt_list -> . empty
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (2) empty -> .
+    (20) statement -> . expression
+    (14) empty -> .
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 22
-    stmt_list                      shift and go to state 229
-    statement                      shift and go to state 230
-    empty                          shift and go to state 231
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    var_ref                        shift and go to state 232
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
-    ns_ref                         shift and go to state 233
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    ELSE            reduce using rule 14 (empty -> .)
+    ELIF            reduce using rule 14 (empty -> .)
+    END             reduce using rule 14 (empty -> .)
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 21
+    stmt_list                      shift and go to state 216
+    statement                      shift and go to state 217
+    empty                          shift and go to state 218
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    var_ref                        shift and go to state 219
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+    ns_ref                         shift and go to state 220
+    class_ref                      shift and go to state 87
 
-state 172
+state 161
 
-    (117) boolean_expression -> map_lookup IS DEFINED .
+    (116) boolean_expression -> map_lookup IS DEFINED .
 
-    CMP_OP          reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    IN              reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    AND             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    OR              reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    NOT             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ?               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ENTITY          reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    IMPLEMENT       reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    IMPLEMENTATION  reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    INDEX           reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    IMPORT          reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    CID             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    FOR             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    IF              reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    (               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    TYPEDEF         reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ID              reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    INT             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    FLOAT           reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    NULL            reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    REGEX           reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    TRUE            reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    FALSE           reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    STRING          reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    FSTRING         reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    RSTRING         reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    MLS             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    [               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    {               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    $end            reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    )               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    :               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ,               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ]               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ELSE            reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    ELIF            reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    END             reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
-    }               reduce using rule 117 (boolean_expression -> map_lookup IS DEFINED .)
+    CMP_OP          reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    IN              reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    AND             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    OR              reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ?               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ENTITY          reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    IMPLEMENT       reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    IMPLEMENTATION  reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    INDEX           reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    IMPORT          reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    CID             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    FOR             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    IF              reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    (               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    TYPEDEF         reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ID              reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    NOT             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    INT             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    FLOAT           reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    NULL            reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    REGEX           reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    TRUE            reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    FALSE           reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    STRING          reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    FSTRING         reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    RSTRING         reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    MLS             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    [               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    {               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    $end            reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    )               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    :               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ,               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ]               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ELSE            reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    ELIF            reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    END             reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
+    }               reduce using rule 116 (boolean_expression -> map_lookup IS DEFINED .)
 
 
-state 173
+state 162
 
-    (121) map_lookup -> map_lookup [ operand . ]
+    (120) map_lookup -> map_lookup [ operand . ]
 
-    ]               shift and go to state 234
+    ]               shift and go to state 221
 
 
-state 174
+state 163
 
     (94) typedef_inner -> TYPEDEF ID AS . ns_ref MATCHING expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    ID              shift and go to state 67
+    ID              shift and go to state 66
 
-    ns_ref                         shift and go to state 235
+    ns_ref                         shift and go to state 222
 
-state 175
+state 164
 
     (95) typedef_inner -> TYPEDEF CID AS . constructor
-    (122) constructor -> . class_ref ( param_list )
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    constructor                    shift and go to state 236
-    class_ref                      shift and go to state 237
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
-
-state 176
-
-    (124) function_call -> attr_ref ( function_param_list . )
-
-    )               shift and go to state 238
+    (121) constructor -> . class_ref ( param_list )
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    constructor                    shift and go to state 223
+    class_ref                      shift and go to state 224
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
+state 165
 
-state 177
-
-    (119) map_lookup -> attr_ref [ operand . ]
+    (123) function_call -> attr_ref ( function_param_list . )
 
-    ]               shift and go to state 239
+    )               shift and go to state 225
 
 
-state 178
+state 166
 
-    (140) index_lookup -> attr_ref [ param_list . ]
+    (118) map_lookup -> attr_ref [ operand . ]
 
-    ]               shift and go to state 240
+    ]               shift and go to state 226
 
 
-state 179
+state 167
 
-    (125) list_def -> [ operand_list ] .
+    (139) index_lookup -> attr_ref [ param_list . ]
 
-    CMP_OP          reduce using rule 125 (list_def -> [ operand_list ] .)
-    IN              reduce using rule 125 (list_def -> [ operand_list ] .)
-    AND             reduce using rule 125 (list_def -> [ operand_list ] .)
-    OR              reduce using rule 125 (list_def -> [ operand_list ] .)
-    NOT             reduce using rule 125 (list_def -> [ operand_list ] .)
-    ?               reduce using rule 125 (list_def -> [ operand_list ] .)
-    ENTITY          reduce using rule 125 (list_def -> [ operand_list ] .)
-    IMPLEMENT       reduce using rule 125 (list_def -> [ operand_list ] .)
-    IMPLEMENTATION  reduce using rule 125 (list_def -> [ operand_list ] .)
-    INDEX           reduce using rule 125 (list_def -> [ operand_list ] .)
-    IMPORT          reduce using rule 125 (list_def -> [ operand_list ] .)
-    CID             reduce using rule 125 (list_def -> [ operand_list ] .)
-    FOR             reduce using rule 125 (list_def -> [ operand_list ] .)
-    IF              reduce using rule 125 (list_def -> [ operand_list ] .)
-    (               reduce using rule 125 (list_def -> [ operand_list ] .)
-    TYPEDEF         reduce using rule 125 (list_def -> [ operand_list ] .)
-    ID              reduce using rule 125 (list_def -> [ operand_list ] .)
-    INT             reduce using rule 125 (list_def -> [ operand_list ] .)
-    FLOAT           reduce using rule 125 (list_def -> [ operand_list ] .)
-    NULL            reduce using rule 125 (list_def -> [ operand_list ] .)
-    REGEX           reduce using rule 125 (list_def -> [ operand_list ] .)
-    TRUE            reduce using rule 125 (list_def -> [ operand_list ] .)
-    FALSE           reduce using rule 125 (list_def -> [ operand_list ] .)
-    STRING          reduce using rule 125 (list_def -> [ operand_list ] .)
-    FSTRING         reduce using rule 125 (list_def -> [ operand_list ] .)
-    RSTRING         reduce using rule 125 (list_def -> [ operand_list ] .)
-    MLS             reduce using rule 125 (list_def -> [ operand_list ] .)
-    [               reduce using rule 125 (list_def -> [ operand_list ] .)
-    {               reduce using rule 125 (list_def -> [ operand_list ] .)
-    $end            reduce using rule 125 (list_def -> [ operand_list ] .)
-    )               reduce using rule 125 (list_def -> [ operand_list ] .)
-    :               reduce using rule 125 (list_def -> [ operand_list ] .)
-    ,               reduce using rule 125 (list_def -> [ operand_list ] .)
-    ]               reduce using rule 125 (list_def -> [ operand_list ] .)
-    ELSE            reduce using rule 125 (list_def -> [ operand_list ] .)
-    ELIF            reduce using rule 125 (list_def -> [ operand_list ] .)
-    END             reduce using rule 125 (list_def -> [ operand_list ] .)
-    }               reduce using rule 125 (list_def -> [ operand_list ] .)
+    ]               shift and go to state 227
 
 
-state 180
+state 168
 
-    (126) list_comprehension -> [ expression list_comprehension_for . list_comprehension_guard ]
-    (130) list_comprehension_guard -> . empty
-    (131) list_comprehension_guard -> . IF expression list_comprehension_guard
-    (2) empty -> .
+    (124) list_def -> [ operand_list ] .
 
-    IF              shift and go to state 243
-    ]               reduce using rule 2 (empty -> .)
+    CMP_OP          reduce using rule 124 (list_def -> [ operand_list ] .)
+    IN              reduce using rule 124 (list_def -> [ operand_list ] .)
+    AND             reduce using rule 124 (list_def -> [ operand_list ] .)
+    OR              reduce using rule 124 (list_def -> [ operand_list ] .)
+    ?               reduce using rule 124 (list_def -> [ operand_list ] .)
+    ENTITY          reduce using rule 124 (list_def -> [ operand_list ] .)
+    IMPLEMENT       reduce using rule 124 (list_def -> [ operand_list ] .)
+    IMPLEMENTATION  reduce using rule 124 (list_def -> [ operand_list ] .)
+    INDEX           reduce using rule 124 (list_def -> [ operand_list ] .)
+    IMPORT          reduce using rule 124 (list_def -> [ operand_list ] .)
+    CID             reduce using rule 124 (list_def -> [ operand_list ] .)
+    FOR             reduce using rule 124 (list_def -> [ operand_list ] .)
+    IF              reduce using rule 124 (list_def -> [ operand_list ] .)
+    (               reduce using rule 124 (list_def -> [ operand_list ] .)
+    TYPEDEF         reduce using rule 124 (list_def -> [ operand_list ] .)
+    ID              reduce using rule 124 (list_def -> [ operand_list ] .)
+    NOT             reduce using rule 124 (list_def -> [ operand_list ] .)
+    INT             reduce using rule 124 (list_def -> [ operand_list ] .)
+    FLOAT           reduce using rule 124 (list_def -> [ operand_list ] .)
+    NULL            reduce using rule 124 (list_def -> [ operand_list ] .)
+    REGEX           reduce using rule 124 (list_def -> [ operand_list ] .)
+    TRUE            reduce using rule 124 (list_def -> [ operand_list ] .)
+    FALSE           reduce using rule 124 (list_def -> [ operand_list ] .)
+    STRING          reduce using rule 124 (list_def -> [ operand_list ] .)
+    FSTRING         reduce using rule 124 (list_def -> [ operand_list ] .)
+    RSTRING         reduce using rule 124 (list_def -> [ operand_list ] .)
+    MLS             reduce using rule 124 (list_def -> [ operand_list ] .)
+    [               reduce using rule 124 (list_def -> [ operand_list ] .)
+    {               reduce using rule 124 (list_def -> [ operand_list ] .)
+    $end            reduce using rule 124 (list_def -> [ operand_list ] .)
+    )               reduce using rule 124 (list_def -> [ operand_list ] .)
+    :               reduce using rule 124 (list_def -> [ operand_list ] .)
+    ,               reduce using rule 124 (list_def -> [ operand_list ] .)
+    ]               reduce using rule 124 (list_def -> [ operand_list ] .)
+    ELSE            reduce using rule 124 (list_def -> [ operand_list ] .)
+    ELIF            reduce using rule 124 (list_def -> [ operand_list ] .)
+    END             reduce using rule 124 (list_def -> [ operand_list ] .)
+    }               reduce using rule 124 (list_def -> [ operand_list ] .)
 
-    list_comprehension_guard       shift and go to state 241
-    empty                          shift and go to state 242
 
-state 181
+state 169
 
-    (118) operand -> expression empty .
+    (125) list_comprehension -> [ expression list_comprehension_for . list_comprehension_guard ]
+    (129) list_comprehension_guard -> . empty
+    (130) list_comprehension_guard -> . IF expression list_comprehension_guard
+    (14) empty -> .
 
-    ,               reduce using rule 118 (operand -> expression empty .)
-    ]               reduce using rule 118 (operand -> expression empty .)
-    )               reduce using rule 118 (operand -> expression empty .)
-    ENTITY          reduce using rule 118 (operand -> expression empty .)
-    IMPLEMENT       reduce using rule 118 (operand -> expression empty .)
-    IMPLEMENTATION  reduce using rule 118 (operand -> expression empty .)
-    INDEX           reduce using rule 118 (operand -> expression empty .)
-    IMPORT          reduce using rule 118 (operand -> expression empty .)
-    CID             reduce using rule 118 (operand -> expression empty .)
-    FOR             reduce using rule 118 (operand -> expression empty .)
-    IF              reduce using rule 118 (operand -> expression empty .)
-    (               reduce using rule 118 (operand -> expression empty .)
-    TYPEDEF         reduce using rule 118 (operand -> expression empty .)
-    ID              reduce using rule 118 (operand -> expression empty .)
-    NOT             reduce using rule 118 (operand -> expression empty .)
-    INT             reduce using rule 118 (operand -> expression empty .)
-    FLOAT           reduce using rule 118 (operand -> expression empty .)
-    NULL            reduce using rule 118 (operand -> expression empty .)
-    REGEX           reduce using rule 118 (operand -> expression empty .)
-    TRUE            reduce using rule 118 (operand -> expression empty .)
-    FALSE           reduce using rule 118 (operand -> expression empty .)
-    STRING          reduce using rule 118 (operand -> expression empty .)
-    FSTRING         reduce using rule 118 (operand -> expression empty .)
-    RSTRING         reduce using rule 118 (operand -> expression empty .)
-    MLS             reduce using rule 118 (operand -> expression empty .)
-    [               reduce using rule 118 (operand -> expression empty .)
-    {               reduce using rule 118 (operand -> expression empty .)
-    $end            reduce using rule 118 (operand -> expression empty .)
-    ELSE            reduce using rule 118 (operand -> expression empty .)
-    ELIF            reduce using rule 118 (operand -> expression empty .)
-    END             reduce using rule 118 (operand -> expression empty .)
-    :               reduce using rule 118 (operand -> expression empty .)
-    }               reduce using rule 118 (operand -> expression empty .)
+    IF              shift and go to state 230
+    ]               reduce using rule 14 (empty -> .)
 
+    list_comprehension_guard       shift and go to state 228
+    empty                          shift and go to state 229
 
-state 182
+state 170
 
-    (128) list_comprehension_for -> FOR . ID IN expression list_comprehension_for_empty
-    (129) list_comprehension_for -> FOR . ID IN expression list_comprehension_for
+    (127) list_comprehension_for -> FOR . ID IN expression list_comprehension_for_empty
+    (128) list_comprehension_for -> FOR . ID IN expression list_comprehension_for
 
-    ID              shift and go to state 244
+    ID              shift and go to state 231
 
 
-state 183
+state 171
 
-    (169) operand_list -> operand , . operand_list
-    (169) operand_list -> . operand , operand_list
-    (170) operand_list -> . operand
-    (171) operand_list -> . empty
-    (118) operand -> . expression empty
-    (2) empty -> .
+    (168) operand_list -> operand , . operand_list
+    (168) operand_list -> . operand , operand_list
+    (169) operand_list -> . operand
+    (170) operand_list -> .
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    ]               reduce using rule 2 (empty -> .)
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-  ! CID             [ reduce using rule 2 (empty -> .) ]
-  ! ID              [ reduce using rule 2 (empty -> .) ]
-
-    operand                        shift and go to state 115
-    operand_list                   shift and go to state 245
-    empty                          shift and go to state 116
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    ]               reduce using rule 170 (operand_list -> .)
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+  ! CID             [ reduce using rule 170 (operand_list -> .) ]
+  ! ID              [ reduce using rule 170 (operand_list -> .) ]
+
+    operand                        shift and go to state 106
+    operand_list                   shift and go to state 232
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 184
+state 172
 
-    (138) map_def -> { pair_list } .
+    (137) map_def -> { pair_list } .
 
-    CMP_OP          reduce using rule 138 (map_def -> { pair_list } .)
-    IN              reduce using rule 138 (map_def -> { pair_list } .)
-    AND             reduce using rule 138 (map_def -> { pair_list } .)
-    OR              reduce using rule 138 (map_def -> { pair_list } .)
-    NOT             reduce using rule 138 (map_def -> { pair_list } .)
-    ?               reduce using rule 138 (map_def -> { pair_list } .)
-    ENTITY          reduce using rule 138 (map_def -> { pair_list } .)
-    IMPLEMENT       reduce using rule 138 (map_def -> { pair_list } .)
-    IMPLEMENTATION  reduce using rule 138 (map_def -> { pair_list } .)
-    INDEX           reduce using rule 138 (map_def -> { pair_list } .)
-    IMPORT          reduce using rule 138 (map_def -> { pair_list } .)
-    CID             reduce using rule 138 (map_def -> { pair_list } .)
-    FOR             reduce using rule 138 (map_def -> { pair_list } .)
-    IF              reduce using rule 138 (map_def -> { pair_list } .)
-    (               reduce using rule 138 (map_def -> { pair_list } .)
-    TYPEDEF         reduce using rule 138 (map_def -> { pair_list } .)
-    ID              reduce using rule 138 (map_def -> { pair_list } .)
-    INT             reduce using rule 138 (map_def -> { pair_list } .)
-    FLOAT           reduce using rule 138 (map_def -> { pair_list } .)
-    NULL            reduce using rule 138 (map_def -> { pair_list } .)
-    REGEX           reduce using rule 138 (map_def -> { pair_list } .)
-    TRUE            reduce using rule 138 (map_def -> { pair_list } .)
-    FALSE           reduce using rule 138 (map_def -> { pair_list } .)
-    STRING          reduce using rule 138 (map_def -> { pair_list } .)
-    FSTRING         reduce using rule 138 (map_def -> { pair_list } .)
-    RSTRING         reduce using rule 138 (map_def -> { pair_list } .)
-    MLS             reduce using rule 138 (map_def -> { pair_list } .)
-    [               reduce using rule 138 (map_def -> { pair_list } .)
-    {               reduce using rule 138 (map_def -> { pair_list } .)
-    $end            reduce using rule 138 (map_def -> { pair_list } .)
-    )               reduce using rule 138 (map_def -> { pair_list } .)
-    :               reduce using rule 138 (map_def -> { pair_list } .)
-    ,               reduce using rule 138 (map_def -> { pair_list } .)
-    ]               reduce using rule 138 (map_def -> { pair_list } .)
-    ELSE            reduce using rule 138 (map_def -> { pair_list } .)
-    ELIF            reduce using rule 138 (map_def -> { pair_list } .)
-    END             reduce using rule 138 (map_def -> { pair_list } .)
-    }               reduce using rule 138 (map_def -> { pair_list } .)
-    DICT            reduce using rule 138 (map_def -> { pair_list } .)
+    CMP_OP          reduce using rule 137 (map_def -> { pair_list } .)
+    IN              reduce using rule 137 (map_def -> { pair_list } .)
+    AND             reduce using rule 137 (map_def -> { pair_list } .)
+    OR              reduce using rule 137 (map_def -> { pair_list } .)
+    ?               reduce using rule 137 (map_def -> { pair_list } .)
+    ENTITY          reduce using rule 137 (map_def -> { pair_list } .)
+    IMPLEMENT       reduce using rule 137 (map_def -> { pair_list } .)
+    IMPLEMENTATION  reduce using rule 137 (map_def -> { pair_list } .)
+    INDEX           reduce using rule 137 (map_def -> { pair_list } .)
+    IMPORT          reduce using rule 137 (map_def -> { pair_list } .)
+    CID             reduce using rule 137 (map_def -> { pair_list } .)
+    FOR             reduce using rule 137 (map_def -> { pair_list } .)
+    IF              reduce using rule 137 (map_def -> { pair_list } .)
+    (               reduce using rule 137 (map_def -> { pair_list } .)
+    TYPEDEF         reduce using rule 137 (map_def -> { pair_list } .)
+    ID              reduce using rule 137 (map_def -> { pair_list } .)
+    NOT             reduce using rule 137 (map_def -> { pair_list } .)
+    INT             reduce using rule 137 (map_def -> { pair_list } .)
+    FLOAT           reduce using rule 137 (map_def -> { pair_list } .)
+    NULL            reduce using rule 137 (map_def -> { pair_list } .)
+    REGEX           reduce using rule 137 (map_def -> { pair_list } .)
+    TRUE            reduce using rule 137 (map_def -> { pair_list } .)
+    FALSE           reduce using rule 137 (map_def -> { pair_list } .)
+    STRING          reduce using rule 137 (map_def -> { pair_list } .)
+    FSTRING         reduce using rule 137 (map_def -> { pair_list } .)
+    RSTRING         reduce using rule 137 (map_def -> { pair_list } .)
+    MLS             reduce using rule 137 (map_def -> { pair_list } .)
+    [               reduce using rule 137 (map_def -> { pair_list } .)
+    {               reduce using rule 137 (map_def -> { pair_list } .)
+    $end            reduce using rule 137 (map_def -> { pair_list } .)
+    )               reduce using rule 137 (map_def -> { pair_list } .)
+    :               reduce using rule 137 (map_def -> { pair_list } .)
+    ,               reduce using rule 137 (map_def -> { pair_list } .)
+    ]               reduce using rule 137 (map_def -> { pair_list } .)
+    ELSE            reduce using rule 137 (map_def -> { pair_list } .)
+    ELIF            reduce using rule 137 (map_def -> { pair_list } .)
+    END             reduce using rule 137 (map_def -> { pair_list } .)
+    }               reduce using rule 137 (map_def -> { pair_list } .)
+    DICT            reduce using rule 137 (map_def -> { pair_list } .)
 
 
-state 185
+state 173
 
-    (134) pair_list -> dict_key : . operand , pair_list
-    (135) pair_list -> dict_key : . operand empty pair_list_empty
-    (118) operand -> . expression empty
+    (133) pair_list -> dict_key : . operand , pair_list
+    (134) pair_list -> dict_key : . operand empty pair_list_empty
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    operand                        shift and go to state 246
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    operand                        shift and go to state 233
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 186
+state 174
 
     (31) entity_def -> ENTITY CID : entity_body_outer .
 
     ENTITY          reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     IMPLEMENT       reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     IMPLEMENTATION  reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     INDEX           reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
@@ -6836,15 +6302,15 @@
     RSTRING         reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     MLS             reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     [               reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     {               reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
     $end            reduce using rule 31 (entity_def -> ENTITY CID : entity_body_outer .)
 
 
-state 187
+state 175
 
     (35) entity_body_outer -> MLS . entity_body END
     (38) entity_body_outer -> MLS . END
     (39) entity_body -> . entity_body attr
     (40) entity_body -> . attr
     (48) attr -> . attr_type CID empty
     (49) attr -> . attr_type CID = constant
@@ -6869,30 +6335,30 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    END             shift and go to state 248
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    entity_body                    shift and go to state 247
-    attr                           shift and go to state 190
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    END             shift and go to state 235
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    entity_body                    shift and go to state 234
+    attr                           shift and go to state 178
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 188
+state 176
 
     (36) entity_body_outer -> entity_body . END
     (39) entity_body -> entity_body . attr
     (48) attr -> . attr_type CID empty
     (49) attr -> . attr_type CID = constant
     (50) attr -> . attr_type CID = constant_list
     (51) attr -> . attr_type CID = UNDEF
@@ -6915,29 +6381,29 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    END             shift and go to state 249
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    attr                           shift and go to state 250
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    END             shift and go to state 236
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    attr                           shift and go to state 237
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 189
+state 177
 
     (37) entity_body_outer -> END .
 
     ENTITY          reduce using rule 37 (entity_body_outer -> END .)
     IMPLEMENT       reduce using rule 37 (entity_body_outer -> END .)
     IMPLEMENTATION  reduce using rule 37 (entity_body_outer -> END .)
     INDEX           reduce using rule 37 (entity_body_outer -> END .)
@@ -6960,145 +6426,143 @@
     RSTRING         reduce using rule 37 (entity_body_outer -> END .)
     MLS             reduce using rule 37 (entity_body_outer -> END .)
     [               reduce using rule 37 (entity_body_outer -> END .)
     {               reduce using rule 37 (entity_body_outer -> END .)
     $end            reduce using rule 37 (entity_body_outer -> END .)
 
 
-state 190
+state 178
 
     (40) entity_body -> attr .
 
     END             reduce using rule 40 (entity_body -> attr .)
     DICT            reduce using rule 40 (entity_body -> attr .)
     ID              reduce using rule 40 (entity_body -> attr .)
 
 
-state 191
+state 179
 
     (48) attr -> attr_type . CID empty
     (49) attr -> attr_type . CID = constant
     (50) attr -> attr_type . CID = constant_list
     (51) attr -> attr_type . CID = UNDEF
     (52) attr -> attr_type . ID
     (53) attr -> attr_type . ID = constant
     (54) attr -> attr_type . ID = constant_list
     (55) attr -> attr_type . ID = UNDEF
 
-    CID             shift and go to state 251
-    ID              shift and go to state 252
+    CID             shift and go to state 238
+    ID              shift and go to state 239
 
 
-state 192
+state 180
 
     (56) attr -> DICT . empty CID empty
     (57) attr -> DICT . empty CID = map_def
     (58) attr -> DICT . empty CID = NULL
     (59) attr -> DICT . ? CID empty
     (60) attr -> DICT . ? CID = map_def
     (61) attr -> DICT . ? CID = NULL
     (62) attr -> DICT . ID
     (63) attr -> DICT . ID = map_def
     (64) attr -> DICT . ID = NULL
     (65) attr -> DICT . ? ID
     (66) attr -> DICT . ? ID = map_def
     (67) attr -> DICT . ? ID = NULL
-    (2) empty -> .
+    (14) empty -> .
 
-    ?               shift and go to state 254
-    ID              shift and go to state 255
-    CID             reduce using rule 2 (empty -> .)
+    ?               shift and go to state 241
+    ID              shift and go to state 242
+    CID             reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 253
+    empty                          shift and go to state 240
 
-state 193
+state 181
 
     (45) attr_type -> attr_type_opt .
 
     CID             reduce using rule 45 (attr_type -> attr_type_opt .)
     ID              reduce using rule 45 (attr_type -> attr_type_opt .)
 
 
-state 194
+state 182
 
     (46) attr_type -> attr_type_multi .
     (43) attr_type_opt -> attr_type_multi . ?
 
     CID             reduce using rule 46 (attr_type -> attr_type_multi .)
     ID              reduce using rule 46 (attr_type -> attr_type_multi .)
-    ?               shift and go to state 256
+    ?               shift and go to state 243
 
 
-state 195
+state 183
 
     (47) attr_type -> attr_base_type .
     (44) attr_type_opt -> attr_base_type . ?
     (42) attr_type_multi -> attr_base_type . [ ]
 
     CID             reduce using rule 47 (attr_type -> attr_base_type .)
     ID              reduce using rule 47 (attr_type -> attr_base_type .)
-    ?               shift and go to state 257
-    [               shift and go to state 258
+    ?               shift and go to state 244
+    [               shift and go to state 245
 
 
-state 196
+state 184
 
     (41) attr_base_type -> ns_ref .
-    (182) ns_ref -> ns_ref . SEP ID
+    (181) ns_ref -> ns_ref . SEP ID
 
     ?               reduce using rule 41 (attr_base_type -> ns_ref .)
     [               reduce using rule 41 (attr_base_type -> ns_ref .)
     CID             reduce using rule 41 (attr_base_type -> ns_ref .)
     ID              reduce using rule 41 (attr_base_type -> ns_ref .)
-    SEP             shift and go to state 154
+    SEP             shift and go to state 143
 
 
-state 197
+state 185
 
     (33) entity_def -> ENTITY CID EXTENDS class_ref_list . : entity_body_outer
 
-    :               shift and go to state 259
+    :               shift and go to state 246
 
 
-state 198
+state 186
 
-    (178) class_ref_list -> class_ref . , class_ref_list
-    (180) class_ref_list -> class_ref .
+    (177) class_ref_list -> class_ref . , class_ref_list
+    (179) class_ref_list -> class_ref .
 
-    ,               shift and go to state 260
-    :               reduce using rule 180 (class_ref_list -> class_ref .)
+    ,               shift and go to state 247
+    :               reduce using rule 179 (class_ref_list -> class_ref .)
 
 
-state 199
+state 187
 
-    (179) class_ref_list -> var_ref . , class_ref_list
-    (181) class_ref_list -> var_ref .
-    (177) class_ref -> var_ref . . CID
-    (173) attr_ref -> var_ref . . ID
-
-    ,               shift and go to state 261
-    :               reduce using rule 181 (class_ref_list -> var_ref .)
-    .               shift and go to state 129
+    (178) class_ref_list -> var_ref . , class_ref_list
+    (180) class_ref_list -> var_ref .
+    (176) class_ref -> var_ref . . CID
+    (172) attr_ref -> var_ref . . ID
+
+    ,               shift and go to state 248
+    :               reduce using rule 180 (class_ref_list -> var_ref .)
+    .               shift and go to state 119
 
 
-state 200
+state 188
 
-    (176) class_ref -> ns_ref . SEP CID
-    (174) var_ref -> ns_ref . empty
-    (182) ns_ref -> ns_ref . SEP ID
-    (2) empty -> .
-
-    SEP             shift and go to state 94
-    ,               reduce using rule 2 (empty -> .)
-    .               reduce using rule 2 (empty -> .)
-    :               reduce using rule 2 (empty -> .)
+    (175) class_ref -> ns_ref . SEP CID
+    (173) var_ref -> ns_ref .
+    (181) ns_ref -> ns_ref . SEP ID
+
+    SEP             shift and go to state 89
+    ,               reduce using rule 173 (var_ref -> ns_ref .)
+    .               reduce using rule 173 (var_ref -> ns_ref .)
+    :               reduce using rule 173 (var_ref -> ns_ref .)
 
-    empty                          shift and go to state 95
 
-state 201
+state 189
 
     (32) entity_def -> ENTITY ID : entity_body_outer .
 
     ENTITY          reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     IMPLEMENT       reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     IMPLEMENTATION  reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     INDEX           reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
@@ -7121,66 +6585,66 @@
     RSTRING         reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     MLS             reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     [               reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     {               reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
     $end            reduce using rule 32 (entity_def -> ENTITY ID : entity_body_outer .)
 
 
-state 202
+state 190
 
     (34) entity_def -> ENTITY ID EXTENDS class_ref_list . : entity_body_outer
 
-    :               shift and go to state 262
+    :               shift and go to state 249
 
 
-state 203
+state 191
 
     (71) implement_def -> IMPLEMENT class_ref USING implement_ns_list . empty
     (72) implement_def -> IMPLEMENT class_ref USING implement_ns_list . MLS
     (73) implement_def -> IMPLEMENT class_ref USING implement_ns_list . WHEN expression empty
     (74) implement_def -> IMPLEMENT class_ref USING implement_ns_list . WHEN expression MLS
     (70) implement_ns_list -> implement_ns_list . , implement_ns_list
-    (2) empty -> .
+    (14) empty -> .
 
-    MLS             shift and go to state 264
-    WHEN            shift and go to state 265
-    ,               shift and go to state 266
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    MLS             shift and go to state 251
+    WHEN            shift and go to state 252
+    ,               shift and go to state 253
+    ENTITY          reduce using rule 14 (empty -> .)
+    IMPLEMENT       reduce using rule 14 (empty -> .)
+    IMPLEMENTATION  reduce using rule 14 (empty -> .)
+    INDEX           reduce using rule 14 (empty -> .)
+    IMPORT          reduce using rule 14 (empty -> .)
+    CID             reduce using rule 14 (empty -> .)
+    FOR             reduce using rule 14 (empty -> .)
+    IF              reduce using rule 14 (empty -> .)
+    (               reduce using rule 14 (empty -> .)
+    TYPEDEF         reduce using rule 14 (empty -> .)
+    ID              reduce using rule 14 (empty -> .)
+    NOT             reduce using rule 14 (empty -> .)
+    INT             reduce using rule 14 (empty -> .)
+    FLOAT           reduce using rule 14 (empty -> .)
+    NULL            reduce using rule 14 (empty -> .)
+    REGEX           reduce using rule 14 (empty -> .)
+    TRUE            reduce using rule 14 (empty -> .)
+    FALSE           reduce using rule 14 (empty -> .)
+    STRING          reduce using rule 14 (empty -> .)
+    FSTRING         reduce using rule 14 (empty -> .)
+    RSTRING         reduce using rule 14 (empty -> .)
+    [               reduce using rule 14 (empty -> .)
+    {               reduce using rule 14 (empty -> .)
+    $end            reduce using rule 14 (empty -> .)
 
-  ! MLS             [ reduce using rule 2 (empty -> .) ]
+  ! MLS             [ reduce using rule 14 (empty -> .) ]
 
-    empty                          shift and go to state 263
+    empty                          shift and go to state 250
 
-state 204
+state 192
 
     (68) implement_ns_list -> ns_ref .
-    (182) ns_ref -> ns_ref . SEP ID
+    (181) ns_ref -> ns_ref . SEP ID
 
     MLS             reduce using rule 68 (implement_ns_list -> ns_ref .)
     WHEN            reduce using rule 68 (implement_ns_list -> ns_ref .)
     ,               reduce using rule 68 (implement_ns_list -> ns_ref .)
     ENTITY          reduce using rule 68 (implement_ns_list -> ns_ref .)
     IMPLEMENT       reduce using rule 68 (implement_ns_list -> ns_ref .)
     IMPLEMENTATION  reduce using rule 68 (implement_ns_list -> ns_ref .)
@@ -7201,18 +6665,18 @@
     FALSE           reduce using rule 68 (implement_ns_list -> ns_ref .)
     STRING          reduce using rule 68 (implement_ns_list -> ns_ref .)
     FSTRING         reduce using rule 68 (implement_ns_list -> ns_ref .)
     RSTRING         reduce using rule 68 (implement_ns_list -> ns_ref .)
     [               reduce using rule 68 (implement_ns_list -> ns_ref .)
     {               reduce using rule 68 (implement_ns_list -> ns_ref .)
     $end            reduce using rule 68 (implement_ns_list -> ns_ref .)
-    SEP             shift and go to state 154
+    SEP             shift and go to state 143
 
 
-state 205
+state 193
 
     (69) implement_ns_list -> PARENTS .
 
     MLS             reduce using rule 69 (implement_ns_list -> PARENTS .)
     WHEN            reduce using rule 69 (implement_ns_list -> PARENTS .)
     ,               reduce using rule 69 (implement_ns_list -> PARENTS .)
     ENTITY          reduce using rule 69 (implement_ns_list -> PARENTS .)
@@ -7237,640 +6701,577 @@
     FSTRING         reduce using rule 69 (implement_ns_list -> PARENTS .)
     RSTRING         reduce using rule 69 (implement_ns_list -> PARENTS .)
     [               reduce using rule 69 (implement_ns_list -> PARENTS .)
     {               reduce using rule 69 (implement_ns_list -> PARENTS .)
     $end            reduce using rule 69 (implement_ns_list -> PARENTS .)
 
 
-state 206
+state 194
 
-    (173) attr_ref -> var_ref . ID .
+    (172) attr_ref -> var_ref . ID .
 
-    .               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    ,               reduce using rule 173 (attr_ref -> var_ref . ID .)
-    :               reduce using rule 173 (attr_ref -> var_ref . ID .)
+    .               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    ,               reduce using rule 172 (attr_ref -> var_ref . ID .)
+    :               reduce using rule 172 (attr_ref -> var_ref . ID .)
 
 
-state 207
+state 195
 
     (80) relation -> class_ref ID multi REL . multi class_ref ID
     (81) relation -> class_ref ID multi REL . multi class_ref ID MLS
     (88) multi -> . [ INT ]
     (89) multi -> . [ INT : ]
     (90) multi -> . [ INT : INT ]
     (91) multi -> . [ : INT ]
 
-    [               shift and go to state 131
+    [               shift and go to state 121
 
-    multi                          shift and go to state 267
+    multi                          shift and go to state 254
 
-state 208
+state 196
 
     (88) multi -> [ INT . ]
     (89) multi -> [ INT . : ]
     (90) multi -> [ INT . : INT ]
 
-    ]               shift and go to state 268
-    :               shift and go to state 269
+    ]               shift and go to state 255
+    :               shift and go to state 256
 
 
-state 209
+state 197
 
     (91) multi -> [ : . INT ]
 
-    INT             shift and go to state 270
+    INT             shift and go to state 257
 
 
-state 210
+state 198
 
     (84) relation_def -> class_ref . ID multi . REL class_ref . ID multi
     (85) relation_def -> class_ref . ID multi . REL class_ref
     (86) relation_def -> class_ref . ID multi . operand_list class_ref . ID multi
     (87) relation_def -> class_ref . ID multi . operand_list class_ref
-    (169) operand_list -> . operand , operand_list
-    (170) operand_list -> . operand
-    (171) operand_list -> . empty
-    (118) operand -> . expression empty
-    (2) empty -> .
+    (168) operand_list -> . operand , operand_list
+    (169) operand_list -> . operand
+    (170) operand_list -> .
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    REL             shift and go to state 271
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-  ! CID             [ reduce using rule 2 (empty -> .) ]
-  ! ID              [ reduce using rule 2 (empty -> .) ]
-
-    class_ref                      shift and go to state 92
-    operand_list                   shift and go to state 272
-    operand                        shift and go to state 115
-    empty                          shift and go to state 116
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    REL             shift and go to state 258
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+  ! CID             [ reduce using rule 170 (operand_list -> .) ]
+  ! ID              [ reduce using rule 170 (operand_list -> .) ]
+
+    class_ref                      shift and go to state 87
+    operand_list                   shift and go to state 259
+    operand                        shift and go to state 106
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
 
-state 211
+state 199
 
-    (122) constructor -> class_ref ( param_list ) .
+    (121) constructor -> class_ref ( param_list ) .
 
-    CMP_OP          reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    IN              reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    AND             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    OR              reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    NOT             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ?               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ENTITY          reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    IMPLEMENT       reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    IMPLEMENTATION  reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    INDEX           reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    IMPORT          reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    CID             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    FOR             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    IF              reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    (               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    TYPEDEF         reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ID              reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    INT             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    FLOAT           reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    NULL            reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    REGEX           reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    TRUE            reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    FALSE           reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    STRING          reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    FSTRING         reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    RSTRING         reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    MLS             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    [               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    {               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    $end            reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    )               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    :               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ,               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ]               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ELSE            reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    ELIF            reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    END             reduce using rule 122 (constructor -> class_ref ( param_list ) .)
-    }               reduce using rule 122 (constructor -> class_ref ( param_list ) .)
+    CMP_OP          reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    IN              reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    AND             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    OR              reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ?               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ENTITY          reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    IMPLEMENT       reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    IMPLEMENTATION  reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    INDEX           reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    IMPORT          reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    CID             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    FOR             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    IF              reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    (               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    TYPEDEF         reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ID              reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    NOT             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    INT             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    FLOAT           reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    NULL            reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    REGEX           reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    TRUE            reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    FALSE           reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    STRING          reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    FSTRING         reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    RSTRING         reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    MLS             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    [               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    {               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    $end            reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    )               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    :               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ,               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ]               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ELSE            reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    ELIF            reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    END             reduce using rule 121 (constructor -> class_ref ( param_list ) .)
+    }               reduce using rule 121 (constructor -> class_ref ( param_list ) .)
 
 
-state 212
+state 200
 
-    (161) param_list -> param_list_element empty . param_list_empty
-    (160) param_list_empty -> . empty
-    (2) empty -> .
+    (160) param_list -> param_list_element empty . param_list_empty
+    (159) param_list_empty -> . empty
+    (14) empty -> .
 
-    )               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
+    )               reduce using rule 14 (empty -> .)
+    ]               reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 136
-    param_list_empty               shift and go to state 273
+    empty                          shift and go to state 126
+    param_list_empty               shift and go to state 260
 
-state 213
+state 201
 
-    (162) param_list -> param_list_element , . param_list
-    (159) param_list -> . param_list_empty
-    (161) param_list -> . param_list_element empty param_list_empty
-    (162) param_list -> . param_list_element , param_list
-    (160) param_list_empty -> . empty
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (2) empty -> .
-    (156) wrapped_kwargs -> . * * operand
-
-    ID              shift and go to state 137
-    )               reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-    *               shift and go to state 139
-
-    param_list_element             shift and go to state 135
-    param_list                     shift and go to state 274
-    param_list_empty               shift and go to state 134
-    empty                          shift and go to state 136
-    wrapped_kwargs                 shift and go to state 138
+    (161) param_list -> param_list_element , . param_list
+    (158) param_list -> . param_list_empty
+    (160) param_list -> . param_list_element empty param_list_empty
+    (161) param_list -> . param_list_element , param_list
+    (159) param_list_empty -> . empty
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (14) empty -> .
+    (155) wrapped_kwargs -> . * * operand
+
+    ID              shift and go to state 127
+    )               reduce using rule 14 (empty -> .)
+    ]               reduce using rule 14 (empty -> .)
+    *               shift and go to state 129
+
+    param_list_element             shift and go to state 125
+    param_list                     shift and go to state 261
+    param_list_empty               shift and go to state 124
+    empty                          shift and go to state 126
+    wrapped_kwargs                 shift and go to state 128
 
-state 214
+state 202
 
-    (157) param_list_element -> ID = . operand
-    (118) operand -> . expression empty
+    (156) param_list_element -> ID = . operand
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    operand                        shift and go to state 275
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    operand                        shift and go to state 262
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 215
+state 203
 
-    (156) wrapped_kwargs -> * * . operand
-    (118) operand -> . expression empty
+    (155) wrapped_kwargs -> * * . operand
+    (117) operand -> . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    operand                        shift and go to state 276
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
-
-state 216
-
-    (139) index_lookup -> class_ref [ param_list ] .
-
-    CMP_OP          reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    IN              reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    AND             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    OR              reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    NOT             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ?               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ENTITY          reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    IMPLEMENT       reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    IMPLEMENTATION  reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    INDEX           reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    IMPORT          reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    CID             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    FOR             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    IF              reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    (               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    TYPEDEF         reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ID              reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    INT             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    FLOAT           reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    NULL            reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    REGEX           reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    TRUE            reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    FALSE           reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    STRING          reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    FSTRING         reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    RSTRING         reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    MLS             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    [               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    {               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    $end            reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    )               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    :               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ,               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ]               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ELSE            reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    ELIF            reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    END             reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
-    }               reduce using rule 139 (index_lookup -> class_ref [ param_list ] .)
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    operand                        shift and go to state 263
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
+state 204
 
-state 217
-
-    (113) boolean_expression -> expression NOT IN expression .
-    (109) boolean_expression -> expression . CMP_OP expression
-    (110) boolean_expression -> expression . IN expression
-    (111) boolean_expression -> expression . AND expression
-    (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (138) index_lookup -> class_ref [ param_list ] .
 
-    CMP_OP          reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    IN              reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    AND             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    OR              reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    NOT             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ?               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ENTITY          reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    IMPLEMENT       reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    IMPLEMENTATION  reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    INDEX           reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    IMPORT          reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    CID             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    FOR             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    IF              reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    (               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    TYPEDEF         reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ID              reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    INT             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    FLOAT           reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    NULL            reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    REGEX           reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    TRUE            reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    FALSE           reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    STRING          reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    FSTRING         reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    RSTRING         reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    MLS             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    [               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    {               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    $end            reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    )               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    :               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ,               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ]               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ELSE            reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    ELIF            reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    END             reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-    }               reduce using rule 113 (boolean_expression -> expression NOT IN expression .)
-
-  ! CMP_OP          [ shift and go to state 74 ]
-  ! IN              [ shift and go to state 75 ]
-  ! AND             [ shift and go to state 76 ]
-  ! OR              [ shift and go to state 77 ]
-  ! NOT             [ shift and go to state 78 ]
-  ! ?               [ shift and go to state 79 ]
+    CMP_OP          reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    IN              reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    AND             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    OR              reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ?               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ENTITY          reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    IMPLEMENT       reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    IMPLEMENTATION  reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    INDEX           reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    IMPORT          reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    CID             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    FOR             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    IF              reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    (               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    TYPEDEF         reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ID              reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    NOT             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    INT             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    FLOAT           reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    NULL            reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    REGEX           reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    TRUE            reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    FALSE           reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    STRING          reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    FSTRING         reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    RSTRING         reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    MLS             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    [               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    {               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    $end            reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    )               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    :               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ,               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ]               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ELSE            reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    ELIF            reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    END             reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
+    }               reduce using rule 138 (index_lookup -> class_ref [ param_list ] .)
 
 
-state 218
+state 205
 
-    (141) conditional_expression -> expression ? expression : . expression
+    (140) conditional_expression -> expression ? expression : . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 277
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 264
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 219
+state 206
 
     (75) implementation_def -> IMPLEMENTATION ID FOR class_ref . implementation
     (76) implementation -> . implementation_head block
     (77) implementation_head -> . :
     (78) implementation_head -> . : MLS
 
-    :               shift and go to state 280
+    :               shift and go to state 267
 
-    implementation                 shift and go to state 278
-    implementation_head            shift and go to state 279
+    implementation                 shift and go to state 265
+    implementation_head            shift and go to state 266
 
-state 220
+state 207
 
     (25) for -> FOR ID IN operand . : block
 
-    :               shift and go to state 281
+    :               shift and go to state 268
 
 
-state 221
+state 208
 
     (96) index -> INDEX class_ref ( id_list . )
 
-    )               shift and go to state 282
+    )               shift and go to state 269
 
 
-state 222
+state 209
 
-    (184) id_list -> ID . , id_list
-    (185) id_list -> ID .
+    (183) id_list -> ID . , id_list
+    (184) id_list -> ID .
 
-    ,               shift and go to state 283
-    )               reduce using rule 185 (id_list -> ID .)
+    ,               shift and go to state 270
+    )               reduce using rule 184 (id_list -> ID .)
 
 
-state 223
+state 210
 
     (16) import -> IMPORT ns_ref AS ID .
 
     ENTITY          reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     IMPLEMENT       reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     IMPLEMENTATION  reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     INDEX           reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
@@ -7893,506 +7294,500 @@
     RSTRING         reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     MLS             reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     [               reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     {               reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
     $end            reduce using rule 16 (import -> IMPORT ns_ref AS ID .)
 
 
-state 224
+state 211
 
-    (123) function_call -> ns_ref ( function_param_list ) .
+    (122) function_call -> ns_ref ( function_param_list ) .
 
-    CMP_OP          reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    IN              reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    AND             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    OR              reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    NOT             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ?               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ENTITY          reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    IMPLEMENT       reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    IMPLEMENTATION  reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    INDEX           reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    IMPORT          reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    CID             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    FOR             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    IF              reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    (               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    TYPEDEF         reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ID              reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    INT             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    FLOAT           reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    NULL            reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    REGEX           reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    TRUE            reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    FALSE           reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    STRING          reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    FSTRING         reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    RSTRING         reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    MLS             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    [               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    {               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    $end            reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    )               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    :               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ,               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ]               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ELSE            reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    ELIF            reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    END             reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
-    }               reduce using rule 123 (function_call -> ns_ref ( function_param_list ) .)
+    CMP_OP          reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    IN              reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    AND             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    OR              reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ?               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ENTITY          reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    IMPLEMENT       reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    IMPLEMENTATION  reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    INDEX           reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    IMPORT          reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    CID             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    FOR             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    IF              reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    (               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    TYPEDEF         reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ID              reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    NOT             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    INT             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    FLOAT           reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    NULL            reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    REGEX           reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    TRUE            reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    FALSE           reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    STRING          reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    FSTRING         reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    RSTRING         reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    MLS             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    [               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    {               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    $end            reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    )               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    :               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ,               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ]               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ELSE            reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    ELIF            reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    END             reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
+    }               reduce using rule 122 (function_call -> ns_ref ( function_param_list ) .)
 
 
-state 225
+state 212
 
-    (167) function_param_list -> function_param_list_element empty . function_param_list_empty
-    (166) function_param_list_empty -> . empty
-    (2) empty -> .
+    (166) function_param_list -> function_param_list_element empty . function_param_list_empty
+    (165) function_param_list_empty -> . empty
+    (14) empty -> .
 
-    )               reduce using rule 2 (empty -> .)
+    )               reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 160
-    function_param_list_empty      shift and go to state 284
+    empty                          shift and go to state 149
+    function_param_list_empty      shift and go to state 271
 
-state 226
+state 213
 
-    (168) function_param_list -> function_param_list_element , . function_param_list
-    (165) function_param_list -> . function_param_list_empty
-    (167) function_param_list -> . function_param_list_element empty function_param_list_empty
-    (168) function_param_list -> . function_param_list_element , function_param_list
-    (166) function_param_list_empty -> . empty
-    (163) function_param_list_element -> . param_list_element
-    (164) function_param_list_element -> . operand
-    (2) empty -> .
-    (157) param_list_element -> . ID = operand
-    (158) param_list_element -> . wrapped_kwargs
-    (118) operand -> . expression empty
-    (156) wrapped_kwargs -> . * * operand
+    (167) function_param_list -> function_param_list_element , . function_param_list
+    (164) function_param_list -> . function_param_list_empty
+    (166) function_param_list -> . function_param_list_element empty function_param_list_empty
+    (167) function_param_list -> . function_param_list_element , function_param_list
+    (165) function_param_list_empty -> . empty
+    (162) function_param_list_element -> . param_list_element
+    (163) function_param_list_element -> . operand
+    (14) empty -> .
+    (156) param_list_element -> . ID = operand
+    (157) param_list_element -> . wrapped_kwargs
+    (117) operand -> . expression
+    (155) wrapped_kwargs -> . * * operand
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    )               reduce using rule 2 (empty -> .)
-    ID              shift and go to state 163
-    *               shift and go to state 139
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    function_param_list_element    shift and go to state 159
-    function_param_list            shift and go to state 285
-    function_param_list_empty      shift and go to state 158
-    empty                          shift and go to state 160
-    param_list_element             shift and go to state 161
-    operand                        shift and go to state 162
-    wrapped_kwargs                 shift and go to state 138
-    expression                     shift and go to state 164
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    )               reduce using rule 14 (empty -> .)
+    ID              shift and go to state 152
+    *               shift and go to state 129
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    function_param_list_element    shift and go to state 148
+    function_param_list            shift and go to state 272
+    function_param_list_empty      shift and go to state 147
+    empty                          shift and go to state 149
+    param_list_element             shift and go to state 150
+    operand                        shift and go to state 151
+    wrapped_kwargs                 shift and go to state 128
+    expression                     shift and go to state 153
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 227
+state 214
 
-    (115) boolean_expression -> var_ref . ID IS . DEFINED
+    (114) boolean_expression -> var_ref . ID IS . DEFINED
 
-    DEFINED         shift and go to state 286
+    DEFINED         shift and go to state 273
 
 
-state 228
+state 215
 
-    (120) map_lookup -> var_ref [ operand ] .
+    (119) map_lookup -> var_ref [ operand ] .
 
-    IS              reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    [               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    CMP_OP          reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    IN              reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    AND             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    OR              reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    NOT             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ?               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ENTITY          reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    IMPLEMENT       reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    IMPLEMENTATION  reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    INDEX           reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    IMPORT          reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    CID             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    FOR             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    IF              reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    (               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    TYPEDEF         reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ID              reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    INT             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    FLOAT           reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    NULL            reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    REGEX           reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    TRUE            reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    FALSE           reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    STRING          reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    FSTRING         reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    RSTRING         reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    MLS             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    {               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    $end            reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    )               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    :               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ,               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ]               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ELSE            reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    ELIF            reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    END             reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
-    }               reduce using rule 120 (map_lookup -> var_ref [ operand ] .)
+    IS              reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    [               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    CMP_OP          reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    IN              reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    AND             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    OR              reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ?               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ENTITY          reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    IMPLEMENT       reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    IMPLEMENTATION  reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    INDEX           reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    IMPORT          reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    CID             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    FOR             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    IF              reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    (               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    TYPEDEF         reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ID              reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    NOT             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    INT             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    FLOAT           reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    NULL            reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    REGEX           reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    TRUE            reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    FALSE           reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    STRING          reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    FSTRING         reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    RSTRING         reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    MLS             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    {               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    $end            reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    )               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    :               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ,               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ]               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ELSE            reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    ELIF            reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    END             reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
+    }               reduce using rule 119 (map_lookup -> var_ref [ operand ] .)
 
 
-state 229
+state 216
 
     (27) if_body -> expression : stmt_list . if_next
     (28) if_next -> . empty
     (29) if_next -> . ELSE : stmt_list
     (30) if_next -> . ELIF if_body
-    (2) empty -> .
+    (14) empty -> .
 
-    ELSE            shift and go to state 289
-    ELIF            shift and go to state 290
-    END             reduce using rule 2 (empty -> .)
+    ELSE            shift and go to state 276
+    ELIF            shift and go to state 277
+    END             reduce using rule 14 (empty -> .)
 
-    if_next                        shift and go to state 287
-    empty                          shift and go to state 288
+    if_next                        shift and go to state 274
+    empty                          shift and go to state 275
 
-state 230
+state 217
 
     (21) stmt_list -> statement . stmt_list
     (21) stmt_list -> . statement stmt_list
     (22) stmt_list -> . empty
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (2) empty -> .
+    (20) statement -> . expression
+    (14) empty -> .
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    statement                      shift and go to state 230
-    stmt_list                      shift and go to state 291
-    empty                          shift and go to state 231
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    expression                     shift and go to state 22
-    var_ref                        shift and go to state 232
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
-    ns_ref                         shift and go to state 233
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    ELSE            reduce using rule 14 (empty -> .)
+    ELIF            reduce using rule 14 (empty -> .)
+    END             reduce using rule 14 (empty -> .)
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    statement                      shift and go to state 217
+    stmt_list                      shift and go to state 278
+    empty                          shift and go to state 218
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    expression                     shift and go to state 21
+    var_ref                        shift and go to state 219
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+    ns_ref                         shift and go to state 220
+    class_ref                      shift and go to state 87
 
-state 231
+state 218
 
     (22) stmt_list -> empty .
 
     ELSE            reduce using rule 22 (stmt_list -> empty .)
     ELIF            reduce using rule 22 (stmt_list -> empty .)
     END             reduce using rule 22 (stmt_list -> empty .)
 
 
-state 232
+state 219
 
     (23) assign -> var_ref . = operand
     (24) assign -> var_ref . PEQ operand
-    (100) expression -> var_ref . empty
-    (115) boolean_expression -> var_ref . . ID IS DEFINED
-    (120) map_lookup -> var_ref . [ operand ]
-    (173) attr_ref -> var_ref . . ID
-    (177) class_ref -> var_ref . . CID
-    (2) empty -> .
-
-    =               shift and go to state 98
-    PEQ             shift and go to state 99
-    .               shift and go to state 151
-    [               shift and go to state 101
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
+    (100) expression -> var_ref .
+    (114) boolean_expression -> var_ref . . ID IS DEFINED
+    (119) map_lookup -> var_ref . [ operand ]
+    (172) attr_ref -> var_ref . . ID
+    (176) class_ref -> var_ref . . CID
+
+    =               shift and go to state 92
+    PEQ             shift and go to state 93
+    CMP_OP          reduce using rule 100 (expression -> var_ref .)
+    IN              reduce using rule 100 (expression -> var_ref .)
+    AND             reduce using rule 100 (expression -> var_ref .)
+    OR              reduce using rule 100 (expression -> var_ref .)
+    ?               reduce using rule 100 (expression -> var_ref .)
+    FOR             reduce using rule 100 (expression -> var_ref .)
+    IF              reduce using rule 100 (expression -> var_ref .)
+    (               reduce using rule 100 (expression -> var_ref .)
+    NOT             reduce using rule 100 (expression -> var_ref .)
+    ID              reduce using rule 100 (expression -> var_ref .)
+    INT             reduce using rule 100 (expression -> var_ref .)
+    FLOAT           reduce using rule 100 (expression -> var_ref .)
+    NULL            reduce using rule 100 (expression -> var_ref .)
+    REGEX           reduce using rule 100 (expression -> var_ref .)
+    TRUE            reduce using rule 100 (expression -> var_ref .)
+    FALSE           reduce using rule 100 (expression -> var_ref .)
+    STRING          reduce using rule 100 (expression -> var_ref .)
+    FSTRING         reduce using rule 100 (expression -> var_ref .)
+    RSTRING         reduce using rule 100 (expression -> var_ref .)
+    MLS             reduce using rule 100 (expression -> var_ref .)
+    {               reduce using rule 100 (expression -> var_ref .)
+    CID             reduce using rule 100 (expression -> var_ref .)
+    ELSE            reduce using rule 100 (expression -> var_ref .)
+    ELIF            reduce using rule 100 (expression -> var_ref .)
+    END             reduce using rule 100 (expression -> var_ref .)
+    .               shift and go to state 140
+    [               shift and go to state 94
 
-  ! [               [ reduce using rule 2 (empty -> .) ]
+  ! [               [ reduce using rule 100 (expression -> var_ref .) ]
 
-    empty                          shift and go to state 100
 
-state 233
+state 220
 
-    (174) var_ref -> ns_ref . empty
-    (123) function_call -> ns_ref . ( function_param_list )
-    (182) ns_ref -> ns_ref . SEP ID
-    (176) class_ref -> ns_ref . SEP CID
-    (2) empty -> .
-
-    (               shift and go to state 96
-    SEP             shift and go to state 152
-    =               reduce using rule 2 (empty -> .)
-    PEQ             reduce using rule 2 (empty -> .)
-    .               reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    CMP_OP          reduce using rule 2 (empty -> .)
-    IN              reduce using rule 2 (empty -> .)
-    AND             reduce using rule 2 (empty -> .)
-    OR              reduce using rule 2 (empty -> .)
-    NOT             reduce using rule 2 (empty -> .)
-    ?               reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    MLS             reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    ELSE            reduce using rule 2 (empty -> .)
-    ELIF            reduce using rule 2 (empty -> .)
-    END             reduce using rule 2 (empty -> .)
+    (173) var_ref -> ns_ref .
+    (122) function_call -> ns_ref . ( function_param_list )
+    (181) ns_ref -> ns_ref . SEP ID
+    (175) class_ref -> ns_ref . SEP CID
+
+    =               reduce using rule 173 (var_ref -> ns_ref .)
+    PEQ             reduce using rule 173 (var_ref -> ns_ref .)
+    .               reduce using rule 173 (var_ref -> ns_ref .)
+    [               reduce using rule 173 (var_ref -> ns_ref .)
+    CMP_OP          reduce using rule 173 (var_ref -> ns_ref .)
+    IN              reduce using rule 173 (var_ref -> ns_ref .)
+    AND             reduce using rule 173 (var_ref -> ns_ref .)
+    OR              reduce using rule 173 (var_ref -> ns_ref .)
+    ?               reduce using rule 173 (var_ref -> ns_ref .)
+    FOR             reduce using rule 173 (var_ref -> ns_ref .)
+    IF              reduce using rule 173 (var_ref -> ns_ref .)
+    NOT             reduce using rule 173 (var_ref -> ns_ref .)
+    ID              reduce using rule 173 (var_ref -> ns_ref .)
+    INT             reduce using rule 173 (var_ref -> ns_ref .)
+    FLOAT           reduce using rule 173 (var_ref -> ns_ref .)
+    NULL            reduce using rule 173 (var_ref -> ns_ref .)
+    REGEX           reduce using rule 173 (var_ref -> ns_ref .)
+    TRUE            reduce using rule 173 (var_ref -> ns_ref .)
+    FALSE           reduce using rule 173 (var_ref -> ns_ref .)
+    STRING          reduce using rule 173 (var_ref -> ns_ref .)
+    FSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    RSTRING         reduce using rule 173 (var_ref -> ns_ref .)
+    MLS             reduce using rule 173 (var_ref -> ns_ref .)
+    {               reduce using rule 173 (var_ref -> ns_ref .)
+    CID             reduce using rule 173 (var_ref -> ns_ref .)
+    ELSE            reduce using rule 173 (var_ref -> ns_ref .)
+    ELIF            reduce using rule 173 (var_ref -> ns_ref .)
+    END             reduce using rule 173 (var_ref -> ns_ref .)
+    (               shift and go to state 90
+    SEP             shift and go to state 141
 
-  ! (               [ reduce using rule 2 (empty -> .) ]
+  ! (               [ reduce using rule 173 (var_ref -> ns_ref .) ]
 
-    empty                          shift and go to state 95
 
-state 234
+state 221
 
-    (121) map_lookup -> map_lookup [ operand ] .
+    (120) map_lookup -> map_lookup [ operand ] .
 
-    IS              reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    [               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    CMP_OP          reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    IN              reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    AND             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    OR              reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    NOT             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ?               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ENTITY          reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    IMPLEMENT       reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    IMPLEMENTATION  reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    INDEX           reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    IMPORT          reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    CID             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    FOR             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    IF              reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    (               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    TYPEDEF         reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ID              reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    INT             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    FLOAT           reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    NULL            reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    REGEX           reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    TRUE            reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    FALSE           reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    STRING          reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    FSTRING         reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    RSTRING         reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    MLS             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    {               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    $end            reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    )               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    :               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ,               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ]               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ELSE            reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    ELIF            reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    END             reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
-    }               reduce using rule 121 (map_lookup -> map_lookup [ operand ] .)
+    IS              reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    [               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    CMP_OP          reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    IN              reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    AND             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    OR              reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ?               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ENTITY          reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    IMPLEMENT       reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    IMPLEMENTATION  reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    INDEX           reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    IMPORT          reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    CID             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    FOR             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    IF              reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    (               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    TYPEDEF         reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ID              reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    NOT             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    INT             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    FLOAT           reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    NULL            reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    REGEX           reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    TRUE            reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    FALSE           reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    STRING          reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    FSTRING         reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    RSTRING         reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    MLS             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    {               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    $end            reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    )               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    :               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ,               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ]               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ELSE            reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    ELIF            reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    END             reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
+    }               reduce using rule 120 (map_lookup -> map_lookup [ operand ] .)
 
 
-state 235
+state 222
 
     (94) typedef_inner -> TYPEDEF ID AS ns_ref . MATCHING expression
-    (182) ns_ref -> ns_ref . SEP ID
+    (181) ns_ref -> ns_ref . SEP ID
 
-    MATCHING        shift and go to state 292
-    SEP             shift and go to state 154
+    MATCHING        shift and go to state 279
+    SEP             shift and go to state 143
 
 
-state 236
+state 223
 
     (95) typedef_inner -> TYPEDEF CID AS constructor .
 
     MLS             reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     ENTITY          reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     IMPLEMENT       reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     IMPLEMENTATION  reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
@@ -8415,285 +7810,284 @@
     FSTRING         reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     RSTRING         reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     [               reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     {               reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
     $end            reduce using rule 95 (typedef_inner -> TYPEDEF CID AS constructor .)
 
 
-state 237
+state 224
 
-    (122) constructor -> class_ref . ( param_list )
+    (121) constructor -> class_ref . ( param_list )
 
-    (               shift and go to state 71
+    (               shift and go to state 70
 
 
-state 238
+state 225
 
-    (124) function_call -> attr_ref ( function_param_list ) .
+    (123) function_call -> attr_ref ( function_param_list ) .
 
-    CMP_OP          reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    IN              reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    AND             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    OR              reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    NOT             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ?               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ENTITY          reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    IMPLEMENT       reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    IMPLEMENTATION  reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    INDEX           reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    IMPORT          reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    CID             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    FOR             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    IF              reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    (               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    TYPEDEF         reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ID              reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    INT             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    FLOAT           reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    NULL            reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    REGEX           reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    TRUE            reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    FALSE           reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    STRING          reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    FSTRING         reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    RSTRING         reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    MLS             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    [               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    {               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    $end            reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    )               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    :               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ,               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ]               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ELSE            reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    ELIF            reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    END             reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
-    }               reduce using rule 124 (function_call -> attr_ref ( function_param_list ) .)
+    CMP_OP          reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    IN              reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    AND             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    OR              reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ?               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ENTITY          reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    IMPLEMENT       reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    IMPLEMENTATION  reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    INDEX           reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    IMPORT          reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    CID             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    FOR             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    IF              reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    (               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    TYPEDEF         reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ID              reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    NOT             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    INT             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    FLOAT           reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    NULL            reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    REGEX           reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    TRUE            reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    FALSE           reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    STRING          reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    FSTRING         reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    RSTRING         reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    MLS             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    [               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    {               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    $end            reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    )               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    :               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ,               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ]               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ELSE            reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    ELIF            reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    END             reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
+    }               reduce using rule 123 (function_call -> attr_ref ( function_param_list ) .)
 
 
-state 239
+state 226
 
-    (119) map_lookup -> attr_ref [ operand ] .
+    (118) map_lookup -> attr_ref [ operand ] .
 
-    IS              reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    [               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    CMP_OP          reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    IN              reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    AND             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    OR              reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    NOT             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ?               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ENTITY          reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    IMPLEMENT       reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    IMPLEMENTATION  reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    INDEX           reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    IMPORT          reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    CID             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    FOR             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    IF              reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    (               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    TYPEDEF         reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ID              reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    INT             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    FLOAT           reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    NULL            reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    REGEX           reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    TRUE            reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    FALSE           reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    STRING          reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    FSTRING         reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    RSTRING         reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    MLS             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    {               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    $end            reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    )               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    :               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ,               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ]               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ELSE            reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    ELIF            reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    END             reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
-    }               reduce using rule 119 (map_lookup -> attr_ref [ operand ] .)
+    IS              reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    [               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    CMP_OP          reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    IN              reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    AND             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    OR              reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ?               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ENTITY          reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    IMPLEMENT       reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    IMPLEMENTATION  reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    INDEX           reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    IMPORT          reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    CID             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    FOR             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    IF              reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    (               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    TYPEDEF         reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ID              reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    NOT             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    INT             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    FLOAT           reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    NULL            reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    REGEX           reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    TRUE            reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    FALSE           reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    STRING          reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    FSTRING         reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    RSTRING         reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    MLS             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    {               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    $end            reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    )               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    :               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ,               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ]               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ELSE            reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    ELIF            reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    END             reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
+    }               reduce using rule 118 (map_lookup -> attr_ref [ operand ] .)
 
 
-state 240
+state 227
 
-    (140) index_lookup -> attr_ref [ param_list ] .
+    (139) index_lookup -> attr_ref [ param_list ] .
 
-    CMP_OP          reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    IN              reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    AND             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    OR              reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    NOT             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ?               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ENTITY          reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    IMPLEMENT       reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    IMPLEMENTATION  reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    INDEX           reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    IMPORT          reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    CID             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    FOR             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    IF              reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    (               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    TYPEDEF         reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ID              reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    INT             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    FLOAT           reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    NULL            reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    REGEX           reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    TRUE            reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    FALSE           reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    STRING          reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    FSTRING         reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    RSTRING         reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    MLS             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    [               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    {               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    $end            reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    )               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    :               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ,               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ]               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ELSE            reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    ELIF            reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    END             reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
-    }               reduce using rule 140 (index_lookup -> attr_ref [ param_list ] .)
+    CMP_OP          reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    IN              reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    AND             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    OR              reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ?               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ENTITY          reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    IMPLEMENT       reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    IMPLEMENTATION  reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    INDEX           reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    IMPORT          reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    CID             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    FOR             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    IF              reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    (               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    TYPEDEF         reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ID              reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    NOT             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    INT             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    FLOAT           reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    NULL            reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    REGEX           reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    TRUE            reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    FALSE           reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    STRING          reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    FSTRING         reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    RSTRING         reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    MLS             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    [               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    {               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    $end            reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    )               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    :               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ,               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ]               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ELSE            reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    ELIF            reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    END             reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
+    }               reduce using rule 139 (index_lookup -> attr_ref [ param_list ] .)
 
 
-state 241
+state 228
 
-    (126) list_comprehension -> [ expression list_comprehension_for list_comprehension_guard . ]
+    (125) list_comprehension -> [ expression list_comprehension_for list_comprehension_guard . ]
 
-    ]               shift and go to state 293
+    ]               shift and go to state 280
 
 
-state 242
+state 229
 
-    (130) list_comprehension_guard -> empty .
+    (129) list_comprehension_guard -> empty .
 
-    ]               reduce using rule 130 (list_comprehension_guard -> empty .)
+    ]               reduce using rule 129 (list_comprehension_guard -> empty .)
 
 
-state 243
+state 230
 
-    (131) list_comprehension_guard -> IF . expression list_comprehension_guard
+    (130) list_comprehension_guard -> IF . expression list_comprehension_guard
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 294
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 281
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 244
+state 231
 
-    (128) list_comprehension_for -> FOR ID . IN expression list_comprehension_for_empty
-    (129) list_comprehension_for -> FOR ID . IN expression list_comprehension_for
+    (127) list_comprehension_for -> FOR ID . IN expression list_comprehension_for_empty
+    (128) list_comprehension_for -> FOR ID . IN expression list_comprehension_for
 
-    IN              shift and go to state 295
+    IN              shift and go to state 282
 
 
-state 245
+state 232
 
-    (169) operand_list -> operand , operand_list .
+    (168) operand_list -> operand , operand_list .
 
-    ]               reduce using rule 169 (operand_list -> operand , operand_list .)
-    CID             reduce using rule 169 (operand_list -> operand , operand_list .)
-    ID              reduce using rule 169 (operand_list -> operand , operand_list .)
+    ]               reduce using rule 168 (operand_list -> operand , operand_list .)
+    CID             reduce using rule 168 (operand_list -> operand , operand_list .)
+    ID              reduce using rule 168 (operand_list -> operand , operand_list .)
 
 
-state 246
+state 233
 
-    (134) pair_list -> dict_key : operand . , pair_list
-    (135) pair_list -> dict_key : operand . empty pair_list_empty
-    (2) empty -> .
+    (133) pair_list -> dict_key : operand . , pair_list
+    (134) pair_list -> dict_key : operand . empty pair_list_empty
+    (14) empty -> .
 
-    ,               shift and go to state 296
-    }               reduce using rule 2 (empty -> .)
+    ,               shift and go to state 283
+    }               reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 297
+    empty                          shift and go to state 284
 
-state 247
+state 234
 
     (35) entity_body_outer -> MLS entity_body . END
     (39) entity_body -> entity_body . attr
     (48) attr -> . attr_type CID empty
     (49) attr -> . attr_type CID = constant
     (50) attr -> . attr_type CID = constant_list
     (51) attr -> . attr_type CID = UNDEF
@@ -8716,29 +8110,29 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    END             shift and go to state 298
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    attr                           shift and go to state 250
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    END             shift and go to state 285
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    attr                           shift and go to state 237
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 248
+state 235
 
     (38) entity_body_outer -> MLS END .
 
     ENTITY          reduce using rule 38 (entity_body_outer -> MLS END .)
     IMPLEMENT       reduce using rule 38 (entity_body_outer -> MLS END .)
     IMPLEMENTATION  reduce using rule 38 (entity_body_outer -> MLS END .)
     INDEX           reduce using rule 38 (entity_body_outer -> MLS END .)
@@ -8761,15 +8155,15 @@
     RSTRING         reduce using rule 38 (entity_body_outer -> MLS END .)
     MLS             reduce using rule 38 (entity_body_outer -> MLS END .)
     [               reduce using rule 38 (entity_body_outer -> MLS END .)
     {               reduce using rule 38 (entity_body_outer -> MLS END .)
     $end            reduce using rule 38 (entity_body_outer -> MLS END .)
 
 
-state 249
+state 236
 
     (36) entity_body_outer -> entity_body END .
 
     ENTITY          reduce using rule 36 (entity_body_outer -> entity_body END .)
     IMPLEMENT       reduce using rule 36 (entity_body_outer -> entity_body END .)
     IMPLEMENTATION  reduce using rule 36 (entity_body_outer -> entity_body END .)
     INDEX           reduce using rule 36 (entity_body_outer -> entity_body END .)
@@ -8792,109 +8186,109 @@
     RSTRING         reduce using rule 36 (entity_body_outer -> entity_body END .)
     MLS             reduce using rule 36 (entity_body_outer -> entity_body END .)
     [               reduce using rule 36 (entity_body_outer -> entity_body END .)
     {               reduce using rule 36 (entity_body_outer -> entity_body END .)
     $end            reduce using rule 36 (entity_body_outer -> entity_body END .)
 
 
-state 250
+state 237
 
     (39) entity_body -> entity_body attr .
 
     END             reduce using rule 39 (entity_body -> entity_body attr .)
     DICT            reduce using rule 39 (entity_body -> entity_body attr .)
     ID              reduce using rule 39 (entity_body -> entity_body attr .)
 
 
-state 251
+state 238
 
     (48) attr -> attr_type CID . empty
     (49) attr -> attr_type CID . = constant
     (50) attr -> attr_type CID . = constant_list
     (51) attr -> attr_type CID . = UNDEF
-    (2) empty -> .
+    (14) empty -> .
 
-    =               shift and go to state 300
-    END             reduce using rule 2 (empty -> .)
-    DICT            reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
+    =               shift and go to state 287
+    END             reduce using rule 14 (empty -> .)
+    DICT            reduce using rule 14 (empty -> .)
+    ID              reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 299
+    empty                          shift and go to state 286
 
-state 252
+state 239
 
     (52) attr -> attr_type ID .
     (53) attr -> attr_type ID . = constant
     (54) attr -> attr_type ID . = constant_list
     (55) attr -> attr_type ID . = UNDEF
 
     END             reduce using rule 52 (attr -> attr_type ID .)
     DICT            reduce using rule 52 (attr -> attr_type ID .)
     ID              reduce using rule 52 (attr -> attr_type ID .)
-    =               shift and go to state 301
+    =               shift and go to state 288
 
 
-state 253
+state 240
 
     (56) attr -> DICT empty . CID empty
     (57) attr -> DICT empty . CID = map_def
     (58) attr -> DICT empty . CID = NULL
 
-    CID             shift and go to state 302
+    CID             shift and go to state 289
 
 
-state 254
+state 241
 
     (59) attr -> DICT ? . CID empty
     (60) attr -> DICT ? . CID = map_def
     (61) attr -> DICT ? . CID = NULL
     (65) attr -> DICT ? . ID
     (66) attr -> DICT ? . ID = map_def
     (67) attr -> DICT ? . ID = NULL
 
-    CID             shift and go to state 303
-    ID              shift and go to state 304
+    CID             shift and go to state 290
+    ID              shift and go to state 291
 
 
-state 255
+state 242
 
     (62) attr -> DICT ID .
     (63) attr -> DICT ID . = map_def
     (64) attr -> DICT ID . = NULL
 
     END             reduce using rule 62 (attr -> DICT ID .)
     DICT            reduce using rule 62 (attr -> DICT ID .)
     ID              reduce using rule 62 (attr -> DICT ID .)
-    =               shift and go to state 305
+    =               shift and go to state 292
 
 
-state 256
+state 243
 
     (43) attr_type_opt -> attr_type_multi ? .
 
     CID             reduce using rule 43 (attr_type_opt -> attr_type_multi ? .)
     ID              reduce using rule 43 (attr_type_opt -> attr_type_multi ? .)
 
 
-state 257
+state 244
 
     (44) attr_type_opt -> attr_base_type ? .
 
     CID             reduce using rule 44 (attr_type_opt -> attr_base_type ? .)
     ID              reduce using rule 44 (attr_type_opt -> attr_base_type ? .)
 
 
-state 258
+state 245
 
     (42) attr_type_multi -> attr_base_type [ . ]
 
-    ]               shift and go to state 306
+    ]               shift and go to state 293
 
 
-state 259
+state 246
 
     (33) entity_def -> ENTITY CID EXTENDS class_ref_list : . entity_body_outer
     (35) entity_body_outer -> . MLS entity_body END
     (36) entity_body_outer -> . entity_body END
     (37) entity_body_outer -> . END
     (38) entity_body_outer -> . MLS END
     (39) entity_body -> . entity_body attr
@@ -8922,82 +8316,82 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    MLS             shift and go to state 187
-    END             shift and go to state 189
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    entity_body_outer              shift and go to state 307
-    entity_body                    shift and go to state 188
-    attr                           shift and go to state 190
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    MLS             shift and go to state 175
+    END             shift and go to state 177
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    entity_body_outer              shift and go to state 294
+    entity_body                    shift and go to state 176
+    attr                           shift and go to state 178
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 260
+state 247
 
-    (178) class_ref_list -> class_ref , . class_ref_list
-    (178) class_ref_list -> . class_ref , class_ref_list
-    (179) class_ref_list -> . var_ref , class_ref_list
-    (180) class_ref_list -> . class_ref
-    (181) class_ref_list -> . var_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 198
-    class_ref_list                 shift and go to state 308
-    var_ref                        shift and go to state 199
-    ns_ref                         shift and go to state 200
-    attr_ref                       shift and go to state 68
+    (177) class_ref_list -> class_ref , . class_ref_list
+    (177) class_ref_list -> . class_ref , class_ref_list
+    (178) class_ref_list -> . var_ref , class_ref_list
+    (179) class_ref_list -> . class_ref
+    (180) class_ref_list -> . var_ref
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 186
+    class_ref_list                 shift and go to state 295
+    var_ref                        shift and go to state 187
+    ns_ref                         shift and go to state 188
+    attr_ref                       shift and go to state 67
 
-state 261
+state 248
 
-    (179) class_ref_list -> var_ref , . class_ref_list
-    (178) class_ref_list -> . class_ref , class_ref_list
-    (179) class_ref_list -> . var_ref , class_ref_list
-    (180) class_ref_list -> . class_ref
-    (181) class_ref_list -> . var_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    var_ref                        shift and go to state 199
-    class_ref_list                 shift and go to state 309
-    class_ref                      shift and go to state 198
-    ns_ref                         shift and go to state 200
-    attr_ref                       shift and go to state 68
+    (178) class_ref_list -> var_ref , . class_ref_list
+    (177) class_ref_list -> . class_ref , class_ref_list
+    (178) class_ref_list -> . var_ref , class_ref_list
+    (179) class_ref_list -> . class_ref
+    (180) class_ref_list -> . var_ref
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    var_ref                        shift and go to state 187
+    class_ref_list                 shift and go to state 296
+    class_ref                      shift and go to state 186
+    ns_ref                         shift and go to state 188
+    attr_ref                       shift and go to state 67
 
-state 262
+state 249
 
     (34) entity_def -> ENTITY ID EXTENDS class_ref_list : . entity_body_outer
     (35) entity_body_outer -> . MLS entity_body END
     (36) entity_body_outer -> . entity_body END
     (37) entity_body_outer -> . END
     (38) entity_body_outer -> . MLS END
     (39) entity_body -> . entity_body attr
@@ -9025,32 +8419,32 @@
     (45) attr_type -> . attr_type_opt
     (46) attr_type -> . attr_type_multi
     (47) attr_type -> . attr_base_type
     (43) attr_type_opt -> . attr_type_multi ?
     (44) attr_type_opt -> . attr_base_type ?
     (42) attr_type_multi -> . attr_base_type [ ]
     (41) attr_base_type -> . ns_ref
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    MLS             shift and go to state 187
-    END             shift and go to state 189
-    DICT            shift and go to state 192
-    ID              shift and go to state 67
-
-    entity_body_outer              shift and go to state 310
-    entity_body                    shift and go to state 188
-    attr                           shift and go to state 190
-    attr_type                      shift and go to state 191
-    attr_type_opt                  shift and go to state 193
-    attr_type_multi                shift and go to state 194
-    attr_base_type                 shift and go to state 195
-    ns_ref                         shift and go to state 196
+    MLS             shift and go to state 175
+    END             shift and go to state 177
+    DICT            shift and go to state 180
+    ID              shift and go to state 66
+
+    entity_body_outer              shift and go to state 297
+    entity_body                    shift and go to state 176
+    attr                           shift and go to state 178
+    attr_type                      shift and go to state 179
+    attr_type_opt                  shift and go to state 181
+    attr_type_multi                shift and go to state 182
+    attr_base_type                 shift and go to state 183
+    ns_ref                         shift and go to state 184
 
-state 263
+state 250
 
     (71) implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .
 
     ENTITY          reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     IMPLEMENT       reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     IMPLEMENTATION  reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     INDEX           reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
@@ -9073,15 +8467,15 @@
     RSTRING         reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     MLS             reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     [               reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     {               reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
     $end            reduce using rule 71 (implement_def -> IMPLEMENT class_ref USING implement_ns_list empty .)
 
 
-state 264
+state 251
 
     (72) implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .
 
     ENTITY          reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     IMPLEMENT       reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     IMPLEMENTATION  reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     INDEX           reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
@@ -9104,140 +8498,139 @@
     RSTRING         reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     MLS             reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     [               reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     {               reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
     $end            reduce using rule 72 (implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS .)
 
 
-state 265
+state 252
 
     (73) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN . expression empty
     (74) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN . expression MLS
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    class_ref                      shift and go to state 92
-    expression                     shift and go to state 311
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    class_ref                      shift and go to state 87
+    expression                     shift and go to state 298
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
 
-state 266
+state 253
 
     (70) implement_ns_list -> implement_ns_list , . implement_ns_list
     (68) implement_ns_list -> . ns_ref
     (69) implement_ns_list -> . PARENTS
     (70) implement_ns_list -> . implement_ns_list , implement_ns_list
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
 
-    PARENTS         shift and go to state 205
-    ID              shift and go to state 67
+    PARENTS         shift and go to state 193
+    ID              shift and go to state 66
 
-    implement_ns_list              shift and go to state 312
-    ns_ref                         shift and go to state 204
+    implement_ns_list              shift and go to state 299
+    ns_ref                         shift and go to state 192
 
-state 267
+state 254
 
     (80) relation -> class_ref ID multi REL multi . class_ref ID
     (81) relation -> class_ref ID multi REL multi . class_ref ID MLS
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 313
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 300
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 268
+state 255
 
     (88) multi -> [ INT ] .
 
     REL             reduce using rule 88 (multi -> [ INT ] .)
     (               reduce using rule 88 (multi -> [ INT ] .)
     NOT             reduce using rule 88 (multi -> [ INT ] .)
     ID              reduce using rule 88 (multi -> [ INT ] .)
@@ -9261,164 +8654,162 @@
     IMPORT          reduce using rule 88 (multi -> [ INT ] .)
     FOR             reduce using rule 88 (multi -> [ INT ] .)
     IF              reduce using rule 88 (multi -> [ INT ] .)
     TYPEDEF         reduce using rule 88 (multi -> [ INT ] .)
     $end            reduce using rule 88 (multi -> [ INT ] .)
 
 
-state 269
+state 256
 
     (89) multi -> [ INT : . ]
     (90) multi -> [ INT : . INT ]
 
-    ]               shift and go to state 315
-    INT             shift and go to state 314
+    ]               shift and go to state 302
+    INT             shift and go to state 301
 
 
-state 270
+state 257
 
     (91) multi -> [ : INT . ]
 
-    ]               shift and go to state 316
+    ]               shift and go to state 303
 
 
-state 271
+state 258
 
     (84) relation_def -> class_ref . ID multi REL . class_ref . ID multi
     (85) relation_def -> class_ref . ID multi REL . class_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 317
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 304
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 272
+state 259
 
     (86) relation_def -> class_ref . ID multi operand_list . class_ref . ID multi
     (87) relation_def -> class_ref . ID multi operand_list . class_ref
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (173) attr_ref -> . var_ref . ID
-
-    CID             shift and go to state 17
-    ID              shift and go to state 67
-
-    class_ref                      shift and go to state 318
-    ns_ref                         shift and go to state 65
-    var_ref                        shift and go to state 66
-    attr_ref                       shift and go to state 68
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (172) attr_ref -> . var_ref . ID
+
+    CID             shift and go to state 16
+    ID              shift and go to state 66
+
+    class_ref                      shift and go to state 305
+    ns_ref                         shift and go to state 64
+    var_ref                        shift and go to state 65
+    attr_ref                       shift and go to state 67
 
-state 273
+state 260
 
-    (161) param_list -> param_list_element empty param_list_empty .
+    (160) param_list -> param_list_element empty param_list_empty .
 
-    )               reduce using rule 161 (param_list -> param_list_element empty param_list_empty .)
-    ]               reduce using rule 161 (param_list -> param_list_element empty param_list_empty .)
+    )               reduce using rule 160 (param_list -> param_list_element empty param_list_empty .)
+    ]               reduce using rule 160 (param_list -> param_list_element empty param_list_empty .)
 
 
-state 274
+state 261
 
-    (162) param_list -> param_list_element , param_list .
+    (161) param_list -> param_list_element , param_list .
 
-    )               reduce using rule 162 (param_list -> param_list_element , param_list .)
-    ]               reduce using rule 162 (param_list -> param_list_element , param_list .)
+    )               reduce using rule 161 (param_list -> param_list_element , param_list .)
+    ]               reduce using rule 161 (param_list -> param_list_element , param_list .)
 
 
-state 275
+state 262
 
-    (157) param_list_element -> ID = operand .
+    (156) param_list_element -> ID = operand .
 
-    ,               reduce using rule 157 (param_list_element -> ID = operand .)
-    )               reduce using rule 157 (param_list_element -> ID = operand .)
-    ]               reduce using rule 157 (param_list_element -> ID = operand .)
+    ,               reduce using rule 156 (param_list_element -> ID = operand .)
+    )               reduce using rule 156 (param_list_element -> ID = operand .)
+    ]               reduce using rule 156 (param_list_element -> ID = operand .)
 
 
-state 276
+state 263
 
-    (156) wrapped_kwargs -> * * operand .
+    (155) wrapped_kwargs -> * * operand .
 
-    ,               reduce using rule 156 (wrapped_kwargs -> * * operand .)
-    )               reduce using rule 156 (wrapped_kwargs -> * * operand .)
-    ]               reduce using rule 156 (wrapped_kwargs -> * * operand .)
+    ,               reduce using rule 155 (wrapped_kwargs -> * * operand .)
+    )               reduce using rule 155 (wrapped_kwargs -> * * operand .)
+    ]               reduce using rule 155 (wrapped_kwargs -> * * operand .)
 
 
-state 277
+state 264
 
-    (141) conditional_expression -> expression ? expression : expression .
+    (140) conditional_expression -> expression ? expression : expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
-    ENTITY          reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    IMPLEMENT       reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    IMPLEMENTATION  reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    INDEX           reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    IMPORT          reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    CID             reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    FOR             reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    IF              reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    (               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    TYPEDEF         reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    ID              reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    INT             reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    FLOAT           reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    NULL            reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    REGEX           reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    TRUE            reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    FALSE           reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    STRING          reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    FSTRING         reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    RSTRING         reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    MLS             reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    [               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    {               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    $end            reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    )               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    :               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    ,               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    ]               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    ELSE            reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    ELIF            reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    END             reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    }               reduce using rule 141 (conditional_expression -> expression ? expression : expression .)
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-
-  ! CMP_OP          [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
-  ! IN              [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
-  ! AND             [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
-  ! OR              [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
-  ! NOT             [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
-  ! ?               [ reduce using rule 141 (conditional_expression -> expression ? expression : expression .) ]
+    ENTITY          reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    IMPLEMENT       reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    IMPLEMENTATION  reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    INDEX           reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    IMPORT          reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    CID             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    FOR             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    IF              reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    (               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    TYPEDEF         reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    ID              reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    NOT             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    INT             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    FLOAT           reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    NULL            reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    REGEX           reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    TRUE            reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    FALSE           reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    STRING          reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    FSTRING         reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    RSTRING         reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    MLS             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    [               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    {               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    $end            reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    )               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    :               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    ,               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    ]               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    ELSE            reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    ELIF            reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    END             reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    }               reduce using rule 140 (conditional_expression -> expression ? expression : expression .)
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
+
+  ! CMP_OP          [ reduce using rule 140 (conditional_expression -> expression ? expression : expression .) ]
+  ! IN              [ reduce using rule 140 (conditional_expression -> expression ? expression : expression .) ]
+  ! AND             [ reduce using rule 140 (conditional_expression -> expression ? expression : expression .) ]
+  ! OR              [ reduce using rule 140 (conditional_expression -> expression ? expression : expression .) ]
+  ! ?               [ reduce using rule 140 (conditional_expression -> expression ? expression : expression .) ]
 
 
-state 278
+state 265
 
     (75) implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .
 
     ENTITY          reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     IMPLEMENT       reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     IMPLEMENTATION  reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     INDEX           reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
@@ -9441,125 +8832,124 @@
     RSTRING         reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     MLS             reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     [               reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     {               reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
     $end            reduce using rule 75 (implementation_def -> IMPLEMENTATION ID FOR class_ref implementation .)
 
 
-state 279
+state 266
 
     (76) implementation -> implementation_head . block
     (79) block -> . stmt_list END
     (21) stmt_list -> . statement stmt_list
     (22) stmt_list -> . empty
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (2) empty -> .
+    (20) statement -> . expression
+    (14) empty -> .
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    END             reduce using rule 2 (empty -> .)
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    block                          shift and go to state 319
-    stmt_list                      shift and go to state 320
-    statement                      shift and go to state 230
-    empty                          shift and go to state 231
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    expression                     shift and go to state 22
-    var_ref                        shift and go to state 232
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
-    ns_ref                         shift and go to state 233
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    END             reduce using rule 14 (empty -> .)
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    block                          shift and go to state 306
+    stmt_list                      shift and go to state 307
+    statement                      shift and go to state 217
+    empty                          shift and go to state 218
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    expression                     shift and go to state 21
+    var_ref                        shift and go to state 219
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+    ns_ref                         shift and go to state 220
+    class_ref                      shift and go to state 87
 
-state 280
+state 267
 
     (77) implementation_head -> : .
     (78) implementation_head -> : . MLS
 
     FOR             reduce using rule 77 (implementation_head -> : .)
     IF              reduce using rule 77 (implementation_head -> : .)
     (               reduce using rule 77 (implementation_head -> : .)
@@ -9574,130 +8964,129 @@
     STRING          reduce using rule 77 (implementation_head -> : .)
     FSTRING         reduce using rule 77 (implementation_head -> : .)
     RSTRING         reduce using rule 77 (implementation_head -> : .)
     [               reduce using rule 77 (implementation_head -> : .)
     {               reduce using rule 77 (implementation_head -> : .)
     CID             reduce using rule 77 (implementation_head -> : .)
     END             reduce using rule 77 (implementation_head -> : .)
-    MLS             shift and go to state 321
+    MLS             shift and go to state 308
 
   ! MLS             [ reduce using rule 77 (implementation_head -> : .) ]
 
 
-state 281
+state 268
 
     (25) for -> FOR ID IN operand : . block
     (79) block -> . stmt_list END
     (21) stmt_list -> . statement stmt_list
     (22) stmt_list -> . empty
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (2) empty -> .
+    (20) statement -> . expression
+    (14) empty -> .
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    END             reduce using rule 2 (empty -> .)
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    block                          shift and go to state 322
-    stmt_list                      shift and go to state 320
-    statement                      shift and go to state 230
-    empty                          shift and go to state 231
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    expression                     shift and go to state 22
-    var_ref                        shift and go to state 232
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
-    ns_ref                         shift and go to state 233
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    END             reduce using rule 14 (empty -> .)
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    block                          shift and go to state 309
+    stmt_list                      shift and go to state 307
+    statement                      shift and go to state 217
+    empty                          shift and go to state 218
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    expression                     shift and go to state 21
+    var_ref                        shift and go to state 219
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+    ns_ref                         shift and go to state 220
+    class_ref                      shift and go to state 87
 
-state 282
+state 269
 
     (96) index -> INDEX class_ref ( id_list ) .
 
     ENTITY          reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     IMPLEMENT       reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     IMPLEMENTATION  reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     INDEX           reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
@@ -9720,480 +9109,475 @@
     RSTRING         reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     MLS             reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     [               reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     {               reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
     $end            reduce using rule 96 (index -> INDEX class_ref ( id_list ) .)
 
 
-state 283
+state 270
 
-    (184) id_list -> ID , . id_list
-    (184) id_list -> . ID , id_list
-    (185) id_list -> . ID
+    (183) id_list -> ID , . id_list
+    (183) id_list -> . ID , id_list
+    (184) id_list -> . ID
 
-    ID              shift and go to state 222
+    ID              shift and go to state 209
 
-    id_list                        shift and go to state 323
+    id_list                        shift and go to state 310
 
-state 284
+state 271
 
-    (167) function_param_list -> function_param_list_element empty function_param_list_empty .
+    (166) function_param_list -> function_param_list_element empty function_param_list_empty .
 
-    )               reduce using rule 167 (function_param_list -> function_param_list_element empty function_param_list_empty .)
+    )               reduce using rule 166 (function_param_list -> function_param_list_element empty function_param_list_empty .)
 
 
-state 285
+state 272
 
-    (168) function_param_list -> function_param_list_element , function_param_list .
+    (167) function_param_list -> function_param_list_element , function_param_list .
 
-    )               reduce using rule 168 (function_param_list -> function_param_list_element , function_param_list .)
+    )               reduce using rule 167 (function_param_list -> function_param_list_element , function_param_list .)
 
 
-state 286
+state 273
 
-    (115) boolean_expression -> var_ref . ID IS DEFINED .
+    (114) boolean_expression -> var_ref . ID IS DEFINED .
 
-    CMP_OP          reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    IN              reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    AND             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    OR              reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    NOT             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ?               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ENTITY          reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    IMPLEMENT       reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    IMPLEMENTATION  reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    INDEX           reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    IMPORT          reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    CID             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    FOR             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    IF              reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    (               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    TYPEDEF         reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ID              reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    INT             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    FLOAT           reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    NULL            reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    REGEX           reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    TRUE            reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    FALSE           reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    STRING          reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    FSTRING         reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    RSTRING         reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    MLS             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    [               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    {               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    $end            reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    )               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    :               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ,               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ]               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ELSE            reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    ELIF            reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    END             reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
-    }               reduce using rule 115 (boolean_expression -> var_ref . ID IS DEFINED .)
+    CMP_OP          reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    IN              reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    AND             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    OR              reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ?               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ENTITY          reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    IMPLEMENT       reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    IMPLEMENTATION  reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    INDEX           reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    IMPORT          reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    CID             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    FOR             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    IF              reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    (               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    TYPEDEF         reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ID              reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    NOT             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    INT             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    FLOAT           reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    NULL            reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    REGEX           reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    TRUE            reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    FALSE           reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    STRING          reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    FSTRING         reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    RSTRING         reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    MLS             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    [               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    {               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    $end            reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    )               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    :               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ,               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ]               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ELSE            reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    ELIF            reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    END             reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
+    }               reduce using rule 114 (boolean_expression -> var_ref . ID IS DEFINED .)
 
 
-state 287
+state 274
 
     (27) if_body -> expression : stmt_list if_next .
 
     END             reduce using rule 27 (if_body -> expression : stmt_list if_next .)
 
 
-state 288
+state 275
 
     (28) if_next -> empty .
 
     END             reduce using rule 28 (if_next -> empty .)
 
 
-state 289
+state 276
 
     (29) if_next -> ELSE . : stmt_list
 
-    :               shift and go to state 324
+    :               shift and go to state 311
 
 
-state 290
+state 277
 
     (30) if_next -> ELIF . if_body
     (27) if_body -> . expression : stmt_list if_next
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    if_body                        shift and go to state 325
-    expression                     shift and go to state 103
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    if_body                        shift and go to state 312
+    expression                     shift and go to state 96
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 291
+state 278
 
     (21) stmt_list -> statement stmt_list .
 
     ELSE            reduce using rule 21 (stmt_list -> statement stmt_list .)
     ELIF            reduce using rule 21 (stmt_list -> statement stmt_list .)
     END             reduce using rule 21 (stmt_list -> statement stmt_list .)
 
 
-state 292
+state 279
 
     (94) typedef_inner -> TYPEDEF ID AS ns_ref MATCHING . expression
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    ns_ref                         shift and go to state 90
-    expression                     shift and go to state 326
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    ns_ref                         shift and go to state 85
+    expression                     shift and go to state 313
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 293
+state 280
 
-    (126) list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .
+    (125) list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .
 
-    CMP_OP          reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    IN              reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    AND             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    OR              reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    NOT             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ?               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ENTITY          reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    IMPLEMENT       reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    IMPLEMENTATION  reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    INDEX           reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    IMPORT          reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    CID             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    FOR             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    IF              reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    (               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    TYPEDEF         reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ID              reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    INT             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    FLOAT           reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    NULL            reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    REGEX           reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    TRUE            reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    FALSE           reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    STRING          reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    FSTRING         reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    RSTRING         reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    MLS             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    [               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    {               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    $end            reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    )               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    :               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ,               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ]               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ELSE            reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    ELIF            reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    END             reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
-    }               reduce using rule 126 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    CMP_OP          reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    IN              reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    AND             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    OR              reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ?               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ENTITY          reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    IMPLEMENT       reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    IMPLEMENTATION  reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    INDEX           reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    IMPORT          reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    CID             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    FOR             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    IF              reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    (               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    TYPEDEF         reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ID              reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    NOT             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    INT             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    FLOAT           reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    NULL            reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    REGEX           reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    TRUE            reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    FALSE           reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    STRING          reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    FSTRING         reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    RSTRING         reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    MLS             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    [               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    {               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    $end            reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    )               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    :               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ,               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ]               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ELSE            reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    ELIF            reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    END             reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
+    }               reduce using rule 125 (list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ] .)
 
 
-state 294
+state 281
 
-    (131) list_comprehension_guard -> IF expression . list_comprehension_guard
+    (130) list_comprehension_guard -> IF expression . list_comprehension_guard
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (130) list_comprehension_guard -> . empty
-    (131) list_comprehension_guard -> . IF expression list_comprehension_guard
-    (2) empty -> .
-
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    IF              shift and go to state 243
-    ]               reduce using rule 2 (empty -> .)
+    (140) conditional_expression -> expression . ? expression : expression
+    (129) list_comprehension_guard -> . empty
+    (130) list_comprehension_guard -> . IF expression list_comprehension_guard
+    (14) empty -> .
+
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
+    IF              shift and go to state 230
+    ]               reduce using rule 14 (empty -> .)
 
-    list_comprehension_guard       shift and go to state 327
-    empty                          shift and go to state 242
+    list_comprehension_guard       shift and go to state 314
+    empty                          shift and go to state 229
 
-state 295
+state 282
 
-    (128) list_comprehension_for -> FOR ID IN . expression list_comprehension_for_empty
-    (129) list_comprehension_for -> FOR ID IN . expression list_comprehension_for
+    (127) list_comprehension_for -> FOR ID IN . expression list_comprehension_for_empty
+    (128) list_comprehension_for -> FOR ID IN . expression list_comprehension_for
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (173) attr_ref -> . var_ref . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    expression                     shift and go to state 328
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    var_ref                        shift and go to state 88
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    ns_ref                         shift and go to state 90
-    attr_ref                       shift and go to state 91
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (172) attr_ref -> . var_ref . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    expression                     shift and go to state 315
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    var_ref                        shift and go to state 83
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    ns_ref                         shift and go to state 85
+    attr_ref                       shift and go to state 86
+    class_ref                      shift and go to state 87
 
-state 296
+state 283
 
-    (134) pair_list -> dict_key : operand , . pair_list
-    (134) pair_list -> . dict_key : operand , pair_list
-    (135) pair_list -> . dict_key : operand empty pair_list_empty
-    (136) pair_list -> . pair_list_empty
-    (132) dict_key -> . RSTRING
-    (133) dict_key -> . STRING
-    (137) pair_list_empty -> . empty
-    (2) empty -> .
-
-    RSTRING         shift and go to state 121
-    STRING          shift and go to state 122
-    }               reduce using rule 2 (empty -> .)
-
-    dict_key                       shift and go to state 118
-    pair_list                      shift and go to state 329
-    empty                          shift and go to state 119
-    pair_list_empty                shift and go to state 120
+    (133) pair_list -> dict_key : operand , . pair_list
+    (133) pair_list -> . dict_key : operand , pair_list
+    (134) pair_list -> . dict_key : operand empty pair_list_empty
+    (135) pair_list -> . pair_list_empty
+    (131) dict_key -> . RSTRING
+    (132) dict_key -> . STRING
+    (136) pair_list_empty -> . empty
+    (14) empty -> .
+
+    RSTRING         shift and go to state 111
+    STRING          shift and go to state 112
+    }               reduce using rule 14 (empty -> .)
 
-state 297
+    dict_key                       shift and go to state 108
+    pair_list                      shift and go to state 316
+    empty                          shift and go to state 109
+    pair_list_empty                shift and go to state 110
+
+state 284
 
-    (135) pair_list -> dict_key : operand empty . pair_list_empty
-    (137) pair_list_empty -> . empty
-    (2) empty -> .
+    (134) pair_list -> dict_key : operand empty . pair_list_empty
+    (136) pair_list_empty -> . empty
+    (14) empty -> .
 
-    }               reduce using rule 2 (empty -> .)
+    }               reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 119
-    pair_list_empty                shift and go to state 330
+    empty                          shift and go to state 109
+    pair_list_empty                shift and go to state 317
 
-state 298
+state 285
 
     (35) entity_body_outer -> MLS entity_body END .
 
     ENTITY          reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     IMPLEMENT       reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     IMPLEMENTATION  reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     INDEX           reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
@@ -10216,150 +9600,150 @@
     RSTRING         reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     MLS             reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     [               reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     {               reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
     $end            reduce using rule 35 (entity_body_outer -> MLS entity_body END .)
 
 
-state 299
+state 286
 
     (48) attr -> attr_type CID empty .
 
     END             reduce using rule 48 (attr -> attr_type CID empty .)
     DICT            reduce using rule 48 (attr -> attr_type CID empty .)
     ID              reduce using rule 48 (attr -> attr_type CID empty .)
 
 
-state 300
+state 287
 
     (49) attr -> attr_type CID = . constant
     (50) attr -> attr_type CID = . constant_list
     (51) attr -> attr_type CID = . UNDEF
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (152) constant_list -> . [ constants ]
-
-    UNDEF           shift and go to state 333
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 334
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (151) constant_list -> . [ constants ]
+
+    UNDEF           shift and go to state 320
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 321
 
-    constant                       shift and go to state 331
-    constant_list                  shift and go to state 332
+    constant                       shift and go to state 318
+    constant_list                  shift and go to state 319
 
-state 301
+state 288
 
     (53) attr -> attr_type ID = . constant
     (54) attr -> attr_type ID = . constant_list
     (55) attr -> attr_type ID = . UNDEF
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (152) constant_list -> . [ constants ]
-
-    UNDEF           shift and go to state 337
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 334
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (151) constant_list -> . [ constants ]
+
+    UNDEF           shift and go to state 324
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 321
 
-    constant                       shift and go to state 335
-    constant_list                  shift and go to state 336
+    constant                       shift and go to state 322
+    constant_list                  shift and go to state 323
 
-state 302
+state 289
 
     (56) attr -> DICT empty CID . empty
     (57) attr -> DICT empty CID . = map_def
     (58) attr -> DICT empty CID . = NULL
-    (2) empty -> .
+    (14) empty -> .
 
-    =               shift and go to state 339
-    END             reduce using rule 2 (empty -> .)
-    DICT            reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
+    =               shift and go to state 326
+    END             reduce using rule 14 (empty -> .)
+    DICT            reduce using rule 14 (empty -> .)
+    ID              reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 338
+    empty                          shift and go to state 325
 
-state 303
+state 290
 
     (59) attr -> DICT ? CID . empty
     (60) attr -> DICT ? CID . = map_def
     (61) attr -> DICT ? CID . = NULL
-    (2) empty -> .
+    (14) empty -> .
 
-    =               shift and go to state 341
-    END             reduce using rule 2 (empty -> .)
-    DICT            reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
+    =               shift and go to state 328
+    END             reduce using rule 14 (empty -> .)
+    DICT            reduce using rule 14 (empty -> .)
+    ID              reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 340
+    empty                          shift and go to state 327
 
-state 304
+state 291
 
     (65) attr -> DICT ? ID .
     (66) attr -> DICT ? ID . = map_def
     (67) attr -> DICT ? ID . = NULL
 
     END             reduce using rule 65 (attr -> DICT ? ID .)
     DICT            reduce using rule 65 (attr -> DICT ? ID .)
     ID              reduce using rule 65 (attr -> DICT ? ID .)
-    =               shift and go to state 342
+    =               shift and go to state 329
 
 
-state 305
+state 292
 
     (63) attr -> DICT ID = . map_def
     (64) attr -> DICT ID = . NULL
-    (138) map_def -> . { pair_list }
+    (137) map_def -> . { pair_list }
 
-    NULL            shift and go to state 344
-    {               shift and go to state 59
+    NULL            shift and go to state 331
+    {               shift and go to state 58
 
-    map_def                        shift and go to state 343
+    map_def                        shift and go to state 330
 
-state 306
+state 293
 
     (42) attr_type_multi -> attr_base_type [ ] .
 
     ?               reduce using rule 42 (attr_type_multi -> attr_base_type [ ] .)
     CID             reduce using rule 42 (attr_type_multi -> attr_base_type [ ] .)
     ID              reduce using rule 42 (attr_type_multi -> attr_base_type [ ] .)
 
 
-state 307
+state 294
 
     (33) entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .
 
     ENTITY          reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     IMPLEMENT       reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     IMPLEMENTATION  reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     INDEX           reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
@@ -10382,29 +9766,29 @@
     RSTRING         reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     MLS             reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     [               reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     {               reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
     $end            reduce using rule 33 (entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer .)
 
 
-state 308
+state 295
 
-    (178) class_ref_list -> class_ref , class_ref_list .
+    (177) class_ref_list -> class_ref , class_ref_list .
 
-    :               reduce using rule 178 (class_ref_list -> class_ref , class_ref_list .)
+    :               reduce using rule 177 (class_ref_list -> class_ref , class_ref_list .)
 
 
-state 309
+state 296
 
-    (179) class_ref_list -> var_ref , class_ref_list .
+    (178) class_ref_list -> var_ref , class_ref_list .
 
-    :               reduce using rule 179 (class_ref_list -> var_ref , class_ref_list .)
+    :               reduce using rule 178 (class_ref_list -> var_ref , class_ref_list .)
 
 
-state 310
+state 297
 
     (34) entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .
 
     ENTITY          reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     IMPLEMENT       reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     IMPLEMENTATION  reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     INDEX           reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
@@ -10427,63 +9811,61 @@
     RSTRING         reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     MLS             reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     [               reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     {               reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
     $end            reduce using rule 34 (entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer .)
 
 
-state 311
+state 298
 
     (73) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression . empty
     (74) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression . MLS
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (2) empty -> .
-
-    MLS             shift and go to state 346
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    ENTITY          reduce using rule 2 (empty -> .)
-    IMPLEMENT       reduce using rule 2 (empty -> .)
-    IMPLEMENTATION  reduce using rule 2 (empty -> .)
-    INDEX           reduce using rule 2 (empty -> .)
-    IMPORT          reduce using rule 2 (empty -> .)
-    CID             reduce using rule 2 (empty -> .)
-    FOR             reduce using rule 2 (empty -> .)
-    IF              reduce using rule 2 (empty -> .)
-    (               reduce using rule 2 (empty -> .)
-    TYPEDEF         reduce using rule 2 (empty -> .)
-    ID              reduce using rule 2 (empty -> .)
-    INT             reduce using rule 2 (empty -> .)
-    FLOAT           reduce using rule 2 (empty -> .)
-    NULL            reduce using rule 2 (empty -> .)
-    REGEX           reduce using rule 2 (empty -> .)
-    TRUE            reduce using rule 2 (empty -> .)
-    FALSE           reduce using rule 2 (empty -> .)
-    STRING          reduce using rule 2 (empty -> .)
-    FSTRING         reduce using rule 2 (empty -> .)
-    RSTRING         reduce using rule 2 (empty -> .)
-    [               reduce using rule 2 (empty -> .)
-    {               reduce using rule 2 (empty -> .)
-    $end            reduce using rule 2 (empty -> .)
+    (140) conditional_expression -> expression . ? expression : expression
+    (14) empty -> .
 
-  ! NOT             [ reduce using rule 2 (empty -> .) ]
-  ! MLS             [ reduce using rule 2 (empty -> .) ]
+    MLS             shift and go to state 333
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
+    ENTITY          reduce using rule 14 (empty -> .)
+    IMPLEMENT       reduce using rule 14 (empty -> .)
+    IMPLEMENTATION  reduce using rule 14 (empty -> .)
+    INDEX           reduce using rule 14 (empty -> .)
+    IMPORT          reduce using rule 14 (empty -> .)
+    CID             reduce using rule 14 (empty -> .)
+    FOR             reduce using rule 14 (empty -> .)
+    IF              reduce using rule 14 (empty -> .)
+    (               reduce using rule 14 (empty -> .)
+    TYPEDEF         reduce using rule 14 (empty -> .)
+    ID              reduce using rule 14 (empty -> .)
+    NOT             reduce using rule 14 (empty -> .)
+    INT             reduce using rule 14 (empty -> .)
+    FLOAT           reduce using rule 14 (empty -> .)
+    NULL            reduce using rule 14 (empty -> .)
+    REGEX           reduce using rule 14 (empty -> .)
+    TRUE            reduce using rule 14 (empty -> .)
+    FALSE           reduce using rule 14 (empty -> .)
+    STRING          reduce using rule 14 (empty -> .)
+    FSTRING         reduce using rule 14 (empty -> .)
+    RSTRING         reduce using rule 14 (empty -> .)
+    [               reduce using rule 14 (empty -> .)
+    {               reduce using rule 14 (empty -> .)
+    $end            reduce using rule 14 (empty -> .)
 
-    empty                          shift and go to state 345
+  ! MLS             [ reduce using rule 14 (empty -> .) ]
 
-state 312
+    empty                          shift and go to state 332
+
+state 299
 
     (70) implement_ns_list -> implement_ns_list , implement_ns_list .
     (70) implement_ns_list -> implement_ns_list . , implement_ns_list
 
     MLS             reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     WHEN            reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     ENTITY          reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
@@ -10506,35 +9888,35 @@
     FALSE           reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     STRING          reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     FSTRING         reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     RSTRING         reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     [               reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     {               reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
     $end            reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .)
-    ,               shift and go to state 266
+    ,               shift and go to state 253
 
   ! ,               [ reduce using rule 70 (implement_ns_list -> implement_ns_list , implement_ns_list .) ]
 
 
-state 313
+state 300
 
     (80) relation -> class_ref ID multi REL multi class_ref . ID
     (81) relation -> class_ref ID multi REL multi class_ref . ID MLS
 
-    ID              shift and go to state 347
+    ID              shift and go to state 334
 
 
-state 314
+state 301
 
     (90) multi -> [ INT : INT . ]
 
-    ]               shift and go to state 348
+    ]               shift and go to state 335
 
 
-state 315
+state 302
 
     (89) multi -> [ INT : ] .
 
     REL             reduce using rule 89 (multi -> [ INT : ] .)
     (               reduce using rule 89 (multi -> [ INT : ] .)
     NOT             reduce using rule 89 (multi -> [ INT : ] .)
     ID              reduce using rule 89 (multi -> [ INT : ] .)
@@ -10558,15 +9940,15 @@
     IMPORT          reduce using rule 89 (multi -> [ INT : ] .)
     FOR             reduce using rule 89 (multi -> [ INT : ] .)
     IF              reduce using rule 89 (multi -> [ INT : ] .)
     TYPEDEF         reduce using rule 89 (multi -> [ INT : ] .)
     $end            reduce using rule 89 (multi -> [ INT : ] .)
 
 
-state 316
+state 303
 
     (91) multi -> [ : INT ] .
 
     REL             reduce using rule 91 (multi -> [ : INT ] .)
     (               reduce using rule 91 (multi -> [ : INT ] .)
     NOT             reduce using rule 91 (multi -> [ : INT ] .)
     ID              reduce using rule 91 (multi -> [ : INT ] .)
@@ -10590,20 +9972,20 @@
     IMPORT          reduce using rule 91 (multi -> [ : INT ] .)
     FOR             reduce using rule 91 (multi -> [ : INT ] .)
     IF              reduce using rule 91 (multi -> [ : INT ] .)
     TYPEDEF         reduce using rule 91 (multi -> [ : INT ] .)
     $end            reduce using rule 91 (multi -> [ : INT ] .)
 
 
-state 317
+state 304
 
     (84) relation_def -> class_ref . ID multi REL class_ref . . ID multi
     (85) relation_def -> class_ref . ID multi REL class_ref .
 
-    .               shift and go to state 349
+    .               shift and go to state 336
     MLS             reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     ENTITY          reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     IMPLEMENT       reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     IMPLEMENTATION  reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     INDEX           reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     IMPORT          reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     CID             reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
@@ -10623,20 +10005,20 @@
     FSTRING         reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     RSTRING         reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     [               reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     {               reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
     $end            reduce using rule 85 (relation_def -> class_ref . ID multi REL class_ref .)
 
 
-state 318
+state 305
 
     (86) relation_def -> class_ref . ID multi operand_list class_ref . . ID multi
     (87) relation_def -> class_ref . ID multi operand_list class_ref .
 
-    .               shift and go to state 350
+    .               shift and go to state 337
     MLS             reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     ENTITY          reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     IMPLEMENT       reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     IMPLEMENTATION  reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     INDEX           reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     IMPORT          reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     CID             reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
@@ -10656,15 +10038,15 @@
     FSTRING         reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     RSTRING         reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     [               reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     {               reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
     $end            reduce using rule 87 (relation_def -> class_ref . ID multi operand_list class_ref .)
 
 
-state 319
+state 306
 
     (76) implementation -> implementation_head block .
 
     ENTITY          reduce using rule 76 (implementation -> implementation_head block .)
     IMPLEMENT       reduce using rule 76 (implementation -> implementation_head block .)
     IMPLEMENTATION  reduce using rule 76 (implementation -> implementation_head block .)
     INDEX           reduce using rule 76 (implementation -> implementation_head block .)
@@ -10687,22 +10069,22 @@
     RSTRING         reduce using rule 76 (implementation -> implementation_head block .)
     MLS             reduce using rule 76 (implementation -> implementation_head block .)
     [               reduce using rule 76 (implementation -> implementation_head block .)
     {               reduce using rule 76 (implementation -> implementation_head block .)
     $end            reduce using rule 76 (implementation -> implementation_head block .)
 
 
-state 320
+state 307
 
     (79) block -> stmt_list . END
 
-    END             shift and go to state 351
+    END             shift and go to state 338
 
 
-state 321
+state 308
 
     (78) implementation_head -> : MLS .
 
     FOR             reduce using rule 78 (implementation_head -> : MLS .)
     IF              reduce using rule 78 (implementation_head -> : MLS .)
     (               reduce using rule 78 (implementation_head -> : MLS .)
     NOT             reduce using rule 78 (implementation_head -> : MLS .)
@@ -10719,15 +10101,15 @@
     MLS             reduce using rule 78 (implementation_head -> : MLS .)
     [               reduce using rule 78 (implementation_head -> : MLS .)
     {               reduce using rule 78 (implementation_head -> : MLS .)
     CID             reduce using rule 78 (implementation_head -> : MLS .)
     END             reduce using rule 78 (implementation_head -> : MLS .)
 
 
-state 322
+state 309
 
     (25) for -> FOR ID IN operand : block .
 
     ENTITY          reduce using rule 25 (for -> FOR ID IN operand : block .)
     IMPLEMENT       reduce using rule 25 (for -> FOR ID IN operand : block .)
     IMPLEMENTATION  reduce using rule 25 (for -> FOR ID IN operand : block .)
     INDEX           reduce using rule 25 (for -> FOR ID IN operand : block .)
@@ -10753,386 +10135,380 @@
     {               reduce using rule 25 (for -> FOR ID IN operand : block .)
     $end            reduce using rule 25 (for -> FOR ID IN operand : block .)
     ELSE            reduce using rule 25 (for -> FOR ID IN operand : block .)
     ELIF            reduce using rule 25 (for -> FOR ID IN operand : block .)
     END             reduce using rule 25 (for -> FOR ID IN operand : block .)
 
 
-state 323
+state 310
 
-    (184) id_list -> ID , id_list .
+    (183) id_list -> ID , id_list .
 
-    )               reduce using rule 184 (id_list -> ID , id_list .)
+    )               reduce using rule 183 (id_list -> ID , id_list .)
 
 
-state 324
+state 311
 
     (29) if_next -> ELSE : . stmt_list
     (21) stmt_list -> . statement stmt_list
     (22) stmt_list -> . empty
     (17) statement -> . assign
     (18) statement -> . for
     (19) statement -> . if
-    (20) statement -> . expression empty
-    (2) empty -> .
+    (20) statement -> . expression
+    (14) empty -> .
     (23) assign -> . var_ref = operand
     (24) assign -> . var_ref PEQ operand
     (25) for -> . FOR ID IN operand : block
     (26) if -> . IF if_body END
     (97) expression -> . boolean_expression
     (98) expression -> . constant
     (99) expression -> . function_call
-    (100) expression -> . var_ref empty
+    (100) expression -> . var_ref
     (101) expression -> . constructor
     (102) expression -> . list_def
     (103) expression -> . list_comprehension
     (104) expression -> . map_def
-    (105) expression -> . map_lookup empty
+    (105) expression -> . map_lookup
     (106) expression -> . index_lookup
     (107) expression -> . conditional_expression
     (108) expression -> . ( expression )
-    (172) var_ref -> . attr_ref empty
-    (174) var_ref -> . ns_ref empty
+    (171) var_ref -> . attr_ref
+    (173) var_ref -> . ns_ref
     (109) boolean_expression -> . expression CMP_OP expression
     (110) boolean_expression -> . expression IN expression
     (111) boolean_expression -> . expression AND expression
     (112) boolean_expression -> . expression OR expression
-    (113) boolean_expression -> . expression NOT IN expression
-    (114) boolean_expression -> . NOT expression
-    (115) boolean_expression -> . var_ref . ID IS DEFINED
-    (116) boolean_expression -> . ID IS DEFINED
-    (117) boolean_expression -> . map_lookup IS DEFINED
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-    (123) function_call -> . ns_ref ( function_param_list )
-    (124) function_call -> . attr_ref ( function_param_list )
-    (122) constructor -> . class_ref ( param_list )
-    (125) list_def -> . [ operand_list ]
-    (126) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
-    (138) map_def -> . { pair_list }
-    (119) map_lookup -> . attr_ref [ operand ]
-    (120) map_lookup -> . var_ref [ operand ]
-    (121) map_lookup -> . map_lookup [ operand ]
-    (139) index_lookup -> . class_ref [ param_list ]
-    (140) index_lookup -> . attr_ref [ param_list ]
-    (141) conditional_expression -> . expression ? expression : expression
-    (173) attr_ref -> . var_ref . ID
-    (182) ns_ref -> . ns_ref SEP ID
-    (183) ns_ref -> . ID
-    (175) class_ref -> . CID
-    (176) class_ref -> . ns_ref SEP CID
-    (177) class_ref -> . var_ref . CID
-
-    END             reduce using rule 2 (empty -> .)
-    FOR             shift and go to state 24
-    IF              shift and go to state 35
-    (               shift and go to state 31
-    NOT             shift and go to state 48
-    ID              shift and go to state 89
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
-    [               shift and go to state 58
-    {               shift and go to state 59
-    CID             shift and go to state 17
-
-    stmt_list                      shift and go to state 352
-    statement                      shift and go to state 230
-    empty                          shift and go to state 231
-    assign                         shift and go to state 26
-    for                            shift and go to state 27
-    if                             shift and go to state 28
-    expression                     shift and go to state 22
-    var_ref                        shift and go to state 232
-    boolean_expression             shift and go to state 36
-    constant                       shift and go to state 37
-    function_call                  shift and go to state 38
-    constructor                    shift and go to state 39
-    list_def                       shift and go to state 40
-    list_comprehension             shift and go to state 41
-    map_def                        shift and go to state 42
-    map_lookup                     shift and go to state 43
-    index_lookup                   shift and go to state 44
-    conditional_expression         shift and go to state 45
-    attr_ref                       shift and go to state 47
-    ns_ref                         shift and go to state 233
-    class_ref                      shift and go to state 92
+    (113) boolean_expression -> . NOT expression
+    (114) boolean_expression -> . var_ref . ID IS DEFINED
+    (115) boolean_expression -> . ID IS DEFINED
+    (116) boolean_expression -> . map_lookup IS DEFINED
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+    (122) function_call -> . ns_ref ( function_param_list )
+    (123) function_call -> . attr_ref ( function_param_list )
+    (121) constructor -> . class_ref ( param_list )
+    (124) list_def -> . [ operand_list ]
+    (125) list_comprehension -> . [ expression list_comprehension_for list_comprehension_guard ]
+    (137) map_def -> . { pair_list }
+    (118) map_lookup -> . attr_ref [ operand ]
+    (119) map_lookup -> . var_ref [ operand ]
+    (120) map_lookup -> . map_lookup [ operand ]
+    (138) index_lookup -> . class_ref [ param_list ]
+    (139) index_lookup -> . attr_ref [ param_list ]
+    (140) conditional_expression -> . expression ? expression : expression
+    (172) attr_ref -> . var_ref . ID
+    (181) ns_ref -> . ns_ref SEP ID
+    (182) ns_ref -> . ID
+    (174) class_ref -> . CID
+    (175) class_ref -> . ns_ref SEP CID
+    (176) class_ref -> . var_ref . CID
+
+    END             reduce using rule 14 (empty -> .)
+    FOR             shift and go to state 23
+    IF              shift and go to state 34
+    (               shift and go to state 30
+    NOT             shift and go to state 47
+    ID              shift and go to state 84
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
+    [               shift and go to state 57
+    {               shift and go to state 58
+    CID             shift and go to state 16
+
+    stmt_list                      shift and go to state 339
+    statement                      shift and go to state 217
+    empty                          shift and go to state 218
+    assign                         shift and go to state 25
+    for                            shift and go to state 26
+    if                             shift and go to state 27
+    expression                     shift and go to state 21
+    var_ref                        shift and go to state 219
+    boolean_expression             shift and go to state 35
+    constant                       shift and go to state 36
+    function_call                  shift and go to state 37
+    constructor                    shift and go to state 38
+    list_def                       shift and go to state 39
+    list_comprehension             shift and go to state 40
+    map_def                        shift and go to state 41
+    map_lookup                     shift and go to state 42
+    index_lookup                   shift and go to state 43
+    conditional_expression         shift and go to state 44
+    attr_ref                       shift and go to state 46
+    ns_ref                         shift and go to state 220
+    class_ref                      shift and go to state 87
 
-state 325
+state 312
 
     (30) if_next -> ELIF if_body .
 
     END             reduce using rule 30 (if_next -> ELIF if_body .)
 
 
-state 326
+state 313
 
     (94) typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
+    (140) conditional_expression -> expression . ? expression : expression
 
     MLS             reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     ENTITY          reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     IMPLEMENT       reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     IMPLEMENTATION  reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     INDEX           reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     IMPORT          reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     CID             reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     FOR             reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     IF              reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     (               reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     TYPEDEF         reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     ID              reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
+    NOT             reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     INT             reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     FLOAT           reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     NULL            reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     REGEX           reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     TRUE            reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     FALSE           reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     STRING          reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     FSTRING         reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     RSTRING         reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     [               reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     {               reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
     $end            reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .)
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
 
-  ! NOT             [ reduce using rule 94 (typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression .) ]
 
+state 314
 
-state 327
-
-    (131) list_comprehension_guard -> IF expression list_comprehension_guard .
+    (130) list_comprehension_guard -> IF expression list_comprehension_guard .
 
-    ]               reduce using rule 131 (list_comprehension_guard -> IF expression list_comprehension_guard .)
+    ]               reduce using rule 130 (list_comprehension_guard -> IF expression list_comprehension_guard .)
 
 
-state 328
+state 315
 
-    (128) list_comprehension_for -> FOR ID IN expression . list_comprehension_for_empty
-    (129) list_comprehension_for -> FOR ID IN expression . list_comprehension_for
+    (127) list_comprehension_for -> FOR ID IN expression . list_comprehension_for_empty
+    (128) list_comprehension_for -> FOR ID IN expression . list_comprehension_for
     (109) boolean_expression -> expression . CMP_OP expression
     (110) boolean_expression -> expression . IN expression
     (111) boolean_expression -> expression . AND expression
     (112) boolean_expression -> expression . OR expression
-    (113) boolean_expression -> expression . NOT IN expression
-    (141) conditional_expression -> expression . ? expression : expression
-    (127) list_comprehension_for_empty -> . empty
-    (128) list_comprehension_for -> . FOR ID IN expression list_comprehension_for_empty
-    (129) list_comprehension_for -> . FOR ID IN expression list_comprehension_for
-    (2) empty -> .
-
-    CMP_OP          shift and go to state 74
-    IN              shift and go to state 75
-    AND             shift and go to state 76
-    OR              shift and go to state 77
-    NOT             shift and go to state 78
-    ?               shift and go to state 79
-    FOR             shift and go to state 182
-    IF              reduce using rule 2 (empty -> .)
-    ]               reduce using rule 2 (empty -> .)
-
-    list_comprehension_for_empty   shift and go to state 353
-    list_comprehension_for         shift and go to state 354
-    empty                          shift and go to state 355
+    (140) conditional_expression -> expression . ? expression : expression
+    (126) list_comprehension_for_empty -> . empty
+    (127) list_comprehension_for -> . FOR ID IN expression list_comprehension_for_empty
+    (128) list_comprehension_for -> . FOR ID IN expression list_comprehension_for
+    (14) empty -> .
+
+    CMP_OP          shift and go to state 72
+    IN              shift and go to state 73
+    AND             shift and go to state 74
+    OR              shift and go to state 75
+    ?               shift and go to state 76
+    FOR             shift and go to state 170
+    IF              reduce using rule 14 (empty -> .)
+    ]               reduce using rule 14 (empty -> .)
+
+    list_comprehension_for_empty   shift and go to state 340
+    list_comprehension_for         shift and go to state 341
+    empty                          shift and go to state 342
 
-state 329
+state 316
 
-    (134) pair_list -> dict_key : operand , pair_list .
+    (133) pair_list -> dict_key : operand , pair_list .
 
-    }               reduce using rule 134 (pair_list -> dict_key : operand , pair_list .)
+    }               reduce using rule 133 (pair_list -> dict_key : operand , pair_list .)
 
 
-state 330
+state 317
 
-    (135) pair_list -> dict_key : operand empty pair_list_empty .
+    (134) pair_list -> dict_key : operand empty pair_list_empty .
 
-    }               reduce using rule 135 (pair_list -> dict_key : operand empty pair_list_empty .)
+    }               reduce using rule 134 (pair_list -> dict_key : operand empty pair_list_empty .)
 
 
-state 331
+state 318
 
     (49) attr -> attr_type CID = constant .
 
     END             reduce using rule 49 (attr -> attr_type CID = constant .)
     DICT            reduce using rule 49 (attr -> attr_type CID = constant .)
     ID              reduce using rule 49 (attr -> attr_type CID = constant .)
 
 
-state 332
+state 319
 
     (50) attr -> attr_type CID = constant_list .
 
     END             reduce using rule 50 (attr -> attr_type CID = constant_list .)
     DICT            reduce using rule 50 (attr -> attr_type CID = constant_list .)
     ID              reduce using rule 50 (attr -> attr_type CID = constant_list .)
 
 
-state 333
+state 320
 
     (51) attr -> attr_type CID = UNDEF .
 
     END             reduce using rule 51 (attr -> attr_type CID = UNDEF .)
     DICT            reduce using rule 51 (attr -> attr_type CID = UNDEF .)
     ID              reduce using rule 51 (attr -> attr_type CID = UNDEF .)
 
 
-state 334
+state 321
 
-    (152) constant_list -> [ . constants ]
-    (153) constants -> . constant
-    (154) constants -> .
-    (155) constants -> . constant , constants
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-
-    ]               reduce using rule 154 (constants -> .)
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
+    (151) constant_list -> [ . constants ]
+    (152) constants -> . constant
+    (153) constants -> .
+    (154) constants -> . constant , constants
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+
+    ]               reduce using rule 153 (constants -> .)
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
 
-    constants                      shift and go to state 356
-    constant                       shift and go to state 357
+    constants                      shift and go to state 343
+    constant                       shift and go to state 344
 
-state 335
+state 322
 
     (53) attr -> attr_type ID = constant .
 
     END             reduce using rule 53 (attr -> attr_type ID = constant .)
     DICT            reduce using rule 53 (attr -> attr_type ID = constant .)
     ID              reduce using rule 53 (attr -> attr_type ID = constant .)
 
 
-state 336
+state 323
 
     (54) attr -> attr_type ID = constant_list .
 
     END             reduce using rule 54 (attr -> attr_type ID = constant_list .)
     DICT            reduce using rule 54 (attr -> attr_type ID = constant_list .)
     ID              reduce using rule 54 (attr -> attr_type ID = constant_list .)
 
 
-state 337
+state 324
 
     (55) attr -> attr_type ID = UNDEF .
 
     END             reduce using rule 55 (attr -> attr_type ID = UNDEF .)
     DICT            reduce using rule 55 (attr -> attr_type ID = UNDEF .)
     ID              reduce using rule 55 (attr -> attr_type ID = UNDEF .)
 
 
-state 338
+state 325
 
     (56) attr -> DICT empty CID empty .
 
     END             reduce using rule 56 (attr -> DICT empty CID empty .)
     DICT            reduce using rule 56 (attr -> DICT empty CID empty .)
     ID              reduce using rule 56 (attr -> DICT empty CID empty .)
 
 
-state 339
+state 326
 
     (57) attr -> DICT empty CID = . map_def
     (58) attr -> DICT empty CID = . NULL
-    (138) map_def -> . { pair_list }
+    (137) map_def -> . { pair_list }
 
-    NULL            shift and go to state 359
-    {               shift and go to state 59
+    NULL            shift and go to state 346
+    {               shift and go to state 58
 
-    map_def                        shift and go to state 358
+    map_def                        shift and go to state 345
 
-state 340
+state 327
 
     (59) attr -> DICT ? CID empty .
 
     END             reduce using rule 59 (attr -> DICT ? CID empty .)
     DICT            reduce using rule 59 (attr -> DICT ? CID empty .)
     ID              reduce using rule 59 (attr -> DICT ? CID empty .)
 
 
-state 341
+state 328
 
     (60) attr -> DICT ? CID = . map_def
     (61) attr -> DICT ? CID = . NULL
-    (138) map_def -> . { pair_list }
+    (137) map_def -> . { pair_list }
 
-    NULL            shift and go to state 361
-    {               shift and go to state 59
+    NULL            shift and go to state 348
+    {               shift and go to state 58
 
-    map_def                        shift and go to state 360
+    map_def                        shift and go to state 347
 
-state 342
+state 329
 
     (66) attr -> DICT ? ID = . map_def
     (67) attr -> DICT ? ID = . NULL
-    (138) map_def -> . { pair_list }
+    (137) map_def -> . { pair_list }
 
-    NULL            shift and go to state 363
-    {               shift and go to state 59
+    NULL            shift and go to state 350
+    {               shift and go to state 58
 
-    map_def                        shift and go to state 362
+    map_def                        shift and go to state 349
 
-state 343
+state 330
 
     (63) attr -> DICT ID = map_def .
 
     END             reduce using rule 63 (attr -> DICT ID = map_def .)
     DICT            reduce using rule 63 (attr -> DICT ID = map_def .)
     ID              reduce using rule 63 (attr -> DICT ID = map_def .)
 
 
-state 344
+state 331
 
     (64) attr -> DICT ID = NULL .
 
     END             reduce using rule 64 (attr -> DICT ID = NULL .)
     DICT            reduce using rule 64 (attr -> DICT ID = NULL .)
     ID              reduce using rule 64 (attr -> DICT ID = NULL .)
 
 
-state 345
+state 332
 
     (73) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .
 
     ENTITY          reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     IMPLEMENT       reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     IMPLEMENTATION  reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     INDEX           reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
@@ -11155,15 +10531,15 @@
     RSTRING         reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     MLS             reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     [               reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     {               reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
     $end            reduce using rule 73 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty .)
 
 
-state 346
+state 333
 
     (74) implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .
 
     ENTITY          reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     IMPLEMENT       reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     IMPLEMENTATION  reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     INDEX           reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
@@ -11186,15 +10562,15 @@
     RSTRING         reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     MLS             reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     [               reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     {               reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
     $end            reduce using rule 74 (implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS .)
 
 
-state 347
+state 334
 
     (80) relation -> class_ref ID multi REL multi class_ref ID .
     (81) relation -> class_ref ID multi REL multi class_ref ID . MLS
 
     ENTITY          reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     IMPLEMENT       reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     IMPLEMENTATION  reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
@@ -11215,20 +10591,20 @@
     FALSE           reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     STRING          reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     FSTRING         reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     RSTRING         reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     [               reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     {               reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
     $end            reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .)
-    MLS             shift and go to state 364
+    MLS             shift and go to state 351
 
   ! MLS             [ reduce using rule 80 (relation -> class_ref ID multi REL multi class_ref ID .) ]
 
 
-state 348
+state 335
 
     (90) multi -> [ INT : INT ] .
 
     REL             reduce using rule 90 (multi -> [ INT : INT ] .)
     (               reduce using rule 90 (multi -> [ INT : INT ] .)
     NOT             reduce using rule 90 (multi -> [ INT : INT ] .)
     ID              reduce using rule 90 (multi -> [ INT : INT ] .)
@@ -11252,29 +10628,29 @@
     IMPORT          reduce using rule 90 (multi -> [ INT : INT ] .)
     FOR             reduce using rule 90 (multi -> [ INT : INT ] .)
     IF              reduce using rule 90 (multi -> [ INT : INT ] .)
     TYPEDEF         reduce using rule 90 (multi -> [ INT : INT ] .)
     $end            reduce using rule 90 (multi -> [ INT : INT ] .)
 
 
-state 349
+state 336
 
     (84) relation_def -> class_ref . ID multi REL class_ref . . ID multi
 
-    ID              shift and go to state 365
+    ID              shift and go to state 352
 
 
-state 350
+state 337
 
     (86) relation_def -> class_ref . ID multi operand_list class_ref . . ID multi
 
-    ID              shift and go to state 366
+    ID              shift and go to state 353
 
 
-state 351
+state 338
 
     (79) block -> stmt_list END .
 
     ENTITY          reduce using rule 79 (block -> stmt_list END .)
     IMPLEMENT       reduce using rule 79 (block -> stmt_list END .)
     IMPLEMENTATION  reduce using rule 79 (block -> stmt_list END .)
     INDEX           reduce using rule 79 (block -> stmt_list END .)
@@ -11300,116 +10676,116 @@
     {               reduce using rule 79 (block -> stmt_list END .)
     $end            reduce using rule 79 (block -> stmt_list END .)
     ELSE            reduce using rule 79 (block -> stmt_list END .)
     ELIF            reduce using rule 79 (block -> stmt_list END .)
     END             reduce using rule 79 (block -> stmt_list END .)
 
 
-state 352
+state 339
 
     (29) if_next -> ELSE : stmt_list .
 
     END             reduce using rule 29 (if_next -> ELSE : stmt_list .)
 
 
-state 353
+state 340
 
-    (128) list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .
+    (127) list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .
 
-    IF              reduce using rule 128 (list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .)
-    ]               reduce using rule 128 (list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .)
+    IF              reduce using rule 127 (list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .)
+    ]               reduce using rule 127 (list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty .)
 
 
-state 354
+state 341
 
-    (129) list_comprehension_for -> FOR ID IN expression list_comprehension_for .
+    (128) list_comprehension_for -> FOR ID IN expression list_comprehension_for .
 
-    IF              reduce using rule 129 (list_comprehension_for -> FOR ID IN expression list_comprehension_for .)
-    ]               reduce using rule 129 (list_comprehension_for -> FOR ID IN expression list_comprehension_for .)
+    IF              reduce using rule 128 (list_comprehension_for -> FOR ID IN expression list_comprehension_for .)
+    ]               reduce using rule 128 (list_comprehension_for -> FOR ID IN expression list_comprehension_for .)
 
 
-state 355
+state 342
 
-    (127) list_comprehension_for_empty -> empty .
+    (126) list_comprehension_for_empty -> empty .
 
-    IF              reduce using rule 127 (list_comprehension_for_empty -> empty .)
-    ]               reduce using rule 127 (list_comprehension_for_empty -> empty .)
+    IF              reduce using rule 126 (list_comprehension_for_empty -> empty .)
+    ]               reduce using rule 126 (list_comprehension_for_empty -> empty .)
 
 
-state 356
+state 343
 
-    (152) constant_list -> [ constants . ]
+    (151) constant_list -> [ constants . ]
 
-    ]               shift and go to state 367
+    ]               shift and go to state 354
 
 
-state 357
+state 344
 
-    (153) constants -> constant .
-    (155) constants -> constant . , constants
+    (152) constants -> constant .
+    (154) constants -> constant . , constants
 
-    ]               reduce using rule 153 (constants -> constant .)
-    ,               shift and go to state 368
+    ]               reduce using rule 152 (constants -> constant .)
+    ,               shift and go to state 355
 
 
-state 358
+state 345
 
     (57) attr -> DICT empty CID = map_def .
 
     END             reduce using rule 57 (attr -> DICT empty CID = map_def .)
     DICT            reduce using rule 57 (attr -> DICT empty CID = map_def .)
     ID              reduce using rule 57 (attr -> DICT empty CID = map_def .)
 
 
-state 359
+state 346
 
     (58) attr -> DICT empty CID = NULL .
 
     END             reduce using rule 58 (attr -> DICT empty CID = NULL .)
     DICT            reduce using rule 58 (attr -> DICT empty CID = NULL .)
     ID              reduce using rule 58 (attr -> DICT empty CID = NULL .)
 
 
-state 360
+state 347
 
     (60) attr -> DICT ? CID = map_def .
 
     END             reduce using rule 60 (attr -> DICT ? CID = map_def .)
     DICT            reduce using rule 60 (attr -> DICT ? CID = map_def .)
     ID              reduce using rule 60 (attr -> DICT ? CID = map_def .)
 
 
-state 361
+state 348
 
     (61) attr -> DICT ? CID = NULL .
 
     END             reduce using rule 61 (attr -> DICT ? CID = NULL .)
     DICT            reduce using rule 61 (attr -> DICT ? CID = NULL .)
     ID              reduce using rule 61 (attr -> DICT ? CID = NULL .)
 
 
-state 362
+state 349
 
     (66) attr -> DICT ? ID = map_def .
 
     END             reduce using rule 66 (attr -> DICT ? ID = map_def .)
     DICT            reduce using rule 66 (attr -> DICT ? ID = map_def .)
     ID              reduce using rule 66 (attr -> DICT ? ID = map_def .)
 
 
-state 363
+state 350
 
     (67) attr -> DICT ? ID = NULL .
 
     END             reduce using rule 67 (attr -> DICT ? ID = NULL .)
     DICT            reduce using rule 67 (attr -> DICT ? ID = NULL .)
     ID              reduce using rule 67 (attr -> DICT ? ID = NULL .)
 
 
-state 364
+state 351
 
     (81) relation -> class_ref ID multi REL multi class_ref ID MLS .
 
     ENTITY          reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     IMPLEMENT       reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     IMPLEMENTATION  reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     INDEX           reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
@@ -11432,80 +10808,80 @@
     RSTRING         reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     MLS             reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     [               reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     {               reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
     $end            reduce using rule 81 (relation -> class_ref ID multi REL multi class_ref ID MLS .)
 
 
-state 365
+state 352
 
     (84) relation_def -> class_ref . ID multi REL class_ref . ID . multi
     (88) multi -> . [ INT ]
     (89) multi -> . [ INT : ]
     (90) multi -> . [ INT : INT ]
     (91) multi -> . [ : INT ]
 
-    [               shift and go to state 131
+    [               shift and go to state 121
 
-    multi                          shift and go to state 369
+    multi                          shift and go to state 356
 
-state 366
+state 353
 
     (86) relation_def -> class_ref . ID multi operand_list class_ref . ID . multi
     (88) multi -> . [ INT ]
     (89) multi -> . [ INT : ]
     (90) multi -> . [ INT : INT ]
     (91) multi -> . [ : INT ]
 
-    [               shift and go to state 131
+    [               shift and go to state 121
+
+    multi                          shift and go to state 357
+
+state 354
+
+    (151) constant_list -> [ constants ] .
 
-    multi                          shift and go to state 370
+    END             reduce using rule 151 (constant_list -> [ constants ] .)
+    DICT            reduce using rule 151 (constant_list -> [ constants ] .)
+    ID              reduce using rule 151 (constant_list -> [ constants ] .)
 
-state 367
 
-    (152) constant_list -> [ constants ] .
+state 355
 
-    END             reduce using rule 152 (constant_list -> [ constants ] .)
-    DICT            reduce using rule 152 (constant_list -> [ constants ] .)
-    ID              reduce using rule 152 (constant_list -> [ constants ] .)
-
-
-state 368
-
-    (155) constants -> constant , . constants
-    (153) constants -> . constant
-    (154) constants -> .
-    (155) constants -> . constant , constants
-    (142) constant -> . INT
-    (143) constant -> . FLOAT
-    (144) constant -> . NULL
-    (145) constant -> . REGEX
-    (146) constant -> . TRUE
-    (147) constant -> . FALSE
-    (148) constant -> . STRING
-    (149) constant -> . FSTRING
-    (150) constant -> . RSTRING
-    (151) constant -> . MLS
-
-    ]               reduce using rule 154 (constants -> .)
-    INT             shift and go to state 49
-    FLOAT           shift and go to state 50
-    NULL            shift and go to state 51
-    REGEX           shift and go to state 52
-    TRUE            shift and go to state 53
-    FALSE           shift and go to state 54
-    STRING          shift and go to state 55
-    FSTRING         shift and go to state 56
-    RSTRING         shift and go to state 57
-    MLS             shift and go to state 21
+    (154) constants -> constant , . constants
+    (152) constants -> . constant
+    (153) constants -> .
+    (154) constants -> . constant , constants
+    (141) constant -> . INT
+    (142) constant -> . FLOAT
+    (143) constant -> . NULL
+    (144) constant -> . REGEX
+    (145) constant -> . TRUE
+    (146) constant -> . FALSE
+    (147) constant -> . STRING
+    (148) constant -> . FSTRING
+    (149) constant -> . RSTRING
+    (150) constant -> . MLS
+
+    ]               reduce using rule 153 (constants -> .)
+    INT             shift and go to state 48
+    FLOAT           shift and go to state 49
+    NULL            shift and go to state 50
+    REGEX           shift and go to state 51
+    TRUE            shift and go to state 52
+    FALSE           shift and go to state 53
+    STRING          shift and go to state 54
+    FSTRING         shift and go to state 55
+    RSTRING         shift and go to state 56
+    MLS             shift and go to state 20
 
-    constant                       shift and go to state 357
-    constants                      shift and go to state 371
+    constant                       shift and go to state 344
+    constants                      shift and go to state 358
 
-state 369
+state 356
 
     (84) relation_def -> class_ref . ID multi REL class_ref . ID multi .
 
     MLS             reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     ENTITY          reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     IMPLEMENT       reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     IMPLEMENTATION  reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
@@ -11528,15 +10904,15 @@
     FSTRING         reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     RSTRING         reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     [               reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     {               reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
     $end            reduce using rule 84 (relation_def -> class_ref . ID multi REL class_ref . ID multi .)
 
 
-state 370
+state 357
 
     (86) relation_def -> class_ref . ID multi operand_list class_ref . ID multi .
 
     MLS             reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     ENTITY          reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     IMPLEMENT       reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     IMPLEMENTATION  reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
@@ -11559,13 +10935,13 @@
     FSTRING         reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     RSTRING         reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     [               reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     {               reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
     $end            reduce using rule 86 (relation_def -> class_ref . ID multi operand_list class_ref . ID multi .)
 
 
-state 371
+state 358
 
-    (155) constants -> constant , constants .
+    (154) constants -> constant , constants .
 
-    ]               reduce using rule 155 (constants -> constant , constants .)
+    ]               reduce using rule 154 (constants -> constant , constants .)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/parsetab.py` & `inmanta-core-9.3.0/src/inmanta/parser/parsetab.py`

 * *Files 11% similar despite different names*

```diff
@@ -2,214 +2,213 @@
 # parsetab.py
 # This file is automatically generated. Do not edit.
 # pylint: disable=W,C,R
 _tabversion = '3.10'
 
 _lr_method = 'LALR'
 
-_lr_signature = 'nonassocLOWnonassocMATCHINGright,nonassoc:nonassoc?leftORleftANDleftCMP_OPnonassocNOTleftINleftCIDIDleft([leftMLSAND AS CID CMP_OP DEFINED DICT ELIF ELSE END ENTITY EXTENDS FALSE FLOAT FOR FSTRING ID IF IMPLEMENT IMPLEMENTATION IMPORT IN INDEX INT IS MATCHING MLS NOT NULL OR PARENTS PEQ REGEX REL RSTRING SEP STRING TRUE TYPEDEF UNDEF USING WHENmain : head bodyempty : %prec LOWhead : emptyhead : MLSbody : top_stmt bodybody : emptytop_stmt : entity_def\n    | implement_def\n    | implementation_def\n    | relation\n    | statement\n    | typedef\n    | index\n    | importimport : IMPORT ns_refimport : IMPORT ns_ref AS IDstatement : assign\n    | for\n    | if\n    | expression emptystmt_list : statement stmt_liststmt_list : emptyassign : var_ref \'=\' operandassign : var_ref PEQ operandfor : FOR ID IN operand \':\' blockif : IF if_body ENDif_body : expression \':\' stmt_list if_nextif_next : emptyif_next : ELSE \':\' stmt_listif_next : ELIF if_bodyentity_def : ENTITY CID \':\' entity_body_outerentity_def : ENTITY ID \':\' entity_body_outerentity_def : ENTITY CID EXTENDS class_ref_list \':\' entity_body_outerentity_def : ENTITY ID EXTENDS class_ref_list \':\' entity_body_outerentity_body_outer : MLS entity_body ENDentity_body_outer : entity_body ENDentity_body_outer : ENDentity_body_outer : MLS ENDentity_body : entity_body attrentity_body : attrattr_base_type : ns_refattr_type_multi : attr_base_type \'[\' \']\'attr_type_opt : attr_type_multi \'?\'\n    | attr_base_type \'?\'attr_type : attr_type_opt\n    | attr_type_multi\n    | attr_base_typeattr : attr_type CID empty\n    | attr_type CID \'=\' constant\n    | attr_type CID \'=\' constant_list\n    | attr_type CID \'=\' UNDEFattr : attr_type IDattr : attr_type ID \'=\' constant\n    | attr_type ID \'=\' constant_listattr : attr_type ID \'=\' UNDEFattr : DICT empty CID empty\n    | DICT empty CID \'=\' map_def\n    | DICT empty CID \'=\' NULL\n    | DICT \'?\' CID empty\n    | DICT \'?\'  CID \'=\' map_def\n    | DICT \'?\'  CID \'=\' NULLattr : DICT IDattr : DICT ID \'=\' map_defattr : DICT ID \'=\' NULLattr : DICT \'?\' IDattr : DICT \'?\'  ID \'=\' map_defattr : DICT \'?\'  ID \'=\' NULLimplement_ns_list : ns_refimplement_ns_list : PARENTSimplement_ns_list : implement_ns_list \',\' implement_ns_listimplement_def : IMPLEMENT class_ref USING implement_ns_list empty\n    | IMPLEMENT class_ref USING implement_ns_list MLSimplement_def : IMPLEMENT class_ref USING implement_ns_list WHEN expression empty\n    | IMPLEMENT class_ref USING implement_ns_list WHEN expression MLSimplementation_def : IMPLEMENTATION ID FOR class_ref implementationimplementation : implementation_head blockimplementation_head : \':\'implementation_head : \':\' MLSblock : stmt_list ENDrelation : class_ref ID multi REL multi class_ref IDrelation : class_ref ID multi REL multi class_ref ID MLSrelation : relation_def MLSrelation : relation_def emptyrelation_def : class_ref \'.\' ID multi REL class_ref \'.\' ID multirelation_def : class_ref \'.\' ID multi REL class_refrelation_def : class_ref \'.\' ID multi operand_list class_ref \'.\' ID multirelation_def : class_ref \'.\' ID multi operand_list class_refmulti : \'[\' INT \']\'multi : \'[\' INT \':\' \']\'multi : \'[\' INT \':\' INT \']\'multi : \'[\'  \':\' INT \']\'typedef : typedef_inner emptytypedef : typedef_inner MLStypedef_inner : TYPEDEF ID AS ns_ref MATCHING expressiontypedef_inner : TYPEDEF CID AS constructorindex : INDEX class_ref \'(\' id_list \')\'expression : boolean_expression\n    | constant\n    | function_call\n    | var_ref empty\n    | constructor\n    | list_def\n    | list_comprehension\n    | map_def\n    | map_lookup empty\n    | index_lookup\n    | conditional_expressionexpression : \'(\' expression \')\'boolean_expression : expression CMP_OP expression\n    | expression IN expression\n    | expression AND expression\n    | expression OR expressionboolean_expression : expression NOT IN expressionboolean_expression : NOT expressionboolean_expression : var_ref \'.\' ID IS DEFINEDboolean_expression : ID IS DEFINEDboolean_expression : map_lookup IS DEFINEDoperand : expression emptymap_lookup : attr_ref \'[\' operand \']\'\n    | var_ref \'[\' operand \']\'\n    | map_lookup \'[\' operand \']\'constructor : class_ref \'(\' param_list \')\'function_call : ns_ref \'(\' function_param_list \')\'function_call : attr_ref \'(\' function_param_list \')\'list_def : \'[\' operand_list \']\'list_comprehension : \'[\' expression list_comprehension_for list_comprehension_guard \']\'list_comprehension_for_empty : emptylist_comprehension_for : FOR ID IN expression list_comprehension_for_empty\n    | FOR ID IN expression list_comprehension_forlist_comprehension_guard : emptylist_comprehension_guard : IF expression list_comprehension_guarddict_key : RSTRINGdict_key : STRINGpair_list : dict_key \':\' operand \',\' pair_list\n    | dict_key \':\' operand empty pair_list_emptypair_list : pair_list_empty\n    pair_list_empty : emptymap_def : \'{\' pair_list \'}\'index_lookup : class_ref \'[\' param_list \']\'index_lookup : attr_ref \'[\' param_list \']\'conditional_expression : expression \'?\' expression \':\' expressionconstant : INT\n    | FLOAT\n    constant : NULLconstant : REGEXconstant : TRUEconstant : FALSEconstant : STRINGconstant : FSTRINGconstant : RSTRINGconstant : MLSconstant_list : \'[\' constants \']\'constants : constantconstants :constants : constant \',\' constantswrapped_kwargs : \'*\' \'*\' operandparam_list_element : ID \'=\' operandparam_list_element : wrapped_kwargsparam_list : param_list_empty\n    param_list_empty : emptyparam_list : param_list_element empty param_list_empty\n    | param_list_element \',\' param_listfunction_param_list_element : param_list_elementfunction_param_list_element : operandfunction_param_list : function_param_list_empty\n    function_param_list_empty : emptyfunction_param_list : function_param_list_element empty function_param_list_empty\n    | function_param_list_element \',\' function_param_listoperand_list : operand \',\' operand_listoperand_list : operandoperand_list : emptyvar_ref : attr_ref emptyattr_ref : var_ref \'.\' IDvar_ref : ns_ref emptyclass_ref : CIDclass_ref : ns_ref SEP CIDclass_ref : var_ref \'.\' CIDclass_ref_list : class_ref \',\' class_ref_listclass_ref_list : var_ref \',\' class_ref_listclass_ref_list : class_refclass_ref_list : var_refns_ref : ns_ref SEP IDns_ref : IDid_list : ID "," id_listid_list : ID'
+_lr_signature = 'right,nonassoc:nonassoc?leftORleftANDleftCMP_OPnonassocNOTleftINleftRELATION_DEFTYPEDEF_INNEROPERAND_LISTEMPTYNS_REFVAR_REFMAP_LOOKUPleftCIDIDleft([leftMLSAND AS CID CMP_OP DEFINED DICT ELIF ELSE END ENTITY EXTENDS FALSE FLOAT FOR FSTRING ID IF IMPLEMENT IMPLEMENTATION IMPORT IN INDEX INT IS MATCHING MLS NOT NULL OR PARENTS PEQ REGEX REL RSTRING SEP STRING TRUE TYPEDEF UNDEF USING WHENmain : head bodyhead : %prec EMPTYhead : MLSbody : top_stmt bodybody : emptytop_stmt : entity_def\n    | implement_def\n    | implementation_def\n    | relation\n    | statement\n    | typedef\n    | index\n    | importempty : %prec EMPTYimport : IMPORT ns_refimport : IMPORT ns_ref AS IDstatement : assign\n    | for\n    | if\n    | expressionstmt_list : statement stmt_liststmt_list : emptyassign : var_ref \'=\' operandassign : var_ref PEQ operandfor : FOR ID IN operand \':\' blockif : IF if_body ENDif_body : expression \':\' stmt_list if_nextif_next : emptyif_next : ELSE \':\' stmt_listif_next : ELIF if_bodyentity_def : ENTITY CID \':\' entity_body_outerentity_def : ENTITY ID \':\' entity_body_outerentity_def : ENTITY CID EXTENDS class_ref_list \':\' entity_body_outerentity_def : ENTITY ID EXTENDS class_ref_list \':\' entity_body_outerentity_body_outer : MLS entity_body ENDentity_body_outer : entity_body ENDentity_body_outer : ENDentity_body_outer : MLS ENDentity_body : entity_body attrentity_body : attrattr_base_type : ns_refattr_type_multi : attr_base_type \'[\' \']\'attr_type_opt : attr_type_multi \'?\'\n    | attr_base_type \'?\'attr_type : attr_type_opt\n    | attr_type_multi\n    | attr_base_typeattr : attr_type CID empty\n    | attr_type CID \'=\' constant\n    | attr_type CID \'=\' constant_list\n    | attr_type CID \'=\' UNDEFattr : attr_type IDattr : attr_type ID \'=\' constant\n    | attr_type ID \'=\' constant_listattr : attr_type ID \'=\' UNDEFattr : DICT empty CID empty\n    | DICT empty CID \'=\' map_def\n    | DICT empty CID \'=\' NULL\n    | DICT \'?\' CID empty\n    | DICT \'?\'  CID \'=\' map_def\n    | DICT \'?\'  CID \'=\' NULLattr : DICT IDattr : DICT ID \'=\' map_defattr : DICT ID \'=\' NULLattr : DICT \'?\' IDattr : DICT \'?\'  ID \'=\' map_defattr : DICT \'?\'  ID \'=\' NULLimplement_ns_list : ns_refimplement_ns_list : PARENTSimplement_ns_list : implement_ns_list \',\' implement_ns_listimplement_def : IMPLEMENT class_ref USING implement_ns_list empty\n    | IMPLEMENT class_ref USING implement_ns_list MLSimplement_def : IMPLEMENT class_ref USING implement_ns_list WHEN expression empty\n    | IMPLEMENT class_ref USING implement_ns_list WHEN expression MLSimplementation_def : IMPLEMENTATION ID FOR class_ref implementationimplementation : implementation_head blockimplementation_head : \':\'implementation_head : \':\' MLSblock : stmt_list ENDrelation : class_ref ID multi REL multi class_ref IDrelation : class_ref ID multi REL multi class_ref ID MLSrelation : relation_def MLSrelation : relation_def %prec RELATION_DEFrelation_def : class_ref \'.\' ID multi REL class_ref \'.\' ID multirelation_def : class_ref \'.\' ID multi REL class_refrelation_def : class_ref \'.\' ID multi operand_list class_ref \'.\' ID multirelation_def : class_ref \'.\' ID multi operand_list class_refmulti : \'[\' INT \']\'multi : \'[\' INT \':\' \']\'multi : \'[\' INT \':\' INT \']\'multi : \'[\'  \':\' INT \']\'typedef : typedef_inner %prec TYPEDEF_INNERtypedef : typedef_inner MLStypedef_inner : TYPEDEF ID AS ns_ref MATCHING expressiontypedef_inner : TYPEDEF CID AS constructorindex : INDEX class_ref \'(\' id_list \')\'expression : boolean_expression\n    | constant\n    | function_call\n    | var_ref %prec VAR_REF\n    | constructor\n    | list_def\n    | list_comprehension\n    | map_def\n    | map_lookup %prec MAP_LOOKUP\n    | index_lookup\n    | conditional_expressionexpression : \'(\' expression \')\'boolean_expression : expression CMP_OP expression\n    | expression IN expression\n    | expression AND expression\n    | expression OR expressionboolean_expression : NOT expressionboolean_expression : var_ref \'.\' ID IS DEFINEDboolean_expression : ID IS DEFINEDboolean_expression : map_lookup IS DEFINEDoperand : expressionmap_lookup : attr_ref \'[\' operand \']\'\n    | var_ref \'[\' operand \']\'\n    | map_lookup \'[\' operand \']\'constructor : class_ref \'(\' param_list \')\'function_call : ns_ref \'(\' function_param_list \')\'function_call : attr_ref \'(\' function_param_list \')\'list_def : \'[\' operand_list \']\'list_comprehension : \'[\' expression list_comprehension_for list_comprehension_guard \']\'list_comprehension_for_empty : emptylist_comprehension_for : FOR ID IN expression list_comprehension_for_empty\n    | FOR ID IN expression list_comprehension_forlist_comprehension_guard : emptylist_comprehension_guard : IF expression list_comprehension_guarddict_key : RSTRINGdict_key : STRINGpair_list : dict_key \':\' operand \',\' pair_list\n    | dict_key \':\' operand empty pair_list_emptypair_list : pair_list_empty\n    pair_list_empty : emptymap_def : \'{\' pair_list \'}\'index_lookup : class_ref \'[\' param_list \']\'index_lookup : attr_ref \'[\' param_list \']\'conditional_expression : expression \'?\' expression \':\' expressionconstant : INT\n    | FLOAT\n    constant : NULLconstant : REGEXconstant : TRUEconstant : FALSEconstant : STRINGconstant : FSTRINGconstant : RSTRINGconstant : MLSconstant_list : \'[\' constants \']\'constants : constantconstants :constants : constant \',\' constantswrapped_kwargs : \'*\' \'*\' operandparam_list_element : ID \'=\' operandparam_list_element : wrapped_kwargsparam_list : param_list_empty\n    param_list_empty : emptyparam_list : param_list_element empty param_list_empty\n    | param_list_element \',\' param_listfunction_param_list_element : param_list_elementfunction_param_list_element : operandfunction_param_list : function_param_list_empty\n    function_param_list_empty : emptyfunction_param_list : function_param_list_element empty function_param_list_empty\n    | function_param_list_element \',\' function_param_listoperand_list : operand \',\' operand_listoperand_list : operandoperand_list : %prec OPERAND_LISTvar_ref : attr_ref %prec VAR_REFattr_ref : var_ref \'.\' IDvar_ref : ns_ref %prec NS_REFclass_ref : CIDclass_ref : ns_ref SEP CIDclass_ref : var_ref \'.\' CIDclass_ref_list : class_ref \',\' class_ref_listclass_ref_list : var_ref \',\' class_ref_listclass_ref_list : class_refclass_ref_list : var_refns_ref : ns_ref SEP IDns_ref : IDid_list : ID "," id_listid_list : ID'
     
-_lr_action_items = {'MLS':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,123,125,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,259,262,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[4,21,-3,-4,21,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,82,-17,-18,-19,85,21,-2,-2,21,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,21,-142,-143,-144,-145,-146,-147,-148,-149,-150,21,-183,-20,21,21,21,21,21,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,21,21,21,-100,21,-105,21,-172,21,21,-114,187,187,-116,-109,-110,-111,-112,21,21,-108,-176,-182,-2,-177,-173,-23,-24,-26,21,-117,-125,-118,21,-138,21,-31,-37,-32,264,-68,-69,21,-122,21,21,-139,-113,21,-16,-123,21,-120,21,-2,-2,-121,-95,-124,-119,-140,21,-38,-36,187,187,-71,-72,21,-88,-141,-75,21,321,21,-96,-115,21,21,-126,21,-35,21,21,-33,-34,346,-70,-89,-91,-85,-87,-76,-78,-25,21,-94,21,-73,-74,364,-90,-79,-81,21,-84,-86,]),'ENTITY':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,16,-3,-4,16,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPLEMENT':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,19,-3,-4,19,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPLEMENTATION':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,23,-3,-4,23,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'INDEX':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,30,-3,-4,30,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPORT':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,32,-3,-4,32,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'CID':([0,2,3,4,6,8,9,10,11,12,13,14,15,16,17,18,19,21,22,25,26,27,28,29,30,31,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,94,95,96,97,98,99,100,101,104,106,109,110,111,112,115,116,124,126,127,129,141,142,143,144,145,147,148,150,151,152,155,156,164,165,166,167,168,170,171,172,175,179,181,183,184,185,186,189,191,192,193,194,195,196,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,245,248,249,253,254,256,257,260,261,263,264,265,267,268,271,272,277,278,279,280,281,282,286,290,292,293,295,298,306,307,310,311,312,315,316,317,318,319,321,322,324,326,345,346,347,348,351,364,369,370,],[-2,17,-3,-4,17,-7,-8,-9,-10,-11,-12,-13,-14,61,-175,-183,17,-151,-2,-2,-17,-18,-19,-2,17,17,-2,-2,17,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,108,-2,17,-142,-143,-144,-145,-146,-147,-148,-149,-150,17,-183,-20,17,17,17,17,17,-82,-83,-92,-93,-2,-183,-2,-2,-15,155,-174,17,165,17,17,-100,17,-105,17,-172,17,17,-114,-170,-171,17,17,-116,165,-109,-110,-111,-112,17,17,17,-108,165,155,-176,-182,-2,-177,-173,-23,-24,-26,17,-117,17,-125,-118,17,-138,17,-31,-37,251,-2,-45,-46,-47,-41,-32,-2,-68,-69,17,-122,17,17,-139,-113,17,-16,-123,17,-120,17,-2,-2,-121,-95,-124,-119,-140,17,-169,-38,-36,302,303,-43,-44,17,17,-71,-72,17,17,-88,17,17,-141,-75,17,-77,17,-96,-115,17,17,-126,17,-35,-42,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,17,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'FOR':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,80,82,83,84,85,88,89,90,91,93,95,100,104,109,112,114,127,141,142,143,144,150,155,156,164,165,166,167,168,170,171,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,230,232,233,234,236,238,239,240,248,249,263,264,268,277,278,279,280,281,282,286,293,298,307,310,311,312,315,316,317,318,319,321,322,324,326,328,345,346,347,348,351,364,369,370,],[-2,24,-3,-4,24,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,147,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,182,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,24,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,24,-2,-2,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,24,-77,24,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,24,-94,182,-73,-74,-80,-90,-79,-81,-84,-86,]),'IF':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,171,172,179,180,181,184,186,189,201,203,204,205,211,216,217,223,224,228,230,232,233,234,236,238,239,240,248,249,263,264,268,277,278,279,280,281,282,286,293,294,298,307,310,311,312,315,316,317,318,319,321,322,324,326,328,345,346,347,348,351,353,354,355,364,369,370,],[-2,35,-3,-4,35,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,35,-117,-125,243,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,35,-2,-2,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,35,-77,35,-96,-115,-126,243,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,35,-94,-2,-73,-74,-80,-90,-79,-128,-129,-127,-81,-84,-86,]),'(':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,20,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,86,88,89,90,91,92,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,163,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,237,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,307,310,311,312,315,316,317,318,319,321,322,324,326,345,346,347,348,351,364,369,370,],[-2,31,-3,-4,31,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,71,-151,-2,-2,-17,-18,-19,-2,31,96,-2,31,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,110,31,-142,-143,-144,-145,-146,-147,-148,-149,-150,31,-183,-20,31,31,31,31,31,-82,-83,-92,-93,149,-2,-183,96,110,71,-15,-174,31,31,31,-100,31,-105,31,-172,31,31,-114,-116,-109,-110,-111,-112,31,31,-108,-176,-182,-183,-2,-177,-173,-23,-24,-26,31,-117,-125,-118,31,-138,31,-31,-37,-32,-2,-68,-69,31,-122,31,31,-139,-113,31,-16,-123,31,-120,31,-2,96,-121,-95,71,-124,-119,-140,31,-38,-36,-71,-72,31,-88,-141,-75,31,-77,31,-96,-115,31,31,-126,31,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,31,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'TYPEDEF':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,46,-3,-4,46,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'ID':([0,2,3,4,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,67,70,71,72,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,94,95,96,97,98,99,100,101,104,106,109,110,111,112,115,116,123,124,125,126,127,128,129,141,142,143,144,145,147,148,149,150,151,152,153,154,155,156,164,165,166,167,168,170,171,172,174,175,179,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,201,203,204,205,210,211,213,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,245,247,248,249,250,251,252,254,255,256,257,259,260,261,262,263,264,265,266,267,268,271,272,277,278,279,280,281,282,283,286,290,292,293,295,298,299,302,303,304,306,307,310,311,312,313,315,316,317,318,319,321,322,324,326,331,332,333,335,336,337,338,340,343,344,345,346,347,348,349,350,351,358,359,360,361,362,363,364,367,369,370,],[-2,18,-3,-4,18,-7,-8,-9,-10,-11,-12,-13,-14,62,-175,-183,67,69,-151,-2,80,81,-2,-17,-18,-19,-2,67,89,67,-2,-2,89,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,107,-2,89,-142,-143,-144,-145,-146,-147,-148,-149,-150,89,-183,132,137,137,-20,89,89,89,89,89,-82,-83,-92,-93,-2,-183,-2,-2,-15,156,-174,163,166,89,89,-100,89,-105,89,-172,163,163,-114,-170,-171,67,67,67,67,-116,67,206,-109,-110,-111,-112,89,67,89,222,-108,166,156,223,156,-176,-182,-2,-177,-173,-23,-24,-26,89,-117,67,67,-125,-118,244,89,-138,89,-31,67,67,-37,-40,252,255,-45,-46,-47,-41,-32,-2,-68,-69,89,-122,137,89,89,-139,-113,89,-16,-123,163,-120,89,-2,-2,-121,-95,-124,-119,-140,89,-169,67,-38,-36,-39,-2,-52,304,-62,-43,-44,67,67,67,67,-71,-72,89,67,67,-88,67,67,-141,-75,89,-77,89,-96,222,-115,89,89,-126,89,-35,-48,-2,-2,-65,-42,-33,-34,-2,-70,347,-89,-91,-85,-87,-76,-78,-25,89,-94,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-73,-74,-80,-90,365,366,-79,-57,-58,-60,-61,-66,-67,-81,-152,-84,-86,]),'NOT':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,87,88,89,90,91,93,95,96,98,99,100,101,103,104,106,109,110,111,112,114,127,141,142,143,144,145,146,148,150,155,156,163,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,294,295,298,307,310,311,312,315,316,317,318,319,321,322,324,326,328,345,346,347,348,351,364,369,370,],[-2,48,-3,-4,48,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,78,-2,-17,-18,-19,-2,48,-2,-2,48,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,48,-142,-143,-144,-145,-146,-147,-148,-149,-150,48,-183,-20,48,48,48,48,48,-82,-83,-92,-93,78,-2,-183,-2,-2,-15,-174,48,48,48,-100,48,78,-105,48,-172,48,48,None,78,-116,78,-110,78,78,48,78,48,-108,-176,-182,-183,78,-177,-173,-23,-24,-26,48,-117,-125,-118,48,-138,48,-31,-37,-32,-2,-68,-69,48,-122,48,48,-139,-113,48,-16,-123,48,-120,48,-2,-2,-121,-95,-124,-119,-140,48,-38,-36,-71,-72,48,-88,78,-75,48,-77,48,-96,-115,48,48,-126,78,48,-35,-33,-34,78,-70,-89,-91,-85,-87,-76,-78,-25,48,78,78,-73,-74,-80,-90,-79,-81,-84,-86,]),'INT':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,131,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,209,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,269,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,49,-3,-4,49,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,49,-2,-2,49,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,49,-142,-143,-144,-145,-146,-147,-148,-149,-150,49,-183,-20,49,49,49,49,49,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,49,49,49,-100,49,-105,49,-172,49,49,-114,-116,208,-109,-110,-111,-112,49,49,-108,-176,-182,-2,-177,-173,-23,-24,-26,49,-117,-125,-118,49,-138,49,-31,-37,-32,-2,-68,-69,270,49,-122,49,49,-139,-113,49,-16,-123,49,-120,49,-2,-2,-121,-95,-124,-119,-140,49,-38,-36,-71,-72,49,-88,314,-141,-75,49,-77,49,-96,-115,49,49,-126,49,-35,49,49,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,49,-94,49,-73,-74,-80,-90,-79,-81,49,-84,-86,]),'FLOAT':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,50,-3,-4,50,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,50,-2,-2,50,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,50,-142,-143,-144,-145,-146,-147,-148,-149,-150,50,-183,-20,50,50,50,50,50,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,50,50,50,-100,50,-105,50,-172,50,50,-114,-116,-109,-110,-111,-112,50,50,-108,-176,-182,-2,-177,-173,-23,-24,-26,50,-117,-125,-118,50,-138,50,-31,-37,-32,-2,-68,-69,50,-122,50,50,-139,-113,50,-16,-123,50,-120,50,-2,-2,-121,-95,-124,-119,-140,50,-38,-36,-71,-72,50,-88,-141,-75,50,-77,50,-96,-115,50,50,-126,50,-35,50,50,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,50,-94,50,-73,-74,-80,-90,-79,-81,50,-84,-86,]),'NULL':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,305,307,310,311,312,315,316,317,318,319,321,322,324,326,334,339,341,342,345,346,347,348,351,364,368,369,370,],[-2,51,-3,-4,51,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,51,-2,-2,51,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,51,-142,-143,-144,-145,-146,-147,-148,-149,-150,51,-183,-20,51,51,51,51,51,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,51,51,51,-100,51,-105,51,-172,51,51,-114,-116,-109,-110,-111,-112,51,51,-108,-176,-182,-2,-177,-173,-23,-24,-26,51,-117,-125,-118,51,-138,51,-31,-37,-32,-2,-68,-69,51,-122,51,51,-139,-113,51,-16,-123,51,-120,51,-2,-2,-121,-95,-124,-119,-140,51,-38,-36,-71,-72,51,-88,-141,-75,51,-77,51,-96,-115,51,51,-126,51,-35,51,51,344,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,51,-94,51,359,361,363,-73,-74,-80,-90,-79,-81,51,-84,-86,]),'REGEX':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,52,-3,-4,52,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,52,-2,-2,52,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,52,-142,-143,-144,-145,-146,-147,-148,-149,-150,52,-183,-20,52,52,52,52,52,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,52,52,52,-100,52,-105,52,-172,52,52,-114,-116,-109,-110,-111,-112,52,52,-108,-176,-182,-2,-177,-173,-23,-24,-26,52,-117,-125,-118,52,-138,52,-31,-37,-32,-2,-68,-69,52,-122,52,52,-139,-113,52,-16,-123,52,-120,52,-2,-2,-121,-95,-124,-119,-140,52,-38,-36,-71,-72,52,-88,-141,-75,52,-77,52,-96,-115,52,52,-126,52,-35,52,52,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,52,-94,52,-73,-74,-80,-90,-79,-81,52,-84,-86,]),'TRUE':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,53,-3,-4,53,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,53,-2,-2,53,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,53,-142,-143,-144,-145,-146,-147,-148,-149,-150,53,-183,-20,53,53,53,53,53,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,53,53,53,-100,53,-105,53,-172,53,53,-114,-116,-109,-110,-111,-112,53,53,-108,-176,-182,-2,-177,-173,-23,-24,-26,53,-117,-125,-118,53,-138,53,-31,-37,-32,-2,-68,-69,53,-122,53,53,-139,-113,53,-16,-123,53,-120,53,-2,-2,-121,-95,-124,-119,-140,53,-38,-36,-71,-72,53,-88,-141,-75,53,-77,53,-96,-115,53,53,-126,53,-35,53,53,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,53,-94,53,-73,-74,-80,-90,-79,-81,53,-84,-86,]),'FALSE':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,54,-3,-4,54,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,54,-2,-2,54,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,54,-142,-143,-144,-145,-146,-147,-148,-149,-150,54,-183,-20,54,54,54,54,54,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,54,54,54,-100,54,-105,54,-172,54,54,-114,-116,-109,-110,-111,-112,54,54,-108,-176,-182,-2,-177,-173,-23,-24,-26,54,-117,-125,-118,54,-138,54,-31,-37,-32,-2,-68,-69,54,-122,54,54,-139,-113,54,-16,-123,54,-120,54,-2,-2,-121,-95,-124,-119,-140,54,-38,-36,-71,-72,54,-88,-141,-75,54,-77,54,-96,-115,54,54,-126,54,-35,54,54,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,54,-94,54,-73,-74,-80,-90,-79,-81,54,-84,-86,]),'STRING':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,59,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,296,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,55,-3,-4,55,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,55,-2,-2,55,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,55,-142,-143,-144,-145,-146,-147,-148,-149,-150,55,122,-183,-20,55,55,55,55,55,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,55,55,55,-100,55,-105,55,-172,55,55,-114,-116,-109,-110,-111,-112,55,55,-108,-176,-182,-2,-177,-173,-23,-24,-26,55,-117,-125,-118,55,-138,55,-31,-37,-32,-2,-68,-69,55,-122,55,55,-139,-113,55,-16,-123,55,-120,55,-2,-2,-121,-95,-124,-119,-140,55,-38,-36,-71,-72,55,-88,-141,-75,55,-77,55,-96,-115,55,55,-126,55,122,-35,55,55,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,55,-94,55,-73,-74,-80,-90,-79,-81,55,-84,-86,]),'FSTRING':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,56,-3,-4,56,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,56,-2,-2,56,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,56,-142,-143,-144,-145,-146,-147,-148,-149,-150,56,-183,-20,56,56,56,56,56,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,56,56,56,-100,56,-105,56,-172,56,56,-114,-116,-109,-110,-111,-112,56,56,-108,-176,-182,-2,-177,-173,-23,-24,-26,56,-117,-125,-118,56,-138,56,-31,-37,-32,-2,-68,-69,56,-122,56,56,-139,-113,56,-16,-123,56,-120,56,-2,-2,-121,-95,-124,-119,-140,56,-38,-36,-71,-72,56,-88,-141,-75,56,-77,56,-96,-115,56,56,-126,56,-35,56,56,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,56,-94,56,-73,-74,-80,-90,-79,-81,56,-84,-86,]),'RSTRING':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,59,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,296,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,334,345,346,347,348,351,364,368,369,370,],[-2,57,-3,-4,57,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,57,-2,-2,57,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,57,-142,-143,-144,-145,-146,-147,-148,-149,-150,57,121,-183,-20,57,57,57,57,57,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,57,57,57,-100,57,-105,57,-172,57,57,-114,-116,-109,-110,-111,-112,57,57,-108,-176,-182,-2,-177,-173,-23,-24,-26,57,-117,-125,-118,57,-138,57,-31,-37,-32,-2,-68,-69,57,-122,57,57,-139,-113,57,-16,-123,57,-120,57,-2,-2,-121,-95,-124,-119,-140,57,-38,-36,-71,-72,57,-88,-141,-75,57,-77,57,-96,-115,57,57,-126,57,121,-35,57,57,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,57,-94,57,-73,-74,-80,-90,-79,-81,57,-84,-86,]),'[':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,20,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,69,73,74,75,76,77,79,82,83,84,85,88,89,90,91,92,93,95,96,98,99,100,101,104,106,109,110,111,112,127,132,141,142,143,144,145,148,150,155,156,163,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,195,196,201,203,204,205,207,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,300,301,307,310,311,312,315,316,317,318,319,321,322,324,326,345,346,347,348,351,364,365,366,369,370,],[-2,58,-3,-4,58,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,72,-151,-2,-2,-17,-18,-19,-2,58,-2,101,58,-97,-98,-99,-101,-102,-103,-104,106,-106,-107,111,58,-142,-143,-144,-145,-146,-147,-148,-149,-150,58,-183,131,-20,58,58,58,58,58,-82,-83,-92,-93,101,-183,-2,111,72,-15,-174,58,58,58,-100,58,-105,58,-172,58,58,-114,-116,131,-109,-110,-111,-112,58,58,-108,-176,-182,-183,-2,-177,-173,-23,-24,-26,58,-117,-125,-118,58,-138,58,-31,-37,258,-41,-32,-2,-68,-69,131,58,-122,58,58,-139,-113,58,-16,-123,58,-120,58,101,-2,-121,-95,-124,-119,-140,58,-38,-36,-71,-72,58,-88,-141,-75,58,-77,58,-96,-115,58,58,-126,58,-35,334,334,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,58,-94,-73,-74,-80,-90,-79,-81,131,131,-84,-86,]),'{':([0,2,3,4,6,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,31,33,34,35,36,37,38,39,40,41,42,43,44,45,47,48,49,50,51,52,53,54,55,56,57,58,67,73,74,75,76,77,79,82,83,84,85,88,89,90,91,93,95,96,98,99,100,101,104,106,109,110,111,112,127,141,142,143,144,145,148,150,155,156,164,165,166,167,168,170,171,172,179,181,183,184,185,186,189,201,203,204,205,210,211,214,215,216,217,218,223,224,226,228,230,232,233,234,236,238,239,240,243,248,249,263,264,265,268,277,278,279,280,281,282,286,290,292,293,295,298,305,307,310,311,312,315,316,317,318,319,321,322,324,326,339,341,342,345,346,347,348,351,364,369,370,],[-2,59,-3,-4,59,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,59,-2,-2,59,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,59,-142,-143,-144,-145,-146,-147,-148,-149,-150,59,-183,-20,59,59,59,59,59,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,59,59,59,-100,59,-105,59,-172,59,59,-114,-116,-109,-110,-111,-112,59,59,-108,-176,-182,-2,-177,-173,-23,-24,-26,59,-117,-125,-118,59,-138,59,-31,-37,-32,-2,-68,-69,59,-122,59,59,-139,-113,59,-16,-123,59,-120,59,-2,-2,-121,-95,-124,-119,-140,59,-38,-36,-71,-72,59,-88,-141,-75,59,-77,59,-96,-115,59,59,-126,59,-35,59,-33,-34,-2,-70,-89,-91,-85,-87,-76,-78,-25,59,-94,59,59,59,-73,-74,-80,-90,-79,-81,-84,-86,]),'$end':([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,21,22,25,26,27,28,29,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,60,67,73,82,83,84,85,88,89,90,91,93,95,100,104,109,112,127,141,142,143,144,150,155,156,164,165,166,167,168,170,172,179,181,184,186,189,201,203,204,205,211,216,217,223,224,228,234,236,238,239,240,248,249,263,264,268,277,278,282,286,293,298,307,310,311,312,315,316,317,318,319,322,326,345,346,347,348,351,364,369,370,],[-2,0,-2,-3,-4,-1,-2,-6,-7,-8,-9,-10,-11,-12,-13,-14,-175,-183,-151,-2,-2,-17,-18,-19,-2,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-5,-183,-20,-82,-83,-92,-93,-2,-183,-2,-2,-15,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-176,-182,-2,-177,-173,-23,-24,-26,-117,-125,-118,-138,-31,-37,-32,-2,-68,-69,-122,-139,-113,-16,-123,-120,-121,-95,-124,-119,-140,-38,-36,-71,-72,-88,-141,-75,-96,-115,-126,-35,-33,-34,-2,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'.':([17,18,20,33,34,47,65,66,67,68,88,89,90,91,95,109,155,156,163,165,166,199,200,206,232,233,317,318,],[-175,-183,70,-2,97,-2,-2,129,-183,-2,151,-183,-2,-2,-174,-172,-176,-182,-183,-177,-173,129,-2,-173,151,-2,349,350,]),'USING':([17,64,155,165,],[-175,128,-176,-177,]),',':([17,21,36,37,38,39,40,41,42,43,44,45,49,50,51,52,53,54,55,56,57,67,68,88,89,90,91,95,100,104,109,112,114,115,127,135,138,141,142,143,144,150,155,156,159,161,162,163,164,165,166,172,179,181,184,198,199,200,203,204,205,206,211,216,217,222,224,228,234,238,239,240,246,275,276,277,286,293,312,357,],[-175,-151,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,-2,-2,-183,-2,-2,-174,-100,-105,-172,-114,-2,183,-116,213,-158,-109,-110,-111,-112,-108,-176,-182,226,-163,-164,-183,-2,-177,-173,-117,-125,-118,-138,260,261,-2,266,-68,-69,-173,-122,-139,-113,283,-123,-120,-121,-124,-119,-140,296,-157,-156,-141,-115,-126,266,368,]),':':([17,21,36,37,38,39,40,41,42,43,44,45,49,50,51,52,53,54,55,56,57,61,62,67,68,88,89,90,91,95,100,103,104,109,112,118,121,122,127,131,141,142,143,144,146,150,155,156,164,165,166,172,179,181,184,197,198,199,200,202,206,208,211,216,217,219,220,224,228,234,238,239,240,277,286,289,293,308,309,],[-175,-151,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-142,-143,-144,-145,-146,-147,-148,-149,-150,123,125,-183,-2,-2,-183,-2,-2,-174,-100,171,-105,-172,-114,185,-132,-133,-116,209,-109,-110,-111,-112,218,-108,-176,-182,-2,-177,-173,-117,-125,-118,-138,259,-180,-181,-2,262,-173,269,-122,-139,-113,280,281,-123,-120,-121,-124,-119,-140,-141,-115,324,-126,-178,-179,]),'SEP':([18,33,65,67,89,90,93,156,163,196,200,204,233,235,],[-183,94,94,-183,-183,152,154,-182,-183,154,94,154,152,154,]),'=':([18,33,34,47,89,95,109,137,156,163,166,232,233,251,252,255,302,303,304,],[-183,-2,98,-2,-183,-174,-172,214,-182,214,-173,98,-2,300,301,305,339,341,342,]),'PEQ':([18,33,34,47,89,95,109,156,166,232,233,],[-183,-2,99,-2,-183,-174,-172,-182,-173,99,-2,]),'CMP_OP':([18,21,22,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,87,88,89,90,91,95,100,103,104,109,112,114,127,141,142,143,144,146,150,156,163,164,166,172,179,184,211,216,217,224,228,232,233,234,238,239,240,277,286,293,294,311,326,328,],[-183,-151,74,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,74,-2,-183,-2,-2,-174,-100,74,-105,-172,-114,74,-116,-109,-110,74,74,74,-108,-182,-183,74,-173,-117,-125,-138,-122,-139,-113,-123,-120,-2,-2,-121,-124,-119,-140,74,-115,-126,74,74,74,74,]),'IN':([18,21,22,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,78,81,87,88,89,90,91,95,100,103,104,109,112,114,127,141,142,143,144,146,150,156,163,164,166,172,179,184,211,216,217,224,228,232,233,234,238,239,240,244,277,286,293,294,311,326,328,],[-183,-151,75,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,145,148,75,-2,-183,-2,-2,-174,-100,75,-105,-172,75,75,-116,75,-110,75,75,75,-108,-182,-183,75,-173,-117,-125,-138,-122,-139,-113,-123,-120,-2,-2,-121,-124,-119,-140,295,75,-115,-126,75,75,75,75,]),'AND':([18,21,22,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,87,88,89,90,91,95,100,103,104,109,112,114,127,141,142,143,144,146,150,156,163,164,166,172,179,184,211,216,217,224,228,232,233,234,238,239,240,277,286,293,294,311,326,328,],[-183,-151,76,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,76,-2,-183,-2,-2,-174,-100,76,-105,-172,-114,76,-116,-109,-110,-111,76,76,-108,-182,-183,76,-173,-117,-125,-138,-122,-139,-113,-123,-120,-2,-2,-121,-124,-119,-140,76,-115,-126,76,76,76,76,]),'OR':([18,21,22,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,87,88,89,90,91,95,100,103,104,109,112,114,127,141,142,143,144,146,150,156,163,164,166,172,179,184,211,216,217,224,228,232,233,234,238,239,240,277,286,293,294,311,326,328,],[-183,-151,77,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,77,-2,-183,-2,-2,-174,-100,77,-105,-172,-114,77,-116,-109,-110,-111,-112,77,-108,-182,-183,77,-173,-117,-125,-138,-122,-139,-113,-123,-120,-2,-2,-121,-124,-119,-140,77,-115,-126,77,77,77,77,]),'?':([18,21,22,33,34,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,67,87,88,89,90,91,95,100,103,104,109,112,114,127,141,142,143,144,146,150,156,163,164,166,172,179,184,192,194,195,196,211,216,217,224,228,232,233,234,238,239,240,277,286,293,294,306,311,326,328,],[-183,-151,79,-2,-2,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-183,79,-2,-183,-2,-2,-174,-100,79,-105,-172,-114,79,-116,-109,-110,-111,-112,79,-108,-182,-183,79,-173,-117,-125,-138,254,256,257,-41,-122,-139,-113,-123,-120,-2,-2,-121,-124,-119,-140,79,-115,-126,79,-42,79,79,79,]),'IS':([18,43,89,163,166,228,234,239,],[63,105,63,63,227,-120,-121,-119,]),')':([21,36,37,38,39,40,41,42,43,44,45,49,50,51,52,53,54,55,56,57,71,87,88,89,90,91,95,96,100,104,109,110,112,127,133,134,135,136,138,141,142,143,144,150,156,157,158,159,160,161,162,163,164,166,172,176,179,181,184,211,212,213,216,217,221,222,224,225,226,228,234,238,239,240,273,274,275,276,277,284,285,286,293,323,],[-151,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-142,-143,-144,-145,-146,-147,-148,-149,-150,-2,150,-2,-183,-2,-2,-174,-2,-100,-105,-172,-2,-114,-116,211,-159,-2,-160,-158,-109,-110,-111,-112,-108,-182,224,-165,-2,-166,-163,-164,-183,-2,-173,-117,238,-125,-118,-138,-122,-2,-2,-139,-113,282,-185,-123,-2,-2,-120,-121,-124,-119,-140,-161,-162,-157,-156,-141,-167,-168,-115,-126,-184,]),']':([21,36,37,38,39,40,41,42,43,44,45,49,50,51,52,53,54,55,56,57,58,72,88,89,90,91,95,100,104,109,111,112,113,114,115,116,127,134,135,136,138,140,141,142,143,144,150,156,163,164,166,169,172,173,177,178,179,180,181,183,184,208,211,212,213,216,217,224,228,234,238,239,240,241,242,245,258,269,270,273,274,275,276,277,286,293,294,314,327,328,334,353,354,355,356,357,368,371,],[-151,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-142,-143,-144,-145,-146,-147,-148,-149,-150,-2,-2,-2,-183,-2,-2,-174,-100,-105,-172,-2,-114,179,-2,-170,-171,-116,-159,-2,-160,-158,216,-109,-110,-111,-112,-108,-182,-183,-2,-173,228,-117,234,239,240,-125,-2,-118,-2,-138,268,-122,-2,-2,-139,-113,-123,-120,-121,-124,-119,-140,293,-130,-169,306,315,316,-161,-162,-157,-156,-141,-115,-126,-2,348,-131,-2,-154,-128,-129,-127,367,-153,-154,-155,]),'ELSE':([21,22,26,27,28,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,73,88,89,90,91,95,100,104,109,112,127,141,142,143,144,150,156,164,166,167,168,170,171,172,179,181,184,211,216,217,224,228,229,230,231,232,233,234,238,239,240,277,286,291,293,322,351,],[-151,-2,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-20,-2,-183,-2,-2,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-182,-2,-173,-23,-24,-26,-2,-117,-125,-118,-138,-122,-139,-113,-123,-120,289,-2,-22,-2,-2,-121,-124,-119,-140,-141,-115,-21,-126,-25,-79,]),'ELIF':([21,22,26,27,28,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,73,88,89,90,91,95,100,104,109,112,127,141,142,143,144,150,156,164,166,167,168,170,171,172,179,181,184,211,216,217,224,228,229,230,231,232,233,234,238,239,240,277,286,291,293,322,351,],[-151,-2,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-20,-2,-183,-2,-2,-174,-100,-105,-172,-114,-116,-109,-110,-111,-112,-108,-182,-2,-173,-23,-24,-26,-2,-117,-125,-118,-138,-122,-139,-113,-123,-120,290,-2,-22,-2,-2,-121,-124,-119,-140,-141,-115,-21,-126,-25,-79,]),'END':([21,22,26,27,28,36,37,38,39,40,41,42,43,44,45,47,49,50,51,52,53,54,55,56,57,73,88,89,90,91,95,100,102,104,109,112,123,125,127,141,142,143,144,150,156,164,166,167,168,170,171,172,179,181,184,187,188,190,211,216,217,224,228,229,230,231,232,233,234,238,239,240,247,250,251,252,255,259,262,277,279,280,281,286,287,288,291,293,299,302,303,304,320,321,322,324,325,331,332,333,335,336,337,338,340,343,344,351,352,358,359,360,361,362,363,367,],[-151,-2,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-2,-142,-143,-144,-145,-146,-147,-148,-149,-150,-20,-2,-183,-2,-2,-174,-100,170,-105,-172,-114,189,189,-116,-109,-110,-111,-112,-108,-182,-2,-173,-23,-24,-26,-2,-117,-125,-118,-138,248,249,-40,-122,-139,-113,-123,-120,-2,-2,-22,-2,-2,-121,-124,-119,-140,298,-39,-2,-52,-62,189,189,-141,-2,-77,-2,-115,-27,-28,-21,-126,-48,-2,-2,-65,351,-78,-25,-2,-30,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-79,-29,-57,-58,-60,-61,-66,-67,-152,]),'}':([21,36,37,38,39,40,41,42,43,44,45,49,50,51,52,53,54,55,56,57,59,88,89,90,91,95,100,104,109,112,117,119,120,127,141,142,143,144,150,156,164,166,172,179,181,184,211,216,217,224,228,234,238,239,240,246,277,286,293,296,297,329,330,],[-151,-97,-98,-99,-101,-102,-103,-104,-2,-106,-107,-142,-143,-144,-145,-146,-147,-148,-149,-150,-2,-2,-183,-2,-2,-174,-100,-105,-172,-114,184,-137,-136,-116,-109,-110,-111,-112,-108,-182,-2,-173,-117,-125,-118,-138,-122,-139,-113,-123,-120,-121,-124,-119,-140,-2,-141,-115,-126,-2,-2,-134,-135,]),'DICT':([21,49,50,51,52,53,54,55,56,57,123,125,184,187,188,190,247,250,251,252,255,259,262,299,302,303,304,331,332,333,335,336,337,338,340,343,344,358,359,360,361,362,363,367,],[-151,-142,-143,-144,-145,-146,-147,-148,-149,-150,192,192,-138,192,192,-40,192,-39,-2,-52,-62,192,192,-48,-2,-2,-65,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-57,-58,-60,-61,-66,-67,-152,]),'EXTENDS':([61,62,],[124,126,]),'DEFINED':([63,105,227,],[127,172,286,]),'AS':([67,93,107,108,156,],[-183,153,174,175,-182,]),'WHEN':([67,156,203,204,205,312,],[-183,-182,265,-68,-69,-70,]),'MATCHING':([67,156,235,],[-183,-182,292,]),'*':([71,72,96,110,111,139,213,226,],[139,139,139,139,139,215,139,139,]),'PARENTS':([128,266,],[205,205,]),'REL':([130,210,268,315,316,348,],[207,271,-88,-89,-91,-90,]),'UNDEF':([300,301,],[333,337,]),}
+_lr_action_items = {'ENTITY':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,15,-3,15,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPLEMENT':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,18,-3,18,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPLEMENTATION':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,22,-3,22,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'INDEX':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,29,-3,29,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'IMPORT':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,31,-3,31,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'CID':([0,2,3,5,7,8,9,10,11,12,13,14,15,16,17,18,20,21,24,25,26,27,28,29,30,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,89,90,91,92,93,94,98,101,102,103,106,114,116,117,119,131,132,133,134,136,137,139,140,141,144,145,153,154,155,156,157,159,160,161,164,168,171,172,173,174,177,179,180,181,182,183,184,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,232,235,236,240,241,243,244,247,248,250,251,252,254,255,258,259,264,265,266,267,268,269,273,277,279,280,282,285,293,294,297,298,299,302,303,304,305,306,308,309,311,313,332,333,334,335,338,351,356,357,],[-2,16,-3,16,-6,-7,-8,-9,-10,-11,-12,-13,60,-174,-182,16,-150,-20,-83,-17,-18,-19,-92,16,16,-173,-100,16,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,100,-171,16,-141,-142,-143,-144,-145,-146,-147,-148,-149,16,-182,16,16,16,16,16,-82,-93,-100,-182,-173,-171,-15,144,16,154,16,16,16,16,16,16,-113,-169,16,16,-115,154,-109,-110,-111,-112,16,16,-108,154,144,-175,-181,-117,-176,-172,-23,-24,-26,16,-116,16,-124,16,-137,16,-31,-37,238,-14,-45,-46,-47,-41,-32,-14,-68,-69,16,-121,16,16,-138,16,-16,-122,16,-119,16,-100,-173,-120,-95,-123,-118,-139,16,-168,-38,-36,289,290,-43,-44,16,16,-71,-72,16,16,-88,16,16,-140,-75,16,-77,16,-96,-114,16,16,-125,16,-35,-42,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,16,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'FOR':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,77,79,80,83,84,85,86,88,103,105,117,131,132,133,134,139,144,145,153,154,155,156,157,159,160,161,168,172,174,177,189,191,192,193,199,204,210,211,215,217,219,220,221,223,225,226,227,235,236,250,251,255,264,265,266,267,268,269,273,280,285,294,297,298,299,302,303,304,305,306,308,309,311,313,315,332,333,334,335,338,351,356,357,],[-2,23,-3,23,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,136,-82,-93,-100,-182,-173,-171,-15,-113,170,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,23,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,23,-100,-173,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,23,-77,23,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,23,-94,170,-73,-74,-80,-90,-79,-81,-84,-86,]),'IF':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,160,161,168,169,172,174,177,189,191,192,193,199,204,210,211,215,217,219,220,221,223,225,226,227,235,236,250,251,255,264,265,266,267,268,269,273,280,281,285,294,297,298,299,302,303,304,305,306,308,309,311,313,315,332,333,334,335,338,340,341,342,351,356,357,],[-2,34,-3,34,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,34,-116,-124,230,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,34,-100,-173,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,34,-77,34,-96,-114,-125,230,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,34,-94,-14,-73,-74,-80,-90,-79,-127,-128,-126,-81,-84,-86,]),'(':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,19,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,81,83,84,85,86,87,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,152,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,224,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,294,297,298,299,302,303,304,305,306,308,309,311,313,332,333,334,335,338,351,356,357,],[-2,30,-3,30,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,70,-150,-20,-83,-17,-18,-19,-92,30,90,-100,30,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,101,30,-141,-142,-143,-144,-145,-146,-147,-148,-149,30,-182,30,30,30,30,30,-82,-93,138,-100,-182,90,101,70,-15,30,30,30,30,30,30,30,-113,-115,-109,-110,-111,-112,30,-108,-175,-181,-182,-117,-176,-172,-23,-24,-26,30,-116,-124,30,-137,30,-31,-37,-32,-14,-68,-69,30,-121,30,30,-138,30,-16,-122,30,-119,30,-100,90,-120,-95,70,-123,-118,-139,30,-38,-36,-71,-72,30,-88,-140,-75,30,-77,30,-96,-114,30,30,-125,30,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,30,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'TYPEDEF':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,45,-3,45,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'ID':([0,2,3,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,66,69,70,71,72,73,74,75,76,79,80,83,84,85,86,88,89,90,91,92,93,94,98,101,102,103,106,113,114,115,116,117,118,119,131,132,133,134,136,137,138,139,140,141,142,143,144,145,153,154,155,156,157,159,160,161,163,164,168,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,189,191,192,193,198,199,201,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,232,234,235,236,237,238,239,241,242,243,244,246,247,248,249,250,251,252,253,254,255,258,259,264,265,266,267,268,269,270,273,277,279,280,282,285,286,289,290,291,293,294,297,298,299,300,302,303,304,305,306,308,309,311,313,318,319,320,322,323,324,325,327,330,331,332,333,334,335,336,337,338,345,346,347,348,349,350,351,354,356,357,],[-2,17,-3,17,-6,-7,-8,-9,-10,-11,-12,-13,61,-174,-182,66,68,-150,-20,77,78,-83,-17,-18,-19,-92,66,84,66,-173,-100,84,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,99,-171,84,-141,-142,-143,-144,-145,-146,-147,-148,-149,84,-182,122,127,127,84,84,84,84,84,-82,-93,-100,-182,-173,-171,-15,145,152,155,84,84,84,84,152,152,-113,-169,66,66,66,66,-115,66,194,-109,-110,-111,-112,66,84,209,-108,155,145,210,145,-175,-181,-117,-176,-172,-23,-24,-26,84,-116,66,66,-124,231,84,-137,84,-31,66,66,-37,-40,239,242,-45,-46,-47,-41,-32,-14,-68,-69,84,-121,127,84,84,-138,84,-16,-122,152,-119,84,-100,-173,-120,-95,-123,-118,-139,84,-168,66,-38,-36,-39,-14,-52,291,-62,-43,-44,66,66,66,66,-71,-72,84,66,66,-88,66,66,-140,-75,84,-77,84,-96,209,-114,84,84,-125,84,-35,-48,-14,-14,-65,-42,-33,-34,-14,-70,334,-89,-91,-85,-87,-76,-78,-25,84,-94,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-73,-74,-80,-90,352,353,-79,-57,-58,-60,-61,-66,-67,-81,-151,-84,-86,]),'NOT':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,294,297,298,299,302,303,304,305,306,308,309,311,313,332,333,334,335,338,351,356,357,],[-2,47,-3,47,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,47,-173,-100,47,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,47,-141,-142,-143,-144,-145,-146,-147,-148,-149,47,-182,47,47,47,47,47,-82,-93,-100,-182,-173,-171,-15,47,47,47,47,47,47,47,-113,-115,-109,-110,-111,-112,47,-108,-175,-181,-117,-176,-172,-23,-24,-26,47,-116,-124,47,-137,47,-31,-37,-32,-14,-68,-69,47,-121,47,47,-138,47,-16,-122,47,-119,47,-100,-173,-120,-95,-123,-118,-139,47,-38,-36,-71,-72,47,-88,-140,-75,47,-77,47,-96,-114,47,47,-125,47,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,47,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'INT':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,121,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,197,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,256,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,48,-3,48,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,48,-173,-100,48,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,48,-141,-142,-143,-144,-145,-146,-147,-148,-149,48,-182,48,48,48,48,48,-82,-93,-100,-182,-173,-171,-15,48,48,48,48,48,48,48,-113,-115,196,-109,-110,-111,-112,48,-108,-175,-181,-117,-176,-172,-23,-24,-26,48,-116,-124,48,-137,48,-31,-37,-32,-14,-68,-69,257,48,-121,48,48,-138,48,-16,-122,48,-119,48,-100,-173,-120,-95,-123,-118,-139,48,-38,-36,-71,-72,48,-88,301,-140,-75,48,-77,48,-96,-114,48,48,-125,48,-35,48,48,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,48,-94,48,-73,-74,-80,-90,-79,-81,48,-84,-86,]),'FLOAT':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,49,-3,49,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,49,-173,-100,49,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,49,-141,-142,-143,-144,-145,-146,-147,-148,-149,49,-182,49,49,49,49,49,-82,-93,-100,-182,-173,-171,-15,49,49,49,49,49,49,49,-113,-115,-109,-110,-111,-112,49,-108,-175,-181,-117,-176,-172,-23,-24,-26,49,-116,-124,49,-137,49,-31,-37,-32,-14,-68,-69,49,-121,49,49,-138,49,-16,-122,49,-119,49,-100,-173,-120,-95,-123,-118,-139,49,-38,-36,-71,-72,49,-88,-140,-75,49,-77,49,-96,-114,49,49,-125,49,-35,49,49,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,49,-94,49,-73,-74,-80,-90,-79,-81,49,-84,-86,]),'NULL':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,292,294,297,298,299,302,303,304,305,306,308,309,311,313,321,326,328,329,332,333,334,335,338,351,355,356,357,],[-2,50,-3,50,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,50,-173,-100,50,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,50,-141,-142,-143,-144,-145,-146,-147,-148,-149,50,-182,50,50,50,50,50,-82,-93,-100,-182,-173,-171,-15,50,50,50,50,50,50,50,-113,-115,-109,-110,-111,-112,50,-108,-175,-181,-117,-176,-172,-23,-24,-26,50,-116,-124,50,-137,50,-31,-37,-32,-14,-68,-69,50,-121,50,50,-138,50,-16,-122,50,-119,50,-100,-173,-120,-95,-123,-118,-139,50,-38,-36,-71,-72,50,-88,-140,-75,50,-77,50,-96,-114,50,50,-125,50,-35,50,50,331,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,50,-94,50,346,348,350,-73,-74,-80,-90,-79,-81,50,-84,-86,]),'REGEX':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,51,-3,51,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,51,-173,-100,51,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,51,-141,-142,-143,-144,-145,-146,-147,-148,-149,51,-182,51,51,51,51,51,-82,-93,-100,-182,-173,-171,-15,51,51,51,51,51,51,51,-113,-115,-109,-110,-111,-112,51,-108,-175,-181,-117,-176,-172,-23,-24,-26,51,-116,-124,51,-137,51,-31,-37,-32,-14,-68,-69,51,-121,51,51,-138,51,-16,-122,51,-119,51,-100,-173,-120,-95,-123,-118,-139,51,-38,-36,-71,-72,51,-88,-140,-75,51,-77,51,-96,-114,51,51,-125,51,-35,51,51,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,51,-94,51,-73,-74,-80,-90,-79,-81,51,-84,-86,]),'TRUE':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,52,-3,52,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,52,-173,-100,52,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,52,-141,-142,-143,-144,-145,-146,-147,-148,-149,52,-182,52,52,52,52,52,-82,-93,-100,-182,-173,-171,-15,52,52,52,52,52,52,52,-113,-115,-109,-110,-111,-112,52,-108,-175,-181,-117,-176,-172,-23,-24,-26,52,-116,-124,52,-137,52,-31,-37,-32,-14,-68,-69,52,-121,52,52,-138,52,-16,-122,52,-119,52,-100,-173,-120,-95,-123,-118,-139,52,-38,-36,-71,-72,52,-88,-140,-75,52,-77,52,-96,-114,52,52,-125,52,-35,52,52,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,52,-94,52,-73,-74,-80,-90,-79,-81,52,-84,-86,]),'FALSE':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,53,-3,53,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,53,-173,-100,53,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,53,-141,-142,-143,-144,-145,-146,-147,-148,-149,53,-182,53,53,53,53,53,-82,-93,-100,-182,-173,-171,-15,53,53,53,53,53,53,53,-113,-115,-109,-110,-111,-112,53,-108,-175,-181,-117,-176,-172,-23,-24,-26,53,-116,-124,53,-137,53,-31,-37,-32,-14,-68,-69,53,-121,53,53,-138,53,-16,-122,53,-119,53,-100,-173,-120,-95,-123,-118,-139,53,-38,-36,-71,-72,53,-88,-140,-75,53,-77,53,-96,-114,53,53,-125,53,-35,53,53,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,53,-94,53,-73,-74,-80,-90,-79,-81,53,-84,-86,]),'STRING':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,283,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,54,-3,54,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,54,-173,-100,54,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,54,-141,-142,-143,-144,-145,-146,-147,-148,-149,54,112,-182,54,54,54,54,54,-82,-93,-100,-182,-173,-171,-15,54,54,54,54,54,54,54,-113,-115,-109,-110,-111,-112,54,-108,-175,-181,-117,-176,-172,-23,-24,-26,54,-116,-124,54,-137,54,-31,-37,-32,-14,-68,-69,54,-121,54,54,-138,54,-16,-122,54,-119,54,-100,-173,-120,-95,-123,-118,-139,54,-38,-36,-71,-72,54,-88,-140,-75,54,-77,54,-96,-114,54,54,-125,54,112,-35,54,54,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,54,-94,54,-73,-74,-80,-90,-79,-81,54,-84,-86,]),'FSTRING':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,55,-3,55,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,55,-173,-100,55,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,55,-141,-142,-143,-144,-145,-146,-147,-148,-149,55,-182,55,55,55,55,55,-82,-93,-100,-182,-173,-171,-15,55,55,55,55,55,55,55,-113,-115,-109,-110,-111,-112,55,-108,-175,-181,-117,-176,-172,-23,-24,-26,55,-116,-124,55,-137,55,-31,-37,-32,-14,-68,-69,55,-121,55,55,-138,55,-16,-122,55,-119,55,-100,-173,-120,-95,-123,-118,-139,55,-38,-36,-71,-72,55,-88,-140,-75,55,-77,55,-96,-114,55,55,-125,55,-35,55,55,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,55,-94,55,-73,-74,-80,-90,-79,-81,55,-84,-86,]),'RSTRING':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,58,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,283,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[-2,56,-3,56,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,56,-173,-100,56,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,56,-141,-142,-143,-144,-145,-146,-147,-148,-149,56,111,-182,56,56,56,56,56,-82,-93,-100,-182,-173,-171,-15,56,56,56,56,56,56,56,-113,-115,-109,-110,-111,-112,56,-108,-175,-181,-117,-176,-172,-23,-24,-26,56,-116,-124,56,-137,56,-31,-37,-32,-14,-68,-69,56,-121,56,56,-138,56,-16,-122,56,-119,56,-100,-173,-120,-95,-123,-118,-139,56,-38,-36,-71,-72,56,-88,-140,-75,56,-77,56,-96,-114,56,56,-125,56,111,-35,56,56,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,56,-94,56,-73,-74,-80,-90,-79,-81,56,-84,-86,]),'MLS':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,113,115,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,246,249,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,321,332,333,334,335,338,351,355,356,357,],[3,20,-3,20,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,79,-17,-18,-19,80,20,-173,-100,20,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,20,-141,-142,-143,-144,-145,-146,-147,-148,-149,20,-182,20,20,20,20,20,-82,-93,-100,-182,-173,-171,-15,20,20,20,20,20,20,20,-113,175,175,-115,-109,-110,-111,-112,20,-108,-175,-181,-117,-176,-172,-23,-24,-26,20,-116,-124,20,-137,20,-31,-37,-32,251,-68,-69,20,-121,20,20,-138,20,-16,-122,20,-119,20,-100,-173,-120,-95,-123,-118,-139,20,-38,-36,175,175,-71,-72,20,-88,-140,-75,20,308,20,-96,-114,20,20,-125,20,-35,20,20,-33,-34,333,-70,-89,-91,-85,-87,-76,-78,-25,20,-94,20,-73,-74,351,-90,-79,-81,20,-84,-86,]),'[':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,19,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,68,72,73,74,75,76,79,80,83,84,85,86,87,88,90,92,93,94,98,101,102,103,117,122,131,132,133,134,137,139,144,145,152,153,154,155,156,157,159,160,161,168,171,172,173,174,177,183,184,189,191,192,193,195,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,287,288,294,297,298,299,302,303,304,305,306,308,309,311,313,332,333,334,335,338,351,352,353,356,357,],[-2,57,-3,57,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,71,-150,-20,-83,-17,-18,-19,-92,57,-173,94,57,-97,-98,-99,-101,-102,-103,-104,98,-106,-107,102,57,-141,-142,-143,-144,-145,-146,-147,-148,-149,57,-182,121,57,57,57,57,57,-82,-93,94,-182,-173,102,71,-15,57,57,57,57,57,57,57,-113,-115,121,-109,-110,-111,-112,57,-108,-175,-181,-182,-117,-176,-172,-23,-24,-26,57,-116,-124,57,-137,57,-31,-37,245,-41,-32,-14,-68,-69,121,57,-121,57,57,-138,57,-16,-122,57,-119,57,94,-173,-120,-95,-123,-118,-139,57,-38,-36,-71,-72,57,-88,-140,-75,57,-77,57,-96,-114,57,57,-125,57,-35,321,321,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,57,-94,-73,-74,-80,-90,-79,-81,121,121,-84,-86,]),'{':([0,2,3,5,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,42,43,44,46,47,48,49,50,51,52,53,54,55,56,57,66,72,73,74,75,76,79,80,83,84,85,86,88,90,92,93,94,98,101,102,103,117,131,132,133,134,137,139,144,145,153,154,155,156,157,159,160,161,168,171,172,173,174,177,189,191,192,193,198,199,202,203,204,205,210,211,213,215,217,219,220,221,223,225,226,227,230,235,236,250,251,252,255,264,265,266,267,268,269,273,277,279,280,282,285,292,294,297,298,299,302,303,304,305,306,308,309,311,313,326,328,329,332,333,334,335,338,351,356,357,],[-2,58,-3,58,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,58,-173,-100,58,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,58,-141,-142,-143,-144,-145,-146,-147,-148,-149,58,-182,58,58,58,58,58,-82,-93,-100,-182,-173,-171,-15,58,58,58,58,58,58,58,-113,-115,-109,-110,-111,-112,58,-108,-175,-181,-117,-176,-172,-23,-24,-26,58,-116,-124,58,-137,58,-31,-37,-32,-14,-68,-69,58,-121,58,58,-138,58,-16,-122,58,-119,58,-100,-173,-120,-95,-123,-118,-139,58,-38,-36,-71,-72,58,-88,-140,-75,58,-77,58,-96,-114,58,58,-125,58,-35,58,-33,-34,-14,-70,-89,-91,-85,-87,-76,-78,-25,58,-94,58,58,58,-73,-74,-80,-90,-79,-81,-84,-86,]),'$end':([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,17,20,21,24,25,26,27,28,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,59,66,79,80,83,84,85,86,88,103,117,131,132,133,134,139,144,145,153,154,155,156,157,159,161,168,172,174,177,189,191,192,193,199,204,210,211,215,221,223,225,226,227,235,236,250,251,255,264,265,269,273,280,285,294,297,298,299,302,303,304,305,306,309,313,332,333,334,335,338,351,356,357,],[-2,0,-14,-3,-1,-14,-5,-6,-7,-8,-9,-10,-11,-12,-13,-174,-182,-150,-20,-83,-17,-18,-19,-92,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-4,-182,-82,-93,-100,-182,-173,-171,-15,-113,-115,-109,-110,-111,-112,-108,-175,-181,-117,-176,-172,-23,-24,-26,-116,-124,-137,-31,-37,-32,-14,-68,-69,-121,-138,-16,-122,-119,-120,-95,-123,-118,-139,-38,-36,-71,-72,-88,-140,-75,-96,-114,-125,-35,-33,-34,-14,-70,-89,-91,-85,-87,-76,-25,-94,-73,-74,-80,-90,-79,-81,-84,-86,]),'.':([16,17,19,32,33,46,64,65,66,67,83,84,85,86,144,145,152,154,155,187,188,194,219,220,304,305,],[-174,-182,69,-173,91,-171,-173,119,-182,-171,140,-182,-173,-171,-175,-181,-182,-176,-172,119,-173,-172,140,-173,336,337,]),'USING':([16,63,144,154,],[-174,118,-175,-176,]),',':([16,20,35,36,37,38,39,40,41,42,43,44,48,49,50,51,52,53,54,55,56,66,67,83,84,85,86,103,105,106,117,125,128,131,132,133,134,139,144,145,148,150,151,152,153,154,155,161,168,172,186,187,188,191,192,193,194,199,204,209,211,215,221,225,226,227,233,262,263,264,273,280,299,344,],[-174,-150,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,-171,-100,-182,-173,-171,-113,-117,171,-115,201,-157,-109,-110,-111,-112,-108,-175,-181,213,-162,-163,-182,-117,-176,-172,-116,-124,-137,247,248,-173,253,-68,-69,-172,-121,-138,270,-122,-119,-120,-123,-118,-139,283,-156,-155,-140,-114,-125,253,355,]),':':([16,20,35,36,37,38,39,40,41,42,43,44,48,49,50,51,52,53,54,55,56,60,61,66,67,83,84,85,86,96,103,108,111,112,117,121,131,132,133,134,135,139,144,145,153,154,155,161,168,172,185,186,187,188,190,194,196,199,204,206,207,211,215,221,225,226,227,264,273,276,280,295,296,],[-174,-150,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-141,-142,-143,-144,-145,-146,-147,-148,-149,113,115,-182,-171,-100,-182,-173,-171,160,-113,173,-131,-132,-115,197,-109,-110,-111,-112,205,-108,-175,-181,-117,-176,-172,-116,-124,-137,246,-179,-180,-173,249,-172,256,-121,-138,267,268,-122,-119,-120,-123,-118,-139,-140,-114,311,-125,-177,-178,]),'SEP':([17,32,64,66,84,85,88,145,152,184,188,192,220,222,],[-182,89,89,-182,-182,141,143,-181,-182,143,89,143,141,143,]),'=':([17,32,33,46,84,127,145,152,155,219,220,238,239,242,289,290,291,],[-182,-173,92,-171,-182,202,-181,202,-172,92,-173,287,288,292,326,328,329,]),'PEQ':([17,32,33,46,84,145,155,219,220,],[-182,-173,93,-171,-182,-181,-172,93,-173,]),'CMP_OP':([17,20,21,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,82,83,84,85,86,96,103,105,117,131,132,133,134,135,139,145,152,153,155,161,168,172,199,204,211,215,219,220,221,225,226,227,264,273,280,281,298,313,315,],[-182,-150,72,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,72,-100,-182,-173,-171,72,-113,72,-115,-109,-110,72,72,72,-108,-181,-182,72,-172,-116,-124,-137,-121,-138,-122,-119,-100,-173,-120,-123,-118,-139,72,-114,-125,72,72,72,72,]),'IN':([17,20,21,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,78,82,83,84,85,86,96,103,105,117,131,132,133,134,135,139,145,152,153,155,161,168,172,199,204,211,215,219,220,221,225,226,227,231,264,273,280,281,298,313,315,],[-182,-150,73,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,137,73,-100,-182,-173,-171,73,73,73,-115,73,-110,73,73,73,-108,-181,-182,73,-172,-116,-124,-137,-121,-138,-122,-119,-100,-173,-120,-123,-118,-139,282,73,-114,-125,73,73,73,73,]),'AND':([17,20,21,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,82,83,84,85,86,96,103,105,117,131,132,133,134,135,139,145,152,153,155,161,168,172,199,204,211,215,219,220,221,225,226,227,264,273,280,281,298,313,315,],[-182,-150,74,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,74,-100,-182,-173,-171,74,-113,74,-115,-109,-110,-111,74,74,-108,-181,-182,74,-172,-116,-124,-137,-121,-138,-122,-119,-100,-173,-120,-123,-118,-139,74,-114,-125,74,74,74,74,]),'OR':([17,20,21,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,82,83,84,85,86,96,103,105,117,131,132,133,134,135,139,145,152,153,155,161,168,172,199,204,211,215,219,220,221,225,226,227,264,273,280,281,298,313,315,],[-182,-150,75,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,75,-100,-182,-173,-171,75,-113,75,-115,-109,-110,-111,-112,75,-108,-181,-182,75,-172,-116,-124,-137,-121,-138,-122,-119,-100,-173,-120,-123,-118,-139,75,-114,-125,75,75,75,75,]),'?':([17,20,21,32,33,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,66,82,83,84,85,86,96,103,105,117,131,132,133,134,135,139,145,152,153,155,161,168,172,180,182,183,184,199,204,211,215,219,220,221,225,226,227,264,273,280,281,293,298,313,315,],[-182,-150,76,-173,-100,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-182,76,-100,-182,-173,-171,76,-113,76,-115,-109,-110,-111,-112,76,-108,-181,-182,76,-172,-116,-124,-137,241,243,244,-41,-121,-138,-122,-119,-100,-173,-120,-123,-118,-139,76,-114,-125,76,-42,76,76,76,]),'IS':([17,42,84,152,155,215,221,226,],[62,97,62,62,214,-119,-120,-118,]),')':([20,35,36,37,38,39,40,41,42,43,44,48,49,50,51,52,53,54,55,56,70,82,83,84,85,86,90,101,103,117,123,124,125,126,128,131,132,133,134,139,145,146,147,148,149,150,151,152,153,155,161,165,168,172,199,200,201,204,208,209,211,212,213,215,221,225,226,227,260,261,262,263,264,271,272,273,280,310,],[-150,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-141,-142,-143,-144,-145,-146,-147,-148,-149,-14,139,-100,-182,-173,-171,-14,-14,-113,-115,199,-158,-14,-159,-157,-109,-110,-111,-112,-108,-181,211,-164,-14,-165,-162,-163,-182,-117,-172,-116,225,-124,-137,-121,-14,-14,-138,269,-184,-122,-14,-14,-119,-120,-123,-118,-139,-160,-161,-156,-155,-140,-166,-167,-114,-125,-183,]),']':([20,35,36,37,38,39,40,41,42,43,44,48,49,50,51,52,53,54,55,56,57,71,83,84,85,86,102,103,104,105,106,117,124,125,126,128,130,131,132,133,134,139,145,152,153,155,158,161,162,166,167,168,169,171,172,196,199,200,201,204,211,215,221,225,226,227,228,229,232,245,256,257,260,261,262,263,264,273,280,281,301,314,315,321,340,341,342,343,344,355,358,],[-150,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-141,-142,-143,-144,-145,-146,-147,-148,-149,-170,-14,-100,-182,-173,-171,-14,-113,168,-117,-169,-115,-158,-14,-159,-157,204,-109,-110,-111,-112,-108,-181,-182,-117,-172,215,-116,221,226,227,-124,-14,-170,-137,255,-121,-14,-14,-138,-122,-119,-120,-123,-118,-139,280,-129,-168,293,302,303,-160,-161,-156,-155,-140,-114,-125,-14,335,-130,-14,-153,-127,-128,-126,354,-152,-153,-154,]),'ELSE':([20,21,25,26,27,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,83,84,85,86,103,117,131,132,133,134,139,145,153,155,156,157,159,160,161,168,172,199,204,211,215,216,217,218,219,220,221,225,226,227,264,273,278,280,309,338,],[-150,-20,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-100,-182,-173,-171,-113,-115,-109,-110,-111,-112,-108,-181,-117,-172,-23,-24,-26,-14,-116,-124,-137,-121,-138,-122,-119,276,-14,-22,-100,-173,-120,-123,-118,-139,-140,-114,-21,-125,-25,-79,]),'ELIF':([20,21,25,26,27,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,83,84,85,86,103,117,131,132,133,134,139,145,153,155,156,157,159,160,161,168,172,199,204,211,215,216,217,218,219,220,221,225,226,227,264,273,278,280,309,338,],[-150,-20,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-100,-182,-173,-171,-113,-115,-109,-110,-111,-112,-108,-181,-117,-172,-23,-24,-26,-14,-116,-124,-137,-121,-138,-122,-119,277,-14,-22,-100,-173,-120,-123,-118,-139,-140,-114,-21,-125,-25,-79,]),'END':([20,21,25,26,27,35,36,37,38,39,40,41,42,43,44,46,48,49,50,51,52,53,54,55,56,83,84,85,86,95,103,113,115,117,131,132,133,134,139,145,153,155,156,157,159,160,161,168,172,175,176,178,199,204,211,215,216,217,218,219,220,221,225,226,227,234,237,238,239,242,246,249,264,266,267,268,273,274,275,278,280,286,289,290,291,307,308,309,311,312,318,319,320,322,323,324,325,327,330,331,338,339,345,346,347,348,349,350,354,],[-150,-20,-17,-18,-19,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-171,-141,-142,-143,-144,-145,-146,-147,-148,-149,-100,-182,-173,-171,159,-113,177,177,-115,-109,-110,-111,-112,-108,-181,-117,-172,-23,-24,-26,-14,-116,-124,-137,235,236,-40,-121,-138,-122,-119,-14,-14,-22,-100,-173,-120,-123,-118,-139,285,-39,-14,-52,-62,177,177,-140,-14,-77,-14,-114,-27,-28,-21,-125,-48,-14,-14,-65,338,-78,-25,-14,-30,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-79,-29,-57,-58,-60,-61,-66,-67,-151,]),'}':([20,35,36,37,38,39,40,41,42,43,44,48,49,50,51,52,53,54,55,56,58,83,84,85,86,103,107,109,110,117,131,132,133,134,139,145,153,155,161,168,172,199,204,211,215,221,225,226,227,233,264,273,280,283,284,316,317,],[-150,-97,-98,-99,-101,-102,-103,-104,-105,-106,-107,-141,-142,-143,-144,-145,-146,-147,-148,-149,-14,-100,-182,-173,-171,-113,172,-136,-135,-115,-109,-110,-111,-112,-108,-181,-117,-172,-116,-124,-137,-121,-138,-122,-119,-120,-123,-118,-139,-14,-140,-114,-125,-14,-14,-133,-134,]),'DICT':([20,48,49,50,51,52,53,54,55,56,113,115,172,175,176,178,234,237,238,239,242,246,249,286,289,290,291,318,319,320,322,323,324,325,327,330,331,345,346,347,348,349,350,354,],[-150,-141,-142,-143,-144,-145,-146,-147,-148,-149,180,180,-137,180,180,-40,180,-39,-14,-52,-62,180,180,-48,-14,-14,-65,-49,-50,-51,-53,-54,-55,-56,-59,-63,-64,-57,-58,-60,-61,-66,-67,-151,]),'EXTENDS':([60,61,],[114,116,]),'DEFINED':([62,97,214,],[117,161,273,]),'AS':([66,88,99,100,145,],[-182,142,163,164,-181,]),'WHEN':([66,145,191,192,193,299,],[-182,-181,252,-68,-69,-70,]),'MATCHING':([66,145,222,],[-182,-181,279,]),'*':([70,71,90,101,102,129,201,213,],[129,129,129,129,129,203,129,129,]),'PARENTS':([118,253,],[193,193,]),'REL':([120,198,255,302,303,335,],[195,258,-88,-89,-91,-90,]),'UNDEF':([287,288,],[320,324,]),}
 
 _lr_action = {}
 for _k, _v in _lr_action_items.items():
    for _x,_y in zip(_v[0],_v[1]):
       if not _x in _lr_action:  _lr_action[_x] = {}
       _lr_action[_x][_k] = _y
 del _lr_action_items
 
-_lr_goto_items = {'main':([0,],[1,]),'head':([0,],[2,]),'empty':([0,2,6,22,25,29,33,34,43,47,58,59,65,68,71,72,88,90,91,96,110,111,114,135,159,164,171,180,183,192,200,203,210,212,213,225,226,229,230,232,233,246,251,279,281,294,296,297,302,303,311,324,328,],[3,7,7,73,83,84,95,100,104,109,116,119,95,109,136,136,100,95,109,160,160,136,181,212,225,181,231,242,116,253,95,263,116,136,136,160,160,288,231,100,95,297,299,231,231,242,119,119,338,340,345,231,355,]),'body':([2,6,],[5,60,]),'top_stmt':([2,6,],[6,6,]),'entity_def':([2,6,],[8,8,]),'implement_def':([2,6,],[9,9,]),'implementation_def':([2,6,],[10,10,]),'relation':([2,6,],[11,11,]),'statement':([2,6,171,230,279,281,324,],[12,12,230,230,230,230,230,]),'typedef':([2,6,],[13,13,]),'index':([2,6,],[14,14,]),'import':([2,6,],[15,15,]),'class_ref':([2,6,19,30,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,124,126,145,147,148,171,175,183,185,210,214,215,218,226,230,243,260,261,265,267,271,272,279,281,290,292,295,324,],[20,20,64,86,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,198,198,92,219,92,92,237,92,92,92,92,92,92,92,92,92,198,198,92,313,317,318,92,92,92,92,92,92,]),'expression':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[22,22,87,103,112,114,141,142,143,144,146,164,164,164,164,164,164,164,217,164,22,164,164,164,164,164,277,164,22,294,311,22,22,103,326,328,22,]),'relation_def':([2,6,],[25,25,]),'assign':([2,6,171,230,279,281,324,],[26,26,26,26,26,26,26,]),'for':([2,6,171,230,279,281,324,],[27,27,27,27,27,27,27,]),'if':([2,6,171,230,279,281,324,],[28,28,28,28,28,28,28,]),'typedef_inner':([2,6,],[29,29,]),'ns_ref':([2,6,19,30,31,32,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,123,124,125,126,128,145,147,148,171,174,175,183,185,187,188,210,214,215,218,226,230,243,247,259,260,261,262,265,266,267,271,272,279,281,290,292,295,324,],[33,33,65,65,90,93,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,196,200,196,200,204,90,65,90,233,235,65,90,90,196,196,90,90,90,90,90,233,90,196,196,200,200,196,90,204,65,65,65,233,233,90,90,90,233,]),'var_ref':([2,6,19,30,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,124,126,145,147,148,171,175,183,185,210,214,215,218,226,230,243,260,261,265,267,271,272,279,281,290,292,295,324,],[34,34,66,66,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,199,199,88,66,88,232,66,88,88,88,88,88,88,88,232,88,199,199,88,66,66,66,232,232,88,88,88,232,]),'boolean_expression':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,]),'constant':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,300,301,324,334,368,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,331,335,37,357,357,]),'function_call':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,]),'constructor':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,175,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,236,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,]),'list_def':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'list_comprehension':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,]),'map_def':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,305,324,339,341,342,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,343,42,358,360,362,]),'map_lookup':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,]),'index_lookup':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'conditional_expression':([2,6,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,145,148,171,183,185,210,214,215,218,226,230,243,265,279,281,290,292,295,324,],[45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,]),'attr_ref':([2,6,19,30,31,35,48,58,74,75,76,77,79,96,98,99,101,106,110,111,124,126,145,147,148,171,175,183,185,210,214,215,218,226,230,243,260,261,265,267,271,272,279,281,290,292,295,324,],[47,47,68,68,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,68,68,91,68,91,47,68,91,91,91,91,91,91,91,47,91,68,68,91,68,68,68,47,47,91,91,91,47,]),'if_body':([35,290,],[102,325,]),'operand_list':([58,183,210,],[113,245,272,]),'operand':([58,96,98,99,101,106,110,111,148,183,185,210,214,215,226,],[115,162,167,168,169,173,162,177,220,115,246,115,275,276,162,]),'pair_list':([59,296,],[117,329,]),'dict_key':([59,296,],[118,118,]),'pair_list_empty':([59,296,297,],[120,120,330,]),'multi':([69,132,207,365,366,],[130,210,267,369,370,]),'param_list':([71,72,111,213,],[133,140,178,274,]),'param_list_empty':([71,72,111,212,213,],[134,134,134,273,134,]),'param_list_element':([71,72,96,110,111,213,226,],[135,135,161,161,135,135,161,]),'wrapped_kwargs':([71,72,96,110,111,213,226,],[138,138,138,138,138,138,138,]),'function_param_list':([96,110,226,],[157,176,285,]),'function_param_list_empty':([96,110,225,226,],[158,158,284,158,]),'function_param_list_element':([96,110,226,],[159,159,159,]),'list_comprehension_for':([114,328,],[180,354,]),'entity_body_outer':([123,125,259,262,],[186,201,307,310,]),'entity_body':([123,125,187,259,262,],[188,188,247,188,188,]),'attr':([123,125,187,188,247,259,262,],[190,190,190,250,250,190,190,]),'attr_type':([123,125,187,188,247,259,262,],[191,191,191,191,191,191,191,]),'attr_type_opt':([123,125,187,188,247,259,262,],[193,193,193,193,193,193,193,]),'attr_type_multi':([123,125,187,188,247,259,262,],[194,194,194,194,194,194,194,]),'attr_base_type':([123,125,187,188,247,259,262,],[195,195,195,195,195,195,195,]),'class_ref_list':([124,126,260,261,],[197,202,308,309,]),'implement_ns_list':([128,266,],[203,312,]),'id_list':([149,283,],[221,323,]),'stmt_list':([171,230,279,281,324,],[229,291,320,320,352,]),'list_comprehension_guard':([180,294,],[241,327,]),'implementation':([219,],[278,]),'implementation_head':([219,],[279,]),'if_next':([229,],[287,]),'block':([279,281,],[319,322,]),'constant_list':([300,301,],[332,336,]),'list_comprehension_for_empty':([328,],[353,]),'constants':([334,368,],[356,371,]),}
+_lr_goto_items = {'main':([0,],[1,]),'head':([0,],[2,]),'body':([2,5,],[4,59,]),'top_stmt':([2,5,],[5,5,]),'empty':([2,5,58,70,71,90,101,102,125,148,160,169,180,191,200,201,212,213,216,217,233,238,266,268,281,283,284,289,290,298,311,315,],[6,6,109,126,126,149,149,126,200,212,218,229,240,250,126,126,149,149,275,218,284,286,218,218,229,109,109,325,327,332,218,342,]),'entity_def':([2,5,],[7,7,]),'implement_def':([2,5,],[8,8,]),'implementation_def':([2,5,],[9,9,]),'relation':([2,5,],[10,10,]),'statement':([2,5,160,217,266,268,311,],[11,11,217,217,217,217,217,]),'typedef':([2,5,],[12,12,]),'index':([2,5,],[13,13,]),'import':([2,5,],[14,14,]),'class_ref':([2,5,18,29,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,114,116,136,137,160,164,171,173,198,202,203,205,213,217,230,247,248,252,254,258,259,266,268,277,279,282,311,],[19,19,63,81,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,186,186,206,87,87,224,87,87,87,87,87,87,87,87,87,186,186,87,300,304,305,87,87,87,87,87,87,]),'expression':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[21,21,82,96,103,105,131,132,133,134,135,153,153,153,153,153,153,153,153,21,153,153,153,153,153,264,153,21,281,298,21,21,96,313,315,21,]),'relation_def':([2,5,],[24,24,]),'assign':([2,5,160,217,266,268,311,],[25,25,25,25,25,25,25,]),'for':([2,5,160,217,266,268,311,],[26,26,26,26,26,26,26,]),'if':([2,5,160,217,266,268,311,],[27,27,27,27,27,27,27,]),'typedef_inner':([2,5,],[28,28,]),'ns_ref':([2,5,18,29,30,31,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,113,114,115,116,118,136,137,160,163,164,171,173,175,176,198,202,203,205,213,217,230,234,246,247,248,249,252,253,254,258,259,266,268,277,279,282,311,],[32,32,64,64,85,88,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,184,188,184,188,192,64,85,220,222,64,85,85,184,184,85,85,85,85,85,220,85,184,184,188,188,184,85,192,64,64,64,220,220,85,85,85,220,]),'var_ref':([2,5,18,29,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,114,116,136,137,160,164,171,173,198,202,203,205,213,217,230,247,248,252,254,258,259,266,268,277,279,282,311,],[33,33,65,65,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,187,187,65,83,219,65,83,83,83,83,83,83,83,219,83,187,187,83,65,65,65,219,219,83,83,83,219,]),'boolean_expression':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,]),'constant':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,287,288,311,321,355,],[36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,318,322,36,344,344,]),'function_call':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,]),'constructor':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,164,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,223,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,]),'list_def':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,]),'list_comprehension':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,]),'map_def':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,292,311,326,328,329,],[41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,330,41,345,347,349,]),'map_lookup':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,]),'index_lookup':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,]),'conditional_expression':([2,5,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,137,160,171,173,198,202,203,205,213,217,230,252,266,268,277,279,282,311,],[44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,]),'attr_ref':([2,5,18,29,30,34,47,57,72,73,74,75,76,90,92,93,94,98,101,102,114,116,136,137,160,164,171,173,198,202,203,205,213,217,230,247,248,252,254,258,259,266,268,277,279,282,311,],[46,46,67,67,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,67,67,67,86,46,67,86,86,86,86,86,86,86,46,86,67,67,86,67,67,67,46,46,86,86,86,46,]),'if_body':([34,277,],[95,312,]),'operand_list':([57,171,198,],[104,232,259,]),'operand':([57,90,92,93,94,98,101,102,137,171,173,198,202,203,213,],[106,151,156,157,158,162,151,166,207,106,233,106,262,263,151,]),'pair_list':([58,283,],[107,316,]),'dict_key':([58,283,],[108,108,]),'pair_list_empty':([58,283,284,],[110,110,317,]),'multi':([68,122,195,352,353,],[120,198,254,356,357,]),'param_list':([70,71,102,201,],[123,130,167,261,]),'param_list_empty':([70,71,102,200,201,],[124,124,124,260,124,]),'param_list_element':([70,71,90,101,102,201,213,],[125,125,150,150,125,125,150,]),'wrapped_kwargs':([70,71,90,101,102,201,213,],[128,128,128,128,128,128,128,]),'function_param_list':([90,101,213,],[146,165,272,]),'function_param_list_empty':([90,101,212,213,],[147,147,271,147,]),'function_param_list_element':([90,101,213,],[148,148,148,]),'list_comprehension_for':([105,315,],[169,341,]),'entity_body_outer':([113,115,246,249,],[174,189,294,297,]),'entity_body':([113,115,175,246,249,],[176,176,234,176,176,]),'attr':([113,115,175,176,234,246,249,],[178,178,178,237,237,178,178,]),'attr_type':([113,115,175,176,234,246,249,],[179,179,179,179,179,179,179,]),'attr_type_opt':([113,115,175,176,234,246,249,],[181,181,181,181,181,181,181,]),'attr_type_multi':([113,115,175,176,234,246,249,],[182,182,182,182,182,182,182,]),'attr_base_type':([113,115,175,176,234,246,249,],[183,183,183,183,183,183,183,]),'class_ref_list':([114,116,247,248,],[185,190,295,296,]),'implement_ns_list':([118,253,],[191,299,]),'id_list':([138,270,],[208,310,]),'stmt_list':([160,217,266,268,311,],[216,278,307,307,339,]),'list_comprehension_guard':([169,281,],[228,314,]),'implementation':([206,],[265,]),'implementation_head':([206,],[266,]),'if_next':([216,],[274,]),'block':([266,268,],[306,309,]),'constant_list':([287,288,],[319,323,]),'list_comprehension_for_empty':([315,],[340,]),'constants':([321,355,],[343,358,]),}
 
 _lr_goto = {}
 for _k, _v in _lr_goto_items.items():
    for _x, _y in zip(_v[0], _v[1]):
        if not _x in _lr_goto: _lr_goto[_x] = {}
        _lr_goto[_x][_k] = _y
 del _lr_goto_items
 _lr_productions = [
   ("S' -> main","S'",1,None,None,None),
-  ('main -> head body','main',2,'p_main','plyInmantaParser.py',130),
-  ('empty -> <empty>','empty',0,'p_empty','plyInmantaParser.py',141),
-  ('head -> empty','head',1,'p_main_head','plyInmantaParser.py',145),
-  ('head -> MLS','head',1,'p_main_head_doc','plyInmantaParser.py',150),
-  ('body -> top_stmt body','body',2,'p_body_collect','plyInmantaParser.py',155),
-  ('body -> empty','body',1,'p_body_term','plyInmantaParser.py',162),
-  ('top_stmt -> entity_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',167),
-  ('top_stmt -> implement_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',168),
-  ('top_stmt -> implementation_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',169),
-  ('top_stmt -> relation','top_stmt',1,'p_top_stmt','plyInmantaParser.py',170),
-  ('top_stmt -> statement','top_stmt',1,'p_top_stmt','plyInmantaParser.py',171),
-  ('top_stmt -> typedef','top_stmt',1,'p_top_stmt','plyInmantaParser.py',172),
-  ('top_stmt -> index','top_stmt',1,'p_top_stmt','plyInmantaParser.py',173),
-  ('top_stmt -> import','top_stmt',1,'p_top_stmt','plyInmantaParser.py',174),
-  ('import -> IMPORT ns_ref','import',2,'p_import','plyInmantaParser.py',184),
-  ('import -> IMPORT ns_ref AS ID','import',4,'p_import_1','plyInmantaParser.py',190),
-  ('statement -> assign','statement',1,'p_stmt','plyInmantaParser.py',201),
-  ('statement -> for','statement',1,'p_stmt','plyInmantaParser.py',202),
-  ('statement -> if','statement',1,'p_stmt','plyInmantaParser.py',203),
-  ('statement -> expression empty','statement',2,'p_stmt','plyInmantaParser.py',204),
-  ('stmt_list -> statement stmt_list','stmt_list',2,'p_stmt_list_collect','plyInmantaParser.py',218),
-  ('stmt_list -> empty','stmt_list',1,'p_stmt_list_empty','plyInmantaParser.py',225),
-  ('assign -> var_ref = operand','assign',3,'p_assign','plyInmantaParser.py',230),
-  ('assign -> var_ref PEQ operand','assign',3,'p_assign_extend','plyInmantaParser.py',236),
-  ('for -> FOR ID IN operand : block','for',6,'p_for','plyInmantaParser.py',242),
-  ('if -> IF if_body END','if',3,'p_if_start','plyInmantaParser.py',249),
-  ('if_body -> expression : stmt_list if_next','if_body',4,'p_if_body','plyInmantaParser.py',255),
-  ('if_next -> empty','if_next',1,'p_if_end','plyInmantaParser.py',262),
-  ('if_next -> ELSE : stmt_list','if_next',3,'p_if_else','plyInmantaParser.py',268),
-  ('if_next -> ELIF if_body','if_next',2,'p_if_elif','plyInmantaParser.py',274),
-  ('entity_def -> ENTITY CID : entity_body_outer','entity_def',4,'p_entity','plyInmantaParser.py',286),
-  ('entity_def -> ENTITY ID : entity_body_outer','entity_def',4,'p_entity_err_1','plyInmantaParser.py',293),
-  ('entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer','entity_def',6,'p_entity_extends','plyInmantaParser.py',298),
-  ('entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer','entity_def',6,'p_entity_extends_err','plyInmantaParser.py',305),
-  ('entity_body_outer -> MLS entity_body END','entity_body_outer',3,'p_entity_body_outer','plyInmantaParser.py',310),
-  ('entity_body_outer -> entity_body END','entity_body_outer',2,'p_entity_body_outer_1','plyInmantaParser.py',315),
-  ('entity_body_outer -> END','entity_body_outer',1,'p_entity_body_outer_none','plyInmantaParser.py',320),
-  ('entity_body_outer -> MLS END','entity_body_outer',2,'p_entity_body_outer_4','plyInmantaParser.py',325),
-  ('entity_body -> entity_body attr','entity_body',2,'p_entity_body_collect','plyInmantaParser.py',330),
-  ('entity_body -> attr','entity_body',1,'p_entity_body','plyInmantaParser.py',336),
-  ('attr_base_type -> ns_ref','attr_base_type',1,'p_attribute_base_type','plyInmantaParser.py',341),
-  ('attr_type_multi -> attr_base_type [ ]','attr_type_multi',3,'p_attribute_type_multi','plyInmantaParser.py',347),
-  ('attr_type_opt -> attr_type_multi ?','attr_type_opt',2,'p_attribute_type_opt','plyInmantaParser.py',353),
-  ('attr_type_opt -> attr_base_type ?','attr_type_opt',2,'p_attribute_type_opt','plyInmantaParser.py',354),
-  ('attr_type -> attr_type_opt','attr_type',1,'p_attribute_type','plyInmantaParser.py',360),
-  ('attr_type -> attr_type_multi','attr_type',1,'p_attribute_type','plyInmantaParser.py',361),
-  ('attr_type -> attr_base_type','attr_type',1,'p_attribute_type','plyInmantaParser.py',362),
-  ('attr -> attr_type CID empty','attr',3,'p_attr_err','plyInmantaParser.py',367),
-  ('attr -> attr_type CID = constant','attr',4,'p_attr_err','plyInmantaParser.py',368),
-  ('attr -> attr_type CID = constant_list','attr',4,'p_attr_err','plyInmantaParser.py',369),
-  ('attr -> attr_type CID = UNDEF','attr',4,'p_attr_err','plyInmantaParser.py',370),
-  ('attr -> attr_type ID','attr',2,'p_attr','plyInmantaParser.py',377),
-  ('attr -> attr_type ID = constant','attr',4,'p_attr_cte','plyInmantaParser.py',383),
-  ('attr -> attr_type ID = constant_list','attr',4,'p_attr_cte','plyInmantaParser.py',384),
-  ('attr -> attr_type ID = UNDEF','attr',4,'p_attr_undef','plyInmantaParser.py',390),
-  ('attr -> DICT empty CID empty','attr',4,'p_attr_dict_err','plyInmantaParser.py',396),
-  ('attr -> DICT empty CID = map_def','attr',5,'p_attr_dict_err','plyInmantaParser.py',397),
-  ('attr -> DICT empty CID = NULL','attr',5,'p_attr_dict_err','plyInmantaParser.py',398),
-  ('attr -> DICT ? CID empty','attr',4,'p_attr_dict_err','plyInmantaParser.py',399),
-  ('attr -> DICT ? CID = map_def','attr',5,'p_attr_dict_err','plyInmantaParser.py',400),
-  ('attr -> DICT ? CID = NULL','attr',5,'p_attr_dict_err','plyInmantaParser.py',401),
-  ('attr -> DICT ID','attr',2,'p_attr_dict','plyInmantaParser.py',408),
-  ('attr -> DICT ID = map_def','attr',4,'p_attr_list_dict','plyInmantaParser.py',414),
-  ('attr -> DICT ID = NULL','attr',4,'p_attr_list_dict_null_err','plyInmantaParser.py',420),
-  ('attr -> DICT ? ID','attr',3,'p_attr_dict_nullable','plyInmantaParser.py',425),
-  ('attr -> DICT ? ID = map_def','attr',5,'p_attr_list_dict_nullable','plyInmantaParser.py',431),
-  ('attr -> DICT ? ID = NULL','attr',5,'p_attr_list_dict_null','plyInmantaParser.py',437),
-  ('implement_ns_list -> ns_ref','implement_ns_list',1,'p_implement_ns_list_ref','plyInmantaParser.py',444),
-  ('implement_ns_list -> PARENTS','implement_ns_list',1,'p_implement_ns_list_parents','plyInmantaParser.py',449),
-  ('implement_ns_list -> implement_ns_list , implement_ns_list','implement_ns_list',3,'p_implement_ns_list_collect','plyInmantaParser.py',454),
-  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list empty','implement_def',5,'p_implement','plyInmantaParser.py',459),
-  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS','implement_def',5,'p_implement','plyInmantaParser.py',460),
-  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty','implement_def',7,'p_implement_when','plyInmantaParser.py',469),
-  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS','implement_def',7,'p_implement_when','plyInmantaParser.py',470),
-  ('implementation_def -> IMPLEMENTATION ID FOR class_ref implementation','implementation_def',5,'p_implementation_def','plyInmantaParser.py',480),
-  ('implementation -> implementation_head block','implementation',2,'p_implementation','plyInmantaParser.py',493),
-  ('implementation_head -> :','implementation_head',1,'p_implementation_head','plyInmantaParser.py',498),
-  ('implementation_head -> : MLS','implementation_head',2,'p_implementation_head_doc','plyInmantaParser.py',503),
-  ('block -> stmt_list END','block',2,'p_block','plyInmantaParser.py',508),
-  ('relation -> class_ref ID multi REL multi class_ref ID','relation',7,'p_relation_deprecated','plyInmantaParser.py',514),
-  ('relation -> class_ref ID multi REL multi class_ref ID MLS','relation',8,'p_relation_deprecated_comment','plyInmantaParser.py',525),
-  ('relation -> relation_def MLS','relation',2,'p_relation_outer_comment','plyInmantaParser.py',564),
-  ('relation -> relation_def empty','relation',2,'p_relation_outer','plyInmantaParser.py',571),
-  ('relation_def -> class_ref . ID multi REL class_ref . ID multi','relation_def',9,'p_relation','plyInmantaParser.py',576),
-  ('relation_def -> class_ref . ID multi REL class_ref','relation_def',6,'p_relation_unidir','plyInmantaParser.py',582),
-  ('relation_def -> class_ref . ID multi operand_list class_ref . ID multi','relation_def',9,'p_relation_annotated','plyInmantaParser.py',588),
-  ('relation_def -> class_ref . ID multi operand_list class_ref','relation_def',6,'p_relation_annotated_unidir','plyInmantaParser.py',594),
-  ('multi -> [ INT ]','multi',3,'p_multi_1','plyInmantaParser.py',600),
-  ('multi -> [ INT : ]','multi',4,'p_multi_2','plyInmantaParser.py',605),
-  ('multi -> [ INT : INT ]','multi',5,'p_multi_3','plyInmantaParser.py',610),
-  ('multi -> [ : INT ]','multi',4,'p_multi_4','plyInmantaParser.py',615),
-  ('typedef -> typedef_inner empty','typedef',2,'p_typedef_outer','plyInmantaParser.py',623),
-  ('typedef -> typedef_inner MLS','typedef',2,'p_typedef_outer_comment','plyInmantaParser.py',628),
-  ('typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression','typedef_inner',6,'p_typedef_1','plyInmantaParser.py',635),
-  ('typedef_inner -> TYPEDEF CID AS constructor','typedef_inner',4,'p_typedef_cls','plyInmantaParser.py',642),
-  ('index -> INDEX class_ref ( id_list )','index',5,'p_index','plyInmantaParser.py',650),
-  ('expression -> boolean_expression','expression',1,'p_expression','plyInmantaParser.py',660),
-  ('expression -> constant','expression',1,'p_expression','plyInmantaParser.py',661),
-  ('expression -> function_call','expression',1,'p_expression','plyInmantaParser.py',662),
-  ('expression -> var_ref empty','expression',2,'p_expression','plyInmantaParser.py',663),
-  ('expression -> constructor','expression',1,'p_expression','plyInmantaParser.py',664),
-  ('expression -> list_def','expression',1,'p_expression','plyInmantaParser.py',665),
-  ('expression -> list_comprehension','expression',1,'p_expression','plyInmantaParser.py',666),
-  ('expression -> map_def','expression',1,'p_expression','plyInmantaParser.py',667),
-  ('expression -> map_lookup empty','expression',2,'p_expression','plyInmantaParser.py',668),
-  ('expression -> index_lookup','expression',1,'p_expression','plyInmantaParser.py',669),
-  ('expression -> conditional_expression','expression',1,'p_expression','plyInmantaParser.py',670),
-  ('expression -> ( expression )','expression',3,'p_expression_parentheses','plyInmantaParser.py',675),
-  ('boolean_expression -> expression CMP_OP expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',680),
-  ('boolean_expression -> expression IN expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',681),
-  ('boolean_expression -> expression AND expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',682),
-  ('boolean_expression -> expression OR expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',683),
-  ('boolean_expression -> expression NOT IN expression','boolean_expression',4,'p_boolean_expression_not_in','plyInmantaParser.py',692),
-  ('boolean_expression -> NOT expression','boolean_expression',2,'p_boolean_expression_not','plyInmantaParser.py',698),
-  ('boolean_expression -> var_ref . ID IS DEFINED','boolean_expression',5,'p_boolean_expression_is_defined','plyInmantaParser.py',704),
-  ('boolean_expression -> ID IS DEFINED','boolean_expression',3,'p_boolean_expression_is_defined_short','plyInmantaParser.py',710),
-  ('boolean_expression -> map_lookup IS DEFINED','boolean_expression',3,'p_boolean_expression_is_defined_map_lookup','plyInmantaParser.py',716),
-  ('operand -> expression empty','operand',2,'p_operand','plyInmantaParser.py',736),
-  ('map_lookup -> attr_ref [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',741),
-  ('map_lookup -> var_ref [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',742),
-  ('map_lookup -> map_lookup [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',743),
-  ('constructor -> class_ref ( param_list )','constructor',4,'p_constructor','plyInmantaParser.py',748),
-  ('function_call -> ns_ref ( function_param_list )','function_call',4,'p_function_call','plyInmantaParser.py',754),
-  ('function_call -> attr_ref ( function_param_list )','function_call',4,'p_function_call_err_dot','plyInmantaParser.py',761),
-  ('list_def -> [ operand_list ]','list_def',3,'p_list_def','plyInmantaParser.py',766),
-  ('list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ]','list_comprehension',5,'p_list_comprehension','plyInmantaParser.py',779),
-  ('list_comprehension_for_empty -> empty','list_comprehension_for_empty',1,'p_list_comprehension_for_empty','plyInmantaParser.py',804),
-  ('list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty','list_comprehension_for',5,'p_list_comprehension_for','plyInmantaParser.py',809),
-  ('list_comprehension_for -> FOR ID IN expression list_comprehension_for','list_comprehension_for',5,'p_list_comprehension_for','plyInmantaParser.py',810),
-  ('list_comprehension_guard -> empty','list_comprehension_guard',1,'p_list_comprehension_guard_empty','plyInmantaParser.py',817),
-  ('list_comprehension_guard -> IF expression list_comprehension_guard','list_comprehension_guard',3,'p_list_comprehension_guard','plyInmantaParser.py',822),
-  ('dict_key -> RSTRING','dict_key',1,'p_r_string_dict_key','plyInmantaParser.py',832),
-  ('dict_key -> STRING','dict_key',1,'p_string_dict_key','plyInmantaParser.py',837),
-  ('pair_list -> dict_key : operand , pair_list','pair_list',5,'p_pair_list_collect','plyInmantaParser.py',852),
-  ('pair_list -> dict_key : operand empty pair_list_empty','pair_list',5,'p_pair_list_collect','plyInmantaParser.py',853),
-  ('pair_list -> pair_list_empty','pair_list',1,'p_pair_list_empty','plyInmantaParser.py',862),
-  ('pair_list_empty -> empty','pair_list_empty',1,'p_pair_list_empty','plyInmantaParser.py',863),
-  ('map_def -> { pair_list }','map_def',3,'p_map_def','plyInmantaParser.py',868),
-  ('index_lookup -> class_ref [ param_list ]','index_lookup',4,'p_index_lookup','plyInmantaParser.py',874),
-  ('index_lookup -> attr_ref [ param_list ]','index_lookup',4,'p_short_index_lookup','plyInmantaParser.py',880),
-  ('conditional_expression -> expression ? expression : expression','conditional_expression',5,'p_conditional_expression','plyInmantaParser.py',887),
-  ('constant -> INT','constant',1,'p_constant','plyInmantaParser.py',897),
-  ('constant -> FLOAT','constant',1,'p_constant','plyInmantaParser.py',898),
-  ('constant -> NULL','constant',1,'p_constant_none','plyInmantaParser.py',905),
-  ('constant -> REGEX','constant',1,'p_constant_regex','plyInmantaParser.py',911),
-  ('constant -> TRUE','constant',1,'p_constant_true','plyInmantaParser.py',917),
-  ('constant -> FALSE','constant',1,'p_constant_false','plyInmantaParser.py',923),
-  ('constant -> STRING','constant',1,'p_constant_string','plyInmantaParser.py',929),
-  ('constant -> FSTRING','constant',1,'p_constant_fstring','plyInmantaParser.py',935),
-  ('constant -> RSTRING','constant',1,'p_constant_rstring','plyInmantaParser.py',998),
-  ('constant -> MLS','constant',1,'p_constant_mls','plyInmantaParser.py',1004),
-  ('constant_list -> [ constants ]','constant_list',3,'p_constant_list','plyInmantaParser.py',1116),
-  ('constants -> constant','constants',1,'p_constants_term','plyInmantaParser.py',1122),
-  ('constants -> <empty>','constants',0,'p_constants_term_2','plyInmantaParser.py',1127),
-  ('constants -> constant , constants','constants',3,'p_constants_collect','plyInmantaParser.py',1132),
-  ('wrapped_kwargs -> * * operand','wrapped_kwargs',3,'p_wrapped_kwargs','plyInmantaParser.py',1138),
-  ('param_list_element -> ID = operand','param_list_element',3,'p_param_list_element_explicit','plyInmantaParser.py',1144),
-  ('param_list_element -> wrapped_kwargs','param_list_element',1,'p_param_list_element_kwargs','plyInmantaParser.py',1150),
-  ('param_list -> param_list_empty','param_list',1,'p_param_list_empty','plyInmantaParser.py',1156),
-  ('param_list_empty -> empty','param_list_empty',1,'p_param_list_empty','plyInmantaParser.py',1157),
-  ('param_list -> param_list_element empty param_list_empty','param_list',3,'p_param_list_nonempty','plyInmantaParser.py',1163),
-  ('param_list -> param_list_element , param_list','param_list',3,'p_param_list_nonempty','plyInmantaParser.py',1164),
-  ('function_param_list_element -> param_list_element','function_param_list_element',1,'p_function_param_list_element','plyInmantaParser.py',1179),
-  ('function_param_list_element -> operand','function_param_list_element',1,'p_function_param_list_element_arg','plyInmantaParser.py',1186),
-  ('function_param_list -> function_param_list_empty','function_param_list',1,'p_function_param_list_empty','plyInmantaParser.py',1192),
-  ('function_param_list_empty -> empty','function_param_list_empty',1,'p_function_param_list_empty','plyInmantaParser.py',1193),
-  ('function_param_list -> function_param_list_element empty function_param_list_empty','function_param_list',3,'p_function_param_list_nonempty','plyInmantaParser.py',1199),
-  ('function_param_list -> function_param_list_element , function_param_list','function_param_list',3,'p_function_param_list_nonempty','plyInmantaParser.py',1200),
-  ('operand_list -> operand , operand_list','operand_list',3,'p_operand_list_collect','plyInmantaParser.py',1218),
-  ('operand_list -> operand','operand_list',1,'p_operand_list_term','plyInmantaParser.py',1224),
-  ('operand_list -> empty','operand_list',1,'p_operand_list_term_2','plyInmantaParser.py',1229),
-  ('var_ref -> attr_ref empty','var_ref',2,'p_var_ref','plyInmantaParser.py',1234),
-  ('attr_ref -> var_ref . ID','attr_ref',3,'p_attr_ref','plyInmantaParser.py',1239),
-  ('var_ref -> ns_ref empty','var_ref',2,'p_var_ref_2','plyInmantaParser.py',1245),
-  ('class_ref -> CID','class_ref',1,'p_class_ref_direct','plyInmantaParser.py',1251),
-  ('class_ref -> ns_ref SEP CID','class_ref',3,'p_class_ref','plyInmantaParser.py',1262),
-  ('class_ref -> var_ref . CID','class_ref',3,'p_class_ref_err_dot','plyInmantaParser.py',1268),
-  ('class_ref_list -> class_ref , class_ref_list','class_ref_list',3,'p_class_ref_list_collect','plyInmantaParser.py',1283),
-  ('class_ref_list -> var_ref , class_ref_list','class_ref_list',3,'p_class_ref_list_collect_err','plyInmantaParser.py',1289),
-  ('class_ref_list -> class_ref','class_ref_list',1,'p_class_ref_list_term','plyInmantaParser.py',1294),
-  ('class_ref_list -> var_ref','class_ref_list',1,'p_class_ref_list_term_err','plyInmantaParser.py',1299),
-  ('ns_ref -> ns_ref SEP ID','ns_ref',3,'p_ns_ref','plyInmantaParser.py',1305),
-  ('ns_ref -> ID','ns_ref',1,'p_ns_ref_term','plyInmantaParser.py',1311),
-  ('id_list -> ID , id_list','id_list',3,'p_id_list_collect','plyInmantaParser.py',1316),
-  ('id_list -> ID','id_list',1,'p_id_list_term','plyInmantaParser.py',1322),
+  ('main -> head body','main',2,'p_main','plyInmantaParser.py',127),
+  ('head -> <empty>','head',0,'p_main_head','plyInmantaParser.py',135),
+  ('head -> MLS','head',1,'p_main_head_doc','plyInmantaParser.py',140),
+  ('body -> top_stmt body','body',2,'p_body_collect','plyInmantaParser.py',145),
+  ('body -> empty','body',1,'p_body_term','plyInmantaParser.py',152),
+  ('top_stmt -> entity_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',157),
+  ('top_stmt -> implement_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',158),
+  ('top_stmt -> implementation_def','top_stmt',1,'p_top_stmt','plyInmantaParser.py',159),
+  ('top_stmt -> relation','top_stmt',1,'p_top_stmt','plyInmantaParser.py',160),
+  ('top_stmt -> statement','top_stmt',1,'p_top_stmt','plyInmantaParser.py',161),
+  ('top_stmt -> typedef','top_stmt',1,'p_top_stmt','plyInmantaParser.py',162),
+  ('top_stmt -> index','top_stmt',1,'p_top_stmt','plyInmantaParser.py',163),
+  ('top_stmt -> import','top_stmt',1,'p_top_stmt','plyInmantaParser.py',164),
+  ('empty -> <empty>','empty',0,'p_empty','plyInmantaParser.py',169),
+  ('import -> IMPORT ns_ref','import',2,'p_import','plyInmantaParser.py',179),
+  ('import -> IMPORT ns_ref AS ID','import',4,'p_import_1','plyInmantaParser.py',185),
+  ('statement -> assign','statement',1,'p_stmt','plyInmantaParser.py',196),
+  ('statement -> for','statement',1,'p_stmt','plyInmantaParser.py',197),
+  ('statement -> if','statement',1,'p_stmt','plyInmantaParser.py',198),
+  ('statement -> expression','statement',1,'p_stmt','plyInmantaParser.py',199),
+  ('stmt_list -> statement stmt_list','stmt_list',2,'p_stmt_list_collect','plyInmantaParser.py',213),
+  ('stmt_list -> empty','stmt_list',1,'p_stmt_list_empty','plyInmantaParser.py',220),
+  ('assign -> var_ref = operand','assign',3,'p_assign','plyInmantaParser.py',225),
+  ('assign -> var_ref PEQ operand','assign',3,'p_assign_extend','plyInmantaParser.py',231),
+  ('for -> FOR ID IN operand : block','for',6,'p_for','plyInmantaParser.py',237),
+  ('if -> IF if_body END','if',3,'p_if_start','plyInmantaParser.py',244),
+  ('if_body -> expression : stmt_list if_next','if_body',4,'p_if_body','plyInmantaParser.py',250),
+  ('if_next -> empty','if_next',1,'p_if_end','plyInmantaParser.py',257),
+  ('if_next -> ELSE : stmt_list','if_next',3,'p_if_else','plyInmantaParser.py',263),
+  ('if_next -> ELIF if_body','if_next',2,'p_if_elif','plyInmantaParser.py',269),
+  ('entity_def -> ENTITY CID : entity_body_outer','entity_def',4,'p_entity','plyInmantaParser.py',281),
+  ('entity_def -> ENTITY ID : entity_body_outer','entity_def',4,'p_entity_err_1','plyInmantaParser.py',288),
+  ('entity_def -> ENTITY CID EXTENDS class_ref_list : entity_body_outer','entity_def',6,'p_entity_extends','plyInmantaParser.py',293),
+  ('entity_def -> ENTITY ID EXTENDS class_ref_list : entity_body_outer','entity_def',6,'p_entity_extends_err','plyInmantaParser.py',300),
+  ('entity_body_outer -> MLS entity_body END','entity_body_outer',3,'p_entity_body_outer','plyInmantaParser.py',305),
+  ('entity_body_outer -> entity_body END','entity_body_outer',2,'p_entity_body_outer_1','plyInmantaParser.py',310),
+  ('entity_body_outer -> END','entity_body_outer',1,'p_entity_body_outer_none','plyInmantaParser.py',315),
+  ('entity_body_outer -> MLS END','entity_body_outer',2,'p_entity_body_outer_4','plyInmantaParser.py',320),
+  ('entity_body -> entity_body attr','entity_body',2,'p_entity_body_collect','plyInmantaParser.py',325),
+  ('entity_body -> attr','entity_body',1,'p_entity_body','plyInmantaParser.py',331),
+  ('attr_base_type -> ns_ref','attr_base_type',1,'p_attribute_base_type','plyInmantaParser.py',336),
+  ('attr_type_multi -> attr_base_type [ ]','attr_type_multi',3,'p_attribute_type_multi','plyInmantaParser.py',342),
+  ('attr_type_opt -> attr_type_multi ?','attr_type_opt',2,'p_attribute_type_opt','plyInmantaParser.py',348),
+  ('attr_type_opt -> attr_base_type ?','attr_type_opt',2,'p_attribute_type_opt','plyInmantaParser.py',349),
+  ('attr_type -> attr_type_opt','attr_type',1,'p_attribute_type','plyInmantaParser.py',355),
+  ('attr_type -> attr_type_multi','attr_type',1,'p_attribute_type','plyInmantaParser.py',356),
+  ('attr_type -> attr_base_type','attr_type',1,'p_attribute_type','plyInmantaParser.py',357),
+  ('attr -> attr_type CID empty','attr',3,'p_attr_err','plyInmantaParser.py',362),
+  ('attr -> attr_type CID = constant','attr',4,'p_attr_err','plyInmantaParser.py',363),
+  ('attr -> attr_type CID = constant_list','attr',4,'p_attr_err','plyInmantaParser.py',364),
+  ('attr -> attr_type CID = UNDEF','attr',4,'p_attr_err','plyInmantaParser.py',365),
+  ('attr -> attr_type ID','attr',2,'p_attr','plyInmantaParser.py',372),
+  ('attr -> attr_type ID = constant','attr',4,'p_attr_cte','plyInmantaParser.py',378),
+  ('attr -> attr_type ID = constant_list','attr',4,'p_attr_cte','plyInmantaParser.py',379),
+  ('attr -> attr_type ID = UNDEF','attr',4,'p_attr_undef','plyInmantaParser.py',385),
+  ('attr -> DICT empty CID empty','attr',4,'p_attr_dict_err','plyInmantaParser.py',391),
+  ('attr -> DICT empty CID = map_def','attr',5,'p_attr_dict_err','plyInmantaParser.py',392),
+  ('attr -> DICT empty CID = NULL','attr',5,'p_attr_dict_err','plyInmantaParser.py',393),
+  ('attr -> DICT ? CID empty','attr',4,'p_attr_dict_err','plyInmantaParser.py',394),
+  ('attr -> DICT ? CID = map_def','attr',5,'p_attr_dict_err','plyInmantaParser.py',395),
+  ('attr -> DICT ? CID = NULL','attr',5,'p_attr_dict_err','plyInmantaParser.py',396),
+  ('attr -> DICT ID','attr',2,'p_attr_dict','plyInmantaParser.py',403),
+  ('attr -> DICT ID = map_def','attr',4,'p_attr_list_dict','plyInmantaParser.py',409),
+  ('attr -> DICT ID = NULL','attr',4,'p_attr_list_dict_null_err','plyInmantaParser.py',415),
+  ('attr -> DICT ? ID','attr',3,'p_attr_dict_nullable','plyInmantaParser.py',420),
+  ('attr -> DICT ? ID = map_def','attr',5,'p_attr_list_dict_nullable','plyInmantaParser.py',426),
+  ('attr -> DICT ? ID = NULL','attr',5,'p_attr_list_dict_null','plyInmantaParser.py',432),
+  ('implement_ns_list -> ns_ref','implement_ns_list',1,'p_implement_ns_list_ref','plyInmantaParser.py',439),
+  ('implement_ns_list -> PARENTS','implement_ns_list',1,'p_implement_ns_list_parents','plyInmantaParser.py',444),
+  ('implement_ns_list -> implement_ns_list , implement_ns_list','implement_ns_list',3,'p_implement_ns_list_collect','plyInmantaParser.py',449),
+  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list empty','implement_def',5,'p_implement','plyInmantaParser.py',454),
+  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list MLS','implement_def',5,'p_implement','plyInmantaParser.py',455),
+  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression empty','implement_def',7,'p_implement_when','plyInmantaParser.py',464),
+  ('implement_def -> IMPLEMENT class_ref USING implement_ns_list WHEN expression MLS','implement_def',7,'p_implement_when','plyInmantaParser.py',465),
+  ('implementation_def -> IMPLEMENTATION ID FOR class_ref implementation','implementation_def',5,'p_implementation_def','plyInmantaParser.py',475),
+  ('implementation -> implementation_head block','implementation',2,'p_implementation','plyInmantaParser.py',488),
+  ('implementation_head -> :','implementation_head',1,'p_implementation_head','plyInmantaParser.py',493),
+  ('implementation_head -> : MLS','implementation_head',2,'p_implementation_head_doc','plyInmantaParser.py',498),
+  ('block -> stmt_list END','block',2,'p_block','plyInmantaParser.py',503),
+  ('relation -> class_ref ID multi REL multi class_ref ID','relation',7,'p_relation_deprecated','plyInmantaParser.py',509),
+  ('relation -> class_ref ID multi REL multi class_ref ID MLS','relation',8,'p_relation_deprecated_comment','plyInmantaParser.py',520),
+  ('relation -> relation_def MLS','relation',2,'p_relation_outer_comment','plyInmantaParser.py',559),
+  ('relation -> relation_def','relation',1,'p_relation_outer','plyInmantaParser.py',566),
+  ('relation_def -> class_ref . ID multi REL class_ref . ID multi','relation_def',9,'p_relation','plyInmantaParser.py',571),
+  ('relation_def -> class_ref . ID multi REL class_ref','relation_def',6,'p_relation_unidir','plyInmantaParser.py',577),
+  ('relation_def -> class_ref . ID multi operand_list class_ref . ID multi','relation_def',9,'p_relation_annotated','plyInmantaParser.py',583),
+  ('relation_def -> class_ref . ID multi operand_list class_ref','relation_def',6,'p_relation_annotated_unidir','plyInmantaParser.py',589),
+  ('multi -> [ INT ]','multi',3,'p_multi_1','plyInmantaParser.py',595),
+  ('multi -> [ INT : ]','multi',4,'p_multi_2','plyInmantaParser.py',600),
+  ('multi -> [ INT : INT ]','multi',5,'p_multi_3','plyInmantaParser.py',605),
+  ('multi -> [ : INT ]','multi',4,'p_multi_4','plyInmantaParser.py',610),
+  ('typedef -> typedef_inner','typedef',1,'p_typedef_outer','plyInmantaParser.py',618),
+  ('typedef -> typedef_inner MLS','typedef',2,'p_typedef_outer_comment','plyInmantaParser.py',623),
+  ('typedef_inner -> TYPEDEF ID AS ns_ref MATCHING expression','typedef_inner',6,'p_typedef_1','plyInmantaParser.py',630),
+  ('typedef_inner -> TYPEDEF CID AS constructor','typedef_inner',4,'p_typedef_cls','plyInmantaParser.py',637),
+  ('index -> INDEX class_ref ( id_list )','index',5,'p_index','plyInmantaParser.py',645),
+  ('expression -> boolean_expression','expression',1,'p_expression','plyInmantaParser.py',655),
+  ('expression -> constant','expression',1,'p_expression','plyInmantaParser.py',656),
+  ('expression -> function_call','expression',1,'p_expression','plyInmantaParser.py',657),
+  ('expression -> var_ref','expression',1,'p_expression','plyInmantaParser.py',658),
+  ('expression -> constructor','expression',1,'p_expression','plyInmantaParser.py',659),
+  ('expression -> list_def','expression',1,'p_expression','plyInmantaParser.py',660),
+  ('expression -> list_comprehension','expression',1,'p_expression','plyInmantaParser.py',661),
+  ('expression -> map_def','expression',1,'p_expression','plyInmantaParser.py',662),
+  ('expression -> map_lookup','expression',1,'p_expression','plyInmantaParser.py',663),
+  ('expression -> index_lookup','expression',1,'p_expression','plyInmantaParser.py',664),
+  ('expression -> conditional_expression','expression',1,'p_expression','plyInmantaParser.py',665),
+  ('expression -> ( expression )','expression',3,'p_expression_parentheses','plyInmantaParser.py',670),
+  ('boolean_expression -> expression CMP_OP expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',675),
+  ('boolean_expression -> expression IN expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',676),
+  ('boolean_expression -> expression AND expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',677),
+  ('boolean_expression -> expression OR expression','boolean_expression',3,'p_boolean_expression','plyInmantaParser.py',678),
+  ('boolean_expression -> NOT expression','boolean_expression',2,'p_boolean_expression_not','plyInmantaParser.py',687),
+  ('boolean_expression -> var_ref . ID IS DEFINED','boolean_expression',5,'p_boolean_expression_is_defined','plyInmantaParser.py',693),
+  ('boolean_expression -> ID IS DEFINED','boolean_expression',3,'p_boolean_expression_is_defined_short','plyInmantaParser.py',699),
+  ('boolean_expression -> map_lookup IS DEFINED','boolean_expression',3,'p_boolean_expression_is_defined_map_lookup','plyInmantaParser.py',705),
+  ('operand -> expression','operand',1,'p_operand','plyInmantaParser.py',725),
+  ('map_lookup -> attr_ref [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',730),
+  ('map_lookup -> var_ref [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',731),
+  ('map_lookup -> map_lookup [ operand ]','map_lookup',4,'p_map_lookup','plyInmantaParser.py',732),
+  ('constructor -> class_ref ( param_list )','constructor',4,'p_constructor','plyInmantaParser.py',737),
+  ('function_call -> ns_ref ( function_param_list )','function_call',4,'p_function_call','plyInmantaParser.py',743),
+  ('function_call -> attr_ref ( function_param_list )','function_call',4,'p_function_call_err_dot','plyInmantaParser.py',750),
+  ('list_def -> [ operand_list ]','list_def',3,'p_list_def','plyInmantaParser.py',755),
+  ('list_comprehension -> [ expression list_comprehension_for list_comprehension_guard ]','list_comprehension',5,'p_list_comprehension','plyInmantaParser.py',768),
+  ('list_comprehension_for_empty -> empty','list_comprehension_for_empty',1,'p_list_comprehension_for_empty','plyInmantaParser.py',793),
+  ('list_comprehension_for -> FOR ID IN expression list_comprehension_for_empty','list_comprehension_for',5,'p_list_comprehension_for','plyInmantaParser.py',798),
+  ('list_comprehension_for -> FOR ID IN expression list_comprehension_for','list_comprehension_for',5,'p_list_comprehension_for','plyInmantaParser.py',799),
+  ('list_comprehension_guard -> empty','list_comprehension_guard',1,'p_list_comprehension_guard_empty','plyInmantaParser.py',806),
+  ('list_comprehension_guard -> IF expression list_comprehension_guard','list_comprehension_guard',3,'p_list_comprehension_guard','plyInmantaParser.py',811),
+  ('dict_key -> RSTRING','dict_key',1,'p_r_string_dict_key','plyInmantaParser.py',821),
+  ('dict_key -> STRING','dict_key',1,'p_string_dict_key','plyInmantaParser.py',826),
+  ('pair_list -> dict_key : operand , pair_list','pair_list',5,'p_pair_list_collect','plyInmantaParser.py',840),
+  ('pair_list -> dict_key : operand empty pair_list_empty','pair_list',5,'p_pair_list_collect','plyInmantaParser.py',841),
+  ('pair_list -> pair_list_empty','pair_list',1,'p_pair_list_empty','plyInmantaParser.py',850),
+  ('pair_list_empty -> empty','pair_list_empty',1,'p_pair_list_empty','plyInmantaParser.py',851),
+  ('map_def -> { pair_list }','map_def',3,'p_map_def','plyInmantaParser.py',856),
+  ('index_lookup -> class_ref [ param_list ]','index_lookup',4,'p_index_lookup','plyInmantaParser.py',862),
+  ('index_lookup -> attr_ref [ param_list ]','index_lookup',4,'p_short_index_lookup','plyInmantaParser.py',868),
+  ('conditional_expression -> expression ? expression : expression','conditional_expression',5,'p_conditional_expression','plyInmantaParser.py',875),
+  ('constant -> INT','constant',1,'p_constant','plyInmantaParser.py',885),
+  ('constant -> FLOAT','constant',1,'p_constant','plyInmantaParser.py',886),
+  ('constant -> NULL','constant',1,'p_constant_none','plyInmantaParser.py',893),
+  ('constant -> REGEX','constant',1,'p_constant_regex','plyInmantaParser.py',899),
+  ('constant -> TRUE','constant',1,'p_constant_true','plyInmantaParser.py',905),
+  ('constant -> FALSE','constant',1,'p_constant_false','plyInmantaParser.py',911),
+  ('constant -> STRING','constant',1,'p_constant_string','plyInmantaParser.py',917),
+  ('constant -> FSTRING','constant',1,'p_constant_fstring','plyInmantaParser.py',923),
+  ('constant -> RSTRING','constant',1,'p_constant_rstring','plyInmantaParser.py',980),
+  ('constant -> MLS','constant',1,'p_constant_mls','plyInmantaParser.py',986),
+  ('constant_list -> [ constants ]','constant_list',3,'p_constant_list','plyInmantaParser.py',1075),
+  ('constants -> constant','constants',1,'p_constants_term','plyInmantaParser.py',1081),
+  ('constants -> <empty>','constants',0,'p_constants_term_2','plyInmantaParser.py',1086),
+  ('constants -> constant , constants','constants',3,'p_constants_collect','plyInmantaParser.py',1091),
+  ('wrapped_kwargs -> * * operand','wrapped_kwargs',3,'p_wrapped_kwargs','plyInmantaParser.py',1097),
+  ('param_list_element -> ID = operand','param_list_element',3,'p_param_list_element_explicit','plyInmantaParser.py',1103),
+  ('param_list_element -> wrapped_kwargs','param_list_element',1,'p_param_list_element_kwargs','plyInmantaParser.py',1109),
+  ('param_list -> param_list_empty','param_list',1,'p_param_list_empty','plyInmantaParser.py',1115),
+  ('param_list_empty -> empty','param_list_empty',1,'p_param_list_empty','plyInmantaParser.py',1116),
+  ('param_list -> param_list_element empty param_list_empty','param_list',3,'p_param_list_nonempty','plyInmantaParser.py',1122),
+  ('param_list -> param_list_element , param_list','param_list',3,'p_param_list_nonempty','plyInmantaParser.py',1123),
+  ('function_param_list_element -> param_list_element','function_param_list_element',1,'p_function_param_list_element','plyInmantaParser.py',1138),
+  ('function_param_list_element -> operand','function_param_list_element',1,'p_function_param_list_element_arg','plyInmantaParser.py',1145),
+  ('function_param_list -> function_param_list_empty','function_param_list',1,'p_function_param_list_empty','plyInmantaParser.py',1151),
+  ('function_param_list_empty -> empty','function_param_list_empty',1,'p_function_param_list_empty','plyInmantaParser.py',1152),
+  ('function_param_list -> function_param_list_element empty function_param_list_empty','function_param_list',3,'p_function_param_list_nonempty','plyInmantaParser.py',1158),
+  ('function_param_list -> function_param_list_element , function_param_list','function_param_list',3,'p_function_param_list_nonempty','plyInmantaParser.py',1159),
+  ('operand_list -> operand , operand_list','operand_list',3,'p_operand_list_collect','plyInmantaParser.py',1177),
+  ('operand_list -> operand','operand_list',1,'p_operand_list_term','plyInmantaParser.py',1183),
+  ('operand_list -> <empty>','operand_list',0,'p_operand_list_term_2','plyInmantaParser.py',1188),
+  ('var_ref -> attr_ref','var_ref',1,'p_var_ref','plyInmantaParser.py',1193),
+  ('attr_ref -> var_ref . ID','attr_ref',3,'p_attr_ref','plyInmantaParser.py',1198),
+  ('var_ref -> ns_ref','var_ref',1,'p_var_ref_2','plyInmantaParser.py',1204),
+  ('class_ref -> CID','class_ref',1,'p_class_ref_direct','plyInmantaParser.py',1210),
+  ('class_ref -> ns_ref SEP CID','class_ref',3,'p_class_ref','plyInmantaParser.py',1221),
+  ('class_ref -> var_ref . CID','class_ref',3,'p_class_ref_err_dot','plyInmantaParser.py',1227),
+  ('class_ref_list -> class_ref , class_ref_list','class_ref_list',3,'p_class_ref_list_collect','plyInmantaParser.py',1242),
+  ('class_ref_list -> var_ref , class_ref_list','class_ref_list',3,'p_class_ref_list_collect_err','plyInmantaParser.py',1248),
+  ('class_ref_list -> class_ref','class_ref_list',1,'p_class_ref_list_term','plyInmantaParser.py',1253),
+  ('class_ref_list -> var_ref','class_ref_list',1,'p_class_ref_list_term_err','plyInmantaParser.py',1258),
+  ('ns_ref -> ns_ref SEP ID','ns_ref',3,'p_ns_ref','plyInmantaParser.py',1264),
+  ('ns_ref -> ID','ns_ref',1,'p_ns_ref_term','plyInmantaParser.py',1270),
+  ('id_list -> ID , id_list','id_list',3,'p_id_list_collect','plyInmantaParser.py',1275),
+  ('id_list -> ID','id_list',1,'p_id_list_term','plyInmantaParser.py',1281),
 ]
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/pickle.py` & `inmanta-core-9.3.0/src/inmanta/parser/pickle.py`

 * *Files 12% similar despite different names*

```diff
@@ -13,34 +13,34 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 from io import BytesIO
 from pickle import Pickler, Unpickler, UnpicklingError
-from typing import Optional
+from typing import Optional, Tuple
 
 from inmanta.ast import Namespace
 
 
 class ASTPickler(Pickler):
-    def persistent_id(self, obj: object) -> Optional[tuple[str, str]]:
+    def persistent_id(self, obj: object) -> Optional[Tuple[str, str]]:
         if isinstance(obj, Namespace):
             # Don't pickle namespaces
             return ("Namespace", obj.get_full_name())
         else:
             return None
 
 
 class ASTUnpickler(Unpickler):
     def __init__(self, file: BytesIO, namespace: Namespace) -> None:
         super().__init__(file)
         self.namespace = namespace
         self.namespace_name = namespace.get_full_name()
 
-    def persistent_load(self, pid: tuple[str, str]) -> object:
+    def persistent_load(self, pid: Tuple[str, str]) -> object:
         type_tag, key_id = pid
         if type_tag == "Namespace":
             assert self.namespace_name == key_id
             return self.namespace
         else:
             raise UnpicklingError("unsupported persistent object")
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/plyInmantaLex.py` & `inmanta-core-9.3.0/src/inmanta/parser/plyInmantaLex.py`

 * *Files 2% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 tokens = ["INT", "FLOAT", "ID", "CID", "SEP", "STRING", "MLS", "CMP_OP", "REGEX", "REL", "PEQ", "RSTRING", "FSTRING"] + sorted(
     list(reserved.values())
 )
 
 
 def t_FSTRING(t: lex.LexToken) -> lex.LexToken:  # noqa: N802
     r"f(\"([^\\\"\n]|\\.)*\")|f(\'([^\\\'\n]|\\.)*\')"
-    t.value = safe_decode(token=t, warning_message="Invalid escape sequence in f-string.", start=2, end=-1)
+    t.value = t.value[2:-1]
     lexer = t.lexer
 
     end = lexer.lexpos - lexer.linestart + 1
     (s, e) = lexer.lexmatch.span()
     start = end - (e - s)
 
     t.value = LocatableString(
@@ -134,20 +134,22 @@
     return t
 
 
 def t_COMMENT(t: lex.LexToken) -> None:  # noqa: N802
     r"\#.*?\n"
     t.lexer.lineno += 1
     t.lexer.linestart = t.lexer.lexpos
+    pass
 
 
 def t_JCOMMENT(t: lex.LexToken) -> None:  # noqa: N802
     r"\//.*?\n"
     t.lexer.lineno += 1
     t.lexer.linestart = t.lexer.lexpos
+    pass
 
 
 def t_MLS(t: lex.LexToken) -> lex.LexToken:
     r'"{3,5}([\s\S]*?)"{3,5}'
 
     value = safe_decode(token=t, warning_message="Invalid escape sequence in multi-line string.", start=3, end=-3)
 
@@ -205,15 +207,15 @@
         return t
     except RegexError as error:
         end = t.lexer.lexpos - t.lexer.linestart + 1
         (s, e) = t.lexer.lexmatch.span()
         start = end - (e - s)
 
         r: Range = Range(t.lexer.inmfile, t.lexer.lineno, start, t.lexer.lineno, end)
-        raise ParserException(r, t.value, f"Regex error in {t.value}: '{error}'")
+        raise ParserException(r, t.value, "Regex error in %s: '%s'" % (t.value, error))
 
 
 # Define a rule so we can track line numbers
 def t_newline(t: lex.LexToken) -> None:  # noqa: N802
     r"\n+"
     t.lexer.lineno += len(t.value)
     t.lexer.linestart = t.lexer.lexpos
@@ -234,15 +236,15 @@
 
 
 # Build the lexer
 lexer = lex.lex()
 
 
 def safe_decode(token: lex.LexToken, warning_message: str, start: int = 1, end: int = -1) -> str:
-    r"""
+    """
     Check for the presence of an invalid escape sequence (e.g. "\.") in the value attribute of a given token.  # noqa: W605
     This function assumes to be called from within a t_STRING or a t_MLS rule.
 
     - Python < 3.12 raises a DeprecationWarning when encountering an invalid escape sequence
     - Python 3.12 will raise a SyntaxWarning
     - Future versions will eventually raise a SyntaxError
     (see https://docs.python.org/3.12/whatsnew/3.12.html#other-language-changes )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/parser/plyInmantaParser.py` & `inmanta-core-9.3.0/src/inmanta/parser/plyInmantaParser.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,17 +17,17 @@
 """
 import functools
 import logging
 import re
 import string
 import warnings
 from collections import abc
-from collections.abc import Iterable
 from dataclasses import dataclass
-from typing import Optional, Union
+from itertools import accumulate
+from typing import Iterable, Iterator, List, Optional, Tuple, Union
 
 import ply.yacc as yacc
 from ply.yacc import YaccProduction
 
 from inmanta.ast import LocatableString, Location, Namespace, Range
 from inmanta.ast.blocks import BasicBlock
 from inmanta.ast.constraint.expression import And, In, IsDefined, Not, NotEqual, Operator
@@ -64,26 +64,23 @@
 
 LOGGER = logging.getLogger()
 
 file = "NOFILE"
 namespace: Optional[Namespace] = None
 
 precedence = (
-    # precedence rule for productions that should eagerly shift new tokens as long as they remain feasible
-    # e.g. prefer one statement `x = 1 not in []` over two statements `x = 1` and `not in []`
-    ("nonassoc", "LOW"),
-    ("nonassoc", "MATCHING"),
     ("right", ","),
     ("nonassoc", ":"),
     ("nonassoc", "?"),
     ("left", "OR"),
     ("left", "AND"),
     ("left", "CMP_OP"),
     ("nonassoc", "NOT"),
     ("left", "IN"),
+    ("left", "RELATION_DEF", "TYPEDEF_INNER", "OPERAND_LIST", "EMPTY", "NS_REF", "VAR_REF", "MAP_LOOKUP"),
     ("left", "CID", "ID"),
     ("left", "(", "["),
     ("left", "MLS"),
 )
 
 
 def attach_lnr(p: YaccProduction, token: int = 1) -> None:
@@ -130,23 +127,16 @@
     "main : head body"
     v = p[2]
     if p[1]:
         v.insert(0, p[1])
     p[0] = v
 
 
-# low-precedence production that consumes no tokens, has two use cases:
-# - use its low precedence compared to other tokens to prefer one production over another (especially relevant for recursion)
-# - simple placeholder to unify multiple similar rules with optional tokens under one production
-def p_empty(p: YaccProduction) -> None:
-    "empty : %prec LOW"
-
-
 def p_main_head(p: YaccProduction) -> None:
-    "head : empty"
+    "head : %prec EMPTY"
     p[0] = None
 
 
 def p_main_head_doc(p: YaccProduction) -> None:
     "head : MLS"
     p[0] = p[1]
 
@@ -171,14 +161,19 @@
     | statement
     | typedef
     | index
     | import"""
     p[0] = p[1]
 
 
+def p_empty(p: YaccProduction) -> None:
+    "empty : %prec EMPTY"
+    pass
+
+
 #######################
 # IMPORT
 #######################
 
 
 def p_import(p: YaccProduction) -> None:
     """import : IMPORT ns_ref"""
@@ -197,15 +192,15 @@
 #######################
 
 
 def p_stmt(p: YaccProduction) -> None:
     """statement : assign
     | for
     | if
-    | expression empty"""
+    | expression"""
     p[0] = p[1]
 
 
 # def p_stmt_err(p):
 #     '''statement : list_def
 #               | map_def
 #               | var_ref
@@ -510,37 +505,37 @@
 
 
 # RELATION
 def p_relation_deprecated(p: YaccProduction) -> None:
     "relation : class_ref ID multi REL multi class_ref ID"
     if not (p[4] == "--"):
         LOGGER.warning(
-            f"DEPRECATION: use of {p[4]} in relation definition is deprecated, use -- (in {Location(file, p.lineno(4))})"
+            "DEPRECATION: use of %s in relation definition is deprecated, use -- (in %s)" % (p[4], Location(file, p.lineno(4)))
         )
     p[0] = DefineRelation((p[1], p[2], p[3]), (p[6], p[7], p[5]))
     attach_lnr(p, 2)
     deprecated_relation_warning(p)
 
 
 def p_relation_deprecated_comment(p: YaccProduction) -> None:
     "relation : class_ref ID multi REL multi class_ref ID MLS"
     if not (p[4] == "--"):
         LOGGER.warning(
-            f"DEPRECATION: use of {p[4]} in relation definition is deprecated, use -- (in {Location(file, p.lineno(4))})"
+            "DEPRECATION: use of %s in relation definition is deprecated, use -- (in %s)" % (p[4], Location(file, p.lineno(4)))
         )
     rel = DefineRelation((p[1], p[2], p[3]), (p[6], p[7], p[5]))
     rel.comment = str(p[8])
     p[0] = rel
     attach_lnr(p, 2)
     deprecated_relation_warning(p)
 
 
 def deprecated_relation_warning(p: YaccProduction) -> None:
-    def format_multi(multi: tuple[int, Optional[int]]) -> str:
-        values: tuple[str, str] = tuple(v if v is not None else "" for v in multi)
+    def format_multi(multi: Tuple[int, Optional[int]]) -> str:
+        values: Tuple[str, str] = tuple(v if v is not None else "" for v in multi)
         return "[%s:%s]" % values if values[0] != values[1] else "[%s]" % values[0]
 
     warnings.warn(
         SyntaxDeprecationWarning(
             p[0].location,
             None,
             "The relation definition syntax"
@@ -564,15 +559,15 @@
     "relation : relation_def MLS"
     rel = p[1]
     rel.comment = str(p[2])
     p[0] = rel
 
 
 def p_relation_outer(p: YaccProduction) -> None:
-    "relation : relation_def empty"
+    "relation : relation_def %prec RELATION_DEF"
     p[0] = p[1]
 
 
 def p_relation(p: YaccProduction) -> None:
     "relation_def : class_ref '.' ID multi REL class_ref '.' ID multi"
     p[0] = DefineRelation((p[1], p[8], p[9]), (p[6], p[3], p[4]))
     attach_lnr(p, 2)
@@ -616,15 +611,15 @@
     p[0] = (0, p[3])
 
 
 # typedef
 
 
 def p_typedef_outer(p: YaccProduction) -> None:
-    """typedef : typedef_inner empty"""
+    """typedef : typedef_inner %prec TYPEDEF_INNER"""
     p[0] = p[1]
 
 
 def p_typedef_outer_comment(p: YaccProduction) -> None:
     """typedef : typedef_inner MLS"""
     tdef = p[1]
     tdef.comment = str(p[2])
@@ -656,20 +651,20 @@
 # EXPRESSIONS
 
 
 def p_expression(p: YaccProduction) -> None:
     """expression : boolean_expression
     | constant
     | function_call
-    | var_ref empty
+    | var_ref %prec VAR_REF
     | constructor
     | list_def
     | list_comprehension
     | map_def
-    | map_lookup empty
+    | map_lookup %prec MAP_LOOKUP
     | index_lookup
     | conditional_expression"""
     p[0] = p[1]
 
 
 def p_expression_parentheses(p: YaccProduction) -> None:
     """expression : '(' expression ')'"""
@@ -684,20 +679,14 @@
     operator = Operator.get_operator_class(str(p[2]))
     if operator is None:
         raise ParserException(p[1].location, str(p[1]), f"Invalid operator {str(p[1])}")
     p[0] = operator(p[1], p[3])
     attach_lnr(p, 2)
 
 
-def p_boolean_expression_not_in(p: YaccProduction) -> None:
-    """boolean_expression : expression NOT IN expression"""
-    p[0] = Not(In(p[1], p[4]))
-    attach_lnr(p, 2)
-
-
 def p_boolean_expression_not(p: YaccProduction) -> None:
     """boolean_expression : NOT expression"""
     p[0] = Not(p[2])
     attach_lnr(p)
 
 
 def p_boolean_expression_is_defined(p: YaccProduction) -> None:
@@ -729,15 +718,15 @@
     not_empty_list = attach_lnr_to_statement(NotEqual(p[1], attach_lnr_to_statement(CreateList(list()))))
 
     out = attach_lnr_to_statement(And(attach_lnr_to_statement(And(key_in_dict, not_none)), not_empty_list))
     p[0] = out
 
 
 def p_operand(p: YaccProduction) -> None:
-    """operand : expression empty"""
+    """operand : expression"""
     p[0] = p[1]
 
 
 def p_map_lookup(p: YaccProduction) -> None:
     """map_lookup : attr_ref '[' operand ']'
     | var_ref '[' operand ']'
     | map_lookup '[' operand ']'"""
@@ -838,16 +827,15 @@
 
     key = str(p[1])
     match_obj = format_regex_compiled.findall(key)
     if len(match_obj) != 0:
         raise ParserException(
             p[1].location,
             str(p[1]),
-            "String interpolation is not supported in dictionary keys. "
-            "Use raw string to use a key containing double curly brackets",
+            "String interpolation is not supported in dictionary keys. Use raw string to use a key containing double curly brackets",  # NOQA E501
         )
     p[0] = p[1]
 
 
 def p_pair_list_collect(p: YaccProduction) -> None:
     """pair_list : dict_key ':' operand ',' pair_list
     | dict_key ':' operand empty pair_list_empty"""
@@ -932,64 +920,58 @@
 
 
 def p_constant_fstring(p: YaccProduction) -> None:
     "constant : FSTRING"
     formatter = string.Formatter()
 
     # formatter.parse returns an iterable of tuple (literal_text, field_name, format_spec, conversion)
-    parsed: abc.Sequence[tuple[str, Optional[str], Optional[str], Optional[str]]]
-    try:
-        parsed = list(formatter.parse(str(p[1])))
-    except ValueError as e:
-        raise ParserException(p[1].location, str(p[1]), f"Invalid f-string: {e}")
+    parsed: Iterable[Tuple[str, Optional[str], Optional[str], Optional[str]]] = formatter.parse(str(p[1]))
 
     start_lnr = p[1].location.lnr
     start_char_pos = p[1].location.start_char + 2  # FSTRING tokens begin with `f"` or `f'` of length 2
 
-    locatable_matches: list[tuple[str, LocatableString]] = []
+    locatable_matches: List[Tuple[str, LocatableString]] = []
 
-    def locate_match(
-        match: tuple[str, Optional[str], Optional[str], Optional[str]], start_char_pos: int, end_char: int
-    ) -> None:
+    def locate_match(match: Tuple[str, Optional[str], Optional[str], Optional[str]]) -> None:
         """
         Associates a parsed field name with a locatable string
         """
-        assert match[1]  # make mypy happy
         range: Range = Range(p[1].location.file, start_lnr, start_char_pos, start_lnr, end_char)
+        assert match[1]  # make mypy happy
         locatable_string = LocatableString(match[1], range, p[1].lexpos, p[1].namespace)
         locatable_matches.append((match[1], locatable_string))
 
     for match in parsed:
         if not match[1]:
             # Happens when the format string ends with literal text (and not a replacement field): we're done parsing.
             break
         literal_text_len = len(match[0])
         field_name_len = len(match[1])
         brackets_length = 1 if field_name_len else 0
         start_char_pos += literal_text_len + brackets_length
         end_char = start_char_pos + field_name_len
 
-        locate_match(match, start_char_pos, end_char)
+        locate_match(match)
         start_char_pos += field_name_len
 
         if match[2]:
             # A format specifier was provided
             start_char_pos += 1  # Account for the ":" character
-            sub_parsed: Iterable[tuple[str, Optional[str], Optional[str], Optional[str]]] = formatter.parse(match[2])
+            sub_parsed: Iterable[Tuple[str, Optional[str], Optional[str], Optional[str]]] = formatter.parse(match[2])
             for submatch in sub_parsed:
                 if not submatch[1]:
                     # Happens when the format string ends with literal text (and not a replacement field): we're done parsing.
                     break
                 literal_text_len = len(submatch[0])
                 inner_field_name_len = len(submatch[1])
                 inner_brackets_len = 1 if inner_field_name_len else 0
                 start_char_pos += literal_text_len + inner_brackets_len
                 end_char = start_char_pos + inner_field_name_len
 
-                locate_match(submatch, start_char_pos, end_char)
+                locate_match(submatch)
                 start_char_pos += inner_field_name_len + inner_brackets_len
 
         start_char_pos += brackets_length
 
     p[0] = StringFormatV2(str(p[1]), convert_to_references(locatable_matches))
     attach_from_string(p)
 
@@ -1007,108 +989,85 @@
 
 
 format_regex = r"""({{\s*([\.A-Za-z0-9_-]+)\s*}})"""
 format_regex_compiled = re.compile(format_regex, re.MULTILINE | re.DOTALL)
 
 
 def get_string_ast_node(string_ast: LocatableString, mls: bool) -> Union[Literal, StringFormat]:
-    matches: list[re.Match[str]] = list(format_regex_compiled.finditer(str(string_ast)))
+    matches: List[re.Match[str]] = list(format_regex_compiled.finditer(str(string_ast)))
     if len(matches) == 0:
         return Literal(str(string_ast))
 
     start_lnr = string_ast.location.lnr
     start_char_pos = string_ast.location.start_char
     whole_string = str(string_ast)
     mls_offset: int = 3 if mls else 1  # len(""")  or len(') or len(")
 
-    def char_count_to_lnr_char(position: int) -> tuple[int, int]:
+    def char_count_to_lnr_char(position: int) -> Tuple[int, int]:
         # convert in-string position to lnr/charcount
         before = whole_string[0:position]
         lines = before.count("\n")
         if lines == 0:
             return start_lnr, start_char_pos + position + mls_offset
         else:
             return start_lnr + lines, position - before.rindex("\n")
 
-    locatable_matches: list[tuple[str, LocatableString]] = []
+    locatable_matches: List[Tuple[str, LocatableString]] = []
     for match in matches:
         start_line, start_char = char_count_to_lnr_char(match.start(2))
         end_line, end_char = char_count_to_lnr_char(match.end(2))
         range: Range = Range(string_ast.location.file, start_line, start_char, end_line, end_char)
         locatable_string = LocatableString(match[2], range, string_ast.lexpos, string_ast.namespace)
         locatable_matches.append((match[1], locatable_string))
 
     return StringFormat(str(string_ast), convert_to_references(locatable_matches))
 
 
-def convert_to_references(variables: list[tuple[str, LocatableString]]) -> list[tuple["Reference", str]]:
+def convert_to_references(variables: List[Tuple[str, LocatableString]]) -> List[Tuple["Reference", str]]:
     """
     This function is used in a context of string formatting. It expects variables that are part of a single line
     format string and converts them to a format that can be processed by StringFormat (for regular
     string interpolation) or by StringFormatV2 (for f-string formatting).
 
     :param variables: A list of tuples where each tuple is a combination of a string and LocatableString.
         For regular string interpolation:
             - The string is the match containing the {{}} (ex: {{a.b}})
             - The LocatableString is composed of just the variables and the range for those variables.
             (ex. LocatableString("a.b", range(a.b), lexpos, namespace))
 
         For f-strings:
-            - The string is the plain variable name without brackets (ex: 'a.b') and including any potential whitespaces.
+            - The string is the plain variable name without brackets (ex: 'a.b')
             - The LocatableString is the same as for regular string interpolation
-    :returns: A tuple where all LocatableString have been converted to Reference. These references are cleaned up of any
-        potential whitespace character. The matching str holding the variable name is left untouched i.e. will still contain
-        potential whitespace characters.
+    :returns: A tuple where all LocatableString have been converted to Reference. The matching str holding the variable
+        name is left untouched
     """
-
-    def normalize(variable: str, locatable: LocatableString, offset: int = 0) -> LocatableString:
-        """
-        Strip a variable of potential whitespaces and compute the locatable string.
-        :param variable: String representation for a plain variable or composite part of a variable
-            including potential whitespace.
-        :param locatable: LocatableString associated to this variable.
-        :param offset: Used when normalizing a subpart of a composite variable (e.g. 'a.b.c') to track where the current
-            subpart starts.
-        """
-        start_char = locatable.location.start_char + offset
-        end_char = start_char + len(variable)
-
-        variable_left_trim = variable.lstrip()
-        left_spaces: int = len(variable) - len(variable_left_trim)
-        variable_full_trim = variable_left_trim.rstrip()
-        right_spaces: int = len(variable_left_trim) - len(variable_full_trim)
-
-        range: Range = Range(
-            locatable.location.file,
-            locatable.location.lnr,
-            start_char + left_spaces,
-            locatable.location.lnr,
-            end_char - right_spaces,
-        )
-        return LocatableString(variable_full_trim, range, locatable.lexpos, locatable.namespace)
-
     assert namespace
-    _vars: list[tuple[Reference, str]] = []
+    _vars: List[Tuple[Reference, str]] = []
     for match, var in variables:
         var_name: str = str(var)
-        var_parts: list[str] = var_name.split(".")
-
-        ref_locatable_string: LocatableString = normalize(var_parts[0], var)
-
+        var_parts: List[str] = var_name.split(".")
+        start_char = var.location.start_char
+        end_char = start_char + len(var_parts[0])
+        range: Range = Range(var.location.file, var.location.lnr, start_char, var.location.lnr, end_char)
+        ref_locatable_string = LocatableString(var_parts[0], range, var.lexpos, var.namespace)
         ref = Reference(ref_locatable_string)
         ref.location = ref_locatable_string.location
         ref.namespace = namespace
         if len(var_parts) > 1:
-            offset = len(var_parts[0]) + 1
-            for attr in var_parts[1:]:
-                attr_locatable_string: LocatableString = normalize(attr, var, offset=offset)
+            attribute_offsets: Iterator[int] = accumulate(
+                var_parts[1:], lambda acc, part: acc + len(part) + 1, initial=end_char + 1
+            )
+            for attr, char_offset in zip(var_parts[1:], attribute_offsets):
+                range_attr: Range = Range(
+                    var.location.file, var.location.lnr, char_offset, var.location.lnr, char_offset + len(attr)
+                )
+                attr_locatable_string: LocatableString = LocatableString(attr, range_attr, var.lexpos, var.namespace)
                 ref = AttributeReference(ref, attr_locatable_string)
-                ref.location = attr_locatable_string.location
+                ref.location = range_attr
                 ref.namespace = namespace
-                offset += len(attr) + 1
             # For a composite variable e.g. 'a.b.c', we only add the reference to the innermost attribute (e.g. 'c')
             _vars.append((ref, match))
         else:
             _vars.append((ref, match))
     return _vars
 
 
@@ -1222,31 +1181,31 @@
 
 def p_operand_list_term(p: YaccProduction) -> None:
     "operand_list : operand"
     p[0] = [p[1]]
 
 
 def p_operand_list_term_2(p: YaccProduction) -> None:
-    "operand_list : empty"
+    "operand_list : %prec OPERAND_LIST"
     p[0] = []
 
 
 def p_var_ref(p: YaccProduction) -> None:
-    "var_ref : attr_ref empty"
+    "var_ref : attr_ref %prec VAR_REF"
     p[0] = p[1]
 
 
 def p_attr_ref(p: YaccProduction) -> None:
     "attr_ref : var_ref '.' ID"
     p[0] = AttributeReference(p[1], p[3])
     attach_lnr(p, 2)
 
 
 def p_var_ref_2(p: YaccProduction) -> None:
-    "var_ref : ns_ref empty"
+    "var_ref : ns_ref %prec NS_REF"
     p[0] = Reference(p[1])
     attach_from_string(p, 1)
 
 
 def p_class_ref_direct(p: YaccProduction) -> None:
     "class_ref : CID"
     p[0] = p[1]
@@ -1256,26 +1215,26 @@
 #     "class_ref : ID"
 #     raise ParserException(
 #         file, p.lineno(1), p.lexpos(1), p[1], "Invalid identifier: Entity names must start with a capital")
 
 
 def p_class_ref(p: YaccProduction) -> None:
     "class_ref : ns_ref SEP CID"
-    p[0] = f"{str(p[1])}::{p[3]}"
+    p[0] = "%s::%s" % (str(p[1]), p[3])
     merge_lnr_to_string(p, 1, 3)
 
 
 def p_class_ref_err_dot(p: YaccProduction) -> None:
     "class_ref : var_ref '.' CID"
     var: Union[LocatableString, Reference] = p[1]
     var_str: LocatableString = var if isinstance(var, LocatableString) else var.locatable_name
     cid: LocatableString = p[3]
     assert namespace
     full_string: LocatableString = LocatableString(
-        f"{var_str}.{cid}",
+        "%s.%s" % (var_str, cid),
         expand_range(var_str.location, cid.location),
         var_str.lexpos,
         namespace,
     )
     raise InvalidNamespaceAccess(full_string)
 
 
@@ -1299,15 +1258,15 @@
     "class_ref_list : var_ref"
 
     raise ParserException(p[1].location, str(p[1]), "Invalid identifier: Entity names must start with a capital")
 
 
 def p_ns_ref(p: YaccProduction) -> None:
     "ns_ref : ns_ref SEP ID"
-    p[0] = f"{p[1]}::{p[3]}"
+    p[0] = "%s::%s" % (p[1], p[3])
     merge_lnr_to_string(p, 1, 3)
 
 
 def p_ns_ref_term(p: YaccProduction) -> None:
     "ns_ref : ID"
     p[0] = p[1]
 
@@ -1349,26 +1308,26 @@
 
 
 # Build the parser
 lexer = plyInmantaLex.lexer
 parser = yacc.yacc()
 
 
-def base_parse(ns: Namespace, tfile: str, content: Optional[str]) -> list[Statement]:
+def base_parse(ns: Namespace, tfile: str, content: Optional[str]) -> List[Statement]:
     """Actual parsing code"""
     global file
     file = tfile
     lexer.inmfile = tfile
     global namespace
     namespace = ns
     lexer.namespace = ns
     lexer.begin("INITIAL")
 
     if content is None:
-        with open(tfile, encoding="utf-8") as myfile:
+        with open(tfile, "r", encoding="utf-8") as myfile:
             data = myfile.read()
             if len(data) == 0:
                 return []
             # prevent problems with EOF
             data = data + "\n"
             lexer.lineno = 1
             lexer.linestart = 0
@@ -1383,14 +1342,14 @@
         lexer.linestart = 0
         return parser.parse(data, lexer=lexer, debug=False)
 
 
 cache_manager = CacheManager()
 
 
-def parse(namespace: Namespace, filename: str, content: Optional[str] = None) -> list[Statement]:
+def parse(namespace: Namespace, filename: str, content: Optional[str] = None) -> List[Statement]:
     statements = cache_manager.un_cache(namespace, filename)
     if statements is not None:
         return statements
     statements = base_parse(namespace, filename, content)
     cache_manager.cache(namespace, filename, statements)
     return statements
```

### Comparing `inmanta-core-8.7.4/src/inmanta/plugins.py` & `inmanta-core-9.3.0/src/inmanta/plugins.py`

 * *Files 18% similar despite different names*

```diff
@@ -12,31 +12,39 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import asyncio
-import collections.abc
 import inspect
 import os
 import subprocess
 import warnings
 from collections import abc
-from collections.abc import Callable
-from typing import TYPE_CHECKING, Any, Literal, Optional, Type, TypeVar
+from functools import reduce
+from typing import TYPE_CHECKING, Any, Callable, Dict, FrozenSet, List, Optional, Tuple, Type, TypeVar
 
 import inmanta.ast.type as inmanta_type
 from inmanta import const, protocol, util
-from inmanta.ast import LocatableString, Location, Namespace, Range, RuntimeException, TypeNotFoundException, WithComment
+from inmanta.ast import (
+    CompilerException,
+    LocatableString,
+    Location,
+    Namespace,
+    Range,
+    RuntimeException,
+    TypeNotFoundException,
+    WithComment,
+)
 from inmanta.ast.type import NamedType
 from inmanta.config import Config
 from inmanta.execute.proxy import DynamicProxy
 from inmanta.execute.runtime import QueueScheduler, Resolver, ResultVariable
-from inmanta.execute.util import NoneValue, Unknown
+from inmanta.execute.util import Unknown
 from inmanta.stable_api import stable_api
 from inmanta.warnings import InmantaWarning
 
 T = TypeVar("T")
 
 if TYPE_CHECKING:
     from inmanta.ast.statements import DynamicStatement
@@ -45,15 +53,15 @@
 
 
 class PluginDeprecationWarning(InmantaWarning):
     pass
 
 
 @stable_api
-class Context:
+class Context(object):
     """
     An instance of this class is used to pass context to the plugin
     """
 
     __client: Optional["protocol.Client"] = None
     __sync_client = None
 
@@ -138,31 +146,31 @@
 
 @stable_api
 class PluginMeta(type):
     """
     A metaclass that keeps track of concrete plugin subclasses. This class is responsible for all plugin registration.
     """
 
-    def __new__(cls, name: str, bases: tuple[type, ...], dct: dict[str, object]) -> type:
+    def __new__(cls, name: str, bases: Tuple[type, ...], dct: Dict[str, object]) -> Type:
         subclass = type.__new__(cls, name, bases, dct)
         if hasattr(subclass, "__function_name__"):
             cls.add_function(subclass)
         return subclass
 
-    __functions: dict[str, type["Plugin"]] = {}
+    __functions: Dict[str, Type["Plugin"]] = {}
 
     @classmethod
-    def add_function(cls, plugin_class: type["Plugin"]) -> None:
+    def add_function(cls, plugin_class: Type["Plugin"]) -> None:
         """
         Add a function plugin class
         """
         cls.__functions[plugin_class.__fq_plugin_name__] = plugin_class
 
     @classmethod
-    def get_functions(cls) -> dict[str, "Type[Plugin]"]:
+    def get_functions(cls) -> Dict[str, "Type[Plugin]"]:
         """
         Get all functions that are registered
         """
         return dict(cls.__functions)
 
     @classmethod
     def clear(cls, inmanta_module: Optional[str] = None) -> None:
@@ -179,168 +187,42 @@
                 for fq_name, plugin_class in cls.__functions.items()
                 if plugin_class.__module__ != top_level and not plugin_class.__module__.startswith(f"{top_level}.")
             }
         else:
             cls.__functions = {}
 
 
-class Null(inmanta_type.Type):
-    """
-    This custom type is used for the validation of plugins which only
-    accept null as an argument or return value.
-    """
-
-    def validate(self, value: Optional[object]) -> bool:
-        if isinstance(value, NoneValue):
-            return True
-
-        raise RuntimeException(None, f"Invalid value '{value}', expected {self.type_string()}")
-
-    def type_string(self) -> str:
-        return "null"
-
-    def type_string_internal(self) -> str:
-        return self.type_string()
-
-
-# Define some types which are used in the context of plugins.
-PLUGIN_TYPES = {
-    "any": inmanta_type.Type(),  # Any value will pass validation
-    "expression": inmanta_type.Type(),  # Any value will pass validation
-    "null": Null(),  # Only NoneValue will pass validation
-    None: inmanta_type.Type(),  # In iso6, a None return type accepts any value, from iso7+ it expects a None value.
-}
-
-
-class PluginValue:
-    """
-    Base class for all values that go in and out of a plugin: arguments and return value.
-
-    The class has two class attributes that should be set in the different subclasses:
-    :attr VALUE_TYPE: The type of io value it is, argument or return value
-    :attr VALUE_NAME: The name of the io value, the argument name or "return value"
-
-    These attributes are only used for better error reporting.
-    """
-
-    VALUE_TYPE: str = ""
-    VALUE_NAME: str = ""
-
-    def __init__(self, type_expression: object) -> None:
-        self.type_expression = type_expression
-        self._resolved_type: Optional[inmanta_type.Type] = None
-
-    @property
-    def resolved_type(self) -> inmanta_type.Type:
-        """
-        Get the resolved type of this plugin io.  The resolved type can only be accessed
-        once this object has been normalized (which happens during the plugin normalization).
-        """
-        if self._resolved_type is None:
-            raise RuntimeException(
-                stmt=None,
-                msg=f"{type(self).__name__} {self.VALUE_NAME} ({repr(self.type_expression)}) has not been normalized, "
-                "its resolved type can't be accessed.",
-            )
-        return self._resolved_type
-
-    def resolve_type(self, plugin: "Plugin", resolver: Namespace) -> inmanta_type.Type:
-        """
-        Convert the string representation of this argument's type to a type.
-        If no type annotation is present or if the type annotation allows any type to be passed
-        as argument, then None is returned.
-
-        :param plugin: The plugin that this argument is part of.
-        :param resolver: The namespace that can be used to resolve the type annotation of this
-            argument.
-        """
-        if self.type_expression in PLUGIN_TYPES:
-            self._resolved_type = PLUGIN_TYPES[self.type_expression]
-            return self._resolved_type
-
-        if not isinstance(self.type_expression, str):
-            raise RuntimeException(
-                stmt=None,
-                msg="Bad annotation in plugin %s for %s, expected str but got %s (%s)"
-                % (plugin.get_full_name(), self.VALUE_NAME, type(self.type_expression).__name__, self.type_expression),
-            )
-
-        plugin_line: Range = Range(plugin.location.file, plugin.location.lnr, 1, plugin.location.lnr + 1, 1)
-        locatable_type: LocatableString = LocatableString(self.type_expression, plugin_line, 0, resolver)
-        self._resolved_type = inmanta_type.resolve_type(locatable_type, resolver)
-        return self._resolved_type
-
-    def validate(self, value: object) -> bool:
-        """
-        Validate that the given value can be passed to this argument.  Returns True if the value is known
-        and valid, False if the value is unknown, and raises a ValueError is the value is not of the
-        expected type.
-
-        :param value: The value to validate
-        """
-        if isinstance(value, Unknown):
-            # Value is not known, it can not be validated
-            return False
-
-        # Validate the value, use custom validate method of the type if it exists
-        return self.resolved_type.validate(value)
-
-
-class PluginArgument(PluginValue):
+class PluginArgument:
     """
     Represents the argument of an Inmanta plugin.
     """
 
-    VALUE_TYPE = "argument value"
-
     # Marker used to indicate that a plugin argument has no default value.
     NO_DEFAULT_VALUE_SET = object()
 
     def __init__(
-        self,
-        arg_name: str,
-        arg_type: object,
-        arg_position: Optional[int] = None,
-        default_value: object = NO_DEFAULT_VALUE_SET,
+        self, arg_name: str, arg_type: object, is_kw_only_argument: bool, default_value: object = NO_DEFAULT_VALUE_SET
     ) -> None:
-        super().__init__(arg_type)
         self.arg_name = arg_name
-        self.arg_type = self.type_expression
-        self.arg_position = arg_position
-        self.is_kw_only_argument = arg_position is None
+        self.arg_type = arg_type
+        self.is_kw_only_argument = is_kw_only_argument
         self._default_value = default_value
-        self.VALUE_NAME = self.arg_name
 
     @property
     def default_value(self) -> Optional[object]:
         if not self.has_default_value():
             raise Exception("PluginArgument doesn't have a default value")
         return self._default_value
 
     def has_default_value(self) -> bool:
         """
         Return True iff this plugin argument has a default value set.
         """
         return self._default_value is not self.NO_DEFAULT_VALUE_SET
 
-    def __str__(self) -> str:
-        if self.has_default_value():
-            return "%s: %s = %s" % (self.arg_name, repr(self.arg_type), str(self.default_value))
-        else:
-            return "%s: %s" % (self.arg_name, repr(self.arg_type))
-
-
-class PluginReturn(PluginValue):
-    """
-    Represent the return type of an Inmanta plugin.
-    """
-
-    VALUE_TYPE = "returned value"
-    VALUE_NAME = "return value"
-
 
 class Plugin(NamedType, WithComment, metaclass=PluginMeta):
     """
     This class models a plugin that can be called from the language.
     """
 
     deprecated: bool = False
@@ -348,24 +230,21 @@
 
     def __init__(self, namespace: Namespace) -> None:
         self.ns = namespace
         self.namespace = namespace
 
         # The index of the Context attribute.
         self._context: int = -1
+        self._return = None
 
-        # Load the signature and build all the PluginArgument objects corresponding to it
-        self.args: list[PluginArgument] = list()
-        self.var_args: Optional[PluginArgument] = None
-        self.kwargs: dict[str, PluginArgument] = dict()
-        self.var_kwargs: Optional[PluginArgument] = None
-        self.all_args: dict[str, PluginArgument] = dict()
-        self.return_type: PluginReturn = PluginReturn("null")
+        self.arguments: List[PluginArgument]
         if hasattr(self.__class__, "__function__"):
-            self._load_signature(self.__class__.__function__)
+            self.arguments = self._load_signature(self.__class__.__function__)
+        else:
+            self.arguments = []
 
         self.new_statement = None
 
         filename: Optional[str] = inspect.getsourcefile(self.__class__.__function__)
         assert filename is not None
         try:
             line: int = inspect.getsourcelines(self.__class__.__function__)[1] + 1
@@ -376,284 +255,196 @@
         if self.__class__.__function__.__doc__:
             self.comment = self.__class__.__function__.__doc__
 
         self.location = Location(filename, line)
 
     def normalize(self) -> None:
         self.resolver = self.namespace
+        self.argtypes = [self.to_type(arg.arg_type, self.namespace) for arg in self.arguments]
+        self.returntype = self.to_type(self._return, self.namespace)
 
-        # Resolve all the types that we expect to receive as input of our plugin
-        for arg in self.all_args.values():
-            arg.resolve_type(self, self.resolver)
-        if self.var_args is not None:
-            self.var_args.resolve_type(self, self.resolver)
-        if self.var_kwargs is not None:
-            self.var_kwargs.resolve_type(self, self.resolver)
-
-        self.return_type.resolve_type(self, self.resolver)
-
-    def _load_signature(self, function: Callable[..., object]) -> None:
-        """
-        Load the signature from the given python function, and update the relevant attributes
-        of this object.
-        """
-        # Reset relevant object attributes
-        self.args = list()
-        self.var_args = None
-        self.kwargs = dict()
-        self.var_kwargs = None
-        self.all_args = dict()
-
-        # Inspect the function to get its arguments and annotations
+    def _load_signature(self, function: Callable[..., object]) -> List[PluginArgument]:
+        """
+        Load the signature from the given python function
+        """
         arg_spec = inspect.getfullargspec(function)
 
-        # Load the return annotation.  If not return annotation is provided, the returned
-        # type is "any".
-        if "return" not in arg_spec.annotations:
-            self.return_type = PluginReturn("any")
+        # Calculate at which index the default values start (for the non-keyword-only attributes)
+        default_start_for_args: Optional[int]
+        if arg_spec.defaults is not None:
+            default_start_for_args = len(arg_spec.args) - len(arg_spec.defaults)
         else:
-            self.return_type = PluginReturn(arg_spec.annotations["return"])
+            default_start_for_args = None
 
-        def get_annotation(arg: str) -> object:
-            """
-            Get the annotation for a specific argument, and if none exists, raise an exception
-            """
-            if arg not in arg_spec.annotations:
-                raise RuntimeException(
-                    stmt=None,
-                    msg=f"All arguments of plugin {repr(self.get_full_name())} should be annotated: "
-                    f"{repr(arg)} has no annotation",
-                )
-
-            return arg_spec.annotations[arg]
+        arguments: List[PluginArgument] = []
 
-        if arg_spec.varargs is not None:
-            # We have a catch-all positional arguments
-            self.var_args = PluginArgument(
-                arg_name=arg_spec.varargs,
-                arg_type=get_annotation(arg_spec.varargs),
-            )
+        def process_kw_only_args(argument_name: str, annotation: object) -> PluginArgument:
+            if arg_spec.kwonlydefaults and argument_name in arg_spec.kwonlydefaults:
+                default_value = arg_spec.kwonlydefaults[argument_name]
+                return PluginArgument(argument_name, annotation, is_kw_only_argument=True, default_value=default_value)
+            else:
+                return PluginArgument(argument_name, annotation, is_kw_only_argument=True)
 
-        if arg_spec.varkw is not None:
-            # We have a catch-all keyword arguments
-            self.var_kwargs = PluginArgument(
-                arg_name=arg_spec.varkw,
-                arg_type=get_annotation(arg_spec.varkw),
-            )
+        def process_regular_args(index: int, argument_name: str, annotation: object) -> PluginArgument:
+            if default_start_for_args is not None and default_start_for_args <= index:
+                default_value = arg_spec.defaults[default_start_for_args - index]
+                return PluginArgument(argument_name, annotation, is_kw_only_argument=False, default_value=default_value)
+            else:
+                return PluginArgument(argument_name, annotation, is_kw_only_argument=False)
 
-        # Save all positional arguments
-        defaults_start_at = len(arg_spec.args) - len(arg_spec.defaults or [])
-        for position, arg in enumerate(arg_spec.args):
-            annotation = get_annotation(arg)
+        def process_arg(index: int, argument_name: str, is_kwonly_arg: bool) -> None:
+            if argument_name not in arg_spec.annotations:
+                raise CompilerException(f"All arguments of plugin '{function.__name__}' should be annotated")
+            annotation = arg_spec.annotations[argument_name]
             if annotation == Context:
-                self._context = position
-                continue
-
-            # Resolve the default before changing the position because
-            # of the context presence, as the defaults list definitely
-            # takes into account the context presence.
-            default = (
-                arg_spec.defaults[position - defaults_start_at]
-                if position >= defaults_start_at
-                else PluginArgument.NO_DEFAULT_VALUE_SET
-            )
+                self._context = index
+            else:
+                if is_kwonly_arg:
+                    plugin_argument = process_kw_only_args(argument_name, annotation)
+                else:
+                    plugin_argument = process_regular_args(index, argument_name, annotation)
+                arguments.append(plugin_argument)
+
+        # Process regular arguments
+        for i in range(len(arg_spec.args)):
+            process_arg(i, arg_spec.args[i], is_kwonly_arg=False)
+        # Process keyword-only arguments
+        for i in range(len(arg_spec.kwonlyargs)):
+            process_arg(i, arg_spec.kwonlyargs[i], is_kwonly_arg=True)
 
-            if self._context != -1:
-                # If we have a context argument, the position index
-                # needs to be adapted as this context object can never be passed
-                # from the model.
-                position -= 1
-
-            argument = PluginArgument(
-                arg_name=arg,
-                arg_type=annotation,
-                arg_position=position,
-                default_value=default,
-            )
+        if "return" in arg_spec.annotations:
+            self._return = arg_spec.annotations["return"]
 
-            # This is a positional argument, we register it now
-            self.args.append(argument)
-            self.all_args[arg] = argument
-
-        # Save all key-word arguments
-        for arg in arg_spec.kwonlyargs:
-            argument = PluginArgument(
-                arg_name=arg,
-                arg_type=get_annotation(arg),
-                default_value=(
-                    arg_spec.kwonlydefaults[arg]
-                    if arg_spec.kwonlydefaults is not None and arg in arg_spec.kwonlydefaults
-                    else PluginArgument.NO_DEFAULT_VALUE_SET
-                ),
-            )
-            self.kwargs[arg] = argument
-            self.all_args[arg] = argument
+        return arguments
 
     def get_signature(self) -> str:
         """
-        Generate the signature of this plugin.  The signature is a string representing the the function
-        as it can be called as a plugin in the model.
+        Generate the signature of this plugin
         """
-        # Start the list with all positional arguments
-        arg_list = [str(arg) for arg in self.args]
+        arg_list = []
+        for arg in self.arguments:
+            if arg.has_default_value():
+                arg_list.append("%s: %s=%s" % (arg.arg_name, arg.arg_type, str(arg.default_value)))
+            else:
+                arg_list.append("%s: %s" % (arg.arg_name, arg.arg_type))
 
-        # Filter all positional arguments out of the kwargs list
-        kwargs = [str(arg) for _, arg in self.kwargs.items() if arg.is_kw_only_argument]
+        args = ", ".join(arg_list)
 
-        if self.var_args is not None:
-            arg_list.append("*" + str(self.var_args))
-        elif kwargs:
-            # For keyword only arguments, we need a marker if we don't have a catch-all
-            # positional argument
-            arg_list.append("*")
+        if self._return is None:
+            return "%s(%s)" % (self.__class__.__function_name__, args)
+        return "%s(%s) -> %s" % (self.__class__.__function_name__, args, self._return)
 
-        # Add all keyword-only arguments to the list
-        arg_list.extend(kwargs)
+    def to_type(self, arg_type: Optional[object], resolver: Namespace) -> Optional[inmanta_type.Type]:
+        """
+        Convert a string representation of a type to a type
+        """
+        if arg_type is None:
+            return None
 
-        if self.var_kwargs is not None:
-            arg_list.append("**" + str(self.var_kwargs))
+        if not isinstance(arg_type, str):
+            raise CompilerException(
+                "bad annotation in plugin %s::%s, expected str but got %s (%s)"
+                % (self.ns, self.__class__.__function_name__, type(arg_type), arg_type)
+            )
 
-        # Join all arguments, separated by a comma
-        args_string = ", ".join(arg_list)
+        if arg_type == "any":
+            return None
 
-        if self.return_type.type_expression is None:
-            return "%s(%s)" % (self.__class__.__function_name__, args_string)
-        return "%s(%s) -> %s" % (self.__class__.__function_name__, args_string, repr(self.return_type.type_expression))
+        if arg_type == "expression":
+            return None
 
-    def get_arg(self, position: int) -> PluginArgument:
-        """
-        Get the argument at a given position, raise a RuntimeException if it doesn't exists..
-        If a catch-all positional argument is defined, it will never raise a RuntimeException.
+        # quickfix issue #1774
+        allowed_element_type: inmanta_type.Type = inmanta_type.Type()
+        if arg_type == "list":
+            return inmanta_type.TypedList(allowed_element_type)
+        if arg_type == "dict":
+            return inmanta_type.TypedDict(allowed_element_type)
 
-        :param position: The position of the argument (excluding any Context argument)
-        """
-        if position < len(self.args):
-            return self.args[position]
-        elif self.var_args is not None:
-            return self.var_args
-        else:
-            raise RuntimeException(None, f"{self.get_full_name()}() got an unexpected positional argument: {position}")
+        plugin_line: Range = Range(self.location.file, self.location.lnr, 1, self.location.lnr + 1, 1)
+        locatable_type: LocatableString = LocatableString(arg_type, plugin_line, 0, None)
 
-    def get_kwarg(self, name: str) -> PluginArgument:
-        """
-        Get the argument with a given name, raise a RuntimeException if it doesn't exists.
-        If a catch-all keyword argument is defined, it will never raise a RuntimeException.
+        # stack of transformations to be applied to the base inmanta_type.Type
+        # transformations will be applied right to left
+        transformation_stack: List[Callable[[inmanta_type.Type], inmanta_type.Type]] = []
 
-        We currently don't support positional-only parameters, so we can simply look for any
-        parameter named this way, positional or not.
+        if locatable_type.value.endswith("?"):
+            locatable_type.value = locatable_type.value[0:-1]
+            transformation_stack.append(inmanta_type.NullableType)
 
-        :param name: The name of the argument
-        """
-        if name in self.all_args:
-            return self.all_args[name]
-        elif self.var_kwargs is not None:
-            return self.var_kwargs
-        else:
-            # Trying to provide a keyword argument which doesn't exist
-            # The exception raised here tries to match as closely as possible what python
-            # would have raised as exception
-            raise RuntimeException(None, f"{self.get_full_name()}() got an unexpected keyword argument: '{name}'")
+        if locatable_type.value.endswith("[]"):
+            locatable_type.value = locatable_type.value[0:-2]
+            transformation_stack.append(inmanta_type.TypedList)
 
-    def report_missing_arguments(
-        self, missing_args: collections.abc.Sequence[str], args_sort: Literal["positional", "keyword-only"]
-    ) -> None:
+        return reduce(lambda acc, transform: transform(acc), reversed(transformation_stack), resolver.get_type(locatable_type))
+
+    def _is_instance(self, value: object, arg_type: Type[object]) -> bool:
+        """
+        Check if value is of arg_type
         """
-        Helper method to raise an exception specifying that the given arguments are missing.  We try here
-        to stick as much as possible to the error that python would have raised, only changing its type.
+        if arg_type is None:
+            return True
 
-        The type of the exception raised is RuntimeException.
+        if hasattr(arg_type, "validate"):
+            return arg_type.validate(value)
 
-        If the list of missing_args is empty, we don't report any exception.
+        return isinstance(value, arg_type)
 
-        :param missing_args: The missing arguments we should report
-        :param args_sort: The sort of argument we are checking (positional or kw)
-        """
-        func = self.get_full_name()
-        if len(missing_args) == 1:
-            # The exception raised here tries to match as closely as possible what python
-            # would have raised as exception
-            raise RuntimeException(None, f"{func}() missing 1 required {args_sort} argument: '{missing_args[0]}'")
-        if len(missing_args) > 1:
-            arg_names = " and ".join(
-                (
-                    ", ".join(repr(arg) for arg in missing_args[:-1]),
-                    repr(missing_args[-1]),
-                )
-            )
-            # The exception raised here tries to match as closely as possible what python
-            # would have raised as exception
-            raise RuntimeException(None, f"{func}() missing {len(missing_args)} required {args_sort} arguments: {arg_names}")
-
-    def check_args(self, args: list[object], kwargs: dict[str, object]) -> bool:
-        """
-        Check if the arguments of the call match the function signature.
-
-        1. Check if we have too many arguments
-        2. Check if we have too few arguments
-        3. Check if we have any duplicate arguments (provided as positional and keyword)
-        4. Validate the type of each of the provided arguments
-
-        :param args: All the positional arguments to pass on to the plugin function
-        :param kwargs: All the keyword arguments to pass on to the plugin function
-        """
-        if self.var_args is None and len(args) > len(self.args):
-            # (1) We got too many positional arguments
-            # The exception raised here tries to match as closely as possible what python
-            # would have raised as exception
+    def check_args(self, args: List[object], kwargs: Dict[str, object]) -> bool:
+        """
+        Check if the arguments of the call match the function signature
+        """
+        max_arg = len(self.arguments)
+        if len(args) + len(kwargs) > max_arg:
+            raise Exception(
+                "Incorrect number of arguments for %s. Expected at most %d, got %d"
+                % (self.get_signature(), max_arg, len(args) + len(kwargs))
+            )
+        # check for missing arguments
+        required_args: FrozenSet[str] = frozenset(arg.arg_name for arg in self.arguments if not arg.has_default_value())
+        present_positional_args: FrozenSet[str] = frozenset(arg.arg_name for arg in self.arguments[: len(args)])
+        present_kwargs: FrozenSet[str] = frozenset(kwargs.keys())
+        missing_args = required_args.difference({*present_positional_args, *present_kwargs})
+        if missing_args:
             raise RuntimeException(
-                None, f"{self.get_full_name()}() takes {len(self.args)} positional arguments but {len(args)} were given"
-            )
-
-        # (2) Check that all positional arguments without a default are provided
-        missing_positional_arguments = [
-            arg.arg_name
-            for position, arg in enumerate(self.args)
-            if (
-                position >= len(args)  # No input from user in positional args
-                and arg.arg_name not in kwargs  # No input from user in keyword args
-                and not arg.has_default_value()  # No default value in plugin definition
-            )
-        ]
-        self.report_missing_arguments(missing_positional_arguments, "positional")
-
-        # (2) Check that all keyword arguments without a default are provided
-        missing_keyword_arguments = [
-            name
-            for name, arg in self.kwargs.items()
-            if (
-                arg.is_kw_only_argument  # The argument was not yet checked as positional arg
-                and name not in kwargs  # No input from user in keyword args
-                and not arg.has_default_value()  # No default value in plugin definition
+                None,
+                "Missing %d required arguments for %s(): %s"
+                % (len(missing_args), self.__class__.__function_name__, ",".join(missing_args)),
+            )
+        # check for kwargs overlap with positional arguments
+        overlapping_args: FrozenSet[str] = present_kwargs.intersection(present_positional_args)
+        if overlapping_args:
+            raise RuntimeException(
+                None,
+                "Multiple values for %s in %s()" % (",".join(overlapping_args), self.__class__.__function_name__),
             )
-        ]
-        self.report_missing_arguments(missing_keyword_arguments, "keyword-only")
-
-        # Validate all positional arguments
-        for position, value in enumerate(args):
-            # (1) Get the corresponding argument, fails if we don't have one
-            arg = self.get_arg(position)
 
-            # (4) Validate the input value
-            if not arg.validate(value):
+        def is_valid(expected_arg: PluginArgument, expected_type: Type[object], arg: object) -> bool:
+            if isinstance(arg, Unknown):
                 return False
 
-        # Validate all kw arguments
-        for name, value in kwargs.items():
-            # (1) Get the corresponding kwarg, fails if we don't have one
-            kwarg = self.get_kwarg(name)
-
-            # (3) Make sure that our argument is not provided twice
-            if kwarg.arg_position is not None and kwarg.arg_position < len(args):
-                # The exception raised here tries to match as closely as possible what python
-                # would have raised as exception
-                raise RuntimeException(None, f"{self.get_full_name()}() got multiple values for argument '{name}'")
+            if not self._is_instance(arg, expected_type):
+                raise Exception(
+                    "Invalid type for argument %s of '%s', it should be %s and %s given."
+                    % (expected_arg.arg_name, self.__class__.__function_name__, expected_arg.arg_type, arg.__class__.__name__)
+                )
+            return True
 
-            # (4) Validate the input value
-            if not kwarg.validate(value):
+        for i in range(len(args)):
+            if not is_valid(self.arguments[i], self.argtypes[i], args[i]):
                 return False
+        arg_types: Dict[str, Tuple[PluginArgument, Optional[inmanta_type.Type]]] = {
+            arg.arg_name: (arg, self.argtypes[i]) for i, arg in enumerate(self.arguments)
+        }
+        for k, v in kwargs.items():
+            try:
+                (expected_arg, expected_type) = arg_types[k]
+                if not is_valid(expected_arg, expected_type, v):
+                    return False
+            except KeyError:
+                raise RuntimeException(None, "Invalid keyword argument '%s' for '%s()'" % (k, self.__class__.__function_name__))
         return True
 
     def emit_statement(self) -> "DynamicStatement":
         """
         This method is called to determine if the plugin call pushes a new
         statement
         """
@@ -668,27 +459,27 @@
         """
         if "bin" in self.opts and self.opts["bin"] is not None:
             for _bin in self.opts["bin"]:
                 p = subprocess.Popen(["bash", "-c", "type -p %s" % _bin], stdout=subprocess.PIPE)
                 result = p.communicate()
 
                 if len(result[0]) == 0:
-                    raise Exception(f"{self.__function_name__} requires {_bin} to be available in $PATH")
+                    raise Exception("%s requires %s to be available in $PATH" % (self.__function_name__, _bin))
 
     @classmethod
     def deprecate_function(cls, replaced_by: Optional[str] = None) -> None:
         cls.deprecated = True
         cls.replaced_by = replaced_by
 
     def __call__(self, *args: object, **kwargs: object) -> object:
         """
         The function call itself
         """
         if self.deprecated:
-            msg: str = f"Plugin '{self.get_full_name()}' is deprecated."
+            msg: str = f"Plugin '{self.__function_name__}' in module '{self.__module__}' is deprecated."
             if self.replaced_by:
                 msg += f" It should be replaced by '{self.replaced_by}'."
             warnings.warn(PluginDeprecationWarning(msg))
         self.check_requirements()
 
         def new_arg(arg: object) -> object:
             if isinstance(arg, Context):
@@ -701,21 +492,39 @@
         new_args = [new_arg(arg) for arg in args]
         new_kwargs = {k: new_arg(v) for k, v in kwargs.items()}
 
         value = self.call(*new_args, **new_kwargs)
 
         value = DynamicProxy.unwrap(value)
 
-        # Validate the returned value
-        self.return_type.validate(value)
+        if self.returntype is not None and not isinstance(value, Unknown):
+            valid = False
+            exception = None
+
+            try:
+                valid = value is None or self._is_instance(value, self.returntype)
+            except RuntimeException as e:
+                raise e
+            except Exception as exp:
+                exception = exp
+
+            if not valid:
+                msg = ""
+                if exception is not None:
+                    msg = "\n\tException details: " + str(exception)
+
+                raise Exception(
+                    "Plugin %s should return value of type %s ('%s' was returned) %s"
+                    % (self.__class__.__function_name__, self.returntype, value, msg)
+                )
 
         return value
 
     def get_full_name(self) -> str:
-        return f"{self.ns.get_full_name()}::{self.__class__.__function_name__}"
+        return "%s::%s" % (self.ns.get_full_name(), self.__class__.__function_name__)
 
     def type_string(self) -> str:
         return self.get_full_name()
 
 
 @stable_api
 class PluginException(Exception):
@@ -726,15 +535,15 @@
     def __init__(self, message: str) -> None:
         self.message = message
 
 
 @stable_api
 def plugin(
     function: Optional[Callable] = None,
-    commands: Optional[list[str]] = None,
+    commands: Optional[List[str]] = None,
     emits_statements: bool = False,
     allow_unknown: bool = False,
 ) -> Callable:
     """
     Python decorator to register functions with inmanta as plugin
 
     :param function: The function to register with inmanta. This is the first argument when it is used as decorator.
@@ -743,15 +552,15 @@
     :param emits_statements: Set to true if this plugin emits new statements that the compiler should execute. This is only
                              required for complex plugins such as integrating a template engine.
     :param allow_unknown: Set to true if this plugin accepts Unknown values as valid input.
     """
 
     def curry_name(
         name: Optional[str] = None,
-        commands: Optional[list[str]] = None,
+        commands: Optional[List[str]] = None,
         emits_statements: bool = False,
         allow_unknown: bool = False,
     ) -> Callable:
         """
         Function to curry the name of the function
         """
```

### Comparing `inmanta-core-8.7.4/src/inmanta/postgresproc.py` & `inmanta-core-9.3.0/src/inmanta/postgresproc.py`

 * *Files 1% similar despite different names*

```diff
@@ -37,25 +37,25 @@
         path = os.path.abspath(path)
         executable_path = os.path.join(path, executable)
         if os.path.isfile(executable_path):
             return executable_path
 
     # fall back to pg_config
     try:
-        bindir = subprocess.check_output(["pg_config", "--bindir"], text=True).strip()
+        bindir = subprocess.check_output(["pg_config", "--bindir"], universal_newlines=True).strip()
         binpath = os.path.join(bindir, executable)
         if os.path.isfile(binpath):
             return binpath
     except FileNotFoundError:
         return None
 
     return None
 
 
-class PostgresProc:
+class PostgresProc(object):
     def __init__(
         self, port: int, pg_ctl_bin: Optional[str] = None, initdb_bin: Optional[str] = None, db_path: Optional[str] = None
     ) -> None:
         self.port = port
         self.db_path = db_path
         if self.db_path:
             if os.path.exists(self.db_path) and os.path.isfile(self.db_path):
```

### Comparing `inmanta-core-8.7.4/src/inmanta/profile_mem.py` & `inmanta-core-9.3.0/src/inmanta/server/services/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -11,13 +11,7 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-import gc
-import sys
-
-
-def total_size() -> int:
-    return sum(sys.getsizeof(x) for x in gc.get_objects())
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/__init__.py` & `inmanta-core-9.3.0/src/inmanta/protocol/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/common.py` & `inmanta-core-9.3.0/src/inmanta/protocol/common.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,20 +22,37 @@
 import io
 import json
 import logging
 import re
 import time
 import uuid
 from collections import defaultdict
-from collections.abc import Callable, Coroutine, Iterable, MutableMapping
 from datetime import datetime
 from enum import Enum
-from functools import partial
 from inspect import Parameter
-from typing import TYPE_CHECKING, Any, ClassVar, Generic, Optional, TypeVar, Union, cast, get_type_hints
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Callable,
+    ClassVar,
+    Coroutine,
+    Dict,
+    Generic,
+    Iterable,
+    List,
+    MutableMapping,
+    Optional,
+    Set,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    cast,
+    get_type_hints,
+)
 from urllib import parse
 
 import docstring_parser
 import jwt
 import pydantic
 import typing_inspect
 from pydantic.error_wrappers import ValidationError
@@ -65,22 +82,22 @@
 HTML_CONTENT = "text/html"
 OCTET_STREAM_CONTENT = "application/octet-stream"
 ZIP_CONTENT = "application/zip"
 UTF8_CHARSET = "charset=UTF-8"
 HTML_CONTENT_WITH_UTF8_CHARSET = f"{HTML_CONTENT}; {UTF8_CHARSET}"
 
 
-class ArgOption:
+class ArgOption(object):
     """
     Argument options to transform arguments before dispatch
     """
 
     def __init__(
         self,
-        getter: Callable[[Any, dict[str, str]], Coroutine[Any, Any, Any]],
+        getter: Callable[[Any, Dict[str, str]], Coroutine[Any, Any, Any]],
         # Type is Any to Any because it transforms from method to handler but in the current typing there is no link
         header: Optional[str] = None,
         reply_header: bool = True,
     ) -> None:
         """
         :param header: Map this argument to a header with the following name.
         :param reply_header: If the argument is mapped to a header, this header will also be included in the reply
@@ -88,39 +105,36 @@
                        type of the argument. This method can raise an HTTPException to return a 404 for example.
         """
         self.header = header
         self.reply_header = reply_header
         self.getter = getter
 
 
-class Request:
+class Request(object):
     """
     A protocol request
     """
 
-    def __init__(self, url: str, method: str, headers: dict[str, str], body: Optional[JsonType]) -> None:
+    def __init__(self, url: str, method: str, headers: Dict[str, str], body: Optional[JsonType]) -> None:
         self._url = url
         self._method = method
         self._headers = headers
         self._body = body
-        # Reply ID is used to send back the result
-        # If None, no reply is expected
-        #  i.e. this call will immediately return, potentially even before the request is dispatched
         self._reply_id: Optional[uuid.UUID] = None
 
     @property
     def body(self) -> Optional[JsonType]:
         return self._body
 
     @property
     def url(self) -> str:
         return self._url
 
     @property
-    def headers(self) -> dict[str, str]:
+    def headers(self) -> Dict[str, str]:
         return self._headers
 
     @property
     def method(self) -> str:
         return self._method
 
     def set_reply_id(self, reply_id: uuid.UUID) -> None:
@@ -163,18 +177,18 @@
 
     def __init__(
         self,
         status_code: int = 200,
         headers: MutableMapping[str, str] = {},
         response: Optional[T] = None,
         content_type: str = JSON_CONTENT,
-        links: Optional[dict[str, str]] = None,
+        links: Optional[Dict[str, str]] = None,
     ) -> None:
         self._status_code = status_code
-        self._warnings: list[str] = []
+        self._warnings: List[str] = []
         self._headers = headers
         self._headers[CONTENT_TYPE] = content_type
         self._content_type = content_type
         self._response = response
         self._links = links
 
     @property
@@ -195,15 +209,15 @@
                 return {"metadata": {"warnings": self._warnings}}
             return None
 
         return self._response
 
     def _get_with_envelope(self, envelope_key: str) -> ReturnTypes:
         """Get the body with an envelope specified"""
-        response: dict[str, Any] = {}
+        response: Dict[str, Any] = {}
         response[envelope_key] = self._response
 
         if len(self._warnings):
             response["metadata"] = {"warnings": self._warnings}
         if self._links:
             response["links"] = self._links
 
@@ -220,15 +234,15 @@
         :param envelope_key: The envelope key to use
         """
         if not envelope or self._headers[CONTENT_TYPE] != JSON_CONTENT:
             return self._get_without_envelope()
         else:
             return self._get_with_envelope(envelope_key)
 
-    def add_warnings(self, warnings: list[str]) -> None:
+    def add_warnings(self, warnings: List[str]) -> None:
         self._warnings.extend(warnings)
 
     def __repr__(self) -> str:
         return f"ReturnValue<code={self.status_code} headers=<{self.headers}> response=<{self._response}>>"
 
     def __str__(self) -> str:
         return repr(self)
@@ -269,22 +283,22 @@
         return self._status_code
 
 
 class InvalidPathException(Exception):
     """This exception is raised when a path definition is invalid."""
 
 
-class UrlPath:
+class UrlPath(object):
     """Class to handle manipulation of method paths"""
 
     def __init__(self, path: str) -> None:
         self._path = path
         self._vars = self._parse_path()
 
-    def _parse_path(self) -> list[str]:
+    def _parse_path(self) -> List[str]:
         if self._path[0] != "/":
             raise InvalidPathException(f"{self._path} should start with a /")
 
         return re.findall("<([^<>]+)>", self._path)
 
     def validate_vars(self, method_vars: Iterable[str], function_name: str) -> None:
         """Are all variable defined in the method"""
@@ -292,15 +306,15 @@
             if var not in method_vars:
                 raise InvalidPathException(f"Variable {var} in path {self._path} is not defined in function {function_name}.")
 
     @property
     def path(self) -> str:
         return self._path
 
-    def generate_path(self, variables: dict[str, str]) -> str:
+    def generate_path(self, variables: Dict[str, str]) -> str:
         """Create a path with all variables substituted"""
         path = self._path
         for var in self._vars:
             if var not in variables:
                 raise KeyError(f"No value provided for variable {var}")
             path = path.replace(f"<{var}>", variables[var])
 
@@ -331,20 +345,20 @@
 
 class MethodArgumentsBaseModel(pydantic.BaseModel):
     _normalize_timestamps: ClassVar[classmethod] = pydantic.validator("*", allow_reuse=True)(
         validator_timezone_aware_timestamps
     )
 
 
-class MethodProperties:
+class MethodProperties(object):
     """
     This class stores the information from a method definition
     """
 
-    methods: dict[str, list["MethodProperties"]] = defaultdict(list)
+    methods: Dict[str, List["MethodProperties"]] = defaultdict(list)
 
     @classmethod
     def register_method(cls, properties: "MethodProperties") -> None:
         """
         Register new method properties. Multiple properties on a method is supported but the (URL, API version) combination has
         to be unique.
         """
@@ -359,21 +373,21 @@
 
     def __init__(
         self,
         function: MethodType,
         path: str,
         operation: str,
         reply: bool,
-        arg_options: dict[str, ArgOption],
+        arg_options: Dict[str, ArgOption],
         timeout: Optional[int],
         server_agent: bool,
         api: Optional[bool],
         agent_server: bool,
         validate_sid: Optional[bool],
-        client_types: list[const.ClientType],
+        client_types: List[const.ClientType],
         api_version: int,
         api_prefix: str,
         envelope: bool,
         typed: bool = False,
         envelope_key: str = const.ENVELOPE_KEY,
         strict_typing: bool = True,
         enforce_auth: bool = True,
@@ -399,15 +413,14 @@
         :param typed: Is the method definition typed or not
         :param envelope_key: The envelope key to use
         :param strict_typing: If true, does not allow `Any` when validating argument types
         :param enforce_auth: When set to true authentication is enforced on this endpoint. When set to false, authentication is
                              not enforced, even if auth is enabled.
         :param varkw: If true, additional arguments are allowed and will be dispatched to the handler. The handler is
                       responsible for the validation.
-        :param reply: If False, this is a fire-and-forget query: we will not wait for any result, just deliver the call
         """
         if api is None:
             api = not server_agent and not agent_server
 
         if validate_sid is None:
             validate_sid = agent_server and not api
 
@@ -434,49 +447,49 @@
 
         self._parsed_docstring = docstring_parser.parse(text=function.__doc__, style=docstring_parser.DocstringStyle.REST)
         self._docstring_parameter_map = {p.arg_name: p.description for p in self._parsed_docstring.params}
 
         # validate client types
         for ct in self._client_types:
             if ct not in [client_type for client_type in const.ClientType]:
-                raise InvalidMethodDefinition(f"Invalid client type {ct} specified for function {function}")
+                raise InvalidMethodDefinition("Invalid client type %s specified for function %s" % (ct, function))
 
         self._validate_function_types(typed)
         self.argument_validator = self.arguments_to_pydantic()
 
     @property
     def varkw(self) -> bool:
         """Does the method allow for a variable number of key/value arguments."""
         return self._varkw
 
     @property
     def enforce_auth(self) -> bool:
         return self._enforce_auth
 
-    def validate_arguments(self, values: dict[str, Any]) -> dict[str, Any]:
+    def validate_arguments(self, values: Dict[str, Any]) -> Dict[str, Any]:
         """
         Validate methods arguments. Values is a dict with key/value pairs for the arguments (similar to kwargs). This method
         validates and converts types if required (e.g. str to int). The returns value has the correct typing to dispatch
         to method handlers.
         """
         try:
             out = self.argument_validator(**values)
             return {f: getattr(out, f) for f in out.__fields__.keys()}
         except ValidationError as e:
             error_msg = f"Failed to validate argument\n{str(e)}"
             LOGGER.exception(error_msg)
             raise BadRequest(error_msg, {"validation_errors": e.errors()})
 
-    def arguments_to_pydantic(self) -> type[pydantic.BaseModel]:
+    def arguments_to_pydantic(self) -> Type[pydantic.BaseModel]:
         """
         Convert the method arguments to a pydantic model that allows to validate a message body with pydantic
         """
         sig = inspect.signature(self.function)
 
-        def to_tuple(param: Parameter) -> tuple[object, Optional[object]]:
+        def to_tuple(param: Parameter) -> Tuple[object, Optional[object]]:
             if param.annotation is Parameter.empty:
                 return (Any, param.default if param.default is not Parameter.empty else None)
             if param.default is not Parameter.empty:
                 return (param.annotation, param.default)
             else:
                 return (param.annotation, None)
 
@@ -540,20 +553,20 @@
         elif full_spec.varkw is not None:
             raise InvalidMethodDefinition(
                 f"A key/value argument is only allowed when `varkw` is set to true in method {self.function}."
             )
 
         self._validate_return_type(type_hints["return"], strict=self.strict_typing)
 
-    def _validate_return_type(self, arg_type: type, *, strict: bool = True) -> None:
+    def _validate_return_type(self, arg_type: Type, *, strict: bool = True) -> None:
         """Validate the return type"""
         # Note: we cannot call issubclass on a generic type!
         arg = "return type"
 
-        def is_return_value_type(arg_type: type) -> bool:
+        def is_return_value_type(arg_type: Type) -> bool:
             if typing_inspect.is_generic_type(arg_type):
                 origin = typing_inspect.get_origin(arg_type)
                 assert origin is not None  # Make mypy happy
                 return types.issubclass(origin, ReturnValue)
             else:
                 return False
 
@@ -569,15 +582,15 @@
         ):
             raise InvalidMethodDefinition("ReturnValue should have a type specified.")
 
         else:
             self._validate_type_arg(arg, arg_type, allow_none_type=True, strict=strict)
 
     def _validate_type_arg(
-        self, arg: str, arg_type: type, *, strict: bool = True, allow_none_type: bool = False, in_url: bool = False
+        self, arg: str, arg_type: Type, *, strict: bool = True, allow_none_type: bool = False, in_url: bool = False
     ) -> None:
         """Validate the given type arg recursively
 
         :param arg: The name of the argument
         :param arg_type: The annotated type fo the argument
         :param strict: If true, does not allow `Any`
         :param allow_none_type: If true, allow `None` as the type for this argument
@@ -596,15 +609,15 @@
         if arg_type is Any:
             if strict:
                 raise InvalidMethodDefinition(f"Invalid type for argument {arg}: Any type is not allowed in strict mode")
             return
 
         if typing_inspect.is_union_type(arg_type):
             # Make sure there is only one list and one dict in the union, otherwise we cannot process the arguments
-            cnt: dict[str, int] = defaultdict(int)
+            cnt: Dict[str, int] = defaultdict(lambda: 0)
             for sub_arg in typing_inspect.get_args(arg_type, evaluate=True):
                 self._validate_type_arg(arg, sub_arg, strict=strict, allow_none_type=allow_none_type, in_url=in_url)
 
                 if typing_inspect.is_generic_type(sub_arg):
                     # there is a difference between python 3.6 and >=3.7
                     if hasattr(sub_arg, "__name__"):
                         cnt[sub_arg.__name__] += 1
@@ -677,15 +690,15 @@
 
     @property
     def operation(self) -> str:
         return self._operation
 
     @property
     @stable_api
-    def arg_options(self) -> dict[str, ArgOption]:
+    def arg_options(self) -> Dict[str, ArgOption]:
         return self._arg_options
 
     @property
     def timeout(self) -> Optional[int]:
         return self._timeout
 
     @property
@@ -697,15 +710,15 @@
         return self._agent_server
 
     @property
     def reply(self) -> bool:
         return self._reply
 
     @property
-    def client_types(self) -> list[const.ClientType]:
+    def client_types(self) -> List[const.ClientType]:
         return self._client_types
 
     @property
     def envelope(self) -> bool:
         return self._envelope
 
     @property
@@ -767,15 +780,15 @@
             if not inspect.isclass(cls) or BaseHttpException not in cls.mro():
                 return 500
             cls_instance = cls()
             return cls_instance.to_status()
         except Exception:
             return 500
 
-    def get_description_foreach_http_status_code(self) -> dict[int, str]:
+    def get_description_foreach_http_status_code(self) -> Dict[int, str]:
         """
         This method return a mapping from the HTTP status code to
         the associated description specified in the docstring using
         the :returns: and :raises <exception>: statements.
         """
         result = {}
 
@@ -789,15 +802,15 @@
         for raise_statement in self._parsed_docstring.raises:
             exception_name = raise_statement.type_name
             status_code = self._get_http_status_code_for_exception(exception_name)
             result[status_code] = raise_statement.description if raise_statement.description is not None else ""
 
         return result
 
-    def get_call_headers(self) -> set[str]:
+    def get_call_headers(self) -> Set[str]:
         """
         Returns the set of headers required to create call
         """
         headers = set()
         headers.add("Authorization")
 
         for arg in self._arg_options.values():
@@ -809,27 +822,27 @@
     def get_listen_url(self) -> str:
         """
         Create a listen url for this method
         """
         url = "/%s/v%d" % (self._api_prefix, self._api_version)
         return url + self._path.generate_regex_path()
 
-    def get_call_url(self, msg: dict[str, str]) -> str:
+    def get_call_url(self, msg: Dict[str, str]) -> str:
         """
         Create a calling url for the client
         """
         url = "/%s/v%d" % (self._api_prefix, self._api_version)
         return url + self._path.generate_path({k: parse.quote(str(v), safe="") for k, v in msg.items()})
 
-    def build_call(self, args: list[object], kwargs: dict[str, object] = {}) -> Request:
+    def build_call(self, args: List[object], kwargs: Dict[str, object] = {}) -> Request:
         """
         Build a call from the given arguments. This method returns the url, headers, and body for the call.
         """
         # create the message
-        msg: dict[str, Any] = dict(kwargs)
+        msg: Dict[str, Any] = dict(kwargs)
 
         # map the argument in arg to names
         argspec = inspect.getfullargspec(self.function)
         for i in range(len(args)):
             msg[argspec.args[i]] = args[i]
 
         path_params = {k for k, v in msg.items() if v is not None and f"<{k}>" in self._path.path}
@@ -869,16 +882,16 @@
             body = None
         else:
             body = msg
 
         return Request(url=url, method=self.operation, headers=headers, body=body)
 
     def _encode_dict_for_get(
-        self, query_param_name: str, query_param_value: dict[str, Union[Any, list[Any]]]
-    ) -> dict[str, str]:
+        self, query_param_name: str, query_param_value: Dict[str, Union[Any, List[Any]]]
+    ) -> Dict[str, str]:
         """Dicts are encoded in the following manner: param = {'ab': 1, 'cd': 2} to param.abc=1&param.cd=2"""
         sub_dict = {f"{query_param_name}.{key}": value for key, value in query_param_value.items()}
         return sub_dict
 
     @stable_api
     def get_openapi_parameter_type_for(self, param_name: str) -> Optional[openapi_model.ParameterType]:
         """
@@ -891,15 +904,15 @@
             return openapi_model.ParameterType.path
         elif self.arguments_in_url():
             return openapi_model.ParameterType.query
         else:
             return None
 
 
-class UrlMethod:
+class UrlMethod(object):
     """
     This class holds the method definition together with the API (url, method) information
 
     :param properties: The properties of this method
     :param endpoint: The object on which this method is defined
     :param handler: The method to call on the endpoint
     :param method_name: The name of the method to call on the endpoint
@@ -942,42 +955,42 @@
         return self._properties.get_long_method_description()
 
     def get_operation(self) -> str:
         return self._properties.operation
 
 
 # Util functions
-def custom_json_encoder(o: object, tz_aware: bool = False) -> Union[ReturnTypes, util.JSONSerializable]:
+def custom_json_encoder(o: object) -> Union[ReturnTypes, util.JSONSerializable]:
     """
     A custom json encoder that knows how to encode other types commonly used by Inmanta
     """
     if isinstance(o, execute.util.Unknown):
         return const.UNKNOWN_STRING
 
     # handle common python types
-    return util.api_boundary_json_encoder(o, tz_aware)
+    return util.api_boundary_json_encoder(o)
 
 
-def attach_warnings(code: int, value: Optional[JsonType], warnings: Optional[list[str]]) -> tuple[int, JsonType]:
+def attach_warnings(code: int, value: Optional[JsonType], warnings: Optional[List[str]]) -> Tuple[int, JsonType]:
     if value is None:
         value = {}
     if warnings:
         meta = value.setdefault("metadata", {})
         warns = meta.setdefault("warnings", [])
         warns.extend(warnings)
     return code, value
 
 
-def json_encode(value: ReturnTypes, tz_aware: bool = False) -> str:
+def json_encode(value: ReturnTypes) -> str:
     """Our json encode is able to also serialize other types than a dict."""
     # see json_encode in tornado.escape
-    return json.dumps(value, default=partial(custom_json_encoder, tz_aware=tz_aware)).replace("</", "<\\/")
+    return json.dumps(value, default=custom_json_encoder).replace("</", "<\\/")
 
 
-def gzipped_json(value: JsonType) -> tuple[bool, Union[bytes, str]]:
+def gzipped_json(value: JsonType) -> Tuple[bool, Union[bytes, str]]:
     json_string = json_encode(value)
     if len(json_string) < web.GZipContentEncoding.MIN_LENGTH:
         return False, json_string
 
     gzip_value = io.BytesIO()
     gzip_file = gzip.GzipFile(mode="w", fileobj=gzip_value, compresslevel=web.GZipContentEncoding.GZIP_LEVEL)
 
@@ -990,27 +1003,27 @@
 def shorten(msg: str, max_len: int = 10) -> str:
     if len(msg) < max_len:
         return msg
     return msg[0 : max_len - 3] + "..."
 
 
 def encode_token(
-    client_types: list[str], environment: Optional[str] = None, idempotent: bool = False, expire: Optional[float] = None
+    client_types: List[str], environment: Optional[str] = None, idempotent: bool = False, expire: Optional[float] = None
 ) -> str:
     cfg = inmanta_config.AuthJWTConfig.get_sign_config()
     if cfg is None:
         raise Exception("No JWT signing configuration available.")
 
     for ct in client_types:
         if ct not in cfg.client_types:
             raise Exception(
                 f"The signing config does not support the requested client type {ct}. Only {cfg.client_types} are allowed."
             )
 
-    payload: dict[str, Any] = {"iss": cfg.issuer, "aud": [cfg.audience], const.INMANTA_URN + "ct": ",".join(client_types)}
+    payload: Dict[str, Any] = {"iss": cfg.issuer, "aud": [cfg.audience], const.INMANTA_URN + "ct": ",".join(client_types)}
 
     if not idempotent:
         payload["iat"] = int(time.time())
 
         if cfg.expire > 0:
             payload["exp"] = int(time.time() + cfg.expire)
         elif expire is not None:
@@ -1018,15 +1031,15 @@
 
     if environment is not None:
         payload[const.INMANTA_URN + "env"] = environment
 
     return jwt.encode(payload, cfg.key, cfg.algo)
 
 
-def decode_token(token: str) -> dict[str, str]:
+def decode_token(token: str) -> Dict[str, str]:
     try:
         # First decode the token without verification
         header = jwt.get_unverified_header(token)
         payload = jwt.decode(token, options={"verify_signature": False})
     except Exception:
         raise exceptions.Forbidden("Unable to decode provided JWT bearer token.")
 
@@ -1061,15 +1074,15 @@
     except Exception as e:
         raise exceptions.Forbidden(*e.args)
 
     return payload
 
 
 @stable_api
-class Result:
+class Result(object):
     """
     A result of a method call
     """
 
     def __init__(self, code: int = 0, result: Optional[JsonType] = None) -> None:
         self._result = result
         self.code = code
@@ -1112,15 +1125,15 @@
     def callback(self, fnc: Callable[["Result"], None]) -> None:
         """
         Set a callback function that is to be called when the result is ready.
         """
         self._callback = fnc
 
 
-class SessionManagerInterface:
+class SessionManagerInterface(object):
     """
     An interface for a sessionmanager
     """
 
     def validate_sid(self, sid: uuid.UUID) -> bool:
         """
         Check if the given sid is a valid session
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/decorators.py` & `inmanta-core-9.3.0/src/inmanta/protocol/decorators.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,38 +12,37 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import inspect
-from collections.abc import Callable
-from typing import Optional, TypeVar, Union
+from typing import Callable, Dict, List, Optional, TypeVar, Union
 
 from inmanta import const
 from inmanta.types import Apireturn, HandlerType, MethodType
 
 from . import common
 
 FuncT = TypeVar("FuncT", bound=HandlerType)
 
 
-class handle:  # noqa: N801
+class handle(object):  # noqa: N801
     """
     Decorator for subclasses of an endpoint to handle protocol methods
 
     :param method: A subclass of method that defines the method
     :param api_version: When specific this handler is only associated with a method of the specific api version. If the
                         version is not defined, the handler is not associated with a rest endpoint.
     :param kwargs: Map arguments in the message from one name to an other
     """
 
     def __init__(self, method: Callable[..., Apireturn], api_version: Optional[int] = None, **kwargs: str) -> None:
         self.method = method
-        self.mapping: dict[str, str] = kwargs
+        self.mapping: Dict[str, str] = kwargs
         self._api_version = api_version
 
     def __call__(self, function: FuncT) -> FuncT:
         """
         The wrapping
         """
         if not inspect.iscoroutinefunction(function):
@@ -58,21 +57,21 @@
 MethodT = TypeVar("MethodT", bound=MethodType)
 
 
 def method(
     path: str,
     operation: str = "POST",
     reply: bool = True,
-    arg_options: dict[str, common.ArgOption] = {},
+    arg_options: Dict[str, common.ArgOption] = {},
     timeout: Optional[int] = None,
     server_agent: bool = False,
     api: Optional[bool] = None,
     agent_server: bool = False,
     validate_sid: Optional[bool] = None,
-    client_types: list[const.ClientType] = [const.ClientType.api],
+    client_types: List[const.ClientType] = [const.ClientType.api],
     api_version: int = 1,
     api_prefix: str = "api",
     envelope: bool = False,
     envelope_key: str = const.ENVELOPE_KEY,
 ) -> Callable[..., Callable]:
     """
     Decorator to identify a method as a RPC call. The arguments of the decorator are used by each transport to build
@@ -128,21 +127,21 @@
     return wrapper
 
 
 def typedmethod(
     path: Union[str, list[str]],
     operation: str = "POST",
     reply: bool = True,
-    arg_options: dict[str, common.ArgOption] = {},
+    arg_options: Dict[str, common.ArgOption] = {},
     timeout: Optional[int] = None,
     server_agent: bool = False,
     api: Optional[bool] = None,
     agent_server: bool = False,
     validate_sid: Optional[bool] = None,
-    client_types: list[const.ClientType] = [const.ClientType.api],
+    client_types: List[const.ClientType] = [const.ClientType.api],
     api_version: int = 1,
     api_prefix: str = "api",
     envelope_key: str = const.ENVELOPE_KEY,
     strict_typing: bool = True,
     enforce_auth: bool = True,
     varkw: bool = False,
 ) -> Callable[..., Callable]:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/endpoints.py` & `inmanta-core-9.3.0/src/inmanta/protocol/endpoints.py`

 * *Files 10% similar despite different names*

```diff
@@ -18,71 +18,53 @@
 import asyncio
 import inspect
 import logging
 import socket
 import uuid
 from asyncio import CancelledError, run_coroutine_threadsafe, sleep
 from collections import abc, defaultdict
-from collections.abc import Callable, Coroutine
 from enum import Enum
-from typing import Any, Optional
+from typing import Any, Callable, Coroutine, Dict, List, Optional, Set, Tuple
 from urllib import parse
 
 from inmanta import config as inmanta_config
 from inmanta import util
 from inmanta.protocol.common import UrlMethod
 from inmanta.util import TaskHandler
 
 from . import common
 from .rest import client
 
 LOGGER: logging.Logger = logging.getLogger(__name__)
-TORNADO_LOGGER: logging.Logger = logging.getLogger("tornado.general")
-TORNADO_LOGGER.setLevel(logging.DEBUG)
 
 
-# Create a custom log handler for Tornados 'max_clients limit reached' debug logs
-class TornadoDebugLogHandler(logging.Handler):
-    def emit(self, record: logging.LogRecord) -> None:
-        if (
-            record.levelno == logging.DEBUG
-            and record.name.startswith("tornado.general")
-            and record.msg.startswith("max_clients limit reached")
-        ):
-            LOGGER.warning(record.msg)  # Log Tornado log as inmanta warnings
-
-
-tornado_logger = TornadoDebugLogHandler()
-TORNADO_LOGGER.addHandler(tornado_logger)
-
-
-class CallTarget:
+class CallTarget(object):
     """
     A baseclass for all classes that are target for protocol calls / methods
     """
 
-    def _get_endpoint_metadata(self) -> dict[str, list[tuple[str, Callable]]]:
+    def _get_endpoint_metadata(self) -> Dict[str, List[Tuple[str, Callable]]]:
         total_dict = {
             method_name: method
             for method_name, method in inspect.getmembers(self)
             if callable(method) and method_name[0] != "_"
         }
 
-        methods: dict[str, list[tuple[str, Callable]]] = defaultdict(list)
+        methods: Dict[str, List[Tuple[str, Callable]]] = defaultdict(list)
         for name, attr in total_dict.items():
             if hasattr(attr, "__protocol_method__"):
                 methods[attr.__protocol_method__.__name__].append((name, attr))
 
         return methods
 
-    def get_op_mapping(self) -> dict[str, dict[str, UrlMethod]]:
+    def get_op_mapping(self) -> Dict[str, Dict[str, UrlMethod]]:
         """
         Build a mapping between urls, ops and methods
         """
-        url_map: dict[str, dict[str, UrlMethod]] = defaultdict(dict)
+        url_map: Dict[str, Dict[str, UrlMethod]] = defaultdict(dict)
 
         # Loop over all methods in this class that have a handler annotation. The handler annotation refers to a method
         # definition. This method definition defines how the handler is invoked.
         for method, handler_list in self._get_endpoint_metadata().items():
             for method_handlers in handler_list:
                 # Go over all method annotation on the method associated with the handler
                 for properties in common.MethodProperties.methods[method]:
@@ -105,28 +87,28 @@
 
 class Endpoint(TaskHandler):
     """
     An end-point in the rpc framework
     """
 
     def __init__(self, name: str):
-        super().__init__()
+        super(Endpoint, self).__init__()
         self._name: str = name
         self._node_name: str = inmanta_config.nodename.get()
-        self._end_point_names: set[str] = set()
-        self._targets: list[CallTarget] = []
+        self._end_point_names: Set[str] = set()
+        self._targets: List[CallTarget] = []
 
     def add_call_target(self, target: CallTarget) -> None:
         self._targets.append(target)
 
     @property
-    def call_targets(self) -> list[CallTarget]:
+    def call_targets(self) -> List[CallTarget]:
         return self._targets
 
-    def get_end_point_names(self) -> set[str]:
+    def get_end_point_names(self) -> Set[str]:
         return self._end_point_names
 
     async def add_end_point_name(self, name: str) -> None:
         """
         Add an additional name to this endpoint to which it reacts and sends out in heartbeats
         """
         LOGGER.debug("Adding '%s' as endpoint", name)
@@ -154,24 +136,23 @@
     def get_node_name(self) -> str:
         return self._node_name
 
     node_name = property(get_node_name)
 
     async def stop(self) -> None:
         """Stop this endpoint"""
-        await super().stop()
+        await super(Endpoint, self).stop()
 
 
 class SessionEndpoint(Endpoint, CallTarget):
     """
     An endpoint for clients that make calls to a server and that receive calls back from the server using long-poll
     """
 
     _client: "SessionClient"
-    _heartbeat_client: "SessionClient"
 
     def __init__(self, name: str, timeout: int = 120, reconnect_delay: int = 5):
         super().__init__(name)
         self._transport = client.RESTClient
         self._sched = util.Scheduler("session endpoint")
 
         self._env_id: Optional[uuid.UUID] = None
@@ -198,68 +179,69 @@
         else:
             self._env_id = environment_id
 
     async def start_connected(self) -> None:
         """
         This method is called after starting the client transport, but before sending the first heartbeat.
         """
+        pass
 
     async def start(self) -> None:
         """
         Connect to the server and use a heartbeat and long-poll for two-way communication
         """
         assert self._env_id is not None
-        LOGGER.info("Starting agent for %s", str(self.sessionid))
+        LOGGER.log(3, "Starting agent for %s", str(self.sessionid))
         self._client = SessionClient(self.name, self.sessionid, timeout=self.server_timeout)
-        self._heartbeat_client = SessionClient(self.name, self.sessionid, timeout=self.server_timeout, force_instance=True)
         await self.start_connected()
         self.add_background_task(self.perform_heartbeat())
 
     async def stop(self) -> None:
-        self._heartbeat_client.close()
         await self._sched.stop()
-        await super().stop()
+        await super(SessionEndpoint, self).stop()
 
     async def on_reconnect(self) -> None:
         """
         Called when a connection becomes active. i.e. when a first heartbeat is received after startup or
         a first hearbeat after an :py:`on_disconnect`
         """
+        pass
 
     async def on_disconnect(self) -> None:
         """
         Called when the connection is lost unexpectedly (not on shutdown)
         """
+        pass
 
     async def perform_heartbeat(self) -> None:
         """
         Start a continuous heartbeat call
         """
-        if self._heartbeat_client is None or self._client is None:
+        if self._client is None:
             raise Exception("AgentEndpoint not started")
 
         connected: bool = False
         try:
             while True:
                 LOGGER.log(3, "sending heartbeat for %s", str(self.sessionid))
-                result = await self._heartbeat_client.heartbeat(
+                result = await self._client.heartbeat(
                     sid=str(self.sessionid),
                     tid=str(self._env_id),
                     endpoint_names=list(self.end_point_names),
                     nodename=self.node_name,
                     no_hang=not connected,
                 )
                 LOGGER.log(3, "returned heartbeat for %s", str(self.sessionid))
                 if result.code == 200:
                     if not connected:
                         connected = True
                         self.add_background_task(self.on_reconnect())
                     if result.result is not None:
                         if "method_calls" in result.result:
-                            method_calls: list[common.Request] = [
+                            method_calls: List[common.Request] = [
                                 common.Request.from_dict(req) for req in result.result["method_calls"]
                             ]
                             # FIXME: reuse transport?
                             transport = self._transport(self)
 
                             for method_call in method_calls:
                                 self.add_background_task(self.dispatch_method(transport, method_call))
@@ -280,34 +262,34 @@
         if self._client is None:
             raise Exception("AgentEndpoint not started")
 
         LOGGER.debug("Received call through heartbeat: %s %s %s", method_call.reply_id, method_call.method, method_call.url)
         kwargs, config = transport.match_call(method_call.url, method_call.method)
 
         if config is None:
-            msg = "An error occurred during heartbeat method call ({} {} {}): {}".format(
+            msg = "An error occurred during heartbeat method call (%s %s %s): %s" % (
                 method_call.reply_id,
                 method_call.method,
                 method_call.url,
                 "No such method",
             )
             LOGGER.error(msg)
-            # if reply_id is none, we don't send the reply
-            if method_call.reply_id is not None:
-                await self._client.heartbeat_reply(self.sessionid, method_call.reply_id, {"result": msg, "code": 500})
-            return
+            self.add_background_task(
+                self._client.heartbeat_reply(self.sessionid, method_call.reply_id, {"result": msg, "code": 500})
+            )
 
         body = method_call.body or {}
         query_string = parse.urlparse(method_call.url).query
         for key, value in parse.parse_qs(query_string, keep_blank_values=True):
             if len(value) == 1:
                 body[key] = value[0].decode("latin-1")
             else:
                 body[key] = [v.decode("latin-1") for v in value]
 
+        # FIXME: why create a new transport instance on each call? keep-alive?
         response: common.Response = await transport._execute_call(kwargs, method_call.method, config, body, method_call.headers)
 
         if response.status_code == 500:
             msg = ""
             if response.body is not None and "message" in response.body:
                 msg = response.body["message"]
             LOGGER.error(
@@ -317,19 +299,17 @@
                 method_call.url,
                 msg,
             )
 
         if self._client is None:
             raise Exception("AgentEndpoint not started")
 
-        # if reply is is none, we don't send the reply
-        if method_call.reply_id is not None:
-            await self._client.heartbeat_reply(
-                self.sessionid, method_call.reply_id, {"result": response.body, "code": response.status_code}
-            )
+        await self._client.heartbeat_reply(
+            self.sessionid, method_call.reply_id, {"result": response.body, "code": response.status_code}
+        )
 
 
 class VersionMatch(str, Enum):
     lowest = "lowest"
     """ Select the lowest available version of the method
     """
     highest = "highest"
@@ -348,34 +328,27 @@
     def __init__(
         self,
         name: str,
         timeout: int = 120,
         version_match: VersionMatch = VersionMatch.lowest,
         exact_version: int = 0,
         with_rest_client: bool = True,
-        force_instance: bool = False,
     ) -> None:
         super().__init__(name)
         assert isinstance(timeout, int), "Timeout needs to be an integer value."
         LOGGER.debug("Start transport for client %s", self.name)
         if with_rest_client:
-            self._transport_instance = client.RESTClient(self, connection_timout=timeout, force_instance=force_instance)
+            self._transport_instance = client.RESTClient(self, connection_timout=timeout)
         else:
             self._transport_instance = None
         self._version_match = version_match
         self._exact_version = exact_version
 
-    def close(self):
-        """
-        Closes the RESTclient instance manually. This is only needed when it is started with force_instance set to true
-        """
-        self._transport_instance.close()
-
     async def _call(
-        self, method_properties: common.MethodProperties, args: list[object], kwargs: dict[str, object]
+        self, method_properties: common.MethodProperties, args: List[object], kwargs: Dict[str, object]
     ) -> common.Result:
         """
         Execute a call and return the result
         """
         result = await self._transport_instance.call(method_properties, args, kwargs)
         return result
 
@@ -407,15 +380,15 @@
             assert method
             method.function(*args, **kwargs)
             return self._call(method_properties=method, args=args, kwargs=kwargs)
 
         return wrap
 
 
-class SyncClient:
+class SyncClient(object):
     """
     A synchronous client that communicates with end-point based on its configuration
     """
 
     def __init__(
         self,
         name: Optional[str] = None,
@@ -446,15 +419,15 @@
             self.name = name
             self._client = Client(name, self.timeout)
         else:
             self.name = client.name
             self._client = client
 
     def __getattr__(self, name: str) -> Callable[..., common.Result]:
-        def async_call(*args: list[object], **kwargs: dict[str, object]) -> common.Result:
+        def async_call(*args: List[object], **kwargs: Dict[str, object]) -> common.Result:
             method: Callable[..., abc.Awaitable[common.Result]] = getattr(self._client, name)
             with_timeout: abc.Awaitable[common.Result] = asyncio.wait_for(method(*args, **kwargs), self.timeout)
 
             try:
                 if self._ioloop is None:
                     # no loop is running: create a loop for this thread if it doesn't exist already and run it
                     return util.ensure_event_loop().run_until_complete(with_timeout)
@@ -468,20 +441,20 @@
 
 
 class SessionClient(Client):
     """
     A client that communicates with server endpoints over a session.
     """
 
-    def __init__(self, name: str, sid: uuid.UUID, timeout: int = 120, force_instance: bool = False) -> None:
-        super().__init__(name, timeout, force_instance=force_instance)
+    def __init__(self, name: str, sid: uuid.UUID, timeout: int = 120) -> None:
+        super().__init__(name, timeout)
         self._sid = sid
 
     async def _call(
-        self, method_properties: common.MethodProperties, args: list[object], kwargs: dict[str, object]
+        self, method_properties: common.MethodProperties, args: List[object], kwargs: Dict[str, object]
     ) -> common.Result:
         """
         Execute the rpc call
         """
         if "sid" not in kwargs:
             kwargs["sid"] = self._sid
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/exceptions.py` & `inmanta-core-9.3.0/src/inmanta/protocol/exceptions.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from typing import Any, Optional
+from typing import Any, Dict, Optional
 
 from tornado import web
 
 from inmanta.types import JsonType
 
 
 class BaseHttpException(web.HTTPError):
@@ -31,15 +31,15 @@
     :meth:`inmanta.protocol.common.MethodProperties._get_http_status_code_for_exception`
     """
 
     def __init__(self, status_code: int = 500, message: Optional[str] = None, details: Optional[JsonType] = None) -> None:
         super().__init__(status_code, message)
         self.details = details
 
-    def to_body(self) -> dict[str, Any]:
+    def to_body(self) -> Dict[str, Any]:
         """
         Return a response body
         """
         body: JsonType = {"message": self.log_message}
         if self.details is not None:
             body["error_details"] = self.details
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/methods.py` & `inmanta-core-9.3.0/src/inmanta/protocol/methods.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     Contact: code@inmanta.com
 
     Module defining the v1 rest api
 """
 
 import datetime
 import uuid
-from typing import Any, Optional, Union
+from typing import Any, Dict, List, Optional, Union
 
 from inmanta import const, data, resources
 from inmanta.data import model
 from inmanta.types import JsonType, PrimitiveTypes
 
 from . import exceptions
 from .common import ArgOption
@@ -55,103 +55,94 @@
 async def convert_resource_version_id(rvid: model.ResourceVersionIdStr, metadata: dict) -> "resources.Id":
     try:
         return resources.Id.parse_resource_version_id(rvid)
     except Exception:
         raise exceptions.BadRequest(f"Invalid resource version id: {rvid}")
 
 
-ENV_OPTS: dict[str, ArgOption] = {
+ENV_OPTS: Dict[str, ArgOption] = {
     "tid": ArgOption(header=const.INMANTA_MT_HEADER, reply_header=True, getter=convert_environment)
 }
 AGENT_ENV_OPTS = {"tid": ArgOption(header=const.INMANTA_MT_HEADER, reply_header=True, getter=add_env)}
 RVID_OPTS = {"rvid": ArgOption(getter=convert_resource_version_id)}
 
 
 # Method for working with projects
 @method(path="/project", operation="PUT", client_types=[const.ClientType.api])
 def create_project(name: str, project_id: uuid.UUID = None):
     """
     Create a new project
 
     :param name: The name of the project
-    :param project_id: Optional. A unique uuid, when it is not provided the server generates one
+    :param project_id: A unique uuid, when it is not provided the server generates one
     """
 
 
 @method(path="/project/<id>", operation="POST", client_types=[const.ClientType.api])
 def modify_project(id: uuid.UUID, name: str):
     """
-    Modify the given project.
-
-    :param id: The id of the project to modify.
-    :param name: The new name for the project.
+    Modify the given project
     """
 
 
 @method(path="/project/<id>", operation="DELETE", client_types=[const.ClientType.api])
 def delete_project(id: uuid.UUID):
     """
-    Delete the given project and all related data.
-
-    :param id: The id of the project to be deleted.
+    Delete the given project and all related data
     """
 
 
 @method(path="/project", operation="GET", client_types=[const.ClientType.api])
 def list_projects():
     """
     Returns a list of projects ordered alphabetically by name. The environments within each project are also sorted by name.
     """
 
 
 @method(path="/project/<id>", operation="GET", client_types=[const.ClientType.api])
 def get_project(id: uuid.UUID):
     """
-    Get a project and a list of the ids of all environments.
-
-    :param id: The id of the project to retrieve.
+    Get a project and a list of the ids of all environments
     """
 
 
 # Methods for working with environments
 @method(path="/environment", operation="PUT", client_types=[const.ClientType.api])
 def create_environment(
     project_id: uuid.UUID, name: str, repository: str = None, branch: str = None, environment_id: uuid.UUID = None
 ):
     """
     Create a new environment
 
     :param project_id: The id of the project this environment belongs to
-    :param name: The name of the environment.
-    :param repository: Optional. The URL of the repository.
-    :param branch: Optional. The name of the branch in the repository.
-    :param environment_id: Optional. A unique environment id, if none an id is allocated by the server.
+    :param name: The name of the environment
+    :param repository: The url (in git form) of the repository
+    :param branch: The name of the branch in the repository
+    :param environment_id: A unique environment id, if none an id is allocated by the server
     """
 
 
 @method(path="/environment/<id>", operation="POST", client_types=[const.ClientType.api])
 def modify_environment(id: uuid.UUID, name: str, repository: str = None, branch: str = None):
     """
-    Modify the given environment.
-
-    :param id: The id of the environment to modify.
-    :param name: The new name for the environment.
-    :param repository: Optional. The URL of the repository.
-    :param branch: Optional. The name of the branch in the repository.
+    Modify the given environment
 
-    If 'repository' or 'branch' is provided as None, the corresponding attribute of the environment remains unchanged.
+    :param id: The id of the environment
+    :param name: The name of the environment
+    :param repository: The url (in git form) of the repository
+    :param branch: The name of the branch in the repository
     """
 
 
 @method(path="/environment/<id>", operation="DELETE", client_types=[const.ClientType.api])
 def delete_environment(id: uuid.UUID):
     """
     Delete the given environment and all related data.
 
-    :param id: The id of the environment to be deleted.
+    :param id: The uuid of the environment.
 
     :raises NotFound: The given environment doesn't exist.
     :raises Forbidden: The given environment is protected.
     """
 
 
 @method(path="/environment", operation="GET", client_types=[const.ClientType.api])
@@ -165,21 +156,19 @@
     path="/environment/<id>",
     operation="GET",
     client_types=[const.ClientType.api],
     arg_options={"id": ArgOption(getter=add_env)},
 )
 def get_environment(id: uuid.UUID, versions: int = None, resources: int = None):
     """
-    Get an environment and all versions associated.
+    Get an environment and all versions associated
 
-    :param id: The id of the environment to return.
-    :param versions: Optional. If provided and greater than 0, include this many of the most recent versions for this
-                     environment, ordered in descending order of their version number.
-                     If not provided or 0, no version information is included.
-    :param resources: Optional. If provided and greater than 0, include a summary of the resources in the environment.
+    :param id: The id of the environment to return
+    :param versions: Include this many available version for this environment.
+    :param resources: Include this many available resources for this environment.
     """
 
 
 # Method for listing/getting/setting/removing settings of an environment. This API is also used by agents to configure
 # environments.
 
 
@@ -190,129 +179,91 @@
     api=True,
     agent_server=True,
     client_types=[const.ClientType.api, const.ClientType.agent, const.ClientType.compiler],
 )
 def list_settings(tid: uuid.UUID):
     """
     List the settings in the current environment ordered by name alphabetically.
-
-    :param tid: The id of the environment to list settings for.
     """
 
 
 @method(
     path="/environment_settings/<id>",
     operation="POST",
     arg_options=ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[const.ClientType.api, const.ClientType.agent, const.ClientType.compiler],
 )
 def set_setting(tid: uuid.UUID, id: str, value: Union[PrimitiveTypes, JsonType]):
     """
-    Set a value for a setting.
-
-    :param tid: The id of the environment.
-    :param id: The id of the setting to set.
-    :param value: The value to set for the setting.
+    Set a value
     """
 
 
 @method(
     path="/environment_settings/<id>",
     operation="GET",
     arg_options=ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[const.ClientType.api, const.ClientType.agent],
 )
 def get_setting(tid: uuid.UUID, id: str):
     """
-    Get the value of a setting.
-
-    :param tid: The id of the environment.
-    :param id: The id of the setting to retrieve.
+    Get a value
     """
 
 
 @method(
     path="/environment_settings/<id>",
     operation="DELETE",
     arg_options=ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[const.ClientType.api, const.ClientType.agent],
 )
 def delete_setting(tid: uuid.UUID, id: str):
     """
-    Restore the given setting to its default value.
-
-    :param tid: The id of the environment from which the setting is to be deleted.
-    :param id: The key of the setting to delete.
-
+    Delete a value
     """
 
 
 # Method for listing and creating auth tokens for an environment that can be used by the agent and compilers
 
 
 @method(
     path="/environment_auth",
     operation="POST",
     arg_options=ENV_OPTS,
     client_types=[const.ClientType.api, const.ClientType.compiler],
 )
 def create_token(tid: uuid.UUID, client_types: list, idempotent: bool = True):
     """
-    Create or get a new token for the given client types.
+    Create or get a new token for the given client types. Tokens generated with this call are scoped to the current
+    environment.
 
-    :param tid: The environment id.
-    :param client_types: The client types for which this token is valid (api, agent, compiler).
-    :param idempotent: Optional. The token should be idempotent, meaning it does not have an expire or issued at set,
-                       so its value will not change.
-    """
-
-
-#  Decomission an environment
-
-
-@method(
-    path="/decommission/<id>",
-    operation="POST",
-    arg_options={"id": ArgOption(getter=convert_environment)},
-    client_types=[const.ClientType.api],
-    api_version=1,
-)
-def decomission_environment(id: uuid.UUID, metadata: dict = None):
-    """
-    Decommision an environment. This is done by uploading an empty model to the server and let purge_on_delete handle
-    removal.
-
-    :param id: The uuid of the environment.
-    :param metadata: Optional metadata associated with the decommissioning
-
-    :raises NotFound: The given environment doesn't exist.
-    :raises Forbidden: The given environment is protected.
+    :param tid: The environment id
+    :param client_types: The client types for which this token is valid (api, agent, compiler)
+    :param idempotent: The token should be idempotent, such tokens do not have an expire or issued at set so their
+                       value will not change.
     """
 
 
 @method(
     path="/decommission/<id>",
     operation="DELETE",
     arg_options={"id": ArgOption(getter=convert_environment)},
     client_types=[const.ClientType.api],
 )
 def clear_environment(id: uuid.UUID):
     """
-    Clears an environment by removing most of its associated data.
-    This method deletes various components associated with the specified environment from the database,
-    including agents, compile data, parameters, notifications, code, resources, and configuration models.
-    However, it retains the entry in the Environment table itself and settings are kept.
+    Clear all data from this environment.
 
-    :param id: The id of the environment to be cleared.
+    :param id: The uuid of the environment.
 
     :raises NotFound: The given environment doesn't exist.
     :raises Forbidden: The given environment is protected.
 
     """
 
 
@@ -329,15 +280,15 @@
     """
     Send a heartbeat to the server
 
     :param sid: The session ID used by this agent at this moment
     :param tid: The environment this node and its agents belongs to
     :param endpoint_names: The names of the endpoints on this node
     :param nodename: The name of the node from which the heart beat comes
-    :param no_hang: Optional. don't use this call for long polling, but for connectivity check
+    :param no_hang: don't use this call for long polling, but for connectivity check
 
     also registered as API method, because it is called with an invalid SID the first time
     """
 
 
 @method(
     path="/heartbeat",
@@ -414,15 +365,15 @@
     client_types=[const.ClientType.api, const.ClientType.agent, const.ClientType.compiler],
     arg_options={"files": ArgOption(getter=ignore_env)},
 )
 def stat_files(files: list):
     """
     Check which files exist in the given list
 
-    :param files: A list of file ids to check
+    :param files: A list of file id to check
     :return: A list of files that do not exist.
     """
 
 
 # Manage resources on the server
 
 
@@ -439,38 +390,37 @@
     tid: uuid.UUID, id: str, logs: bool = None, status: bool = None, log_action: const.ResourceAction = None, log_limit: int = 0
 ):
     """
     Return a resource with the given id.
 
     :param tid: The id of the environment this resource belongs to
     :param id: Get the resource with the given resource version id
-    :param logs: Optional. Include the logs in the response
-    :param status: Optional. Only return the status of the resource
-    :param log_action: Optional. The log action to include, leave empty/none for all actions. Valid actions are one of
+    :param logs: Include the logs in the response
+    :param status: Only return the status of the resource
+    :param log_action: The log action to include, leave empty/none for all actions. Valid actions are one of
                       the action strings in const.ResourceAction
-    :param log_limit: Optional. Limit the number of logs included in the response, up to a maximum of 1000.
+    :param log_limit: Limit the number of logs included in the response, up to a maximum of 1000.
                       To retrieve more entries, use  /api/v2/resource_actions
                       (:func:`~inmanta.protocol.methods_v2.get_resource_actions`)
-                      If None, a default limit (set to 1000) is applied.
     """
 
 
 @method(path="/resource", operation="GET", agent_server=True, arg_options=ENV_OPTS, client_types=[const.ClientType.agent])
 def get_resources_for_agent(
     tid: uuid.UUID, agent: str, sid: uuid.UUID = None, version: int = None, incremental_deploy: bool = False
 ):
     """
     Return the most recent state for the resources associated with agent, or the version requested
 
-    :param tid: The environment ID this resource belongs to.
-    :param agent: The agent name.
-    :param sid: Optional. Session id of the agent (transparently added by agent client).
-    :param version: Optional. The version to retrieve. If none, the latest available version is returned. With a specific
-                    version that version is returned, even if it has not been released yet.
-    :param incremental_deploy: Optional. Indicates whether the server should only return the resources that changed since the
+    :param tid: The id of the environment this resource belongs to
+    :param agent: The agent
+    :param sid: Session id of the agent (transparently added by agent client)
+    :param version: The version to retrieve. If none, the latest available version is returned. With a specific version
+                    that version is returned, even if it has not been released yet.
+    :param incremental_deploy: Indicates whether the server should only return the resources that changed since the
                                previous deployment.
     """
 
 
 @method(path="/resource", operation="POST", agent_server=True, arg_options=ENV_OPTS, client_types=[const.ClientType.agent])
 def resource_action_update(
     tid: uuid.UUID,
@@ -488,56 +438,54 @@
     """
     Send a resource update to the server
 
     :param tid: The id of the environment this resource belongs to
     :param resource_ids: The resource with the given resource_version_id id from the agent
     :param action_id: A unique id to indicate the resource action that has be updated
     :param action: The action performed
-    :param started: Optional. The timestamp when this action was started. When this action (action_id) has not been saved yet,
+    :param started: The timestamp when this action was started. When this action (action_id) has not been saved yet,
                     started has to be defined.
-    :param finished: Optional. The timestamp when this action was finished. Afterwards, no changes with the same action_id
+    :param finished: The timestamp when this action was finished. Afterwards, no changes with the same action_id
                     can be stored. The status field also has to be set.
-    :param status: Optional. The current status of the resource (if known)
-    :param messages: Optional. A list of log entries to add to this entry.
-    :param changes: Optional. A dict of changes to this resource. The key of this dict indicates the attributes/fields that
+    :param status: The current status of the resource (if known)
+    :param messages: A list of log entries to add to this entry.
+    :param change:s A dict of changes to this resource. The key of this dict indicates the attributes/fields that
                    have been changed. The value contains the new value and/or the original value.
-    :param change: Optional. The result of the changes
-    :param send_events: Optional. [DEPRECATED] The value of this field is not used anymore.
+    :param change: The result of the changes
+    :param send_events: [DEPRECATED] The value of this field is not used anymore.
     """
 
 
 # Manage configuration model versions
 
 
 @method(path="/version", operation="GET", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def list_versions(tid: uuid.UUID, start: int = None, limit: int = None):
     """
-    Returns a list of all available versions, ordered by version number, descending
+    Returns a list of all available versions
 
     :param tid: The id of the environment
-    :param start: Optional. parameter to control the amount of results that are returned. 0 is the latest version.
-    :param limit: Optional. parameter to control the amount of results returned, up to a maximum of 1000.
-                  If None, a default limit (set to 1000) is applied.
+    :param start: Optional, parameter to control the amount of results that are returned. 0 is the latest version.
+    :param limit: Optional, parameter to control the amount of results returned, up to a maximum of 1000.
     """
 
 
 @method(path="/version/<id>", operation="GET", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def get_version(tid: uuid.UUID, id: int, include_logs: bool = None, log_filter: str = None, limit: int = None):
     """
     Get a particular version and a list of all resources in this version
 
     :param tid: The id of the environment
     :param id: The id of the version to retrieve
-    :param include_logs: Optional. If true, a log of all operations on all resources is included
-    :param log_filter: Optional. Filter log to only include actions of the specified type
-    :param limit: Optional. The maximal number of actions to return per resource (starting from the latest),
+    :param include_logs: If true, a log of all operations on all resources is included
+    :param log_filter: Filter log to only include actions of the specified type
+    :param limit: The maximal number of actions to return per resource (starting from the latest),
                     up to a maximum of 1000.
                     To retrieve more entries, use /api/v2/resource_actions
                     (:func:`~inmanta.protocol.methods_v2.get_resource_actions`)
-                    If None, a default limit (set to 1000) is applied.
     """
 
 
 @method(path="/version/<id>", operation="DELETE", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def delete_version(tid: uuid.UUID, id: int):
     """
     Delete a particular version and resources
@@ -552,50 +500,45 @@
     tid: uuid.UUID,
     version: int,
     resources: list,
     resource_state: dict = {},
     unknowns: list = None,
     version_info: dict = None,
     compiler_version: str = None,
-    resource_sets: dict[model.ResourceIdStr, Optional[str]] = {},
+    resource_sets: Dict[model.ResourceIdStr, Optional[str]] = {},
 ):
     """
     Store a new version of the configuration model
 
     The version number must be obtained through the reserve_version call
 
     :param tid: The id of the environment
     :param version: The version of the configuration model
     :param resources: A list of all resources in the configuration model (deployable)
     :param resource_state: A dictionary with the initial const.ResourceState per resource id. The ResourceState should be set
                            to undefined when the resource depends on an unknown or available when it doesn't.
-    :param unknowns: Optional. A list of unknown parameters that caused the model to be incomplete
-    :param version_info: Optional. Module version information
-    :param compiler_version: Optional. version of the compiler, if not provided, this call will return an error
-    :param resource_sets: Optional. a dictionary describing which resource belongs to which resource set
+    :param unknowns: A list of unknown parameters that caused the model to be incomplete
+    :param version_info: Module version information
+    :param compiler_version: version of the compiler, if not provided, this call will return an error
+    :param resource_sets: a dictionary describing which resource belongs to which resource set
     """
 
 
 @method(
     path="/version/<id>", operation="POST", arg_options=ENV_OPTS, client_types=[const.ClientType.api, const.ClientType.compiler]
 )
 def release_version(tid: uuid.UUID, id: int, push: bool = False, agent_trigger_method: const.AgentTriggerMethod = None):
     """
     Release version of the configuration model for deployment.
 
     :param tid: The id of the environment
     :param id: The version of the CM to deploy
     :param push: Notify all agents to deploy the version
-    :param agent_trigger_method: Optional. Indicates whether the agents should perform a full or an incremental deploy when
+    :param agent_trigger_method: Indicates whether the agents should perform a full or an incremental deploy when
                                 push is true.
-
-     :return: Returns the following status codes:
-            200: The version is released
-            404: The requested version does not exist
-            409: The requested version was already released
     """
 
 
 @method(path="/deploy", operation="POST", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def deploy(
     tid: uuid.UUID,
     agent_trigger_method: const.AgentTriggerMethod = const.AgentTriggerMethod.push_full_deploy,
@@ -625,15 +568,15 @@
 
 @method(path="/dryrun", operation="GET", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def dryrun_list(tid: uuid.UUID, version: int = None):
     """
     Get the list of dry runs for an environment. The results are sorted by dry run id.
 
     :param tid: The id of the environment
-    :param version: Optional. Only for this version
+    :param version: Only for this version
     """
 
 
 @method(path="/dryrun/<id>", operation="GET", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def dryrun_report(tid: uuid.UUID, id: uuid.UUID):
     """
     Create a dryrun report
@@ -678,33 +621,30 @@
     operation="GET",
     arg_options={"id": ArgOption(getter=convert_environment)},
     client_types=[const.ClientType.api],
 )
 def notify_change_get(id: uuid.UUID, update: bool = True):
     """
     Simplified GET version of the POST method
-
-    :param id: The id of the environment.
-    :param update: Optional. Indicates whether to update the model code and modules. Defaults to true.
     """
 
 
 @method(
     path="/notify/<id>",
     operation="POST",
     arg_options={"id": ArgOption(getter=convert_environment)},
     client_types=[const.ClientType.api],
 )
 def notify_change(id: uuid.UUID, update: bool = True, metadata: dict = {}):
     """
     Notify the server that the repository of the environment with the given id, has changed.
 
     :param id: The id of the environment
-    :param update: Optional. Update the model code and modules. Default value is true
-    :param metadata: Optional. The metadata that indicates the source of the compilation trigger.
+    :param update: Update the model code and modules. Default value is true
+    :param metadata: The metadata that indicates the source of the compilation trigger.
     """
 
 
 @method(path="/notify/<id>", operation="HEAD", client_types=[const.ClientType.api])
 def is_compiling(id: uuid.UUID):
     """
     Is a compiler running for the given environment
@@ -724,15 +664,15 @@
 )
 def get_param(tid: uuid.UUID, id: str, resource_id: str = None):
     """
     Get a parameter from the server.
 
     :param tid: The id of the environment
     :param id: The name of the parameter
-    :param resource_id: Optional. scope the parameter to resource (fact),
+    :param resource_id: Optionally, scope the parameter to resource (fact),
                         if the resource id should not contain a version, the latest version is used
     :return: Returns the following status codes:
             200: The parameter content is returned
             404: The parameter is not found and unable to find it because its resource is not known to the server
             410: The parameter has expired
             503: The parameter is not found but its value is requested from an agent
     """
@@ -755,19 +695,19 @@
 ):
     """
     Set a parameter on the server. If the parameter is an tracked unknown, it will trigger a recompile on the server.
     Otherwise, if the value is changed and recompile is true, a recompile is also triggered.
 
     :param tid: The id of the environment
     :param id: The name of the parameter
+    :param resource_id: Optionally, scope the parameter to resource (fact)
     :param source: The source of the parameter.
     :param value: The value of the parameter
-    :param resource_id: Optional. Scope the parameter to resource (fact)
-    :param metadata: Optional. Metadata about the parameter
-    :param recompile: Optional. Whether to trigger a recompile
+    :param metadata: metadata about the parameter
+    :param recompile: Whether to trigger a recompile
     """
 
 
 @method(
     path="/parameter/<id>",
     operation="DELETE",
     arg_options=ENV_OPTS,
@@ -775,27 +715,27 @@
 )
 def delete_param(tid: uuid.UUID, id: str, resource_id: str = None):
     """
     Delete a parameter on the server
 
     :param tid: The id of the environment
     :param id: The name of the parameter
-    :param resource_id: Optional. The resource id of the parameter
+    :param resource_id: The resource id of the parameter
     """
 
 
 @method(
     path="/parameter", operation="POST", arg_options=ENV_OPTS, client_types=[const.ClientType.api, const.ClientType.compiler]
 )
 def list_params(tid: uuid.UUID, query: dict = {}):
     """
     List/query parameters in this environment. The results are ordered alphabetically by parameter name.
 
     :param tid: The id of the environment
-    :param query: Optional. A query to match against metadata
+    :param query: A query to match against metadata
     """
 
 
 #  Get and set parameters on the server
 
 
 @method(
@@ -818,92 +758,68 @@
         - metadata metadata about the parameter
     """
 
 
 # Get parameters from the agent
 
 
-@method(
-    path="/agent_parameter",
-    operation="POST",
-    server_agent=True,
-    timeout=5,
-    arg_options=AGENT_ENV_OPTS,
-    client_types=[],
-    reply=False,
-)
+@method(path="/agent_parameter", operation="POST", server_agent=True, timeout=5, arg_options=AGENT_ENV_OPTS, client_types=[])
 def get_parameter(tid: uuid.UUID, agent: str, resource: dict):
     """
     Get all parameters/facts known by the agents for the given resource
 
-    This method will not actually return them.
-    This call wil register the request with the agent and return,
-    The agent will push the parameters back to the server when they are available.
-
     :param tid: The environment
     :param agent: The agent to get the parameters from
     :param resource: The resource to query the parameters from
     """
 
 
 @method(path="/code/<id>", operation="GET", agent_server=True, arg_options=ENV_OPTS, client_types=[const.ClientType.agent])
 def get_code(tid: uuid.UUID, id: int, resource: str):
     """
-    Retrieve the source code associated with a specific version of a configuration model for a given resource in an environment.
+    Get the code for a given version of the configuration model
 
-    :param tid: The id of the environment to which the code belongs.
-    :param id: The version number of the configuration model.
-    :param resource: The identifier of the resource. This should be a resource ID, not a resource version ID.
+    :param tid: The environment the code belongs to
+    :param id: The id (version) of the configuration model
     """
 
 
 @method(path="/codebatched/<id>", operation="PUT", arg_options=ENV_OPTS, client_types=[const.ClientType.compiler])
 def upload_code_batched(tid: uuid.UUID, id: int, resources: dict):
     """
-    Upload batches of code for various resources associated with a specific version of a configuration model in an environment.
-
-    :param tid: The id of the environment to which the code belongs.
-    :param id: The version number of the configuration model.
-    :param resources: A dictionary where each key is a string representing a resource type.
-                  For each resource type, the value is a dictionary. This nested dictionary's keys are file names,
-                  and each key maps to a tuple. This tuple contains three elements: the file name, the module name,
-                  and a list of requirements.
+    Upload the supporting code to the server
 
-    The endpoint validates that all provided file references are valid and checks for conflicts with existing code entries.
+    :param tid: The environment the code belongs to
+    :param id: The id (version) of the configuration model
+    :param resource: a dict mapping resources to dicts mapping file names to file hashes
     """
 
 
 # Generate download the diff of two hashes
 
 
 @method(path="/filediff", client_types=[const.ClientType.api])
-def diff(file_id_1: str, file_id_2: str):
+def diff(a: str, b: str):
     """
     Returns the diff of the files with the two given ids
-
-    :param file_id_1: The identifier of the first file.
-    :param file_id_2: The identifier of the second file.
-
-    :return: A string representing the diff between the two files.
     """
 
 
 # Get a list of compile reports
 
 
 @method(path="/compilereport", operation="GET", arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def get_reports(tid: uuid.UUID, start: str = None, end: str = None, limit: int = None):
     """
     Return compile reports newer then start
 
     :param tid: The id of the environment to get a report from
-    :param start: Optional. Reports after start
-    :param end: Optional. Reports before end
-    :param limit: Optional. Maximum number of results, up to a maximum of 1000
-                  If None, a default limit (set to 1000) is applied.
+    :param start: Reports after start
+    :param end: Reports before end
+    :param limit: Maximum number of results, up to a maximum of 1000
     """
 
 
 @method(path="/compilereport/<id>", operation="GET", client_types=[const.ClientType.api])
 def get_report(id: uuid.UUID):
     """
     Get a compile report from the server
@@ -918,20 +834,19 @@
 @method(path="/agentproc", operation="GET", client_types=[const.ClientType.api])
 def list_agent_processes(
     environment: uuid.UUID = None, expired: bool = True, start: uuid.UUID = None, end: uuid.UUID = None, limit: int = None
 ):
     """
     Return a list of all nodes and the agents for these nodes
 
-    :param environment: Optional. An optional environment. If set, only the agents that belong to this environment are returned
-    :param expired: Optional. if true show expired processes, otherwise only living processes are shown. True by default
-    :param start: Optional. Agent processes after start (sorted by sid in ASC)
-    :param end: Optional. Agent processes before end (sorted by sid in ASC)
-    :param limit: Optional. Maximum number of results, up to a maximum of 1000
-                  If None, a default limit (set to 1000) is applied.
+    :param environment: An optional environment. If set, only the agents that belong to this environment are returned
+    :param expired: Optional, also show expired processes, otherwise only living processes are shown.
+    :param start: Agent processes after start (sorted by sid in ASC)
+    :param end: Agent processes before end (sorted by sid in ASC)
+    :param limit: Maximum number of results, up to a maximum of 1000
 
     :raises BadRequest: limit parameter can not exceed 1000
     :raises NotFound: The given environment id does not exist!
 
     :return: A list of nodes
     """
 
@@ -960,18 +875,17 @@
 
 @method(path="/agent", operation="GET", api=True, timeout=5, arg_options=ENV_OPTS, client_types=[const.ClientType.api])
 def list_agents(tid: uuid.UUID, start: str = None, end: str = None, limit: int = None):
     """
     List all agent for an environment
 
     :param tid: The environment the agents are defined in
-    :param start: Optional. Agent after start (sorted by name in ASC)
-    :param end: Optional. Agent before end (sorted by name in ASC)
-    :param limit: Optional. Maximum number of results, up to a maximum of 1000.
-                  If None, a default limit (set to 1000) is applied.
+    :param start: Agent after start (sorted by name in ASC)
+    :param end: Agent before end (sorted by name in ASC)
+    :param limit: Maximum number of results, up to a maximum of 1000
 
     :raises BadRequest: limit parameter can not exceed 1000
     :raises NotFound: The given environment id does not exist!
     """
 
 
 # Reporting by the agent to the server
@@ -989,17 +903,14 @@
 # Methods to allow the server to set the agents state
 
 
 @method(path="/agentstate", operation="POST", server_agent=True, timeout=5, client_types=[])
 def set_state(agent: str, enabled: bool):
     """
     Set the state of the agent.
-
-    :param agent: The name of the agent.
-    :param enabled: A boolean value indicating whether the agent should be paused (enabled=False) or unpaused (enabled=True).
     """
 
 
 @method(path="/agentstate/<id>", operation="POST", server_agent=True, timeout=5, arg_options=AGENT_ENV_OPTS, client_types=[])
 def trigger(tid: uuid.UUID, id: str, incremental_deploy: bool):
     """
     Request an agent to reload resources
@@ -1009,45 +920,39 @@
     :param incremental_deploy: Indicates whether the agent should perform an incremental deploy or a full deploy
     """
 
 
 # Methods to send event to the server
 
 
-@method(
-    path="/event/<id>", operation="PUT", server_agent=True, timeout=5, arg_options=AGENT_ENV_OPTS, client_types=[], reply=False
-)
+@method(path="/event/<id>", operation="PUT", server_agent=True, timeout=5, arg_options=AGENT_ENV_OPTS, client_types=[])
 def resource_event(
     tid: uuid.UUID, id: str, resource: str, send_events: bool, state: const.ResourceState, change: const.Change, changes={}
 ):
     """
     Tell an agent a resource it waits for has been updated
 
     :param tid: The environment this agent is defined in
     :param id: The name of the agent
     :param resource: The resource ID of the resource being updated
     :param send_events: [DEPRECATED] The value of this field is not used anymore.
     :param state: State the resource acquired (deployed, skipped, canceled)
     :param change: The change that was made to the resource
-    :param changes: Optional. The changes made to the resource
+    :param changes: The changes made to the resource
     """
 
 
 # Methods for the agent to get its initial state from the server
 
 
 @method(path="/agentrecovery", operation="GET", agent_server=True, arg_options=ENV_OPTS, client_types=[const.ClientType.agent])
 def get_state(tid: uuid.UUID, sid: uuid.UUID, agent: str):
     """
     Get the state for this agent.
 
-    :param tid: The id of the environment.
-    :param sid: The session ID associated with this agent.
-    :param agent: The name of the agent.
-
     :return: A map with key enabled and value a boolean.
     """
 
 
 @typedmethod(path="/serverstatus", operation="GET", client_types=[const.ClientType.api])
 def get_server_status() -> model.StatusResponse:
     """
@@ -1059,16 +964,11 @@
     path="/compilequeue",
     operation="GET",
     arg_options=ENV_OPTS,
     client_types=[const.ClientType.api],
     api_version=1,
     envelope_key="queue",
 )
-def get_compile_queue(tid: uuid.UUID) -> list[model.CompileRun]:
+def get_compile_queue(tid: uuid.UUID) -> List[model.CompileRun]:
     """
     Get the current compiler queue on the server, ordered by increasing `requested` timestamp.
-
-    :param tid: The id of the environment for which to retrieve the compile queue.
-
-    :return: A list of CompileRun objects representing the current state of the compiler queue,
-             with each entry detailing a specific compile run.
     """
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/methods_v2.py` & `inmanta-core-9.3.0/src/inmanta/protocol/methods_v2.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,22 +15,22 @@
 
     Contact: code@inmanta.com
 
     Module defining the v2 rest api
 """
 import datetime
 import uuid
-from typing import Literal, Optional, Union
+from typing import Dict, List, Literal, Optional, Union
 
 from inmanta.const import AgentAction, ApiDocsFormat, Change, ClientType, ResourceState
 from inmanta.data import model
 from inmanta.protocol.common import ReturnValue
 from inmanta.types import PrimitiveTypes
 
-from ..data.model import ResourceIdStr
+from ..data.model import DiscoveredResource, ResourceIdStr
 from . import methods
 from .decorators import typedmethod
 from .openapi.model import OpenAPI
 
 
 @typedmethod(
     path="/version/partial",
@@ -38,20 +38,20 @@
     arg_options=methods.ENV_OPTS,
     client_types=[ClientType.compiler],
     api_version=2,
     varkw=True,
 )
 def put_partial(
     tid: uuid.UUID,
-    resource_state: Optional[dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]]] = None,
-    unknowns: Optional[list[dict[str, PrimitiveTypes]]] = None,
-    resource_sets: Optional[dict[ResourceIdStr, Optional[str]]] = None,
-    removed_resource_sets: Optional[list[str]] = None,
+    resource_state: Optional[Dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]]] = None,
+    unknowns: Optional[List[Dict[str, PrimitiveTypes]]] = None,
+    resource_sets: Optional[Dict[ResourceIdStr, Optional[str]]] = None,
+    removed_resource_sets: Optional[List[str]] = None,
     **kwargs: object,  # bypass the type checking for the resources and version_info argument
-) -> ReturnValue[int]:
+) -> int:
     """
     Store a new version of the configuration model after a partial recompile. The partial is applied on top of the latest
     version. Dynamically acquires a new version and serializes concurrent calls. Python code for the new version is copied
     from the base version.
 
     Concurrent put_partial calls are safe from race conditions provided that their resource sets are disjunct. A put_version
     call concurrent with a put_partial is not guaranteed to be safe. It is the caller's responsibility to appropriately
@@ -83,45 +83,37 @@
     :param project_id: A unique uuid, when it is not provided the server generates one
     """
 
 
 @typedmethod(path="/project/<id>", operation="POST", client_types=[ClientType.api], api_version=2)
 def project_modify(id: uuid.UUID, name: str) -> model.Project:
     """
-    Rename the given project
-
-    :param id: The id of the project to be modified.
-    :param name: The new name for the project. This string value will replace the current name of the project.
+    Modify the given project
     """
 
 
 @typedmethod(path="/project/<id>", operation="DELETE", client_types=[ClientType.api], api_version=2)
 def project_delete(id: uuid.UUID) -> None:
     """
     Delete the given project and all related data
-
-    :param id: The id of the project to be deleted.
     """
 
 
 @typedmethod(path="/project", operation="GET", client_types=[ClientType.api], api_version=2)
-def project_list(environment_details: bool = False) -> list[model.Project]:
+def project_list(environment_details: bool = False) -> List[model.Project]:
     """
     Returns a list of projects ordered alphabetically by name. The environments within each project are also sorted by name.
-
     :param environment_details: Whether to include the icon and description of the environments in the results
     """
 
 
 @typedmethod(path="/project/<id>", operation="GET", client_types=[ClientType.api], api_version=2)
 def project_get(id: uuid.UUID, environment_details: bool = False) -> model.Project:
     """
     Get a project and a list of the environments under this project
-
-    :param id: The id for which the project's details are being requested.
     :param environment_details: Whether to include the icon and description of the environments in the results
     """
 
 
 # Methods for working with environments
 @typedmethod(path="/environment", operation="PUT", client_types=[ClientType.api], api_version=2)
 def environment_create(
@@ -133,15 +125,15 @@
     description: str = "",
     icon: str = "",
 ) -> model.Environment:
     """
     Create a new environment
 
     :param project_id: The id of the project this environment belongs to
-    :param name: The name of the environment. The name should be unique for each project.
+    :param name: The name of the environment
     :param repository: The url (in git form) of the repository
     :param branch: The name of the branch in the repository
     :param environment_id: A unique environment id, if none an id is allocated by the server
     :param description: The description of the environment, maximum 255 characters
     :param icon: The data-url of the icon of the environment. It should follow the pattern `<mime-type>;base64,<image>`, where
                  <mime-type> is one of: 'image/png', 'image/jpeg', 'image/webp', 'image/svg+xml', and <image> is the image in
                  the format matching the specified mime-type, and base64 encoded.
@@ -191,18 +183,17 @@
 
     :raises NotFound: The given environment doesn't exist.
     :raises Forbidden: The given environment is protected.
     """
 
 
 @typedmethod(path="/environment", operation="GET", client_types=[ClientType.api], api_version=2)
-def environment_list(details: bool = False) -> list[model.Environment]:
+def environment_list(details: bool = False) -> List[model.Environment]:
     """
     Returns a list of environments
-
     :param details: Whether to include the icon and description of the environments in the results
     """
 
 
 @typedmethod(
     path="/environment/<id>",
     operation="GET",
@@ -254,34 +245,14 @@
 
     :raises NotFound: The given environment doesn't exist.
     """
 
 
 @typedmethod(
     path="/decommission/<id>",
-    operation="POST",
-    arg_options={"id": methods.ArgOption(getter=methods.convert_environment)},
-    client_types=[ClientType.api],
-    api_version=2,
-)
-def environment_decommission(id: uuid.UUID, metadata: Optional[model.ModelMetadata] = None) -> int:
-    """
-    Decommission an environment. This is done by uploading an empty model to the server and let purge_on_delete handle
-    removal.
-
-    :param id: The uuid of the environment.
-    :param metadata: Optional metadata associated with the decommissioning
-
-    :raises NotFound: The given environment doesn't exist.
-    :raises Forbidden: The given environment is protected.
-    """
-
-
-@typedmethod(
-    path="/decommission/<id>",
     operation="DELETE",
     arg_options={"id": methods.ArgOption(getter=methods.convert_environment)},
     client_types=[ClientType.api],
     api_version=2,
 )
 def environment_clear(id: uuid.UUID) -> None:
     """
@@ -298,15 +269,15 @@
 @typedmethod(
     path="/environment_auth",
     operation="POST",
     arg_options=methods.ENV_OPTS,
     client_types=[ClientType.api, ClientType.compiler],
     api_version=2,
 )
-def environment_create_token(tid: uuid.UUID, client_types: list[str], idempotent: bool = True) -> str:
+def environment_create_token(tid: uuid.UUID, client_types: List[str], idempotent: bool = True) -> str:
     """
     Create or get a new token for the given client types. Tokens generated with this call are scoped to the current
     environment.
 
     :param tid: The environment id
     :param client_types: The client types for which this token is valid (api, agent, compiler)
     :param idempotent: The token should be idempotent, such tokens do not have an expire or issued at set so their
@@ -324,92 +295,75 @@
     agent_server=True,
     client_types=[ClientType.api, ClientType.agent, ClientType.compiler],
     api_version=2,
 )
 def environment_settings_list(tid: uuid.UUID) -> model.EnvironmentSettingsReponse:
     """
     List the settings in the current environment ordered by name alphabetically.
-
-    :param tid: The id of the environment for which the list of settings is being requested.
     """
 
 
 @typedmethod(
     path="/environment_settings/<id>",
     operation="POST",
     arg_options=methods.ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[ClientType.api, ClientType.agent, ClientType.compiler],
     api_version=2,
 )
 def environment_settings_set(tid: uuid.UUID, id: str, value: model.EnvSettingType) -> ReturnValue[None]:
     """
-    Set a specific setting in an environment's configuration.
-
-    :param tid: The id of the environment where the setting is to be set or updated.
-    :param id: The id of the setting to be set or updated.
-    :param value: The new value for the setting.
-
+    Set a value
     """
 
 
 @typedmethod(
     path="/environment_settings/<id>",
     operation="GET",
     arg_options=methods.ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[ClientType.api, ClientType.agent],
     api_version=2,
 )
 def environment_setting_get(tid: uuid.UUID, id: str) -> model.EnvironmentSettingsReponse:
     """
-    Retrieve a specific setting from an environment's configuration.
-
-    :param tid: The id of the environment from which the setting is being retrieved.
-    :param id: The id of the setting to be retrieved.
-
+    Get a value
     """
 
 
 @typedmethod(
     path="/environment_settings/<id>",
     operation="DELETE",
     arg_options=methods.ENV_OPTS,
     api=True,
     agent_server=True,
     client_types=[ClientType.api, ClientType.agent],
     api_version=2,
 )
 def environment_setting_delete(tid: uuid.UUID, id: str) -> ReturnValue[None]:
     """
-    Reset the given setting to its default value.
-
-    :param tid: The id of the environment from which the setting is to be deleted.
-    :param id: The identifier of the setting to be deleted.
+    Delete a value
     """
 
 
 @typedmethod(
     path="/reserve_version", operation="POST", arg_options=methods.ENV_OPTS, client_types=[ClientType.compiler], api_version=2
 )
 def reserve_version(tid: uuid.UUID) -> int:
     """
     Reserve a version number in this environment.
-
-    :param tid: The id of the environment in which the version number is to be reserved.
     """
 
 
 @typedmethod(path="/docs", operation="GET", client_types=[ClientType.api], api_version=2)
 def get_api_docs(format: Optional[ApiDocsFormat] = ApiDocsFormat.swagger) -> ReturnValue[Union[OpenAPI, str]]:
     """
     Get the OpenAPI definition of the API
-
     :param format: Use 'openapi' to get the schema in json format, leave empty or use 'swagger' to get the Swagger-UI view
     """
 
 
 @typedmethod(
     path="/agent/<name>/<action>", operation="POST", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
 )
@@ -457,17 +411,17 @@
 def get_agents(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     start: Optional[Union[datetime.datetime, bool, str]] = None,
     end: Optional[Union[datetime.datetime, bool, str]] = None,
     first_id: Optional[str] = None,
     last_id: Optional[str] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "name.asc",
-) -> list[model.Agent]:
+) -> List[model.Agent]:
     """
     Get all of the agents in the given environment
 
     :param tid: The id of the environment the agents should belong to.
     :param limit: Limit the number of agents that are returned.
     :param start: The lower limit for the order by column (exclusive).
     :param first_id: The name to use as a continuation token for paging, in combination with the 'start' value,
@@ -500,15 +454,15 @@
     :param report: Whether to include a report from the agent or not
     :return: The details of an agent process
     :raise NotFound: This exception is raised when the referenced environment or agent process is not found
     """
 
 
 @typedmethod(path="/agentmap", api=False, server_agent=True, operation="POST", client_types=[], api_version=2)
-def update_agent_map(agent_map: dict[str, str]) -> None:
+def update_agent_map(agent_map: Dict[str, str]) -> None:
     """
     Notify an agent about the fact that the autostart_agent_map has been updated.
 
     :param agent_map: The content of the new autostart_agent_map
     """
 
 
@@ -536,16 +490,15 @@
     attribute: Optional[str] = None,
     attribute_value: Optional[str] = None,
     log_severity: Optional[str] = None,
     limit: Optional[int] = 0,
     action_id: Optional[uuid.UUID] = None,
     first_timestamp: Optional[datetime.datetime] = None,
     last_timestamp: Optional[datetime.datetime] = None,
-    exclude_changes: Optional[list[Change]] = None,
-) -> ReturnValue[list[model.ResourceAction]]:
+) -> ReturnValue[List[model.ResourceAction]]:
     """
     Return resource actions matching the search criteria.
 
     :param tid: The id of the environment this resource belongs to
     :param resource_type: The resource entity type that should be queried
     :param agent: Agent name that is used to filter the results
     :param attribute: Attribute name used for filtering
@@ -555,20 +508,18 @@
     :param action_id: Start the query from this action_id.
             To be used in combination with either the first or last timestamp.
     :param first_timestamp: Limit the results to resource actions that started later
             than the value of this parameter (exclusive)
     :param last_timestamp: Limit the results to resource actions that started earlier
             than the value of this parameter (exclusive).
             Only the first_timestamp or last_timestamp parameter should be supplied
-    :param exclude_changes: only return ResourceActions where the change type is different from the one in this list.
-    :return: The list of matching Resource Actions.
-            The order is ascending if first_timestamp is provided, otherwise descending.
-            If a limit is specified, also return links to the next and previous pages.
-            The "next" page refers to actions that started earlier, while the "prev" page refers to actions that started later.
-
+    :return: the list of matching Resource Actions in a descending order according to the 'started' timestamp.
+            If a limit was specified, also return the links to the next and previous pages.
+            The "next" page always refers to the actions that started earlier,
+            while the "prev" page refers to actions that started later.
 
     :raises BadRequest: When the supplied parameters are not valid.
 
     """
 
 
 @typedmethod(
@@ -580,16 +531,16 @@
     api_version=2,
 )
 def resource_deploy_done(
     tid: uuid.UUID,
     rvid: model.ResourceVersionIdStr,
     action_id: uuid.UUID,
     status: ResourceState,
-    messages: list[model.LogLine] = [],
-    changes: dict[str, model.AttributeStateChange] = {},
+    messages: List[model.LogLine] = [],
+    changes: Dict[str, model.AttributeStateChange] = {},
     change: Optional[Change] = None,
 ) -> None:
     """
     Report to the server that an agent has finished the deployment of a certain resource.
 
     :param tid: The id of the environment the resource belongs to
     :param rvid: The resource version id of the resource for which the deployment is finished.
@@ -611,15 +562,15 @@
     client_types=[ClientType.agent],
     api_version=2,
 )
 def resource_deploy_start(
     tid: uuid.UUID,
     rvid: model.ResourceVersionIdStr,
     action_id: uuid.UUID,
-) -> dict[model.ResourceVersionIdStr, ResourceState]:
+) -> Dict[model.ResourceVersionIdStr, ResourceState]:
     """
     Report to the server that the agent will start the deployment of the given resource.
 
     :param tid: The id of the environment the resource belongs to
     :param rvid: The resource version id of the resource for which the deployment will start
     :param action_id: A unique id used to track the action of this deployment
     :return: A dict mapping the resource version id of each dependency of resource_id to
@@ -635,28 +586,25 @@
     agent_server=True,
     client_types=[ClientType.agent],
     api_version=2,
 )
 def get_resource_events(
     tid: uuid.UUID,
     rvid: model.ResourceVersionIdStr,
-    exclude_change: Optional[Change] = None,
-) -> dict[model.ResourceIdStr, list[model.ResourceAction]]:
+) -> Dict[model.ResourceIdStr, List[model.ResourceAction]]:
     """
     Return relevant events for a resource, i.e. all deploy actions for each of its dependencies since this resources' last
-    successful deploy or all deploy actions if this resources hasn't been deployed before. The resource actions are sorted in
-    descending order according to their started timestamp. If exclude_change is set, exclude all resource actions with this
-    specific type of change.
+    deploy or all deploy actions if this resources hasn't been deployed before. The resource actions are sorted in descending
+    order according to their started timestamp.
 
     This method searches through all versions of this resource.
     This method should only be called when a deploy is in progress.
 
     :param tid: The id of the environment this resource belongs to
     :param rvid: The id of the resource to get events for.
-    :param exclude_change: Exclude all resource actions with this specific type of change.
     :raises BadRequest: When this endpoint in called while the resource with the given resource version is not
                         in the deploying state.
     """
 
 
 @typedmethod(
     path="/resource/<rvid>/did_dependency_change",
@@ -687,18 +635,18 @@
 def resource_list(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     first_id: Optional[model.ResourceVersionIdStr] = None,
     last_id: Optional[model.ResourceVersionIdStr] = None,
     start: Optional[str] = None,
     end: Optional[str] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "resource_type.desc",
     deploy_summary: bool = False,
-) -> list[model.LatestReleasedResource]:
+) -> List[model.LatestReleasedResource]:
     """
     :param tid: The id of the environment this resource belongs to
     :param limit: Limit the number of instances that are returned
     :param first_id: The resource_version_id to use as a continuation token for paging, in combination with the 'start' value,
             because the order by column might contain non-unique values
     :param last_id: The resource_version_id to use as a continuation token for paging, in combination with the 'end' value,
             because the order by column might contain non-unique values
@@ -739,18 +687,14 @@
 
 
 @typedmethod(
     path="/resource/<rid>", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
 )
 def resource_details(tid: uuid.UUID, rid: model.ResourceIdStr) -> model.ReleasedResourceDetails:
     """
-    :param tid: The id of the environment from which the resource's details are being requested.
-    :param rid: The unique identifier (ResourceIdStr) of the resource. This value specifies the particular resource
-                for which detailed information is being requested.
-
     :return: The details of the latest released version of a resource
     :raise NotFound: This exception is raised when the referenced environment or resource is not found
     """
 
 
 @typedmethod(
     path="/resource/<rid>/history", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
@@ -760,15 +704,15 @@
     rid: model.ResourceIdStr,
     limit: Optional[int] = None,
     first_id: Optional[str] = None,
     last_id: Optional[str] = None,
     start: Optional[datetime.datetime] = None,
     end: Optional[datetime.datetime] = None,
     sort: str = "date.desc",
-) -> list[model.ResourceHistory]:
+) -> List[model.ResourceHistory]:
     """
     :param tid: The id of the environment this resource belongs to
     :param rid: The id of the resource
     :param limit: Limit the number of instances that are returned
     :param first_id: The attribute_hash to use as a continuation token for paging, in combination with the 'start' value,
             because the order by column might contain non-unique values
     :param last_id: The attribute_hash to use as a continuation token for paging, in combination with the 'end' value,
@@ -793,17 +737,17 @@
 )
 def resource_logs(
     tid: uuid.UUID,
     rid: model.ResourceIdStr,
     limit: Optional[int] = None,
     start: Optional[datetime.datetime] = None,
     end: Optional[datetime.datetime] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "timestamp.desc",
-) -> list[model.ResourceLog]:
+) -> List[model.ResourceLog]:
     """
     Get the logs of a specific resource.
 
     :param tid: The id of the environment this resource belongs to
     :param rid: The id of the resource
     :param limit: Limit the number of instances that are returned
     :param start: The lower limit for the order by column (exclusive). Only one of 'start' and 'end' should be specified at
@@ -848,15 +792,15 @@
     :raise BadRequest: When the parameters used for filtering, sorting or paging are not valid
     """
 
 
 @typedmethod(
     path="/resource/<rid>/facts", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
 )
-def get_facts(tid: uuid.UUID, rid: model.ResourceIdStr) -> list[model.Fact]:
+def get_facts(tid: uuid.UUID, rid: model.ResourceIdStr) -> List[model.Fact]:
     """
     Get the facts related to a specific resource. The results are sorted alphabetically by name.
     :param tid: The id of the environment
     :param rid: Id of the resource
     :return: The facts related to this resource
     :raise NotFound: This status code is returned when the referenced environment is not found
     """
@@ -884,17 +828,17 @@
 def get_compile_reports(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     first_id: Optional[uuid.UUID] = None,
     last_id: Optional[uuid.UUID] = None,
     start: Optional[datetime.datetime] = None,
     end: Optional[datetime.datetime] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "requested.desc",
-) -> list[model.CompileReport]:
+) -> List[model.CompileReport]:
     """
     Get the compile reports from an environment.
 
     :param tid: The id of the environment
     :param limit: Limit the number of instances that are returned
     :param first_id: The id to use as a continuation token for paging, in combination with the 'start' value,
             because the order by column might contain non-unique values
@@ -937,31 +881,28 @@
 
 
 @typedmethod(
     path="/compilereport/<id>", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
 )
 def compile_details(tid: uuid.UUID, id: uuid.UUID) -> model.CompileDetails:
     """
-    :param tid: The id of the environment in which the compilation process occurred.
-    :param id: The id of the compile for which the details are being requested.
-
     :return: The details of a compile
     :raise NotFound: This exception is raised when the referenced environment or compile is not found
     """
 
 
 @typedmethod(path="/desiredstate", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2)
 def list_desired_state_versions(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     start: Optional[int] = None,
     end: Optional[int] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "version.desc",
-) -> list[model.DesiredStateVersion]:
+) -> List[model.DesiredStateVersion]:
     """
     Get the desired state versions from an environment.
 
     :param tid: The id of the environment
     :param limit: Limit the number of versions that are returned
     :param start: The lower limit for the order by column (exclusive).
                 Only one of 'start' and 'end' should be specified at the same time.
@@ -1012,17 +953,17 @@
     tid: uuid.UUID,
     version: int,
     limit: Optional[int] = None,
     first_id: Optional[model.ResourceVersionIdStr] = None,
     last_id: Optional[model.ResourceVersionIdStr] = None,
     start: Optional[str] = None,
     end: Optional[str] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "resource_type.desc",
-) -> list[model.VersionedResource]:
+) -> List[model.VersionedResource]:
     """
     Get the resources that belong to a specific version.
 
     :param tid: The id of the environment
     :param version: The version number
     :param limit: Limit the number of resources that are returned
     :param first_id: The resource_version_id to use as a continuation token for paging, in combination with the 'start' value,
@@ -1054,15 +995,15 @@
     client_types=[ClientType.api],
     api_version=2,
 )
 def get_diff_of_versions(
     tid: uuid.UUID,
     from_version: int,
     to_version: int,
-) -> list[model.ResourceDiff]:
+) -> List[model.ResourceDiff]:
     """
     Compare two versions of desired states, and provide the difference between them,
     with regard to their resources and the attributes of these resources.
     Resources that are the same in both versions are not mentioned in the results.
 
     A resource diff describes whether the resource was 'added', 'modified' or 'deleted',
     and what the values of their attributes were in the versions.
@@ -1105,17 +1046,17 @@
 def get_parameters(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     first_id: Optional[uuid.UUID] = None,
     last_id: Optional[uuid.UUID] = None,
     start: Optional[Union[datetime.datetime, str]] = None,
     end: Optional[Union[datetime.datetime, str]] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "name.asc",
-) -> list[model.Parameter]:
+) -> List[model.Parameter]:
     """
     List the parameters in an environment
 
     :param tid: The id of the environment
     :param limit: Limit the number of parameters that are returned
     :param first_id: The parameter id to use as a continuation token for paging, in combination with the 'start' value,
         because the order by column might contain non-unique values
@@ -1150,17 +1091,17 @@
 def get_all_facts(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     first_id: Optional[uuid.UUID] = None,
     last_id: Optional[uuid.UUID] = None,
     start: Optional[str] = None,
     end: Optional[str] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "name.asc",
-) -> list[model.Fact]:
+) -> List[model.Fact]:
     """
     List the facts in an environment.
 
     :param tid: The id of the environment
     :param limit: Limit the number of facts that are returned
     :param first_id: The fact id to use as a continuation token for paging, in combination with the 'start' value,
             because the order by column might contain non-unique values
@@ -1199,15 +1140,15 @@
     :return: The id of the new dryrun
     """
 
 
 @typedmethod(
     path="/dryrun/<version>", operation="GET", arg_options=methods.ENV_OPTS, client_types=[ClientType.api], api_version=2
 )
-def list_dryruns(tid: uuid.UUID, version: int) -> list[model.DryRun]:
+def list_dryruns(tid: uuid.UUID, version: int) -> List[model.DryRun]:
     """
     Query a list of dry runs for a specific version
 
     :param tid: The id of the environment
     :param version: The configuration model version to return dryruns for
     :raise NotFound: This exception is raised when the referenced environment or version is not found
     :return: The list of dryruns for the specified version in descending order by date
@@ -1244,17 +1185,17 @@
 def list_notifications(
     tid: uuid.UUID,
     limit: Optional[int] = None,
     first_id: Optional[uuid.UUID] = None,
     last_id: Optional[uuid.UUID] = None,
     start: Optional[datetime.datetime] = None,
     end: Optional[datetime.datetime] = None,
-    filter: Optional[dict[str, list[str]]] = None,
+    filter: Optional[Dict[str, List[str]]] = None,
     sort: str = "created.desc",
-) -> list[model.Notification]:
+) -> List[model.Notification]:
     """
     List the notifications in an environment.
 
     :param tid: The id of the environment
     :param limit: Limit the number of notifications that are returned
     :param first_id: The notification id to use as a continuation token for paging, in combination with the 'start' value,
             because the order by column might contain non-unique values
@@ -1330,15 +1271,15 @@
     path="/code/<version>",
     operation="GET",
     agent_server=True,
     arg_options=methods.ENV_OPTS,
     client_types=[ClientType.agent],
     api_version=2,
 )
-def get_source_code(tid: uuid.UUID, version: int, resource_type: str) -> list[model.Source]:
+def get_source_code(tid: uuid.UUID, version: int, resource_type: str) -> List[model.Source]:
     """
     Get the code for the given version and the given resource
     :param tid: The id of the environment
     :param version: The id of the model version
     :param resource_type: The type name of the resource
     :raises NotFound: Raised when the version or type is not found
     """
@@ -1349,58 +1290,42 @@
     operation="GET",
     arg_options=methods.ENV_OPTS,
     client_types=[ClientType.api],
     api_version=2,
 )
 def get_environment_metrics(
     tid: uuid.UUID,
-    metrics: list[str],
+    metrics: List[str],
     start_interval: datetime.datetime,
     end_interval: datetime.datetime,
     nb_datapoints: int,
-    round_timestamps: bool = False,
 ) -> model.EnvironmentMetricsResult:
     """
     Obtain metrics about the given environment for the given time interval.
 
     :param tid: The id of the environment for which the metrics have to be collected.
     :param metrics: List of names of metrics that have to be returned.
     :param start_interval: The start of the time window for which the metrics should be returned.
     :param end_interval: The end of the time window for which the metrics should be returned.
     :param nb_datapoints: The amount of datapoint that will be returned within the given time interval for each metric.
-    :param round_timestamps: If this parameter is set to True, the timestamps in the reply will be rounded to a full hour.
-        All time windows in the reply will have an equal size. To achieve this the start_interval, end_interval and
-        nb_datapoint in the reply may differ from the ones requested.
-
-            * The start_interval may be smaller than requested
-            * The end_interval may be larger than requested
-            * The nb_datapoints may be larger than requested
-
-    :raises BadRequest: start_interval >= end_interval
-    :raises BadRequest: nb_datapoints < 0
-    :raises BadRequest: The provided metrics list is an empty list.
-    :raises BadRequest: The start_interval and end_interval are not separated from each other by at least nb_datapoints minutes
-                        separated from each other.
-    :raises BadRequest: The round_timestamps parameter is set to True and the amount of hours between
-                        start_interval and end_interval is less than the requested number of datapoints.
     """
 
 
 @typedmethod(path="/login", operation="POST", client_types=[ClientType.api], enforce_auth=False, api_version=2)
 def login(username: str, password: str) -> ReturnValue[model.LoginReturn]:
     """Login a user. When the login succeeds an authentication header is returned with the Bearer token set.
 
     :param username: The user to login
     :param password: The password of this user
     :raises UnauthorizedException: Raised when the login failed or if server authentication is not enabled
     """
 
 
 @typedmethod(path="/user", operation="GET", client_types=[ClientType.api], api_version=2)
-def list_users() -> list[model.User]:
+def list_users() -> List[model.User]:
     """List all users
 
     :return: A list of all users"""
 
 
 @typedmethod(path="/user/<username>", operation="DELETE", client_types=[ClientType.api], api_version=2)
 def delete_user(username: str) -> None:
@@ -1428,7 +1353,90 @@
     """Change the password of a user
 
     :param username: The username of the user
     :param password: The password of this new user. The password should be at least 8 characters long.
     :raises NotFound: Raised when the user does not exist
     :raises BadRequest: Raised when server authentication is not enabled
     """
+
+
+@typedmethod(
+    path="/discovered/<discovered_resource_id>",
+    operation="POST",
+    agent_server=True,
+    arg_options=methods.ENV_OPTS,
+    client_types=[ClientType.agent],
+    api_version=2,
+    varkw=True,
+)
+def discovered_resource_create(
+    tid: uuid.UUID, discovered_resource_id: str, **kwargs: object  # bypass the type checking for the values
+) -> None:
+    """
+    create a discovered resource.
+    :param tid: The id of the environment this resource belongs to
+    :param discovered_resource_id: The id of the discovered_resource
+    :param **kwargs: The following arguments are supported:
+           values: The values associated with the discovered_resource
+    """
+
+
+@typedmethod(
+    path="/discovered/",
+    operation="POST",
+    agent_server=True,
+    arg_options=methods.ENV_OPTS,
+    client_types=[ClientType.agent],
+    api_version=2,
+)
+def discovered_resource_create_batch(tid: uuid.UUID, discovered_resources: List[DiscoveredResource]) -> None:
+    """
+    create multiple discovered resource in the DB
+    :param tid: The id of the environment this resource belongs to
+    :param discovered_resources: List of discovered_resources containing the discovered_resource_id and values for each resource
+    """
+
+
+@typedmethod(
+    path="/discovered/<discovered_resource_id>",
+    operation="GET",
+    arg_options=methods.ENV_OPTS,
+    client_types=[ClientType.api],
+    api_version=2,
+)
+def discovered_resources_get(tid: uuid.UUID, discovered_resource_id: ResourceIdStr) -> model.DiscoveredResource:
+    """
+    Get a single discovered resource.
+
+    :param tid: the id of the environment in which to get the discovered resource.
+    :param discovered_resource_id: The id of the discovered resource
+    """
+
+
+@typedmethod(
+    path="/discovered",
+    operation="GET",
+    arg_options=methods.ENV_OPTS,
+    client_types=[ClientType.api],
+    api_version=2,
+)
+def discovered_resources_get_batch(
+    tid: uuid.UUID,
+    limit: Optional[int] = None,
+    start: Optional[str] = None,
+    end: Optional[str] = None,
+    sort: str = "discovered_resource_id.asc",
+) -> List[model.DiscoveredResource]:
+    """
+    :param tid: The id of the environment this resource belongs to
+    :param limit: Limit the number of instances that are returned
+    :param start: The lower limit for the order by column (exclusive).
+                Only one of 'start' and 'end' should be specified at the same time.
+    :param end: The upper limit for the order by column (exclusive).
+                Only one of 'start' and 'end' should be specified at the same time.
+    :param sort: Return the results sorted according to the parameter value.
+            The following sorting attributes are supported: 'discovered_resource_id'.
+            The following orders are supported: 'asc', 'desc'
+    :return: A list of all matching released resources
+    :raise NotFound: This exception is raised when the referenced environment is not found
+    :raise BadRequest: When the parameters used for filtering, sorting or paging are not valid
+    """
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/openapi/__init__.py` & `inmanta-core-9.3.0/src/inmanta/protocol/openapi/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/openapi/converter.py` & `inmanta-core-9.3.0/src/inmanta/protocol/openapi/converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,17 +14,17 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import inspect
 import json
 import re
-from collections.abc import Callable
-from typing import Optional, Union
+from typing import Callable, Dict, List, Optional, Type, Union
 
+from pydantic.networks import AnyUrl
 from pydantic.schema import model_schema
 from pydantic.typing import NoneType
 from typing_inspect import get_args, get_origin, is_generic_type
 
 from inmanta import util
 from inmanta.data.model import BaseModel, patch_pydantic_field_type_schema
 from inmanta.protocol.common import ArgOption, MethodProperties, ReturnValue, UrlMethod
@@ -57,28 +57,25 @@
 
 
 class OpenApiConverter:
     """
     Extracts API information for the OpenAPI definition from the server
     """
 
-    def __init__(self, global_url_map: dict[str, dict[str, UrlMethod]], feature_manager: FeatureManager):
+    def __init__(self, global_url_map: Dict[str, Dict[str, UrlMethod]], feature_manager: FeatureManager):
         self.global_url_map = global_url_map
         self.feature_manager = feature_manager
         self.type_converter = OpenApiTypeConverter()
         self.arg_option_handler = ArgOptionHandler(self.type_converter)
 
-    def _collect_server_information(self) -> list[Server]:
+    def _collect_server_information(self) -> List[Server]:
         bind_port = config.get_bind_port()
         server_address = config.server_address.get()
-        protocol = "https" if config.ssl_enabled() else "http"
         return [
-            Server(
-                url=f"{protocol}://{server_address}:{bind_port}/",
-            )
+            Server(url=AnyUrl(url=f"http://{server_address}:{bind_port}/", scheme="http", host=server_address, port=bind_port))
         ]
 
     def _get_inmanta_version(self) -> Optional[str]:
         metadata = self.feature_manager.get_product_metadata()
         return metadata.version
 
     def generate_openapi_definition(self) -> OpenAPI:
@@ -90,25 +87,25 @@
             api_methods = self._filter_api_methods(methods)
             if len(api_methods) > 0:
                 path_in_openapi_format = self._format_path(path)
                 path_item = self._extract_operations_from_methods(api_methods, path_in_openapi_format)
                 paths[path_in_openapi_format] = path_item
         return OpenAPI(openapi="3.0.2", info=info, paths=paths, servers=servers, components=self.type_converter.components)
 
-    def _filter_api_methods(self, methods: dict[str, UrlMethod]) -> dict[str, UrlMethod]:
+    def _filter_api_methods(self, methods: Dict[str, UrlMethod]) -> Dict[str, UrlMethod]:
         return {
             method_name: url_method
             for method_name, url_method in methods.items()
             if "api" in url_method.properties.client_types
         }
 
     def _format_path(self, path: str) -> str:
         return path.replace("(?P<", "{").replace(">[^/]+)", "}")
 
-    def _extract_operations_from_methods(self, api_methods: dict[str, UrlMethod], path: str) -> PathItem:
+    def _extract_operations_from_methods(self, api_methods: Dict[str, UrlMethod], path: str) -> PathItem:
         path_item = PathItem()
         for http_method_name, url_method in api_methods.items():
             operation_handler = OperationHandler(self.type_converter, self.arg_option_handler)
             operation = operation_handler.handle_method(url_method, path)
             path_item.__setattr__(http_method_name.lower(), operation)
         return path_item
 
@@ -166,28 +163,28 @@
 
     def get_openapi_type_of_parameter(self, parameter_type: inspect.Parameter) -> Schema:
         schema = self.get_openapi_type(parameter_type.annotation)
         if parameter_type.default is not inspect.Parameter.empty:
             schema.default = parameter_type.default
         return schema
 
-    def _handle_pydantic_model(self, type_annotation: type, by_alias: bool = True) -> Schema:
+    def _handle_pydantic_model(self, type_annotation: Type, by_alias: bool = True) -> Schema:
         # JsonSchema stores the model (and sub-model) definitions at #/definitions,
         # but OpenAPI requires them to be placed at "#/components/schemas/"
         # The ref_prefix changes the references, but the actual schemas are still at #/definitions
         schema = model_schema(type_annotation, by_alias=by_alias, ref_prefix=self.ref_prefix)
         if "definitions" in schema.keys():
-            definitions: dict[str, dict[str, object]] = schema.pop("definitions")
+            definitions: Dict[str, Dict[str, object]] = schema.pop("definitions")
             if self.components.schemas is not None:
                 for key, definition in definitions.items():
                     definition = self._add_type_field_to_enum_value(definition)
                     self.components.schemas[key] = Schema(**definition)
         return Schema(**schema)
 
-    def _add_type_field_to_enum_value(self, definition: dict[str, object]) -> dict[str, object]:
+    def _add_type_field_to_enum_value(self, definition: Dict[str, object]) -> Dict[str, object]:
         """
         When pydantic converts a Python Enum type to its corresponding json schema, it doesn't
         populate the type field. This way the rendered API documentation doesn't include all possible
         enum values. This method makes sure that the type attribute of an enum is always populated.
         """
         if definition.get("enum") is not None and not definition.get("type"):
             # Convert Python type to a type known by OpenAPI
@@ -197,15 +194,15 @@
                 definition["type"] = OpenApiDataTypes.INTEGER.value
             elif all(isinstance(e, float) or isinstance(e, int) for e in definition["enum"]):
                 definition["type"] = OpenApiDataTypes.NUMBER.value
             else:
                 definition["type"] = OpenApiDataTypes.STRING.value
         return definition
 
-    def get_openapi_type(self, type_annotation: type) -> Schema:
+    def get_openapi_type(self, type_annotation: Type) -> Schema:
         class Sub(BaseModel):
             the_field: type_annotation
 
             class Config:
                 arbitrary_types_allowed = True
 
         pydantic_result = self._handle_pydantic_model(Sub).properties["the_field"]
@@ -232,31 +229,31 @@
     Extracts header, response header and path parameter information from ArgOptions
     """
 
     def __init__(self, type_converter: OpenApiTypeConverter) -> None:
         self.type_converter = type_converter
 
     def extract_parameters_from_arg_options(
-        self, method_properties: MethodProperties, function_parameters: dict[str, inspect.Parameter]
-    ) -> list[Parameter]:
-        result: list[Parameter] = []
+        self, method_properties: MethodProperties, function_parameters: Dict[str, inspect.Parameter]
+    ) -> List[Parameter]:
+        result: List[Parameter] = []
         for option_name, option in method_properties.arg_options.items():
             param = function_parameters[option_name]
             param_schema = self.type_converter.get_openapi_type_of_parameter(param)
             param_description = method_properties.get_description_for_param(option_name)
             if option.header:
                 result.append(
                     Parameter(in_=ParameterType.header, name=option.header, schema_=param_schema, description=param_description)
                 )
         return result
 
     def extract_response_headers_from_arg_options(
-        self, arg_options: dict[str, ArgOption]
-    ) -> Optional[dict[str, Union[Header, Reference]]]:
-        headers: dict[str, Union[Header, Reference]] = {}
+        self, arg_options: Dict[str, ArgOption]
+    ) -> Optional[Dict[str, Union[Header, Reference]]]:
+        headers: Dict[str, Union[Header, Reference]] = {}
         for option_name, option in arg_options.items():
             if option.header and option.reply_header:
                 headers[option.header] = Header(
                     description=f"The value of the request header {option.header}", schema=Schema(type="string")
                 )
         return headers if headers else None
 
@@ -275,85 +272,85 @@
     ):
         self.type_converter = type_converter
         self.arg_option_handler = arg_option_handler
         self.path = path
         self.method_properties = method_properties
 
         # Get the parameters of the handler function
-        self.all_params_dct: dict[str, inspect.Parameter] = self._extract_function_parameters(method_properties.function)
-        self.path_params: dict[str, inspect.Parameter] = {}
-        self.header_params: dict[str, inspect.Parameter] = {}
-        self.non_path_and_non_header_params: dict[str, inspect.Parameter] = {}
+        self.all_params_dct: Dict[str, inspect.Parameter] = self._extract_function_parameters(method_properties.function)
+        self.path_params: Dict[str, inspect.Parameter] = {}
+        self.header_params: Dict[str, inspect.Parameter] = {}
+        self.non_path_and_non_header_params: Dict[str, inspect.Parameter] = {}
 
         for param_name, param in self.all_params_dct.items():
             if f"{{{param_name}}}" in self.path:
                 self.path_params[param_name] = param
             elif (
                 param_name in self.method_properties.arg_options.keys()
                 and self.method_properties.arg_options[param_name].header is not None
             ):
                 self.header_params[param_name] = param
             else:
                 self.non_path_and_non_header_params[param_name] = param
 
     # Parameters
 
-    def _extract_function_parameters(self, url_method_function: Callable) -> dict[str, inspect.Parameter]:
+    def _extract_function_parameters(self, url_method_function: Callable) -> Dict[str, inspect.Parameter]:
         function_parameters = {
             parameter_name: parameter_type
             for parameter_name, parameter_type in inspect.signature(url_method_function).parameters.items()
         }
         return function_parameters
 
-    def get_parameters(self) -> list[Parameter]:
+    def get_parameters(self) -> List[Parameter]:
         result = self._convert_header_and_path_params()
         if self.method_properties.operation not in ["POST", "PUT", "PATCH"]:
             result.extend(self._convert_function_params_to_query_params())
         return result
 
-    def _convert_header_and_path_params(self) -> list[Parameter]:
-        arg_options_params: list[Parameter] = self.arg_option_handler.extract_parameters_from_arg_options(
+    def _convert_header_and_path_params(self) -> List[Parameter]:
+        arg_options_params: List[Parameter] = self.arg_option_handler.extract_parameters_from_arg_options(
             self.method_properties, self.all_params_dct
         )
-        path_params: list[Parameter] = self._convert_path_params_to_openapi()
+        path_params: List[Parameter] = self._convert_path_params_to_openapi()
         return arg_options_params + path_params
 
-    def _convert_path_params_to_openapi(self) -> list[Parameter]:
-        parameters: list[Union[Parameter, Reference]] = []
+    def _convert_path_params_to_openapi(self) -> List[Parameter]:
+        parameters: List[Union[Parameter, Reference]] = []
         for parameter_name, parameter_type in self.path_params.items():
             type_description = self.type_converter.get_openapi_type_of_parameter(parameter_type)
             param_description = self.method_properties.get_description_for_param(parameter_name)
             parameters.append(
                 Parameter(
                     name=parameter_name,
                     in_=ParameterType.path,
                     required=True,
                     schema_=type_description,
                     description=param_description,
                 )
             )
         return parameters
 
-    def _convert_function_params_to_query_params(self) -> list[Parameter]:
-        parameters: list[Parameter] = []
+    def _convert_function_params_to_query_params(self) -> List[Parameter]:
+        parameters: List[Parameter] = []
         for parameter_name, parameter_type in self.non_path_and_non_header_params.items():
             type_description = self.type_converter.get_openapi_type_of_parameter(parameter_type)
             param_description = self.method_properties.get_description_for_param(parameter_name)
             parameters.append(
                 Parameter(name=parameter_name, in_=ParameterType.query, schema_=type_description, description=param_description)
             )
         return parameters
 
     # Request body
 
     def convert_request_body(self) -> RequestBody:
         properties = self._convert_function_params_to_openapi_request_body_properties()
         return self._build_json_request_body(properties)
 
-    def _convert_function_params_to_openapi_request_body_properties(self) -> dict[str, Schema]:
+    def _convert_function_params_to_openapi_request_body_properties(self) -> Dict[str, Schema]:
         properties = {}
         for parameter_name, parameter_type in self.non_path_and_non_header_params.items():
             type_description = self.type_converter.get_openapi_type_of_parameter(parameter_type)
             properties[parameter_name] = type_description
         return properties
 
     def _get_request_body_description(self) -> str:
@@ -367,15 +364,15 @@
             description = self.method_properties.get_description_for_param(param_name)
             if description is not None:
                 result += f"* **{param_name}:** {description}\n"
             else:
                 result += f"* **{param_name}:**\n"
         return result
 
-    def _build_json_request_body(self, properties: dict[str, Schema]) -> RequestBody:
+    def _build_json_request_body(self, properties: Dict) -> RequestBody:
         request_body = RequestBody(
             required=True,
             content={"application/json": MediaType(schema=Schema(type="object", properties=properties))},
             description=self._get_request_body_description(),
         )
         return request_body
 
@@ -409,53 +406,53 @@
             parameters=(parameters if len(parameters) else None),
             summary=url_method.short_method_description,
             description=url_method.long_method_description,
             tags=tags,
             **extra_params,
         )
 
-    def _get_tags_of_operation(self, url_method: UrlMethod) -> Optional[list[str]]:
+    def _get_tags_of_operation(self, url_method: UrlMethod) -> Optional[List[str]]:
         if url_method.endpoint is not None:
             if hasattr(url_method.endpoint, "_name"):
                 return [url_method.endpoint._name]
             else:
                 return [url_method.endpoint.__class__.__name__]
         else:
             return None
 
-    def _build_responses(self, url_method_properties: MethodProperties) -> dict[str, Response]:
-        result: dict[str, Response] = {}
+    def _build_responses(self, url_method_properties: MethodProperties) -> Dict[str, Response]:
+        result: Dict[str, Response] = {}
         status_code_to_description_map = url_method_properties.get_description_foreach_http_status_code()
         for status_code, description in status_code_to_description_map.items():
             if status_code == 200:
                 response_headers = self.arg_option_handler.extract_response_headers_from_arg_options(
                     url_method_properties.arg_options
                 )
                 return_value = self._build_return_value_wrapper(url_method_properties)
                 result[str(status_code)] = Response(description=description, content=return_value, headers=response_headers)
             else:
                 result[str(status_code)] = Response(description=description)
 
         return result
 
-    def _build_return_value_wrapper(self, url_method_properties: MethodProperties) -> Optional[dict[str, MediaType]]:
+    def _build_return_value_wrapper(self, url_method_properties: MethodProperties) -> Optional[Dict[str, MediaType]]:
         return_type = inspect.signature(url_method_properties.function).return_annotation
 
         if return_type is None or return_type == inspect.Signature.empty:
             return None
 
-        return_properties: Optional[dict[str, Schema]] = None
+        return_properties: Optional[Dict[str, Schema]] = None
 
         if return_type == ReturnValue or is_generic_type(return_type) and get_origin(return_type) == ReturnValue:
             # Dealing with the special case of ReturnValue[...]
-            links_type = self.type_converter.get_openapi_type(dict[str, str])
+            links_type = self.type_converter.get_openapi_type(Dict[str, str])
             links_type.title = "Links"
             links_type.nullable = True
 
-            warnings_type = self.type_converter.get_openapi_type(list[str])
+            warnings_type = self.type_converter.get_openapi_type(List[str])
             warnings_type.title = "Warnings"
 
             return_properties = {
                 "links": links_type,
                 "metadata": Schema(
                     title="Metadata",
                     nullable=True,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/openapi/model.py` & `inmanta-core-9.3.0/src/inmanta/protocol/openapi/model.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,17 +17,16 @@
 """
 """
 Based on the OpenAPI 3.0.2 Specification:
 https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md
 Inspired by FastAPI:
 https://github.com/tiangolo/fastapi
 """
-from collections.abc import Sequence
 from enum import Enum
-from typing import Any, Optional, Union
+from typing import Any, Dict, List, Optional, Sequence, Union
 
 from pydantic import AnyUrl, Field
 
 from inmanta.data.model import BaseModel
 
 
 class License(BaseModel):
@@ -50,32 +49,32 @@
 class Reference(BaseModel):
     ref: str = Field(..., alias="$ref")
 
 
 class Schema(BaseModel):
     ref: Optional[str] = Field(None, alias="$ref")
     title: Optional[str] = None
-    required: Optional[list[str]] = None
+    required: Optional[List[str]] = None
     type: Optional[str] = None
     items: Optional["Schema"] = None
-    properties: Optional[dict[str, "Schema"]] = None
+    properties: Optional[Dict[str, "Schema"]] = None
     additionalProperties: Optional[Union["Schema", bool]] = None
     description: Optional[str] = None
     format: Optional[str] = None
     default: Optional[Any] = None
     nullable: Optional[bool] = None
     readOnly: Optional[bool] = None
     example: Optional[Any] = None
     deprecated: Optional[bool] = None
     anyOf: Optional[Sequence["Schema"]] = None
     allOf: Optional[Sequence["Schema"]] = None
     oneOf: Optional[Sequence["Schema"]] = None
-    enum: Optional[list[str]] = None
+    enum: Optional[List[str]] = None
 
-    def resolve(self, ref_prefix: str, known_schemas: dict[str, "Schema"]) -> "Schema":
+    def resolve(self, ref_prefix: str, known_schemas: Dict[str, "Schema"]) -> "Schema":
         """
         Returns this object or the one this object is refering to.
 
         :param ref_prefix: The prefix this object ref should have if it is only a reference
         :param known_schemas: A dict of known schemas, the keys are the reference diminished from their prefix
 
         :raises ValueError: If the schema has a badly formed ref
@@ -86,15 +85,15 @@
         if not self.ref.startswith(ref_prefix):
             raise ValueError(f"Schema reference (={self.ref}) doesn't start with the expected prefix: '{ref_prefix}'")
 
         reference = self.ref[len(ref_prefix) :]
         return known_schemas[reference]
 
     def recursive_resolve(
-        self, ref_prefix: str, known_schemas: dict[str, "Schema"], update: dict[str, Any], deep: bool = True
+        self, ref_prefix: str, known_schemas: Dict[str, "Schema"], update: Dict[str, Any], deep: bool = True
     ) -> "Schema":
         """
         Returns this object of the one this object is refering to, and resolve all the nested schema it contains.
 
         :param ref_prefix: The prefix this object ref should have if it is only a reference
         :param known_schemas: A dict of known schemas, the keys are the reference diminished from their prefix
         :param update: values to change/add in the new model.
@@ -161,34 +160,34 @@
     header = "header"
     path = "path"
     cookie = "cookie"
 
 
 class Encoding(BaseModel):
     contentType: Optional[str] = None
-    headers: Optional[dict[str, Union[Any, Reference]]] = None
+    headers: Optional[Dict[str, Union[Any, Reference]]] = None
     allowReserved: Optional[bool] = None
 
 
 class MediaType(BaseModel):
     schema_: Optional[Union[Schema, Reference]] = Field(None, alias="schema")
     example: Optional[Any] = None
-    examples: Optional[dict[str, Union[Example, Reference]]] = None
-    encoding: Optional[dict[str, Encoding]] = None
+    examples: Optional[Dict[str, Union[Example, Reference]]] = None
+    encoding: Optional[Dict[str, Encoding]] = None
 
 
 class ParameterBase(BaseModel):
     description: Optional[str] = None
     required: Optional[bool] = None
     deprecated: Optional[bool] = None
     allowReserved: Optional[bool] = None
     schema_: Optional[Union[Schema, Reference]] = Field(None, alias="schema")
     example: Optional[Any] = None
-    examples: Optional[dict[str, Union[Example, Reference]]] = None
-    content: Optional[dict[str, MediaType]] = None
+    examples: Optional[Dict[str, Union[Example, Reference]]] = None
+    content: Optional[Dict[str, MediaType]] = None
 
 
 class Parameter(ParameterBase):
     name: str
     in_: ParameterType = Field(..., alias="in")
 
     class Config:
@@ -197,64 +196,64 @@
 
 class Header(ParameterBase):
     pass
 
 
 class RequestBody(BaseModel):
     description: Optional[str] = None
-    content: dict[str, MediaType]
+    content: Dict[str, MediaType]
     required: Optional[bool] = None
 
 
 class Response(BaseModel):
     description: str
-    headers: Optional[dict[str, Union[Header, Reference]]] = None
-    content: Optional[dict[str, MediaType]] = None
+    headers: Optional[Dict[str, Union[Header, Reference]]] = None
+    content: Optional[Dict[str, MediaType]] = None
 
 
 class Operation(BaseModel):
     operationId: str
     summary: Optional[str] = None
     description: Optional[str] = None
-    parameters: Optional[list[Union[Parameter, Reference]]] = None
+    parameters: Optional[List[Union[Parameter, Reference]]] = None
     requestBody: Optional[Union[RequestBody, Reference]] = None
-    responses: dict[str, Response]
+    responses: Dict[str, Response]
     deprecated: Optional[bool] = None
-    tags: Optional[list[str]] = None
+    tags: Optional[List[str]] = None
 
 
 class PathItem(BaseModel):
     ref: Optional[str] = Field(None, alias="$ref")
     summary: Optional[str] = None
     description: Optional[str] = None
     get: Optional[Operation] = None
     put: Optional[Operation] = None
     post: Optional[Operation] = None
     delete: Optional[Operation] = None
     options: Optional[Operation] = None
     head: Optional[Operation] = None
     patch: Optional[Operation] = None
     trace: Optional[Operation] = None
-    parameters: Optional[list[Union[Parameter, Reference]]] = None
+    parameters: Optional[List[Union[Parameter, Reference]]] = None
 
 
 class Components(BaseModel):
-    schemas: Optional[dict[str, Schema]] = None
-    responses: Optional[dict[str, Union[Response, Reference]]] = None
-    parameters: Optional[dict[str, Union[Parameter, Reference]]] = None
-    examples: Optional[dict[str, Union[Example, Reference]]] = None
-    requestBodies: Optional[dict[str, Union[RequestBody, Reference]]] = None
-    headers: Optional[dict[str, Union[Header, Reference]]] = None
+    schemas: Optional[Dict[str, Schema]] = None
+    responses: Optional[Dict[str, Union[Response, Reference]]] = None
+    parameters: Optional[Dict[str, Union[Parameter, Reference]]] = None
+    examples: Optional[Dict[str, Union[Example, Reference]]] = None
+    requestBodies: Optional[Dict[str, Union[RequestBody, Reference]]] = None
+    headers: Optional[Dict[str, Union[Header, Reference]]] = None
 
 
 class OpenAPI(BaseModel):
     openapi: str
     info: Info
-    servers: Optional[list[Server]] = None
-    paths: dict[str, PathItem]
+    servers: Optional[List[Server]] = None
+    paths: Dict[str, PathItem]
     components: Optional[Components] = None
 
 
 class OpenApiDataTypes(Enum):
     STRING = "string"
     NUMBER = "number"
     INTEGER = "integer"
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/rest/__init__.py` & `inmanta-core-9.3.0/src/inmanta/protocol/rest/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,16 +15,15 @@
 
     Contact: code@inmanta.com
 """
 import inspect
 import json
 import logging
 import uuid
-from collections.abc import Mapping, MutableMapping
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Type, cast  # noqa: F401
+from typing import TYPE_CHECKING, Any, Dict, List, Mapping, MutableMapping, Optional, Tuple, Type, cast  # noqa: F401
 
 import pydantic
 import typing_inspect
 from tornado import escape
 
 from inmanta import const, util
 from inmanta.data.model import BaseModel
@@ -43,85 +42,85 @@
 
 ServerSlice.server [1] -- RestServer.endpoints [1:]
 
 """
 
 
 def authorize_request(
-    auth_data: Optional[MutableMapping[str, str]], metadata: dict[str, str], message: JsonType, config: common.UrlMethod
+    auth_data: Optional[MutableMapping[str, str]], metadata: Dict[str, str], message: JsonType, config: common.UrlMethod
 ) -> None:
     """
     Authorize a request based on the given data
     """
     if auth_data is None:
         return
 
     # Enforce environment restrictions
     env_key: str = const.INMANTA_URN + "env"
     if env_key in auth_data:
         if env_key not in metadata:
-            raise exceptions.Forbidden("The authorization token is scoped to a specific environment.")
+            raise exceptions.UnauthorizedException("The authorization token is scoped to a specific environment.")
 
         if metadata[env_key] != "all" and auth_data[env_key] != metadata[env_key]:
-            raise exceptions.Forbidden("The authorization token is not valid for the requested environment.")
+            raise exceptions.UnauthorizedException("The authorization token is not valid for the requested environment.")
 
     # Enforce client_types restrictions
     ok: bool = False
     ct_key: str = const.INMANTA_URN + "ct"
     for ct in auth_data[ct_key]:
         if ct in config.properties.client_types:
             ok = True
 
     if not ok:
-        raise exceptions.Forbidden(
+        raise exceptions.UnauthorizedException(
             "The authorization token does not have a valid client type for this call."
-            + f" ({auth_data[ct_key]} provided, {config.properties.client_types} expected"
+            + " (%s provided, %s expected" % (auth_data[ct_key], config.properties.client_types)
         )
 
 
-class CallArguments:
+class CallArguments(object):
     """
     This class represents the call arguments for a method call.
     """
 
     def __init__(
-        self, properties: common.MethodProperties, message: dict[str, Optional[object]], request_headers: Mapping[str, str]
+        self, properties: common.MethodProperties, message: Dict[str, Optional[object]], request_headers: Mapping[str, str]
     ) -> None:
         """
         :param method_config: The method configuration that contains the metadata and functions to call
         :param message: The message recieved by the RPC call
         :param request_headers: The headers received by the RPC call
         """
         self._properties = properties
         self._message = message
         self._request_headers = request_headers
         self._argspec: inspect.FullArgSpec = inspect.getfullargspec(self._properties.function)
 
         self._call_args: JsonType = {}
-        self._headers: dict[str, str] = {}
-        self._metadata: dict[str, object] = {}
+        self._headers: Dict[str, str] = {}
+        self._metadata: Dict[str, object] = {}
 
         self._processed: bool = False
 
     @property
-    def call_args(self) -> dict[str, object]:
+    def call_args(self) -> Dict[str, object]:
         if not self._processed:
             raise Exception("Process call first before accessing property")
 
         return self._call_args
 
     @property
-    def headers(self) -> dict[str, str]:
+    def headers(self) -> Dict[str, str]:
         if not self._processed:
             raise Exception("Process call first before accessing property")
 
         return self._headers
 
     @property
-    def metadata(self) -> dict[str, object]:
+    def metadata(self) -> Dict[str, object]:
         if not self._processed:
             raise Exception("Process call first before accessing property")
 
         return self._metadata
 
     def _is_header_param(self, arg: str) -> bool:
         """
@@ -185,77 +184,61 @@
         try:
             value = await self._properties.arg_options[arg].getter(value, self._metadata)
             return value
         except Exception as e:
             LOGGER.exception("Failed to use getter for arg %s", arg)
             raise e
 
-    @staticmethod
-    def _ensure_list_if_list_type(arg_type: Optional[Type[object]], arg_value: object) -> object:
+    async def process(self) -> None:
         """
-        Handles processing of arguments for GET requests, especially for list types encoded as URL query parameters.
-        If a GET endpoint has a parameter of type list that is encoded as a URL query parameter and the specific request
-        provides a list with one element, urllib doesn't parse it as a list. Map it here explicitly to a list.
+        Process the message
         """
-        if typing_inspect.is_optional_type(arg_type):
-            non_none_arg_types = [arg for arg in typing_inspect.get_args(arg_type) if arg is not type(None)]
-            if len(non_none_arg_types) == 1:
-                arg_type = non_none_arg_types[0]
+        args: List[str] = list(self._argspec.args)
 
-        is_generic_list = arg_type and typing_inspect.is_generic_type(arg_type) and typing_inspect.get_origin(arg_type) is list
-        is_single_type_list = len(typing_inspect.get_args(arg_type, evaluate=True)) == 1
-        arg_value_is_not_list = not isinstance(arg_value, list)
+        if "self" in args:
+            args.remove("self")
 
-        if is_generic_list and is_single_type_list and arg_value_is_not_list:
-            return [arg_value]
-        return arg_value
+        all_fields = set(self._message.keys())  # Track all processed fields to warn user
+        defaults_start: int = -1
+        if self._argspec.defaults is not None:
+            defaults_start = len(args) - len(self._argspec.defaults)
 
-    def _validate_argument_consistency(self, args):
-        """
-        Validates the consistency of arguments, ensuring they are not passed both as a header and a non-header value.
-        """
+        # Make sure that an argument is not passed both using the header and a non-header value with a different value
         for arg in args:
             if arg in self._message and self._is_header_param(arg) and self._is_header_param_provided(arg):
                 message_value = self._message[arg]
                 header_value = self._get_header_value_for(arg)
                 if message_value != header_value:
                     raise exceptions.BadRequest(
                         f"Value for argument {arg} was provided via a header and a non-header argument, but both values"
                         f" don't match (header={header_value}; non-header={message_value})"
                     )
 
-    async def process(self) -> None:
-        """
-        Process the message
-        """
-        args: list[str] = list(self._argspec.args)
-
-        if "self" in args:
-            args.remove("self")
-
-        all_fields = set(self._message.keys())  # Track all processed fields to warn user
-        defaults_start: int = -1
-        if self._argspec.defaults is not None:
-            defaults_start = len(args) - len(self._argspec.defaults)
-
-        self._validate_argument_consistency(args)
-
         call_args = {}
 
         for i, arg in enumerate(args):
-            arg_type: Optional[type[object]] = self._argspec.annotations.get(arg)
+            arg_type: Optional[Type[object]] = self._argspec.annotations.get(arg)
             if arg in self._message:
                 # Argument is parameter in body of path of HTTP request
-                value = self._message[arg]
-
-                if arg_type and self._properties.operation == "GET":
-                    value = self._ensure_list_if_list_type(arg_type, value)
-
+                if (
+                    arg_type
+                    and self._properties.operation == "GET"
+                    and typing_inspect.is_generic_type(arg_type)
+                    and issubclass(typing_inspect.get_origin(arg_type), list)
+                    and not isinstance(self._message[arg], list)
+                    and len(typing_inspect.get_args(arg_type, evaluate=True)) == 1
+                    and isinstance(self._message[arg], typing_inspect.get_args(arg_type)[0])
+                ):
+                    # If a GET endpoint has a parameter of type list that is encoded as a URL query parameter and the
+                    # specific request provides a list with one element, urllib doesn't parse it as a list.
+                    # Map it here explicitly to a list.
+                    value = [self._message[arg]]
+                else:
+                    value = self._message[arg]
                 all_fields.remove(arg)
-
             elif arg_type and self._properties.operation == "GET" and self._is_dict_or_optional_dict(arg_type):
                 # Argument is dictionary-based expression in query parameters of GET operation
                 dict_prefix = f"{arg}."
                 dict_with_prefixed_names = {
                     param_name: param_value
                     for param_name, param_value in self._message.items()
                     if param_name.startswith(dict_prefix) and len(param_name) > len(dict_prefix)
@@ -299,16 +282,16 @@
             raise exceptions.BadRequest(
                 "request contains fields %s that are not declared in method and no kwargs argument is provided." % all_fields
             )
 
         self._processed = True
 
     async def _get_dict_value_from_message(
-        self, arg: str, dict_prefix: str, dict_with_prefixed_names: dict[str, object]
-    ) -> dict[str, object]:
+        self, arg: str, dict_prefix: str, dict_with_prefixed_names: Dict[str, object]
+    ) -> Dict[str, object]:
         value = {k[len(dict_prefix) :]: v for k, v in dict_with_prefixed_names.items()}
         # Check if the values should be converted to lists
         type_args = self._argspec.annotations.get(arg)
         if typing_inspect.is_optional_type(type_args):
             # If optional, get the type args from the not None type argument
             dict_args = typing_inspect.get_args(typing_inspect.get_args(type_args, evaluate=True)[0], evaluate=True)
         else:
@@ -316,23 +299,23 @@
         dict_value_arg_type = (
             typing_inspect.get_origin(dict_args[1]) if typing_inspect.get_origin(dict_args[1]) else dict_args[1]
         )
         if issubclass(dict_value_arg_type, list):
             value = {key: [val] if not isinstance(val, list) else val for key, val in value.items()}
         return value
 
-    def _is_dict_or_optional_dict(self, arg_type: type[object]) -> bool:
+    def _is_dict_or_optional_dict(self, arg_type: Type[object]) -> bool:
         if typing_inspect.is_optional_type(arg_type):
             arg_type = typing_inspect.get_args(arg_type, evaluate=True)[0]
         arg_type = typing_inspect.get_origin(arg_type) if typing_inspect.get_origin(arg_type) else arg_type
         if typing_inspect.is_new_type(arg_type):
             arg_type = type(arg_type)
         return issubclass(arg_type, dict)
 
-    def _validate_union_return(self, arg_type: type[object], value: object) -> None:
+    def _validate_union_return(self, arg_type: Type[object], value: object) -> None:
         """Validate a return with a union type
         :see: protocol.common.MethodProperties._validate_function_types
         """
         matching_type = None
         for t in typing_inspect.get_args(arg_type, evaluate=True):
             instanceof_type = t
             if typing_inspect.is_generic_type(t):
@@ -350,15 +333,15 @@
             raise exceptions.BadRequest(
                 f"Invalid return value, no matching type found in union {arg_type} for value type {type(value)}"
             )
 
         if typing_inspect.is_generic_type(matching_type):
             self._validate_generic_return(arg_type, matching_type)
 
-    def _validate_generic_return(self, arg_type: type[object], value: object) -> None:
+    def _validate_generic_return(self, arg_type: Type[object], value: object) -> None:
         """Validate List or Dict types.
 
         :note: we return any here because the calling function also returns any.
         """
         if issubclass(typing_inspect.get_origin(arg_type), list):
             if not isinstance(value, list):
                 raise exceptions.ServerError(
@@ -507,18 +490,18 @@
         return result
 
     def validate_sid(self, sid: uuid.UUID) -> bool:
         raise NotImplementedError()
 
     async def _execute_call(
         self,
-        kwargs: dict[str, str],
+        kwargs: Dict[str, str],
         http_method: str,
         config: common.UrlMethod,
-        message: dict[str, object],
+        message: Dict[str, object],
         request_headers: Mapping[str, str],
         auth: Optional[MutableMapping[str, str]] = None,
     ) -> common.Response:
         try:
             if kwargs is None or config is None:
                 raise Exception("This method is unknown! This should not occur!")
 
@@ -544,15 +527,15 @@
                     if v in call_args:
                         call_args[k] = call_args[v]
                         del call_args[v]
 
             LOGGER.debug(
                 "Calling method %s(%s)",
                 config.handler,
-                ", ".join([f"{name}='{common.shorten(str(value))}'" for name, value in arguments.call_args.items()]),
+                ", ".join(["%s='%s'" % (name, common.shorten(str(value))) for name, value in arguments.call_args.items()]),
             )
 
             result = await config.handler(**arguments.call_args)
             return await arguments.process_return(config, result)
         except pydantic.ValidationError:
             LOGGER.exception(f"The handler {config.handler} caused a validation error in a data model (pydantic).")
             raise exceptions.ServerError("data validation error.")
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/rest/client.py` & `inmanta-core-9.3.0/src/inmanta/protocol/rest/client.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
     Contact: code@inmanta.com
 """
 
 import logging
 import re
 from asyncio import CancelledError
-from typing import TYPE_CHECKING, Any, AnyStr, Optional
+from typing import TYPE_CHECKING, Any, AnyStr, Dict, List, Optional, Set, Tuple
 from urllib.parse import unquote
 
 from tornado.httpclient import AsyncHTTPClient, HTTPError, HTTPRequest, HTTPResponse
 
 from inmanta import config as inmanta_config
 from inmanta.protocol import common
 from inmanta.protocol.rest import RESTBase
@@ -36,37 +36,35 @@
 
 class RESTClient(RESTBase):
     """ "
     A REST (json body over http) client transport. Only methods that operate on resource can use all
     HTTP verbs. For other methods the POST verb is used.
     """
 
-    def __init__(self, endpoint: "Endpoint", connection_timout: int = 120, force_instance: bool = False) -> None:
+    def __init__(self, endpoint: "Endpoint", connection_timout: int = 120) -> None:
         super().__init__()
         self.__end_point: "Endpoint" = endpoint
         self.daemon: bool = True
         self.token: Optional[str] = inmanta_config.Config.get(self.id, "token", None)
         self.connection_timout: int = connection_timout
-        self.headers: set[str] = set()
+        self.headers: Set[str] = set()
         self.request_timeout: int = inmanta_config.Config.get(self.id, "request_timeout", 120)
-        self.forced_instance = force_instance
-        self.client = AsyncHTTPClient(force_instance=force_instance)
 
     @property
     def endpoint(self) -> "Endpoint":
         return self.__end_point
 
     @property
     def id(self) -> str:
         """
         Returns a unique id for a transport on an endpoint
         """
         return "%s_rest_transport" % self.__end_point.name
 
-    def match_call(self, url: str, method: str) -> tuple[Optional[dict[str, AnyStr]], Optional[common.UrlMethod]]:
+    def match_call(self, url: str, method: str) -> Tuple[Optional[Dict[str, AnyStr]], Optional[common.UrlMethod]]:
         """
         Get the method call for the given url and http method. This method is used for return calls over long poll
         """
         for target in self.endpoint.call_targets:
             url_map = target.get_op_mapping()
             for url_re, handlers in url_map.items():
                 if not url_re.endswith("$"):
@@ -90,15 +88,15 @@
             protocol = "https"
         else:
             protocol = "http"
 
         return "%s://%s:%d" % (protocol, host, port)
 
     async def call(
-        self, properties: common.MethodProperties, args: list[object], kwargs: Optional[dict[str, Any]] = None
+        self, properties: common.MethodProperties, args: List[object], kwargs: Optional[Dict[str, Any]] = None
     ) -> common.Result:
         if kwargs is None:
             kwargs = {}
 
         base_request = properties.build_call(args, kwargs)
 
         url_host = self._get_client_config()
@@ -124,15 +122,16 @@
                 headers=headers,
                 body=body,
                 connect_timeout=self.connection_timout,
                 request_timeout=self.request_timeout,
                 ca_certs=ca_certs,
                 decompress_response=True,
             )
-            response = await self.client.fetch(request)
+            client = AsyncHTTPClient()
+            response = await client.fetch(request)
         except HTTPError as e:
             if e.response is not None and e.response.body is not None and len(e.response.body) > 0:
                 try:
                     result = self._decode(e.response.body)
                 except ValueError:
                     result = {}
                 return common.Result(code=e.code, result=result)
@@ -142,21 +141,14 @@
             raise
         except Exception as e:
             LOGGER.exception("Failed to send request")
             return common.Result(code=500, result={"message": str(e)})
 
         return self._decode_response(response)
 
-    def close(self):
-        """
-        Closes the client manually. This is only needed when it is started with force_instance set to true
-        """
-        if self.forced_instance:
-            self.client.close()
-
     def _decode_response(self, response: HTTPResponse):
         content_type = response.headers.get(common.CONTENT_TYPE, None)
 
         if content_type is None or content_type == common.JSON_CONTENT:
             return common.Result(code=response.code, result=self._decode(response.body))
         elif content_type == common.HTML_CONTENT:
             return common.Result(code=response.code, result=response.body.decode(common.HTML_ENCODING))
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/rest/server.py` & `inmanta-core-9.3.0/src/inmanta/protocol/rest/server.py`

 * *Files 5% similar despite different names*

```diff
@@ -17,49 +17,48 @@
 """
 import asyncio
 import logging
 import ssl
 import uuid
 from asyncio import CancelledError
 from collections import defaultdict
-from collections.abc import MutableMapping, Sequence
 from json import JSONDecodeError
-from typing import Optional, Union
+from typing import Dict, List, MutableMapping, Optional, Sequence, Union
 
 import tornado
 from pyformance import timer
 from tornado import httpserver, iostream, routing, web
 
 import inmanta.protocol.endpoints
 from inmanta import config as inmanta_config
 from inmanta import const
 from inmanta.protocol import common, exceptions
 from inmanta.protocol.rest import RESTBase
 from inmanta.server import config as server_config
-from inmanta.server.config import server_access_control_allow_origin, server_enable_auth, server_tz_aware_timestamps
+from inmanta.server.config import server_access_control_allow_origin, server_enable_auth
 from inmanta.types import ReturnTypes
 
 LOGGER: logging.Logger = logging.getLogger(__name__)
 
 
 class RESTHandler(tornado.web.RequestHandler):
     """
     A generic class use by the transport
     """
 
-    def initialize(self, transport: "RESTServer", config: dict[str, common.UrlMethod]) -> None:
+    def initialize(self, transport: "RESTServer", config: Dict[str, common.UrlMethod]) -> None:
         self._transport: "RESTServer" = transport
         self._config = config
 
     def _get_config(self, http_method: str) -> common.UrlMethod:
         if http_method.upper() not in self._config:
             allowed = ", ".join(self._config.keys())
             self.set_header("Allow", allowed)
             raise exceptions.BaseHttpException(
-                405, f"{http_method} is not supported for this url. Supported methods: {allowed}"
+                405, "%s is not supported for this url. Supported methods: %s" % (http_method, allowed)
             )
 
         return self._config[http_method]
 
     def get_auth_token(self, headers: MutableMapping[str, str]) -> Optional[MutableMapping[str, str]]:
         """
         Get the auth token provided by the caller. The token is provided as a bearer token.
@@ -95,29 +94,29 @@
         for header, value in headers.items():
             self.set_header(header, value)
 
         self.set_status(status)
 
     def _encode_body(self, body: ReturnTypes, content_type: str) -> Union[str, bytes]:
         if content_type == common.JSON_CONTENT:
-            return common.json_encode(body, tz_aware=server_tz_aware_timestamps.get())
+            return common.json_encode(body)
         if content_type == common.HTML_CONTENT:
             assert isinstance(body, str)
             return body.encode(common.HTML_ENCODING)
         if content_type == common.HTML_CONTENT_WITH_UTF8_CHARSET:
             assert isinstance(body, str)
             return body.encode(common.UTF8_ENCODING)
         elif not isinstance(body, (str, bytes)):
             raise exceptions.ServerError(
                 f"Body should be str or bytes and not {type(body)}."
                 " For dict make sure content type is set to {common.JSON_CONTENT}"
             )
         return body
 
-    async def _call(self, kwargs: dict[str, str], http_method: str, call_config: common.UrlMethod) -> None:
+    async def _call(self, kwargs: Dict[str, str], http_method: str, call_config: common.UrlMethod) -> None:
         """
         An rpc like call
         """
         if call_config is None:
             raise exceptions.NotFound("This method does not exist")
 
         if not self._transport.running:
@@ -235,15 +234,15 @@
 
 class StaticContentHandler(tornado.web.RequestHandler):
     def initialize(self, transport: "RESTServer", content: str, content_type: str) -> None:
         self._transport = transport
         self._content = content
         self._content_type = content_type
 
-    def get(self, *args: list[str], **kwargs: dict[str, str]) -> None:
+    def get(self, *args: List[str], **kwargs: Dict[str, str]) -> None:
         self.set_header("Content-Type", self._content_type)
         self.write(self._content)
         self.set_status(200)
 
 
 class RESTServer(RESTBase):
     """
@@ -252,15 +251,15 @@
 
     _http_server: Optional[httpserver.HTTPServer]
 
     def __init__(self, session_manager: common.SessionManagerInterface, id: str) -> None:
         super().__init__()
 
         self._id = id
-        self.headers: dict[str, str] = {}
+        self.headers: Dict[str, str] = {}
         self.session_manager = session_manager
         # number of ongoing requests
         self.inflight_counter = 0
         # event indicating no more in flight requests
         self.idle_event = asyncio.Event()
         self.idle_event.set()
         self.running = False
@@ -275,34 +274,34 @@
         if self.inflight_counter == 0:
             self.idle_event.set()
 
     def validate_sid(self, sid: uuid.UUID) -> bool:
         return self.session_manager.validate_sid(sid)
 
     def get_global_url_map(
-        self, targets: list[inmanta.protocol.endpoints.CallTarget]
-    ) -> dict[str, dict[str, common.UrlMethod]]:
-        global_url_map: dict[str, dict[str, common.UrlMethod]] = defaultdict(dict)
+        self, targets: List[inmanta.protocol.endpoints.CallTarget]
+    ) -> Dict[str, Dict[str, common.UrlMethod]]:
+        global_url_map: Dict[str, Dict[str, common.UrlMethod]] = defaultdict(dict)
         for slice in targets:
             url_map = slice.get_op_mapping()
             for url, configs in url_map.items():
                 handler_config = global_url_map[url]
                 for op, cfg in configs.items():
                     handler_config[op] = cfg
         return global_url_map
 
     async def start(
-        self, targets: Sequence[inmanta.protocol.endpoints.CallTarget], additional_rules: list[routing.Rule] = []
+        self, targets: Sequence[inmanta.protocol.endpoints.CallTarget], additional_rules: List[routing.Rule] = []
     ) -> None:
         """
         Start the server on the current ioloop
         """
-        global_url_map: dict[str, dict[str, common.UrlMethod]] = self.get_global_url_map(targets)
+        global_url_map: Dict[str, Dict[str, common.UrlMethod]] = self.get_global_url_map(targets)
 
-        rules: list[routing.Rule] = []
+        rules: List[routing.Rule] = []
         rules.extend(additional_rules)
 
         for url, handler_config in global_url_map.items():
             rules.append(routing.Rule(routing.PathMatches(url), RESTHandler, {"transport": self, "config": handler_config}))
             LOGGER.debug("Registering handler(s) for url %s and methods %s", url, ", ".join(handler_config.keys()))
 
         application = web.Application(rules, compress_response=True)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/protocol/return_value_meta.py` & `inmanta-core-9.3.0/src/inmanta/protocol/return_value_meta.py`

 * *Files 22% similar despite different names*

```diff
@@ -11,47 +11,46 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from collections.abc import Mapping, MutableMapping
-from typing import Any, Optional, cast
+from typing import Any, Dict, Mapping, MutableMapping, Optional, cast
 
 from inmanta.protocol.common import JSON_CONTENT, ReturnValue, T
 from inmanta.types import ArgumentTypes, ReturnTypes
 
 
 class ReturnValueWithMeta(ReturnValue[T]):
     def __init__(
         self,
         status_code: int = 200,
         headers: MutableMapping[str, str] = {},
         response: Optional[T] = None,
         content_type: str = JSON_CONTENT,
-        links: Optional[dict[str, str]] = None,
+        links: Optional[Dict[str, str]] = None,
         metadata: Optional[Mapping[str, ArgumentTypes]] = None,
     ) -> None:
         super().__init__(status_code, headers, response, content_type, links)
         self.metadata = metadata
 
     def _get_with_envelope(self, envelope_key: str) -> ReturnTypes:
         """Get the body with an envelope specified"""
-        response = cast(dict[str, Any], super()._get_with_envelope(envelope_key))
+        response = cast(Dict[str, Any], super()._get_with_envelope(envelope_key))
         if self.metadata:
             if response.get("metadata"):
                 response["metadata"].update(self.metadata)
             else:
                 response["metadata"] = self.metadata
         return response
 
     def _get_without_envelope(self) -> ReturnTypes:
         """Get the body without an envelope specified"""
         response = super()._get_without_envelope()
         if self.metadata:
-            if isinstance(response, dict):
+            if isinstance(response, Dict):
                 if response.get("metadata"):
                     response["metadata"].update(self.metadata)
                 else:
                     response["metadata"] = self.metadata
         return response
```

### Comparing `inmanta-core-8.7.4/src/inmanta/reporter.py` & `inmanta-core-9.3.0/src/inmanta/reporter.py`

 * *Files 5% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 # Adapted from pyformance
 
 import asyncio
 import base64
 import logging
 import time
 from asyncio import Task
-from typing import Optional
+from typing import Dict, Optional
 from urllib.parse import quote
 
 from pyformance import MetricsRegistry, global_registry
 from tornado.httpclient import AsyncHTTPClient, HTTPError, HTTPRequest
 
 LOGGER = logging.getLogger(__name__)
 
@@ -34,15 +34,15 @@
 DEFAULT_INFLUX_PORT = 8086
 DEFAULT_INFLUX_DATABASE = "metrics"
 DEFAULT_INFLUX_USERNAME = None
 DEFAULT_INFLUX_PASSWORD = None
 DEFAULT_INFLUX_PROTOCOL = "http"
 
 
-class AsyncReporter:
+class AsyncReporter(object):
     def __init__(self, registry: Optional[MetricsRegistry] = None, reporting_interval: int = 30) -> None:
         self.registry = registry or global_registry()
         self.reporting_interval = reporting_interval
         self._stopped = False
         self._handle: Optional[Task[None]] = None
 
     def start(self) -> bool:
@@ -89,37 +89,37 @@
         database: str = DEFAULT_INFLUX_DATABASE,
         server: str = DEFAULT_INFLUX_SERVER,
         username: Optional[str] = DEFAULT_INFLUX_USERNAME,
         password: Optional[str] = DEFAULT_INFLUX_PASSWORD,
         port: int = DEFAULT_INFLUX_PORT,
         protocol: str = DEFAULT_INFLUX_PROTOCOL,
         autocreate_database: bool = False,
-        tags: dict[str, str] = {},
+        tags: Dict[str, str] = {},
     ) -> None:
-        super().__init__(registry, reporting_interval)
+        super(InfluxReporter, self).__init__(registry, reporting_interval)
         self.database = database
         self.username = username
         self.password = password
         self.port = port
         self.protocol = protocol
         self.server = server
         self.autocreate_database = autocreate_database
         self._did_create_database = False
         self.tags = tags
         self.key = "metrics"
         if self.tags:
-            tagstring = ",".join(f"{key}={value}" for key, value in self.tags.items())
-            self.key = f"{self.key},{tagstring}"
+            tagstring = ",".join("%s=%s" % (key, value) for key, value in self.tags.items())
+            self.key = "%s,%s" % (self.key, tagstring)
         self.key = "%s,key=" % self.key
 
         if not self.server:
             raise Exception("Unable to start the metrics reporter without a server. Empty string given.")
 
     async def _create_database(self, http_client: AsyncHTTPClient) -> None:
-        url = f"{self.protocol}://{self.server}:{self.port}/query"
+        url = "%s://%s:%s/query" % (self.protocol, self.server, self.port)
         q = quote("CREATE DATABASE %s" % self.database)
         request = HTTPRequest(url + "?q=" + q)
         if self.username and self.password:
             auth = _encode_username(self.username, self.password)
             request.headers.add("Authorization", "Basic %s" % auth.decode("utf-8"))
         try:
             response = await http_client.fetch(request)
@@ -135,27 +135,29 @@
         if self.autocreate_database and not self._did_create_database:
             await self._create_database(http_client)
         timestamp = timestamp or int(round(time.time()))
         metrics = (registry or self.registry).dump_metrics()
         post_data = []
         for key, metric_values in metrics.items():
             table = self.key + key
-            values = ",".join(["{}={}".format(k, v if type(v) is not str else f'"{v}"') for (k, v) in metric_values.items()])
-            line = f"{table} {values} {timestamp}"
+            values = ",".join(
+                ["%s=%s" % (k, v if type(v) is not str else '"{}"'.format(v)) for (k, v) in metric_values.items()]
+            )
+            line = "%s %s %s" % (table, values, timestamp)
             post_data.append(line)
         post_data_all = "\n".join(post_data)
         path = "/write?db=%s&precision=s" % self.database
-        url = f"{self.protocol}://{self.server}:{self.port}{path}"
+        url = "%s://%s:%s%s" % (self.protocol, self.server, self.port, path)
         request = HTTPRequest(url, method="POST", body=post_data_all.encode("utf-8"))
         if self.username and self.password:
             auth = _encode_username(self.username, self.password)
             request.headers.add("Authorization", "Basic %s" % auth.decode("utf-8"))
         try:
             response = await http_client.fetch(request)
             response.rethrow()
         except HTTPError:
             LOGGER.warning("Cannot write to %s", self.server, exc_info=True)
 
 
 def _encode_username(username: str, password: str) -> bytes:
-    auth_string = (f"{username}:{password}").encode()
+    auth_string = ("%s:%s" % (username, password)).encode()
     return base64.b64encode(auth_string)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/resources.py` & `inmanta-core-9.3.0/src/inmanta/resources.py`

 * *Files 4% similar despite different names*

```diff
@@ -14,16 +14,31 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import json
 import logging
 import re
-from collections.abc import Callable, Iterable, Iterator, Sequence
-from typing import TYPE_CHECKING, Any, Optional, TypeVar, Union, cast
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Callable,
+    Dict,
+    Iterable,
+    Iterator,
+    List,
+    Optional,
+    Sequence,
+    Set,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    cast,
+)
 
 import inmanta.util
 from inmanta import plugins
 from inmanta.ast import CompilerException, ExplicitPluginException, ExternalException
 from inmanta.data.model import ResourceIdStr, ResourceVersionIdStr
 from inmanta.execute import proxy, util
 from inmanta.stable_api import stable_api
@@ -41,15 +56,15 @@
     pass
 
 
 T = TypeVar("T", bound="Resource")
 
 
 @stable_api
-class resource:  # noqa: N801
+class resource(object):  # noqa: N801
     """
     A decorator that registers a new resource. The decorator must be applied to classes that inherit from
     :class:`~inmanta.resources.Resource`
 
     :param name: The name of the entity in the configuration model it creates a resources from. For example
                  :inmanta:entity:`std::File`
     :param id_attribute: The attribute of `this` resource that uniquely identifies a resource on an agent. This attribute
@@ -57,23 +72,23 @@
     :param agent: This string indicates how the agent of this resource is determined. This string points to an attribute,
                   but it can navigate relations (this value cannot be mapped). For example, the agent argument could be
                   ``host.name``
     """
 
     # The _resources dict is accessed by the compile function in pytest-inmanta.
     # see https://github.com/inmanta/pytest-inmanta/pull/381
-    _resources: dict[str, tuple[type["Resource"], dict[str, str]]] = {}
+    _resources: Dict[str, Tuple[Type["Resource"], Dict[str, str]]] = {}
 
     def __init__(self, name: str, id_attribute: str, agent: str):
         if not isinstance(agent, str):
             raise ResourceException(f"The agent parameter has to be a string, got {agent} of type {type(agent)}")
         self._cls_name = name
         self._options = {"agent": agent, "name": id_attribute}
 
-    def __call__(self, cls: type[T]) -> type[T]:
+    def __call__(self, cls: Type[T]) -> Type[T]:
         """
         The wrapping
         """
         if self._cls_name in resource._resources:
             LOGGER.info("Reloading module %s" % self._cls_name)
             del resource._resources[self._cls_name]
 
@@ -89,25 +104,25 @@
     def get_entity_resources(cls) -> Iterable[str]:
         """
         Returns a list of entity types for which a resource has been registered
         """
         return cls._resources.keys()
 
     @classmethod
-    def get_class(cls, name: str) -> tuple[Optional[type["Resource"]], Optional[dict[str, str]]]:
+    def get_class(cls, name: str) -> Tuple[Optional[Type["Resource"]], Optional[Dict[str, str]]]:
         """
         Get the class definition for the given entity.
         """
         if name in cls._resources:
             return cls._resources[name]
 
         return (None, None)
 
     @classmethod
-    def get_resources(cls) -> Iterator[tuple[str, type["Resource"]]]:
+    def get_resources(cls) -> Iterator[Tuple[str, Type["Resource"]]]:
         """Return an iterator over resource type, resource definition"""
         return (
             (resource_type, resource_definition) for resource_type, (resource_definition, _options) in cls._resources.items()
         )
 
     @classmethod
     def reset(cls) -> None:
@@ -123,15 +138,14 @@
     """
 
 
 @stable_api
 class IgnoreResourceException(Exception):
     """
     Throw this exception when a resource should not be included by the exported.
-    Typically resources use this to indicate that they are not managed by the orchestrator.
     """
 
 
 def to_id(entity: "proxy.DynamicProxy") -> Optional[str]:
     """
     Convert an entity instance from the model to its resource id
     """
@@ -147,16 +161,16 @@
         return str(obj_id)
 
     return None
 
 
 class ResourceMeta(type):
     @classmethod
-    def _get_parent_fields(cls, bases: Sequence[type["Resource"]]) -> list[str]:
-        fields: list[str] = []
+    def _get_parent_fields(cls, bases: Sequence[Type["Resource"]]) -> List[str]:
+        fields: List[str] = []
         for base in bases:
             if "fields" in base.__dict__:
                 if not isinstance(base.__dict__["fields"], (tuple, list)):
                     raise Exception("fields attribute of %s should be a tuple or list" % base)
 
                 fields.extend(base.__dict__["fields"])
 
@@ -189,36 +203,36 @@
     itself and all superclasses. If a field it not available directly in the model object the serializer will look for
     static methods in the class with the name "get_$fieldname".
     """
 
     fields: Sequence[str] = ("send_event",)
     send_event: bool  # Deprecated field
     model: "proxy.DynamicProxy"
-    map: dict[str, Callable[[Optional["export.Exporter"], "proxy.DynamicProxy"], Any]]
+    map: Dict[str, Callable[[Optional["export.Exporter"], "proxy.DynamicProxy"], Any]]
 
     @staticmethod
     def get_send_event(_exporter: "export.Exporter", obj: "Resource") -> bool:
         try:
             return obj.send_event
         except Exception:
             return False
 
     @classmethod
     def convert_requires(
-        cls, resources: dict["runtime.Instance", "Resource"], ignored_resources: set["runtime.Instance"]
+        cls, resources: Dict["runtime.Instance", "Resource"], ignored_resources: Set["runtime.Instance"]
     ) -> None:
         """
         Convert all requires
 
         :param resources: A dict with a mapping from model objects to resource objects
         :param ignored_resources: A set of model objects that have been ignored (and not converted to resources)
         """
         for res in resources.values():
-            final_requires: set["Resource"] = set()
-            initial_requires: list["runtime.Instance"] = [x for x in res.model.requires]
+            final_requires: Set["Resource"] = set()
+            initial_requires: List["runtime.Instance"] = [x for x in res.model.requires]
 
             for r in initial_requires:
                 if r in resources:
                     final_requires.add(resources[r])
 
             if len(final_requires) == 0 and not len(initial_requires) == 0:
                 for r in initial_requires:
@@ -246,15 +260,15 @@
 
         :param model_object: The object to convert to an id
         :param entity_name: The entity type
         :param attribute_name: The name of the attribute that uniquely identifies the entity
         :param agent_attribute: The "path" to the attribute that defines the agent
         """
         # first get the agent attribute
-        path_elements: list[str] = agent_attribute.split(".")
+        path_elements: List[str] = agent_attribute.split(".")
         agent_value = model_object
         for el in path_elements:
             try:
                 # TODO cleanup this hack
                 if isinstance(agent_value, list):
                     agent_value = agent_value[0]
 
@@ -275,15 +289,15 @@
             raise proxy.UnknownException(attribute_value)
         if not isinstance(agent_value, str):
             raise ResourceException(
                 f"The agent attribute should lead to a string, got {agent_value} of type {type(agent_value)}"
             )
 
         # agent_value is no longer a proxy.DynamicProxy here, force this for mypy validation
-        return Id(entity_name, str(agent_value), attribute_name, str(attribute_value))
+        return Id(entity_name, str(agent_value), attribute_name, attribute_value)
 
     @classmethod
     def map_field(
         cls, exporter: Optional["export.Exporter"], entity_name: str, field_name: str, model_object: "proxy.DynamicProxy"
     ) -> str:
         try:
             if hasattr(cls, "get_" + field_name):
@@ -357,37 +371,37 @@
     @classmethod
     def validate(cls) -> None:
         for field in cls.fields:
             if field.startswith("_"):
                 raise ResourceException("Resource field names can not start with _, reported in %s" % cls.__name__)
             if field in RESERVED_FOR_RESOURCE:
                 raise ResourceException(
-                    f"Resource {field} is a reserved keyword and not a valid field name, reported in {cls.__name__}"
+                    "Resource %s is a reserved keyword and not a valid field name, reported in %s" % (field, cls.__name__)
                 )
 
     def __init__(self, _id: "Id") -> None:
         self.id = _id
-        self.requires: set[Id] = set()
-        self.resource_requires: set[Resource] = set()
-        self.unknowns: set[str] = set()
+        self.requires: Set[Id] = set()
+        self.resource_requires: Set[Resource] = set()
+        self.unknowns: Set[str] = set()
 
         if not hasattr(self.__class__, "fields"):
             raise Exception("A resource should have a list of fields")
 
         for field in self.__class__.fields:
             setattr(self, field, None)
 
         self.version = _id.version
 
-    def populate(self, fields: dict[str, Any], force_fields: bool = False) -> None:
+    def populate(self, fields: Dict[str, Any], force_fields: bool = False) -> None:
         for field in self.__class__.fields:
             if field in fields or force_fields:
                 setattr(self, field, fields[field])
             else:
-                raise Exception("Resource with id {} does not have field {}".format(fields["id"], field))
+                raise Exception("Resource with id %s does not have field %s" % (fields["id"], field))
         if "requires" in fields:
             # parse requires into ID's
             for require in fields["requires"]:
                 self.requires.add(Id.parse_id(require))
 
     def set_version(self, version: int) -> None:
         """
@@ -420,15 +434,15 @@
 
         return res
 
     def serialize(self) -> JsonType:
         """
         Serialize this resource to its dictionary representation
         """
-        dictionary: dict[str, Any] = {}
+        dictionary: Dict[str, Any] = {}
 
         for field in self.__class__.fields:
             dictionary[field] = getattr(self, field)
 
         dictionary["requires"] = [str(x) for x in self.requires]
         dictionary["version"] = self.version
         dictionary["id"] = self.id.resource_version_str()
@@ -475,15 +489,15 @@
 PARSE_RVID_REGEX = re.compile(
     r"^(?P<id>(?P<type>(?P<ns>[\w-]+(::[\w-]+)*)::(?P<class>[\w-]+))\[(?P<hostname>[^,]+),"
     r"(?P<attr>[^=]+)=(?P<value>[^\]]+)\]),v=(?P<version>[0-9]+)$"
 )
 
 
 @stable_api
-class Id:
+class Id(object):
     """
     A unique id that identifies a resource that is managed by an agent
     """
 
     def __init__(self, entity_type: str, agent_name: str, attribute: str, attribute_value: str, version: int = 0) -> None:
         self._entity_type = entity_type
         self._agent_name = agent_name
@@ -532,15 +546,15 @@
             return self.resource_version_str()
         return self.resource_str()
 
     def __hash__(self) -> int:
         return hash(str(self))
 
     def __eq__(self, other: object) -> bool:
-        return str(self) == str(other) and type(self) is type(other)
+        return str(self) == str(other) and type(self) == type(other)
 
     def resource_str(self) -> ResourceIdStr:
         return cast(
             ResourceIdStr,
             "%(type)s[%(agent)s,%(attribute)s=%(value)s]"
             % {
                 "type": self._entity_type,
@@ -658,11 +672,11 @@
         self.user = user
         self.error = error
 
     def to_action(self) -> "ResourceAction":
         from inmanta.data import ResourceAction
 
         ra = ResourceAction()  # @UndefinedVariable
-        ra.message = f"Failed to access host {self.hostname} as user {self.user} over ssh."
+        ra.message = "Failed to access host %s as user %s over ssh." % (self.hostname, self.user)
         ra.data = {"host": self.hostname, "user": self.user, "error": self.error}
 
         return ra
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/__init__.py` & `inmanta-core-9.3.0/src/inmanta/server/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/server/agentmanager.py` & `inmanta-core-9.3.0/src/inmanta/server/agentmanager.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,23 +18,22 @@
 import asyncio
 import logging
 import os
 import sys
 import time
 import uuid
 from asyncio import queues, subprocess
-from collections.abc import Iterable, Sequence
 from datetime import datetime
 from enum import Enum
-from typing import Any, Optional, Union, cast
+from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Tuple, Union, cast
 from uuid import UUID
 
 import asyncpg.connection
 
-from inmanta import const, data
+from inmanta import const, data, util
 from inmanta.agent import config as agent_cfg
 from inmanta.config import Config
 from inmanta.const import AgentAction, AgentStatus
 from inmanta.data import APILIMIT, InvalidSort, model
 from inmanta.data.model import ResourceIdStr
 from inmanta.protocol import encode_token, handle, methods, methods_v2
 from inmanta.protocol.common import ReturnValue
@@ -103,15 +102,15 @@
 
 class SessionAction:
     """
     A session update to be executed by the AgentManager.
     """
 
     def __init__(
-        self, action_type: SessionActionType, session: protocol.Session, endpoint_names_snapshot: set[str], timestamp: datetime
+        self, action_type: SessionActionType, session: protocol.Session, endpoint_names_snapshot: Set[str], timestamp: datetime
     ):
         self.action_type = action_type
         self.session = session
         self.endpoint_names_snapshot = endpoint_names_snapshot
         self.timestamp = timestamp
 
 
@@ -133,49 +132,49 @@
 
     Throughout this class the terms "logical agent" or sometimes just "agent" refer to a logical agent managed by an
     instance of this class. The terms "agent instance", "agent process" or just "process" refer to a concrete process
     running an agent instance, which might be the primary for a logical agent.
     """
 
     def __init__(self, closesessionsonstart: bool = True, fact_back_off: Optional[int] = None) -> None:
-        super().__init__(SLICE_AGENT_MANAGER)
+        super(AgentManager, self).__init__(SLICE_AGENT_MANAGER)
 
         if fact_back_off is None:
             fact_back_off = opt.server_fact_resource_block.get()
 
         # back-off timer for fact requests
         self._fact_resource_block: int = fact_back_off
         # per resource time of last fact request
-        self._fact_resource_block_set: dict[str, float] = {}
+        self._fact_resource_block_set: Dict[str, float] = {}
 
         # session lock
         self.session_lock = asyncio.Lock()
         # all sessions
-        self.sessions: dict[UUID, protocol.Session] = {}
+        self.sessions: Dict[UUID, protocol.Session] = {}
         # live sessions: Sessions to agents which are primary and unpaused
-        self.tid_endpoint_to_session: dict[tuple[UUID, str], protocol.Session] = {}
+        self.tid_endpoint_to_session: Dict[Tuple[UUID, str], protocol.Session] = {}
         # All endpoints associated with a sid
-        self.endpoints_for_sid: dict[uuid.UUID, set[str]] = {}
+        self.endpoints_for_sid: Dict[uuid.UUID, Set[str]] = {}
 
         # This queue ensures that notifications from the SessionManager are processed in the same order
         # in which they arrive in the SessionManager, without blocking the SessionManager.
         self._session_listener_actions: queues.Queue[SessionAction] = queues.Queue()
 
         self.closesessionsonstart: bool = closesessionsonstart
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         return {
             "resource_facts": len(self._fact_resource_block_set),
             "sessions": len(self.sessions),
         }
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_SESSION_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await ServerSlice.prestart(self, server)
         autostarted_agent_manager = server.get_slice(SLICE_AUTOSTARTED_AGENT_MANAGER)
         assert isinstance(autostarted_agent_manager, AutostartedAgentManager)
         self._autostarted_agent_manager = autostarted_agent_manager
@@ -205,15 +204,15 @@
         await data.Agent.persist_on_halt(env.id, connection=connection)
         await self._pause_agent(env, connection=connection)
 
     async def resume_agents(self, env: data.Environment, connection: Optional[asyncpg.connection.Connection] = None) -> None:
         """
         Resumes after halting. Unpauses all agents that had been paused by halting.
         """
-        to_unpause: list[str] = await data.Agent.persist_on_resume(env.id, connection=connection)
+        to_unpause: List[str] = await data.Agent.persist_on_resume(env.id, connection=connection)
         await asyncio.gather(*[self._unpause_agent(env, agent, connection=connection) for agent in to_unpause])
 
     @handle(methods_v2.all_agents_action, env="tid")
     async def all_agents_action(self, env: data.Environment, action: AgentAction) -> None:
         if env.halted and action in {AgentAction.pause, AgentAction.unpause}:
             raise Forbidden("Can not pause or unpause agents when the environment has been halted.")
         if not env.halted and action in {AgentAction.keep_paused_on_resume, AgentAction.unpause_on_resume}:
@@ -338,55 +337,55 @@
             await self._seen_session(action.session, action.endpoint_names_snapshot)
         elif action_type == SessionActionType.EXPIRE_SESSION:
             await self._expire_session(action.session, action.endpoint_names_snapshot, action.timestamp)
         else:
             LOGGER.warning("Unknown SessionAction %s", action_type.name)
 
     # Notify from session listener
-    async def new_session(self, session: protocol.Session, endpoint_names_snapshot: set[str]) -> None:
+    async def new_session(self, session: protocol.Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         The _session_listener_actions queue ensures that all SessionActions are executed in the order of arrival.
         """
         session_action = SessionAction(
             action_type=SessionActionType.REGISTER_SESSION,
             session=session,
             endpoint_names_snapshot=endpoint_names_snapshot,
             timestamp=datetime.now().astimezone(),
         )
         await self._session_listener_actions.put(session_action)
 
     # Notify from session listener
-    async def expire(self, session: protocol.Session, endpoint_names_snapshot: set[str]) -> None:
+    async def expire(self, session: protocol.Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         The _session_listener_actions queue ensures that all SessionActions are executed in the order of arrival.
         """
         session_action = SessionAction(
             action_type=SessionActionType.EXPIRE_SESSION,
             session=session,
             endpoint_names_snapshot=endpoint_names_snapshot,
             timestamp=datetime.now().astimezone(),
         )
         await self._session_listener_actions.put(session_action)
 
     # Notify from session listener
-    async def seen(self, session: protocol.Session, endpoint_names_snapshot: set[str]) -> None:
+    async def seen(self, session: protocol.Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         The _session_listener_actions queue ensures that all SessionActions are executed in the order of arrival.
         """
         session_action = SessionAction(
             action_type=SessionActionType.SEEN_SESSION,
             session=session,
             endpoint_names_snapshot=endpoint_names_snapshot,
             timestamp=datetime.now().astimezone(),
         )
         await self._session_listener_actions.put(session_action)
 
     # Seen
-    async def _seen_session(self, session: protocol.Session, endpoint_names_snapshot: set[str]) -> None:
-        endpoints_with_new_primary: list[tuple[str, Optional[uuid.UUID]]] = []
+    async def _seen_session(self, session: protocol.Session, endpoint_names_snapshot: Set[str]) -> None:
+        endpoints_with_new_primary: List[Tuple[str, Optional[uuid.UUID]]] = []
         async with self.session_lock:
             endpoints_in_agent_manager = self.endpoints_for_sid[session.id]
             endpoints_in_session = endpoint_names_snapshot
             endpoints_to_add = endpoints_in_session - endpoints_in_agent_manager
             LOGGER.debug("Adding endpoints %s to session %s on %s", endpoints_to_add, session.id, session.nodename)
             endpoints_to_remove = endpoints_in_agent_manager - endpoints_in_session
             LOGGER.debug("Removing endpoints %s from session %s on %s", endpoints_to_remove, session.id, session.nodename)
@@ -398,31 +397,31 @@
         self.add_background_task(
             self._log_session_seen_to_db(session, endpoints_to_add, endpoints_to_remove, endpoints_with_new_primary)
         )
 
     async def _log_session_seen_to_db(
         self,
         session: protocol.Session,
-        endpoints_to_add: set[str],
-        endpoints_to_remove: set[str],
-        endpoints_with_new_primary: list[tuple[str, Optional[uuid.UUID]]],
+        endpoints_to_add: Set[str],
+        endpoints_to_remove: Set[str],
+        endpoints_with_new_primary: List[Tuple[str, Optional[uuid.UUID]]],
     ) -> None:
         """
         Note: This method call is allowed to fail when the database connection is lost.
         """
         now = datetime.now().astimezone()
         async with data.AgentProcess.get_connection() as connection:
             async with connection.transaction():
                 await data.AgentProcess.update_last_seen(session.id, now, connection)
                 await data.AgentInstance.log_instance_creation(session.tid, session.id, endpoints_to_add, connection)
                 await data.AgentInstance.log_instance_expiry(session.id, endpoints_to_remove, now, connection)
                 await data.Agent.update_primary(session.tid, endpoints_with_new_primary, now, connection)
 
     # Session registration
-    async def _register_session(self, session: protocol.Session, endpoint_names_snapshot: set[str], now: datetime) -> None:
+    async def _register_session(self, session: protocol.Session, endpoint_names_snapshot: Set[str], now: datetime) -> None:
         """
         This method registers a new session in memory and asynchronously updates the agent
         session log in the database. When the database connection is lost, the get_statuses()
         call fails and the new session will be refused.
         """
         LOGGER.debug("New session %s for agents %s on %s", session.id, endpoint_names_snapshot, session.nodename)
         async with self.session_lock:
@@ -443,29 +442,29 @@
             self._log_session_creation_to_db(tid, session, endpoint_names_snapshot, endpoints_with_new_primary, now)
         )
 
     async def _log_session_creation_to_db(
         self,
         tid: uuid.UUID,
         session: protocol.Session,
-        endpoint_names: set[str],
-        endpoints_with_new_primary: Sequence[tuple[str, Optional[uuid.UUID]]],
+        endpoint_names: Set[str],
+        endpoints_with_new_primary: Sequence[Tuple[str, Optional[uuid.UUID]]],
         now: datetime,
     ) -> None:
         """
         Note: This method call is allowed to fail when the database connection is lost.
         """
         async with data.AgentProcess.get_connection() as connection:
             async with connection.transaction():
                 await data.AgentProcess.seen(tid, session.nodename, session.id, now, connection)
                 await data.AgentInstance.log_instance_creation(tid, session.id, endpoint_names, connection)
                 await data.Agent.update_primary(tid, endpoints_with_new_primary, now, connection)
 
     # Session expiry
-    async def _expire_session(self, session: protocol.Session, endpoint_names_snapshot: set[str], now: datetime) -> None:
+    async def _expire_session(self, session: protocol.Session, endpoint_names_snapshot: Set[str], now: datetime) -> None:
         """
         This method expires the given session and update the in-memory session state.
         The in-database session log is updated asynchronously. These database updates
         are allowed to fail when the database connection is lost.
         """
         if not self.is_running() or self.is_stopping():
             return
@@ -481,25 +480,23 @@
             endpoints_with_new_primary = await self._failover_endpoints(session, endpoint_names_snapshot)
 
         self.add_background_task(self._log_session_expiry_to_db(tid, endpoints_with_new_primary, session, now))
 
     async def _log_session_expiry_to_db(
         self,
         tid: uuid.UUID,
-        endpoints_with_new_primary: Sequence[tuple[str, Optional[uuid.UUID]]],
+        endpoints_with_new_primary: Sequence[Tuple[str, Optional[uuid.UUID]]],
         session: protocol.Session,
         now: datetime,
     ) -> None:
         """
         Note: This method call is allowed to fail when the database connection is lost.
         """
         async with data.AgentProcess.get_connection() as connection:
             async with connection.transaction():
-                # Make sure to access the database tables in the order defined in docs string of inmanta/data/__init__.py
-                # to prevent deadlock issues.
                 await data.AgentProcess.expire_process(session.id, now, connection)
                 await data.AgentInstance.log_instance_expiry(session.id, session.endpoint_names, now, connection)
                 await data.Agent.update_primary(tid, endpoints_with_new_primary, now, connection)
 
     async def _expire_all_sessions_in_db(self) -> None:
         async with self.session_lock:
             LOGGER.debug("Cleaning server session DB")
@@ -527,16 +524,16 @@
             set_state_call = new_active_session.get_client().set_state(endpoint_name, enabled=True)
             self.add_background_task(set_state_call)
         elif key in self.tid_endpoint_to_session:
             del self.tid_endpoint_to_session[key]
         return new_active_session
 
     async def _ensure_primary_if_not_exists(
-        self, session: protocol.Session, endpoints: set[str]
-    ) -> Sequence[tuple[str, uuid.UUID]]:
+        self, session: protocol.Session, endpoints: Set[str]
+    ) -> Sequence[Tuple[str, uuid.UUID]]:
         """
         Make this session the primary session for the endpoints of this session if no primary exists and the agent is not
         paused.
 
         :return: The endpoints that got a new primary.
 
         Note: Always call under session lock.
@@ -551,16 +548,16 @@
                 LOGGER.debug("set session %s as primary for agent %s in env %s", session.id, endpoint, session.tid)
                 self.tid_endpoint_to_session[key] = session
                 self.add_background_task(session.get_client().set_state(endpoint, enabled=True))
                 result.append((endpoint, session.id))
         return result
 
     async def _failover_endpoints(
-        self, session: protocol.Session, endpoints: set[str]
-    ) -> Sequence[tuple[str, Optional[uuid.UUID]]]:
+        self, session: protocol.Session, endpoints: Set[str]
+    ) -> Sequence[Tuple[str, Optional[uuid.UUID]]]:
         """
         If the given session is the primary for a given endpoint, failover to a new session.
 
         :return: The endpoints that got a new primary.
 
         Note: Always call under session lock.
         """
@@ -627,27 +624,27 @@
             if session:
                 return session.get_client()
             else:
                 return None
         else:
             return None
 
-    async def are_agents_active(self, tid: uuid.UUID, endpoints: list[str]) -> bool:
+    async def are_agents_active(self, tid: uuid.UUID, endpoints: List[str]) -> bool:
         """
         Return true iff all the given agents are in the up or the paused state.
         """
         return all(active for (_, active) in await self.get_agent_active_status(tid, endpoints))
 
-    async def get_agent_active_status(self, tid: uuid.UUID, endpoints: list[str]) -> list[tuple[str, bool]]:
+    async def get_agent_active_status(self, tid: uuid.UUID, endpoints: List[str]) -> List[Tuple[str, bool]]:
         """
         Return a list of tuples where the first element of the tuple contains the name of an endpoint
         and the second a boolean indicating where there is an active (up or paused) agent for that endpoint.
         """
         all_sids_for_env = [sid for (sid, session) in self.sessions.items() if session.tid == tid]
-        all_active_endpoints_for_env = {ep for sid in all_sids_for_env for ep in self.endpoints_for_sid[sid]}
+        all_active_endpoints_for_env = set(ep for sid in all_sids_for_env for ep in self.endpoints_for_sid[sid])
         return [(ep, ep in all_active_endpoints_for_env) for ep in endpoints]
 
     async def expire_all_sessions_for_environment(self, env_id: uuid.UUID) -> None:
         async with self.session_lock:
             await asyncio.gather(*[s.expire_and_abort(timeout=0) for s in self.sessions.values() if s.tid == env_id])
 
     async def expire_all_sessions(self) -> None:
@@ -715,15 +712,15 @@
         :param start: The sid all of the selected agent process should be greater than this, defaults to None
         :param end: The sid all of the selected agent process should be smaller than this, defaults to None
         :param limit: Whether to limit the number of returned entries, defaults to None
         :raises BadRequest: Limit, start and end can not be set together
         :raises NotFound: The given environment id does not exist!
         :raises BadRequest: Limit parameter can not exceed 1000
         """
-        query: dict[str, Any] = {}
+        query: Dict[str, Any] = {}
         if environment is not None:
             query["environment"] = environment
             env = await data.Environment.get_by_id(environment)
             if env is None:
                 return 404, {"message": "The given environment id does not exist!"}
         if not expired:
             query["expired"] = None
@@ -791,18 +788,15 @@
             end=end,
             no_obj=False,
             lock=None,
             connection=None,
             **query,
         )
 
-        return 200, {
-            "agents": [a.to_dict() for a in ags],
-            "servertime": datetime.now().astimezone(),
-        }
+        return 200, {"agents": [a.to_dict() for a in ags], "servertime": util.datetime_utc_isoformat(datetime.now())}
 
     @handle(methods.get_state, env="tid")
     async def get_state(self, env: data.Environment, sid: uuid.UUID, agent: str) -> Apireturn:
         tid: UUID = env.id
         if isinstance(tid, str):
             tid = uuid.UUID(tid)
         key = (tid, agent)
@@ -849,15 +843,15 @@
                 or (self._fact_resource_block_set[resource_id] + self._fact_resource_block) < now
             ):
                 agents = await data.ConfigurationModel.get_agents(env.id, version)
                 await self._autostarted_agent_manager._ensure_agents(env, agents)
 
                 client = self.get_agent_client(env_id, res.agent)
                 if client is not None:
-                    await client.get_parameter(str(env_id), res.agent, res.to_dict())
+                    self.add_background_task(client.get_parameter(str(env_id), res.agent, res.to_dict()))
 
                 self._fact_resource_block_set[resource_id] = now
 
             else:
                 LOGGER.debug(
                     "Ignore fact request for %s, last request was sent %d seconds ago.",
                     resource_id,
@@ -873,15 +867,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         start: Optional[Union[datetime, bool, str]] = None,
         end: Optional[Union[datetime, bool, str]] = None,
         first_id: Optional[str] = None,
         last_id: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "name.asc",
     ) -> ReturnValue[Sequence[model.Agent]]:
         try:
             handler = AgentView(
                 environment=env,
                 limit=limit,
                 sort=sort,
@@ -912,27 +906,27 @@
 class AutostartedAgentManager(ServerSlice):
     """
     An instance of this class manages autostarted agent instance processes. It does not manage the logical agents as those
     are managed by `:py:class:AgentManager`.
     """
 
     def __init__(self) -> None:
-        super().__init__(SLICE_AUTOSTARTED_AGENT_MANAGER)
-        self._agent_procs: dict[UUID, subprocess.Process] = {}  # env uuid -> subprocess.Process
+        super(AutostartedAgentManager, self).__init__(SLICE_AUTOSTARTED_AGENT_MANAGER)
+        self._agent_procs: Dict[UUID, subprocess.Process] = {}  # env uuid -> subprocess.Process
         self.agent_lock = asyncio.Lock()  # Prevent concurrent updates on _agent_procs
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         return {"processes": len(self._agent_procs)}
 
     async def prestart(self, server: protocol.Server) -> None:
         await ServerSlice.prestart(self, server)
         preserver = server.get_slice(SLICE_SERVER)
         assert isinstance(preserver, Server)
         self._server: Server = preserver
-        self._server_storage: dict[str, str] = self._server._server_storage
+        self._server_storage: Dict[str, str] = self._server._server_storage
 
         agent_manager = server.get_slice(SLICE_AGENT_MANAGER)
         assert isinstance(agent_manager, AgentManager)
         self._agent_manager = agent_manager
 
     async def start(self) -> None:
         await super().start()
@@ -941,18 +935,18 @@
     async def prestop(self) -> None:
         await super().prestop()
         await self._terminate_agents()
 
     async def stop(self) -> None:
         await super().stop()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_SERVER, SLICE_DATABASE, SLICE_AGENT_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def _start_agents(self) -> None:
         """
         Ensure that autostarted agents of each environment are started when AUTOSTART_ON_START is true. This method
         is called on server start.
         """
@@ -1001,31 +995,31 @@
             LOGGER.debug("Expiring all sessions")
             await self._agent_manager.expire_all_sessions()
 
     # Start/stop agents
     async def _ensure_agents(
         self,
         env: data.Environment,
-        agents: list[str],
+        agents: List[str],
         restart: bool = False,
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> bool:
         """
         Ensure that all agents defined in the current environment (model) and that should be autostarted, are started.
 
         :param env: The environment to start the agents for
         :param agents: A list of agent names that possibly should be started in this environment.
         :param restart: Restart all agents even if the list of agents is up to date.
         """
         if self._stopping:
             raise ShutdownInProgress()
 
-        agent_map: dict[str, str] = cast(
-            dict[str, str], await env.get(data.AUTOSTART_AGENT_MAP, connection=connection)
+        agent_map: Dict[str, str] = cast(
+            Dict[str, str], await env.get(data.AUTOSTART_AGENT_MAP, connection=connection)
         )  # we know the type of this map
 
         agents = [agent for agent in agents if agent in agent_map]
         needsstart = restart
         if len(agents) == 0:
             return False
 
@@ -1046,23 +1040,23 @@
             if await is_start_agent_required():
                 LOGGER.info("%s matches agents managed by server, ensuring it is started.", agents)
                 res = await self.__do_start_agent(agents, env, connection=connection)
                 return res
         return False
 
     async def __do_start_agent(
-        self, agents: list[str], env: data.Environment, *, connection: Optional[asyncpg.connection.Connection] = None
+        self, agents: List[str], env: data.Environment, *, connection: Optional[asyncpg.connection.Connection] = None
     ) -> bool:
         """
         Start an agent process for the given agents in the given environment
 
         Note: Always call under agent_lock
         """
-        agent_map: dict[str, str]
-        agent_map = cast(dict[str, str], await env.get(data.AUTOSTART_AGENT_MAP, connection=connection))
+        agent_map: Dict[str, str]
+        agent_map = cast(Dict[str, str], await env.get(data.AUTOSTART_AGENT_MAP, connection=connection))
         config: str
         config = await self._make_agent_config(env, agents, agent_map, connection=connection)
 
         config_dir = os.path.join(self._server_storage["agents"], str(env.id))
         if not os.path.exists(config_dir):
             os.mkdir(config_dir)
 
@@ -1109,22 +1103,22 @@
 
         async def _wait_until_agent_instances_are_active() -> None:
             """
             Wait until all AgentInstances for the endpoints `agents` are active.
             A TimeoutError is raised when not all AgentInstances are active and no new AgentInstance
             became active in the last 5 seconds.
             """
-            agent_statuses: dict[str, Optional[AgentStatus]] = await data.Agent.get_statuses(env.id, set(agents))
+            agent_statuses: Dict[str, Optional[AgentStatus]] = await data.Agent.get_statuses(env.id, set(agents))
             # Only wait for agents that are not paused
-            expected_agents_in_up_state: set[str] = {
+            expected_agents_in_up_state: Set[str] = {
                 agent_name
                 for agent_name, status in agent_statuses.items()
                 if status is not None and status is not AgentStatus.paused
             }
-            actual_agents_in_up_state: set[str] = set()
+            actual_agents_in_up_state: Set[str] = set()
             started = int(time.time())
             last_new_agent_seen = started
             last_log = started
 
             while len(expected_agents_in_up_state) != len(actual_agents_in_up_state):
                 await asyncio.sleep(0.1)
                 now = int(time.time())
@@ -1157,16 +1151,16 @@
         except asyncio.TimeoutError:
             LOGGER.warning("Timeout: agent with PID %s took too long to start", proc.pid)
         return True
 
     async def _make_agent_config(
         self,
         env: data.Environment,
-        agent_names: list[str],
-        agent_map: dict[str, str],
+        agent_names: List[str],
+        agent_map: Dict[str, str],
         *,
         connection: Optional[asyncpg.connection.Connection],
     ) -> str:
         """
         Generate the config file for the process that hosts the autostarted agents
 
         :param env: The environment for which to autostart agents
@@ -1176,35 +1170,35 @@
         """
         environment_id = str(env.id)
         port: int = opt.get_bind_port()
 
         privatestatedir: str = os.path.join(Config.get("config", "state-dir", "/var/lib/inmanta"), environment_id)
 
         agent_deploy_splay: int = cast(int, await env.get(data.AUTOSTART_AGENT_DEPLOY_SPLAY_TIME, connection=connection))
-        agent_deploy_interval: str = cast(str, await env.get(data.AUTOSTART_AGENT_DEPLOY_INTERVAL, connection=connection))
+        agent_deploy_interval: int = cast(int, await env.get(data.AUTOSTART_AGENT_DEPLOY_INTERVAL, connection=connection))
 
         agent_repair_splay: int = cast(int, await env.get(data.AUTOSTART_AGENT_REPAIR_SPLAY_TIME, connection=connection))
-        agent_repair_interval: str = cast(str, await env.get(data.AUTOSTART_AGENT_REPAIR_INTERVAL, connection=connection))
+        agent_repair_interval: int = cast(int, await env.get(data.AUTOSTART_AGENT_REPAIR_INTERVAL, connection=connection))
 
         # The internal agent always needs to have a session. Otherwise the agentmap update trigger doesn't work
         if "internal" not in agent_names:
             agent_names.append("internal")
 
         # generate config file
         config = """[config]
 state-dir=%(statedir)s
 
 use_autostart_agent_map=true
 agent-names = %(agents)s
 environment=%(env_id)s
 
 agent-deploy-splay-time=%(agent_deploy_splay)d
-agent-deploy-interval=%(agent_deploy_interval)s
+agent-deploy-interval=%(agent_deploy_interval)d
 agent-repair-splay-time=%(agent_repair_splay)d
-agent-repair-interval=%(agent_repair_interval)s
+agent-repair-interval=%(agent_repair_interval)d
 
 agent-get-resource-backoff=%(agent_get_resource_backoff)f
 
 [agent_rest_transport]
 port=%(port)s
 host=%(serveradress)s
 """ % {
@@ -1244,15 +1238,15 @@
             config += """
 ssl=True
     """
 
         return config
 
     async def _fork_inmanta(
-        self, args: list[str], outfile: Optional[str], errfile: Optional[str], cwd: Optional[str] = None
+        self, args: List[str], outfile: Optional[str], errfile: Optional[str], cwd: Optional[str] = None
     ) -> subprocess.Process:
         """
         Fork an inmanta process from the same code base as the current code
         """
         full_args = ["-m", "inmanta.app", *args]
         # handles can be closed, owned by child process,...
         outhandle = None
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/bootloader.py` & `inmanta-core-9.3.0/src/inmanta/server/bootloader.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,18 +15,17 @@
 
     Contact: code@inmanta.com
 """
 import asyncio
 import importlib
 import logging
 import pkgutil
-from collections.abc import Generator
 from pkgutil import ModuleInfo
 from types import ModuleType
-from typing import Optional
+from typing import Dict, Generator, List, Optional
 
 from inmanta.const import EXTENSION_MODULE, EXTENSION_NAMESPACE
 from inmanta.server import config
 from inmanta.server.extensions import ApplicationContext, FeatureManager, InvalidSliceNameException
 from inmanta.server.protocol import Server, ServerSlice
 from inmanta.stable_api import stable_api
 
@@ -59,34 +58,33 @@
         self.parent.register_slice(slice)
 
     def set_feature_manager(self, feature_manager: FeatureManager) -> None:
         self.parent.set_feature_manager(feature_manager)
 
 
 @stable_api
-class InmantaBootloader:
+class InmantaBootloader(object):
     """The inmanta bootloader is responsible for:
     - discovering extensions
     - loading extensions
     - loading core and extension slices
     - starting the server and its slices in the correct order
     """
 
     # Cache field for available extensions
-    AVAILABLE_EXTENSIONS: Optional[dict[str, str]] = None
+    AVAILABLE_EXTENSIONS: Optional[Dict[str, str]] = None
 
     def __init__(self) -> None:
         self.restserver = Server()
         self.started = False
         self.feature_manager: Optional[FeatureManager] = None
 
     async def start(self) -> None:
         ctx = self.load_slices()
-        version = ctx.get_feature_manager().get_product_metadata().version
-        LOGGER.info("Starting inmanta-server version %s", version)
+        self.feature_manager = ctx.get_feature_manager()
         for mypart in ctx.get_slices():
             self.restserver.add_slice(mypart)
             ctx.get_feature_manager().add_slice(mypart)
         await self.restserver.start()
         self.started = True
 
     async def stop(self, timeout: Optional[int] = None) -> None:
@@ -99,20 +97,20 @@
             await self._stop()
         else:
             await asyncio.wait_for(self._stop(), timeout=timeout)
 
     async def _stop(self) -> None:
         await self.restserver.stop()
         if self.feature_manager is not None:
-            await self.feature_manager.stop()
+            self.feature_manager.stop()
 
     @classmethod
-    def get_available_extensions(cls) -> dict[str, str]:
+    def get_available_extensions(cls) -> Dict[str, str]:
         """
-        Returns a dictionary of all available inmanta extensions.
+        Returns a dictionary of with all available inmanta extensions.
         The key contains the name of the extension and the value the fully qualified path to the python package.
         """
         if cls.AVAILABLE_EXTENSIONS is None:
             try:
                 inmanta_ext = importlib.import_module(EXTENSION_NAMESPACE)
             except ModuleNotFoundError:
                 # This only happens when a test case creates and activates a new venv
@@ -120,26 +118,26 @@
             else:
                 cls.AVAILABLE_EXTENSIONS = {
                     name[len(EXTENSION_NAMESPACE) + 1 :]: name for finder, name, ispkg in iter_namespace(inmanta_ext)
                 }
         return dict(cls.AVAILABLE_EXTENSIONS)
 
     # Extension loading Phase I: from start to setup functions collected
-    def _discover_plugin_packages(self, return_all_available_packages: bool = False) -> list[str]:
+    def _discover_plugin_packages(self, return_all_available_packages: bool = False) -> List[str]:
         """Discover all packages that are defined in the inmanta_ext namespace package. Filter available extensions based on
         enabled_extensions and disabled_extensions config in the server configuration.
 
         :param return_all_available_packages: Return all available plugin packages independent of whether the extension is
                                               enabled or not.
         :return: A list of all subpackages defined in inmanta_ext
         """
         available = self.get_available_extensions()
         LOGGER.info("Discovered extensions: %s", ", ".join(available.keys()))
 
-        extensions: list[str] = []
+        extensions: List[str] = []
         enabled = [x for x in config.server_enabled_extensions.get() if len(x)]
 
         if return_all_available_packages:
             extensions.extend(available.values())
         elif enabled:
             for ext in enabled:
                 if ext not in available:
@@ -182,18 +180,18 @@
         """
         Validate whether the given extension module satisfied the mandatory requirements for an Inmanta extension.
         If the requirements are not satisfied, this method raises an PluginLoadFailed exception.
         """
         if not hasattr(ext_mod, "setup"):
             raise PluginLoadFailed("extension.py doesn't have a setup method.")
 
-    def _load_extensions(self, load_all_extensions: bool = False) -> dict[str, ModuleType]:
+    def _load_extensions(self, load_all_extensions: bool = False) -> Dict[str, ModuleType]:
         """Discover all extensions, validate correct naming and load its setup function"""
-        plugins: dict[str, ModuleType] = {}
-        enabled_extensions: list[str] = self._discover_plugin_packages(load_all_extensions)
+        plugins: Dict[str, ModuleType] = {}
+        enabled_extensions: List[str] = self._discover_plugin_packages(load_all_extensions)
         LOGGER.info("Enabled extensions: %s", ", ".join(enabled_extensions))
         for name in enabled_extensions:
             try:
                 module = self._load_extension(name)
                 assert name.startswith(f"{EXTENSION_NAMESPACE}.")
                 name = name[len(EXTENSION_NAMESPACE) + 1 :]
                 plugins[name] = module
@@ -208,15 +206,15 @@
         if not hasattr(ext_module, "register_environment_settings"):
             # Extension doesn't define any environment settings.
             return
         ext_module.register_environment_settings(app_ctx)
 
     # Extension loading Phase II: collect slices
     def _collect_slices(
-        self, extensions: dict[str, ModuleType], only_register_environment_settings: bool = False
+        self, extensions: Dict[str, ModuleType], only_register_environment_settings: bool = False
     ) -> ApplicationContext:
         """
         Call the setup function on all extensions and let them register their slices in the ApplicationContext.
         """
         ctx = ApplicationContext()
         for name, ext_module in extensions.items():
             myctx = ConstrainedApplicationContext(ctx, name)
@@ -227,11 +225,9 @@
 
     def load_slices(
         self, *, load_all_extensions: bool = False, only_register_environment_settings: bool = False
     ) -> ApplicationContext:
         """
         Load all slices in the server
         """
-        exts: dict[str, ModuleType] = self._load_extensions(load_all_extensions)
-        ctx: ApplicationContext = self._collect_slices(exts, only_register_environment_settings)
-        self.feature_manager = ctx.get_feature_manager()
-        return ctx
+        exts: Dict[str, ModuleType] = self._load_extensions(load_all_extensions)
+        return self._collect_slices(exts, only_register_environment_settings)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/compilerservice.py` & `inmanta-core-9.3.0/src/inmanta/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2019 Inmanta
+    Copyright 2017 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -12,8 +12,18 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
-from .services.compilerservice import *  # noqa: F401, F403
+COMPILER_VERSION = "2024.0"
+RUNNING_TESTS = False
+"""
+    This is enabled/disabled by the test suite when tests are run.
+    This variable is used to disable certain features that shouldn't run during tests.
+"""
+
+if __name__ == "__main__":
+    import inmanta.app
+
+    inmanta.app.app()
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/config.py` & `inmanta-core-9.3.0/src/inmanta/server/config.py`

 * *Files 5% similar despite different names*

```diff
@@ -14,15 +14,14 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import logging
 import warnings
-from typing import Optional
 
 from inmanta.config import (
     Config,
     Option,
     is_bool,
     is_float,
     is_int,
@@ -48,15 +47,15 @@
 db_name = Option("database", "name", "inmanta", "The name of the database on the postgresql server", is_str)
 db_username = Option("database", "username", "postgres", "The username to access the database in the PostgreSQL server", is_str)
 db_password = Option("database", "password", None, "The password that belong to the database user", is_str)
 db_connection_pool_min_size = Option(
     "database", "connection_pool_min_size", 10, "Number of connections the pool will be initialized with", is_int
 )
 db_connection_pool_max_size = Option(
-    "database", "connection_pool_max_size", 70, "Max number of connections in the pool", is_int
+    "database", "connection_pool_max_size", 10, "Max number of connections in the pool", is_int
 )
 db_connection_timeout = Option("database", "connection_timeout", 60, "Connection timeout in seconds", is_float)
 
 #############################
 # server_rest_transport
 #############################
 transport_port = Option(
@@ -116,43 +115,25 @@
         warnings.warn(
             "The server_rest_transport.port config option is deprecated in favour of the server.bind-port option.",
             category=DeprecationWarning,
         )
         return Config.get("server_rest_transport", "port", 8888)
 
 
-server_tz_aware_timestamps = Option(
-    "server",
-    "tz_aware_timestamps",
-    False,
-    "Whether the server should return timezone aware timestamps. "
-    "If False, the server will serialize timestamps in a time zone naive way (in implicit UTC). "
-    "If True, timestamps are serialized as time zone aware objects.",
-    is_bool,
-)
-
 server_enable_auth = Option("server", "auth", False, "Enable authentication on the server API", is_bool)
 server_auth_method = Option("server", "auth_method", None, "The authentication method to use: oidc or database", is_str_opt)
 
 server_ssl_key = Option(
     "server", "ssl_key_file", None, "Server private key to use for this server Leave blank to disable SSL", is_str_opt
 )
 
 server_ssl_cert = Option(
     "server", "ssl_cert_file", None, "SSL certificate file for the server key. Leave blank to disable SSL", is_str_opt
 )
 
-
-def ssl_enabled():
-    """Is ssl enabled on the server, given the current server config"""
-    ssl_key: Optional[str] = server_ssl_key.get()
-    ssl_cert: Optional[str] = server_ssl_cert.get()
-    return ssl_key is not None and ssl_cert is not None
-
-
 server_ssl_ca_cert = Option(
     "server",
     "ssl_ca_cert_file",
     None,
     "The CA cert file required to validate the server ssl cert. This setting is used by the server"
     "to correctly configure the compiler and agents that the server starts itself. If not set and "
     "SSL is enabled, the server cert should be verifiable with the CAs installed in the OS.",
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/diff.py` & `inmanta-core-9.3.0/src/inmanta/server/diff.py`

 * *Files 5% similar despite different names*

```diff
@@ -13,15 +13,15 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import json
-from typing import Optional
+from typing import Dict, List, Optional, Set
 
 from inmanta import resources
 from inmanta.data.model import AttributeDiff, ResourceDiff, ResourceDiffStatus, ResourceIdStr
 
 
 class Attribute:
     def __init__(self, name: str, value: object) -> None:
@@ -87,15 +87,15 @@
             to_value=None,
             from_value_compare=self.compare_value,
             to_value_compare="",
         )
 
 
 class Resource:
-    def __init__(self, resource_id: ResourceIdStr, attributes: dict[str, object]) -> None:
+    def __init__(self, resource_id: ResourceIdStr, attributes: Dict[str, object]) -> None:
         self.resource_id = resource_id
         self._attributes = {name: Attribute(name, value) for name, value in attributes.items() if name != "version"}
 
     def compare(self, other: "Resource") -> Optional[ResourceDiff]:
         """Compare this resource with another: check which attributes are added, modified and removed.
         The other resource is considered to be the original"""
         other_attributes = set(other._attributes.keys())
@@ -141,27 +141,27 @@
             resource_id=self.resource_id,
             attributes={},
             status=ResourceDiffStatus.unmodified,
         )
 
 
 class Version:
-    def __init__(self, resources: dict[ResourceIdStr, Resource]) -> None:
+    def __init__(self, resources: Dict[ResourceIdStr, Resource]) -> None:
         self._resources = resources
 
-    def get_resource_set(self) -> set[ResourceIdStr]:
+    def get_resource_set(self) -> Set[ResourceIdStr]:
         """The names of the resources in this version"""
         return set(self._resources.keys())
 
-    def generate_diff(self, other: "Version", include_unmodified: bool = False) -> list[ResourceDiff]:
+    def generate_diff(self, other: "Version", include_unmodified: bool = False) -> List[ResourceDiff]:
         """Compare this version with another: check which resources are added, removed and modified.
         The other version is considered to be the original."""
         our_set = self.get_resource_set()
         other_set = other.get_resource_set()
-        result: list[ResourceDiff] = []
+        result: List[ResourceDiff] = []
 
         added = list(our_set - other_set)
         removed = list(other_set - our_set)
         result.extend(self._resources[x].added() for x in added)
         result.extend(other._resources[x].removed() for x in removed)
 
         intersect = our_set.intersection(other_set)
@@ -173,18 +173,18 @@
             elif include_unmodified:
                 result.append(self._resources[res].unmodified())
 
         return sorted(result, key=lambda r: r.resource_id)
 
 
 def generate_diff(
-    from_version_resources: dict[ResourceIdStr, Resource],
-    to_version_resources: dict[ResourceIdStr, Resource],
+    from_version_resources: Dict[ResourceIdStr, Resource],
+    to_version_resources: Dict[ResourceIdStr, Resource],
     include_unmodified: bool = False,
-) -> list[ResourceDiff]:
+) -> List[ResourceDiff]:
     """Generate a diff of two sets of resources, describing what has changed between them
 
     :param from_version_resources: The resources that are considered the starting point for comparison
     :param to_version_resources: The resources that are considered the target for comparison
     :param include_unmodified: If set to true,
     resources that haven't changed between the versions will be included in the results
     """
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/extensions.py` & `inmanta-core-9.3.0/src/inmanta/server/extensions.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
 import os
 from collections import defaultdict
-from typing import Any, Generic, Optional, TypeVar
+from typing import Any, Dict, Generic, List, Optional, TypeVar
 
 import pkg_resources
 import yaml
 
 from inmanta import data
 from inmanta.config import feature_file_config
 from inmanta.data.model import ExtensionStatus
@@ -75,15 +75,15 @@
 class BoolFeature(Feature[bool]):
     """A feature that is on or off. When no value is given it is enabled."""
 
     def __init__(self, slice: str, name: str, description: str = "") -> None:
         super().__init__(slice, name, description, True)
 
 
-class StringListFeature(Feature[list[str]]):
+class StringListFeature(Feature[List[str]]):
     """A feature that holds a list of allowed values. When the list contains "*" it matches everything."""
 
     def __init__(self, slice: str, name: str, description: str = "") -> None:
         super().__init__(slice, name, description, default_value=["*"])
 
 
 class ProductMetadata:
@@ -103,21 +103,21 @@
         slices:
             slice_name:
                 feature_name: bool
 
     """
 
     def __init__(self) -> None:
-        self._features: dict[str, dict[str, Feature[object]]] = defaultdict(dict)
-        self._feature_config: dict[str, dict[str, Any]] = self._load_feature_config()
+        self._features: Dict[str, Dict[str, Feature[object]]] = defaultdict(lambda: {})
+        self._feature_config: Dict[str, Dict[str, Any]] = self._load_feature_config()
 
-    def get_features(self) -> list[Feature[object]]:
+    def get_features(self) -> List[Feature[object]]:
         return [feature for slice in self._features.values() for feature in slice.values()]
 
-    def _load_feature_config(self) -> dict[str, dict[str, Any]]:
+    def _load_feature_config(self) -> Dict[str, Dict[str, Any]]:
         feature_file = feature_file_config.get()
         if feature_file is None:
             return {}
 
         if not os.path.exists(feature_file):
             LOGGER.warning("Feature file %s configured but file does not exist.", feature_file)
             return {}
@@ -174,44 +174,44 @@
     def contains(self, feature: StringListFeature, item: str) -> bool:
         """Check if the value is contained in the list."""
         value = self.get_value(feature)
         if "*" in value:
             return True
         return item in value
 
-    async def stop(self) -> None:
+    def stop(self) -> None:
         """Called when the server is stopped"""
 
 
 @stable_api
 class ApplicationContext:
     def __init__(self) -> None:
-        self._slices: list[ServerSlice] = []
+        self._slices: List[ServerSlice] = []
         self._feature_manager: Optional[FeatureManager] = None
 
     def register_slice(self, slice: ServerSlice) -> None:
         assert slice is not None
         self._slices.append(slice)
 
-    def get_slices(self) -> list[ServerSlice]:
+    def get_slices(self) -> List[ServerSlice]:
         return self._slices
 
     def set_feature_manager(self, feature_manager: FeatureManager) -> None:
         assert self._feature_manager is None
         self._feature_manager = feature_manager
 
     def get_feature_manager(self) -> FeatureManager:
         if self._feature_manager is None:
             self._feature_manager = FeatureManager()
         return self._feature_manager
 
     def get_product_metadata(self) -> ProductMetadata:
         return self.get_feature_manager().get_product_metadata()
 
-    def get_extension_statuses(self) -> list[ExtensionStatus]:
+    def get_extension_statuses(self) -> List[ExtensionStatus]:
         return ServerSlice.get_extension_statuses(list(self._slices))
 
     def register_environment_setting(self, setting: data.Setting) -> None:
         """
         Used by an Inmanta extension to register extension-specific environment settings.
         """
         data.Environment.register_setting(setting)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/protocol.py` & `inmanta-core-9.3.0/src/inmanta/server/protocol.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,17 +17,16 @@
 """
 import asyncio
 import logging
 import socket
 import time
 import uuid
 from collections import defaultdict
-from collections.abc import Callable, Sequence
 from datetime import timedelta
-from typing import TYPE_CHECKING, Optional, Union
+from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Sequence, Set, Tuple, Union
 
 import importlib_metadata
 from tornado import gen, queues, routing, web
 
 import inmanta.protocol.endpoints
 from inmanta.data.model import ExtensionStatus
 from inmanta.protocol import Client, common, endpoints, handle, methods
@@ -55,15 +54,15 @@
 
 class ServerStartFailure(Exception):
     pass
 
 
 class SliceStartupException(ServerStartFailure):
     def __init__(self, slice_name: str, cause: Exception):
-        super().__init__()
+        super(SliceStartupException, self).__init__()
         self.__cause__ = cause
         self.in_slice = slice_name
 
     def __str__(self) -> str:
         return f"Slice {self.in_slice} failed to start because: {str(self.__cause__)}"
 
 
@@ -74,38 +73,35 @@
     """
 
     def __init__(self, name: str, session: "Session") -> None:
         super().__init__(name, with_rest_client=False)
         self.session = session
 
     async def _call(
-        self, method_properties: common.MethodProperties, args: list[object], kwargs: dict[str, object]
+        self, method_properties: common.MethodProperties, args: List[object], kwargs: Dict[str, object]
     ) -> common.Result:
         call_spec = method_properties.build_call(args, kwargs)
-        expect_reply = method_properties.reply
         try:
             if method_properties.timeout:
-                return_value = await self.session.put_call(
-                    call_spec, timeout=method_properties.timeout, expect_reply=expect_reply
-                )
+                return_value = await self.session.put_call(call_spec, timeout=method_properties.timeout)
             else:
-                return_value = await self.session.put_call(call_spec, expect_reply=expect_reply)
+                return_value = await self.session.put_call(call_spec)
         except asyncio.CancelledError:
             return common.Result(code=500, result={"message": "Call timed out"})
 
         return common.Result(code=return_value["code"], result=return_value["result"])
 
 
 # Server Side
 class Server(endpoints.Endpoint):
     def __init__(self, connection_timout: int = 120) -> None:
         super().__init__("server")
-        self._slices: dict[str, ServerSlice] = {}
-        self._slice_sequence: Optional[list[ServerSlice]] = None
-        self._handlers: list[routing.Rule] = []
+        self._slices: Dict[str, ServerSlice] = {}
+        self._slice_sequence: Optional[List[ServerSlice]] = None
+        self._handlers: List[routing.Rule] = []
         self.connection_timout = connection_timout
         self.sessions_handler = SessionManager()
         self.add_slice(self.sessions_handler)
 
         self._transport = server.RESTServer(self.sessions_handler, self.id)
         self.add_slice(TransportSlice(self))
         self.running = False
@@ -113,30 +109,30 @@
     def add_slice(self, slice: "ServerSlice") -> None:
         """
         Add new endpoints to this rest transport
         """
         self._slices[slice.name] = slice
         self._slice_sequence = None
 
-    def get_slices(self) -> dict[str, "ServerSlice"]:
+    def get_slices(self) -> Dict[str, "ServerSlice"]:
         return self._slices
 
     def get_slice(self, name: str) -> "ServerSlice":
         return self._slices[name]
 
     def get_id(self) -> str:
         """
         Returns a unique id for a transport on an endpoint
         """
         return "server_rest_transport"
 
     id = property(get_id)
 
-    def _order_slices(self) -> list["ServerSlice"]:
-        edges: dict[str, set[str]] = defaultdict(set)
+    def _order_slices(self) -> List["ServerSlice"]:
+        edges: Dict[str, Set[str]] = defaultdict(set)
 
         for slice in self.get_slices().values():
             edges[slice.name].update(slice.get_dependencies())
             for depby in slice.get_depended_by():
                 edges[depby].add(slice.name)
 
         names = list(edges.keys())
@@ -195,15 +191,15 @@
         This prevents database connection from being closed too early. This order in which the endpoint
         are started, is hardcoded in the get_server_slices() method in server/bootloader.py
         """
         if not self.running:
             return
         self.running = False
 
-        await super().stop()
+        await super(Server, self).stop()
 
         order = list(reversed(self._get_slice_sequence()))
 
         for endpoint in order:
             LOGGER.debug("Pre Stopping %s", endpoint.name)
             await endpoint.prestop()
 
@@ -233,15 +229,15 @@
 
     feature_manager: "FeatureManager"
 
     def __init__(self, name: str) -> None:
         super().__init__()
 
         self._name: str = name
-        self._handlers: list[routing.Rule] = []
+        self._handlers: List[routing.Rule] = []
         self._sched = Scheduler(f"server slice {name}")
         # is shutdown in progress?
         self._stopping: bool = False
 
     def is_stopping(self) -> bool:
         """True when prestop has been called."""
         return self._stopping
@@ -256,14 +252,15 @@
         """
         Start the server slice.
 
         This method `blocks` until the slice is ready to receive calls
 
         Dependencies are up (if present) prior to invocation of this call
         """
+        pass
 
     async def prestop(self) -> None:
         """
         Always called before stop
 
         Stop producing new work:
         - stop timers
@@ -283,28 +280,28 @@
         """
         Go down
 
         All dependencies are up (if present)
 
         This method `blocks` until the slice is down
         """
-        await super().stop()
+        await super(ServerSlice, self).stop()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         """List of names of slices that must be started before this one."""
         return []
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         """List of names of slices that must be started after this one."""
         return []
 
     # internal API towards extension framework
     name = property(lambda self: self._name)
 
-    def get_handlers(self) -> list[routing.Rule]:
+    def get_handlers(self) -> List[routing.Rule]:
         """Get the list of"""
         return self._handlers
 
     # utility methods for extensions developers
     def schedule(
         self,
         call: TaskMethod,
@@ -382,80 +379,76 @@
                 "Package %s of slice %s is not packaged in a distribution. Unable to determine its extension.",
                 package_name,
                 self.name,
             )
             return None
 
     @classmethod
-    def get_extension_statuses(cls, slices: list["ServerSlice"]) -> list[ExtensionStatus]:
+    def get_extension_statuses(cls, slices: List["ServerSlice"]) -> List[ExtensionStatus]:
         result = {}
         for server_slice in slices:
             ext_status = server_slice.get_extension_status()
             if ext_status is not None:
                 result[ext_status.name] = ext_status
         return list(result.values())
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         """
         Get the status of this slice.
         """
         return {}
 
-    def define_features(self) -> list["Feature[object]"]:
+    def define_features(self) -> List["Feature[object]"]:
         """Return a list of feature that this slice offers"""
         return []
 
 
-class Session:
+class Session(object):
     """
     An environment that segments agents connected to the server. Should only be created in a context with a running event loop.
     """
 
     def __init__(
         self,
         sessionstore: "SessionManager",
         sid: uuid.UUID,
         hang_interval: int,
         timout: int,
         tid: uuid.UUID,
-        endpoint_names: set[str],
+        endpoint_names: Set[str],
         nodename: str,
         disable_expire_check: bool = False,
     ) -> None:
         self._sid = sid
         self._interval = hang_interval
         self._timeout = timout
         self._sessionstore: SessionManager = sessionstore
-        self._seen: float = time.monotonic()
+        self._seen: float = time.time()
         self._callhandle: Optional[asyncio.TimerHandle] = None
         self.expired: bool = False
 
-        self.last_dispatched_call: float = 0
-        self.dispatch_delay = 0.01  # keep at least 10 ms between dispatches
-
         self.tid: uuid.UUID = tid
-        self.endpoint_names: set[str] = endpoint_names
+        self.endpoint_names: Set[str] = endpoint_names
         self.nodename: str = nodename
 
-        self._replies: dict[uuid.UUID, asyncio.Future] = {}
+        self._replies: Dict[uuid.UUID, asyncio.Future] = {}
 
         # Disable expiry in certain tests
         if not disable_expire_check:
             self.check_expire()
         self._queue: queues.Queue[Optional[common.Request]] = queues.Queue()
 
         self.client = ReturnClient(str(sid), self)
 
     def check_expire(self) -> None:
         if self.expired:
             LOGGER.exception("Tried to expire session already expired")
-        now = time.monotonic()
-        ttw = self._timeout + self._seen - now
+        ttw = self._timeout + self._seen - time.time()
         if ttw < 0:
-            expire_coroutine = self.expire(self._seen - now)
+            expire_coroutine = self.expire(self._seen - time.time())
             self._sessionstore.add_background_task(expire_coroutine)
         else:
             self._callhandle = asyncio.get_running_loop().call_later(ttw, self.check_expire)
 
     def get_id(self) -> uuid.UUID:
         return self._sid
 
@@ -465,59 +458,57 @@
         if self.expired:
             return
         self.expired = True
         if self._callhandle is not None:
             self._callhandle.cancel()
         await self._sessionstore.expire(self, timeout)
 
-    def seen(self, endpoint_names: set[str]) -> None:
-        self._seen = time.monotonic()
+    def seen(self, endpoint_names: Set[str]) -> None:
+        self._seen = time.time()
         self.endpoint_names = endpoint_names
 
     async def _handle_timeout(self, future: asyncio.Future, timeout: int, log_message: str) -> None:
         """A function that awaits a future until its value is ready or until timeout. When the call times out, a message is
         logged. The future itself will be cancelled.
 
         This method should be called as a background task. Any other exceptions (which should not occur) will be logged in
         the background task.
         """
         try:
             await asyncio.wait_for(future, timeout)
         except asyncio.TimeoutError:
             LOGGER.warning(log_message)
 
-    def put_call(self, call_spec: common.Request, timeout: int = 10, expect_reply: bool = True) -> asyncio.Future:
-        reply_id = uuid.uuid4()
+    def put_call(self, call_spec: common.Request, timeout: int = 10) -> asyncio.Future:
         future = asyncio.Future()
 
+        reply_id = uuid.uuid4()
+
         LOGGER.debug("Putting call %s: %s %s for agent %s in queue", reply_id, call_spec.method, call_spec.url, self._sid)
 
-        if expect_reply:
-            call_spec.reply_id = reply_id
-            self._sessionstore.add_background_task(
-                self._handle_timeout(
-                    future,
-                    timeout,
-                    f"Call {reply_id}: {call_spec.method} {call_spec.url} for agent {self._sid} timed out.",
-                )
-            )
-            self._replies[reply_id] = future
-        else:
-            future.set_result({"code": 200, "result": None})
+        call_spec.reply_id = reply_id
         self._queue.put(call_spec)
+        self._sessionstore.add_background_task(
+            self._handle_timeout(
+                future,
+                timeout,
+                "Call %s: %s %s for agent %s timed out." % (reply_id, call_spec.method, call_spec.url, self._sid),
+            )
+        )
+        self._replies[reply_id] = future
 
         return future
 
-    async def get_calls(self, no_hang: bool) -> Optional[list[common.Request]]:
+    async def get_calls(self, no_hang: bool) -> Optional[List[common.Request]]:
         """
         Get all calls queued for a node. If no work is available, wait until timeout. This method returns none if a call
         fails.
         """
         try:
-            call_list: list[common.Request] = []
+            call_list: List[common.Request] = []
 
             if no_hang:
                 timeout = 0.1
             else:
                 timeout = self._interval if self._interval > 0.1 else 0.1
                 # We choose to have a minimum of 0.1 as timeout as this is also the value used for no_hang.
                 # Furthermore, the timeout value cannot be zero as this causes an issue with Tornado:
@@ -557,69 +548,72 @@
         self._queue.put(None)
 
     async def expire_and_abort(self, timeout: float) -> None:
         await self.expire(timeout)
         self.abort()
 
 
-class SessionListener:
-    async def new_session(self, session: Session, endpoint_names_snapshot: set[str]) -> None:
+class SessionListener(object):
+    async def new_session(self, session: Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         Notify that a new session was created.
 
         :param session: The session that was created
         :param endpoint_names_snapshot: The endpoint_names field of the session object may be updated after this
                                         method was called. This parameter provides a snapshot which will not change.
         """
+        pass
 
-    async def expire(self, session: Session, endpoint_names_snapshot: set[str]) -> None:
+    async def expire(self, session: Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         Notify that a session expired.
 
         :param session: The session that was created
         :param endpoint_names_snapshot: The endpoint_names field of the session object may be updated after this
                                         method was called. This parameter provides a snapshot which will not change.
         """
+        pass
 
-    async def seen(self, session: Session, endpoint_names_snapshot: set[str]) -> None:
+    async def seen(self, session: Session, endpoint_names_snapshot: Set[str]) -> None:
         """
         Notify that a heartbeat was received for an existing session.
 
         :param session: The session that was created
         :param endpoint_names_snapshot: The endpoint_names field of the session object may be updated after this
                                         method was called. This parameter provides a snapshot which will not change.
         """
+        pass
 
 
 # Internals
 class TransportSlice(ServerSlice):
     """Slice to manage the listening socket"""
 
     def __init__(self, server: Server) -> None:
-        super().__init__(SLICE_TRANSPORT)
+        super(TransportSlice, self).__init__(SLICE_TRANSPORT)
         self.server = server
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         """All Slices with an http endpoint should depend on this one using :func:`get_dependened_by`"""
         return []
 
     async def start(self) -> None:
-        await super().start()
+        await super(TransportSlice, self).start()
         await self.server._transport.start(self.server.get_slices().values(), self.server._handlers)
 
     async def prestop(self) -> None:
-        await super().prestop()
+        await super(TransportSlice, self).prestop()
         LOGGER.debug("Stopping Server Rest Endpoint")
         await self.server._transport.stop()
 
     async def stop(self) -> None:
-        await super().stop()
+        await super(TransportSlice, self).stop()
         await self.server._transport.join()
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         def format_socket(sock: socket.socket) -> str:
             sname = sock.getsockname()
             return f"{sname[0]}:{sname[1]}"
 
         sockets = []
         if self.server._transport._http_server._sockets:
             sockets = [
@@ -636,15 +630,15 @@
 
 
 class SessionManager(ServerSlice):
     """
     A service that receives method calls over one or more transports
     """
 
-    __methods__: dict[str, tuple[str, Callable]] = {}
+    __methods__: Dict[str, Tuple[str, Callable]] = {}
 
     def __init__(self) -> None:
         super().__init__(SLICE_SESSION_MANAGER)
 
         # Config
         interval: int = opt.agent_timeout.get()
         hangtime: Optional[int] = opt.agent_hangtime.get()
@@ -652,45 +646,45 @@
         if hangtime is None:
             hangtime = int(interval * 3 / 4)
 
         self.hangtime: int = hangtime
         self.interval: int = interval
 
         # Session management
-        self._sessions: dict[uuid.UUID, Session] = {}
+        self._sessions: Dict[uuid.UUID, Session] = {}
         self._sessions_lock = asyncio.Lock()
 
         # Listeners
-        self.listeners: list[SessionListener] = []
+        self.listeners: List[SessionListener] = []
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         return {"hangtime": self.hangtime, "interval": self.interval, "sessions": len(self._sessions)}
 
     def add_listener(self, listener: SessionListener) -> None:
         self.listeners.append(listener)
 
     async def prestop(self) -> None:
         async with self._sessions_lock:
             # Keep the super call in the session_lock to make sure that no additional sessions are created
             # while the server is shutting down. This call sets the is_stopping() flag to true.
-            await super().prestop()
+            await super(SessionManager, self).prestop()
         # terminate all sessions cleanly
         for session in self._sessions.copy().values():
             await session.expire(0)
             session.abort()
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     def validate_sid(self, sid: uuid.UUID) -> bool:
         if isinstance(sid, str):
             sid = uuid.UUID(sid)
         return sid in self._sessions
 
-    async def get_or_create_session(self, sid: uuid.UUID, tid: uuid.UUID, endpoint_names: set[str], nodename: str) -> Session:
+    async def get_or_create_session(self, sid: uuid.UUID, tid: uuid.UUID, endpoint_names: Set[str], nodename: str) -> Session:
         if isinstance(sid, str):
             sid = uuid.UUID(sid)
 
         async with self._sessions_lock:
             if self.is_stopping():
                 raise ShutdownInProgress()
             if sid not in self._sessions:
@@ -702,61 +696,52 @@
                 session = self._sessions[sid]
                 self.seen(session, endpoint_names)
                 endpoint_names_snapshot = set(session.endpoint_names)
                 await asyncio.gather(*[listener.seen(session, endpoint_names_snapshot) for listener in self.listeners])
 
             return session
 
-    def new_session(self, sid: uuid.UUID, tid: uuid.UUID, endpoint_names: set[str], nodename: str) -> Session:
-        LOGGER.debug(f"New session with id {sid} on node {nodename} for env {tid} with endpoints {endpoint_names}")
+    def new_session(self, sid: uuid.UUID, tid: uuid.UUID, endpoint_names: Set[str], nodename: str) -> Session:
+        LOGGER.debug("New session with id %s on node %s for env %s with endpoints %s" % (sid, nodename, tid, endpoint_names))
         return Session(self, sid, self.hangtime, self.interval, tid, endpoint_names, nodename)
 
     async def expire(self, session: Session, timeout: float) -> None:
         async with self._sessions_lock:
             LOGGER.debug("Expired session with id %s, last seen %d seconds ago" % (session.get_id(), timeout))
             if session.id in self._sessions:
                 del self._sessions[session.id]
             endpoint_names_snapshot = set(session.endpoint_names)
             await asyncio.gather(*[listener.expire(session, endpoint_names_snapshot) for listener in self.listeners])
 
-    def seen(self, session: Session, endpoint_names: set[str]) -> None:
+    def seen(self, session: Session, endpoint_names: Set[str]) -> None:
         LOGGER.debug("Seen session with id %s; endpoints: %s", session.get_id(), endpoint_names)
         session.seen(endpoint_names)
 
     @handle(methods.heartbeat, env="tid")
     async def heartbeat(
-        self, sid: uuid.UUID, env: "inmanta.data.Environment", endpoint_names: list[str], nodename: str, no_hang: bool = False
-    ) -> Union[int, tuple[int, dict[str, str]]]:
+        self, sid: uuid.UUID, env: "inmanta.data.Environment", endpoint_names: List[str], nodename: str, no_hang: bool = False
+    ) -> Union[int, Tuple[int, Dict[str, str]]]:
         LOGGER.debug("Received heartbeat from %s for agents %s in %s", nodename, ",".join(endpoint_names), env.id)
 
         session: Session = await self.get_or_create_session(sid, env.id, set(endpoint_names), nodename)
 
         LOGGER.debug("Let node %s wait for method calls to become available. (long poll)", nodename)
-
-        # keep a minimal timeout between sending out calls to allow them to batch up
-        now = time.monotonic()
-        wait_time = session.dispatch_delay - (now - session.last_dispatched_call)
-        if wait_time > 0:
-            await asyncio.sleep(wait_time)
-
         call_list = await session.get_calls(no_hang=no_hang)
-
         if call_list is not None:
             LOGGER.debug("Pushing %d method calls to node %s", len(call_list), nodename)
-            session.last_dispatched_call = time.monotonic()
             return 200, {"method_calls": call_list}
         else:
             LOGGER.debug("Heartbeat wait expired for %s, returning. (long poll)", nodename)
 
         return 200
 
     @handle(methods.heartbeat_reply)
     async def heartbeat_reply(
         self, sid: uuid.UUID, reply_id: uuid.UUID, data: JsonType
-    ) -> Union[int, tuple[int, dict[str, str]]]:
+    ) -> Union[int, Tuple[int, Dict[str, str]]]:
         try:
             env = self._sessions[sid]
             env.set_reply(reply_id, data)
             return 200
         except Exception:
-            LOGGER.warning(f"could not deliver agent reply with sid={sid} and reply_id={reply_id}", exc_info=True)
+            LOGGER.warning("could not deliver agent reply with sid=%s and reply_id=%s" % (sid, reply_id), exc_info=True)
             return 500
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/server.py` & `inmanta-core-9.3.0/src/inmanta/server/server.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,15 +16,15 @@
     Contact: code@inmanta.com
 """
 import asyncio
 import json
 import logging
 import os
 import uuid
-from typing import TYPE_CHECKING, Optional, Union, cast
+from typing import TYPE_CHECKING, Dict, List, Optional, Union, cast
 
 from tornado import routing, web
 
 from inmanta import data
 from inmanta.const import ApiDocsFormat
 from inmanta.data.model import FeatureStatus, SliceStatus, StatusResponse
 from inmanta.protocol import exceptions, handle, methods, methods_v2
@@ -46,41 +46,38 @@
 
 class Server(protocol.ServerSlice):
     """
     The central Inmanta server that communicates with clients and agents and persists configuration
     information
     """
 
-    _server_storage: dict[str, str]
+    _server_storage: Dict[str, str]
     compiler: "CompilerService"
     _server: protocol.Server
 
-    # The number of seconds after which the call to the get_status() endpoint of a server slice should time out.
-    GET_SERVER_STATUS_TIMEOUT: int = 1
-
     def __init__(self) -> None:
         super().__init__(name=SLICE_SERVER)
         LOGGER.info("Starting server endpoint")
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_COMPILER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         self._server = server
-        self._server_storage: dict[str, str] = self.check_storage()
+        self._server_storage: Dict[str, str] = self.check_storage()
         self.compiler: "CompilerService" = cast("CompilerService", server.get_slice(SLICE_COMPILER))
         self._handlers.append(routing.Rule(routing.PathMatches(r"/dashboard"), web.RedirectHandler, dict(url=r"/console")))
         self._handlers.append(
             routing.Rule(routing.PathMatches(r"/dashboard/(.*)"), web.RedirectHandler, dict(url=r"/console/{0}"))
         )
 
-    def check_storage(self) -> dict[str, str]:
+    def check_storage(self) -> Dict[str, str]:
         """
         Check if the server storage is configured and ready to use.
         """
 
         def _ensure_directory_exist(directory: str, *subdirs: str) -> str:
             directory = os.path.join(directory, *subdirs)
             if not os.path.exists(directory):
@@ -130,29 +127,26 @@
             raise exceptions.ServerError(
                 "Could not find version number for the inmanta compiler."
                 "Is inmanta installed? Use setuptools install or setuptools dev to install."
             )
 
         async def collect_for_slice(slice_name: str, slice: protocol.ServerSlice) -> SliceStatus:
             try:
-                return SliceStatus(
-                    name=slice_name,
-                    status=await asyncio.wait_for(slice.get_status(), self.GET_SERVER_STATUS_TIMEOUT),
-                )
+                return SliceStatus(name=slice_name, status=await asyncio.wait_for(slice.get_status(), 0.1))
             except asyncio.TimeoutError:
                 return SliceStatus(
                     name=slice_name,
                     status={
                         "error": f"timeout on data collection for {slice_name}, "
                         "consult the server log for additional information"
                     },
                 )
             except Exception:
                 LOGGER.error(
-                    f"The following error occurred while trying to determine the status of slice {slice_name}",
+                    f"The following error occured while trying to determine the status of slice {slice_name}",
                     exc_info=True,
                 )
                 return SliceStatus(name=slice_name, status={"error": "An unexpected error occurred, reported to server log"})
 
         slices = await asyncio.gather(
             *(collect_for_slice(slice_name, slice) for slice_name, slice in self._server.get_slices().items())
         )
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/__init__.py` & `inmanta-core-9.3.0/src/inmanta_ext/core/__init__.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/codeservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/codeservice.py`

 * *Files 10% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
-from typing import cast
+from typing import Dict, List, cast
 
 from inmanta import data
 from inmanta.data import model
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.exceptions import BadRequest, NotFound, ServerError
 from inmanta.server import SLICE_CODE, SLICE_DATABASE, SLICE_FILE, SLICE_TRANSPORT, protocol
 from inmanta.server.services.fileservice import FileService
@@ -31,20 +31,20 @@
 
 class CodeService(protocol.ServerSlice):
     """Slice serving and managing code"""
 
     file_slice: FileService
 
     def __init__(self) -> None:
-        super().__init__(SLICE_CODE)
+        super(CodeService, self).__init__(SLICE_CODE)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_FILE, SLICE_DATABASE]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.file_slice = cast(FileService, server.get_slice(SLICE_FILE))
 
     @handle(methods.upload_code_batched, code_id="id", env="tid")
@@ -73,15 +73,15 @@
 
         val = self.file_slice.stat_file_internal(allrefs)
 
         if len(val) != 0:
             raise BadRequest("Not all file references provided are valid", details={"references": val})
 
         code = await data.Code.get_versions(environment=env.id, version=code_id)
-        oldmap: dict[str, data.Code] = {c.resource: c for c in code}
+        oldmap: Dict[str, data.Code] = {c.resource: c for c in code}
 
         new = {k: v for k, v in resources.items() if k not in oldmap}
         conflict = [k for k, v in resources.items() if k in oldmap and oldmap[k].source_refs != v]
 
         if len(conflict) > 0:
             raise ServerError(
                 "Some of these items already exists, but with different source files", details={"references": conflict}
@@ -112,15 +112,15 @@
                     raise BadRequest(
                         f"The source file {file_name}({hash}) is not correctly encoded," f" use the v2 endpoint to retrieve it"
                     )
 
         return 200, {"version": code_id, "environment": env.id, "resource": resource, "sources": sources}
 
     @handle(methods_v2.get_source_code, env="tid")
-    async def get_source_code(self, env: data.Environment, version: int, resource_type: str) -> list[model.Source]:
+    async def get_source_code(self, env: data.Environment, version: int, resource_type: str) -> List[model.Source]:
         code = await data.Code.get_version(environment=env.id, version=version, resource=resource_type)
         if code is None:
             raise NotFound(f"The version of the code does not exist. {resource_type}, {version}")
 
         sources = []
         if code.source_refs is not None:
             for code_hash, (file_name, module, requires) in code.source_refs.items():
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/compilerservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/compilerservice.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,19 +23,19 @@
 import os
 import re
 import subprocess
 import traceback
 import uuid
 from asyncio import CancelledError, Task
 from asyncio.subprocess import Process
-from collections.abc import AsyncIterator, Awaitable, Hashable, Mapping, Sequence
+from collections.abc import Mapping
 from itertools import chain
 from logging import Logger
 from tempfile import NamedTemporaryFile
-from typing import Optional, cast
+from typing import AsyncIterator, Awaitable, Dict, Hashable, List, Optional, Sequence, Tuple, cast
 
 import dateutil
 import dateutil.parser
 import pydantic
 from asyncpg import Connection
 
 import inmanta.data.model as model
@@ -57,28 +57,29 @@
 
 RETURNCODE_INTERNAL_ERROR = -1
 
 LOGGER: Logger = logging.getLogger(__name__)
 COMPILER_LOGGER: Logger = LOGGER.getChild("report")
 
 
-class CompileStateListener:
+class CompileStateListener(object):
     @abc.abstractmethod
     async def compile_done(self, compile: data.Compile) -> None:
         """Receive notification of all completed compiles
 
         1- Notifications are delivered at least once (retry until all listeners have returned or raise an exception other
         than CancelledError)
         2- Notification are delivered out-of-band (i.e. the next compile can already start, multiple notifications can be in
         flight at any given time, out-of-order delivery is possible but highly unlikely)
         3- Notification are cancelled upon shutdown
         """
+        pass
 
 
-class CompileRun:
+class CompileRun(object):
     """Class encapsulating running the compiler."""
 
     def __init__(self, request: data.Compile, project_dir: str) -> None:
         self.request = request
         self.stage: Optional[data.Report] = None
         self._project_dir = os.path.abspath(project_dir)
         # When set, used to collect tail of std out
@@ -187,15 +188,15 @@
                 sub_process.kill()
 
         if sub_process.returncode != 0:
             return None
 
         return out.decode().strip()
 
-    async def _run_compile_stage(self, name: str, cmd: list[str], cwd: str, env: dict[str, str] = {}) -> data.Report:
+    async def _run_compile_stage(self, name: str, cmd: List[str], cwd: str, env: Dict[str, str] = {}) -> data.Report:
         await self._start_stage(name, " ".join(cmd))
 
         sub_process: Optional[Process] = None
         try:
             env_all = os.environ.copy()
             if env is not None:
                 env_all.update(env)
@@ -213,15 +214,15 @@
             await self._error("".join(traceback.format_exception(type(e), e, e.__traceback__)))
             return await self._end_stage(RETURNCODE_INTERNAL_ERROR)
         finally:
             if sub_process and sub_process.returncode is None:
                 # The process is still running, kill it
                 sub_process.kill()
 
-    async def run(self, force_update: Optional[bool] = False) -> tuple[bool, Optional[model.CompileData]]:
+    async def run(self, force_update: Optional[bool] = False) -> Tuple[bool, Optional[model.CompileData]]:
         """
         Runs this compile run.
 
         :return: Tuple of a boolean representing success and the compile data, if any.
         """
         success = False
 
@@ -240,15 +241,15 @@
 
             if env is None:
                 await self._error("Environment %s does not exist." % environment_id)
                 await self._end_stage(-1)
                 return False, None
 
             if not os.path.exists(project_dir):
-                await self._info(f"Creating project directory for environment {environment_id} at {project_dir}")
+                await self._info("Creating project directory for environment %s at %s" % (environment_id, project_dir))
                 os.mkdir(project_dir)
 
             # Use a separate venv to compile the project to prevent that packages are installed in the
             # venv of the Inmanta server.
             venv_dir = os.path.join(project_dir, ".env")
 
             async def ensure_venv() -> Optional[data.Report]:
@@ -268,15 +269,15 @@
                 else:
                     return await self._end_stage(returncode=0)
 
             async def uninstall_protected_inmanta_packages() -> data.Report:
                 """
                 Ensure that no protected Inmanta packages are installed in the compiler venv.
                 """
-                cmd: list[str] = PipCommandBuilder.compose_uninstall_command(
+                cmd: List[str] = PipCommandBuilder.compose_uninstall_command(
                     python_path=PythonEnvironment.get_python_path_for_env_path(venv_dir),
                     pkg_names=PythonEnvironment.get_protected_inmanta_packages(),
                 )
                 return await self._run_compile_stage(
                     name="Uninstall inmanta packages from the compiler venv", cmd=cmd, cwd=project_dir
                 )
 
@@ -285,15 +286,15 @@
 
             async def install_modules() -> data.Report:
                 return await run_compile_stage_in_venv(
                     "Installing modules", ["-vvv", "-X", "project", "install"], cwd=project_dir
                 )
 
             async def run_compile_stage_in_venv(
-                stage_name: str, inmanta_args: list[str], cwd: str, env: dict[str, str] = {}
+                stage_name: str, inmanta_args: List[str], cwd: str, env: Dict[str, str] = {}
             ) -> data.Report:
                 """
                 Run a compile stage by executing the given command in the venv `venv_dir`.
 
                 :param stage_name: Name of the compile stage.
                 :param inmanta_args: The command to be executed in the venv. This command should not include the part
                                       ["<python-interpreter>", "-m", "inmanta.app"]
@@ -394,17 +395,14 @@
                 cmd.append("--partial")
 
             if self.request.removed_resource_sets is not None:
                 for resource_set in self.request.removed_resource_sets:
                     cmd.append("--delete-resource-set")
                     cmd.append(resource_set)
 
-            if self.request.soft_delete:
-                cmd.append("--soft-delete")
-
             if not self.request.do_export:
                 f = NamedTemporaryFile()
                 cmd.append("-j")
                 cmd.append(f.name)
 
             if config.Config.get("server", "auth", False):
                 token = encode_token(["compiler", "api"], str(environment_id))
@@ -418,15 +416,15 @@
 
             if opt.server_ssl_ca_cert.get() is not None:
                 cmd.append("--ssl-ca-cert")
                 cmd.append(opt.server_ssl_ca_cert.get())
 
             self.tail_stdout = ""
 
-            env_vars_compile: dict[str, str] = os.environ.copy()
+            env_vars_compile: Dict[str, str] = os.environ.copy()
             env_vars_compile.update(self.request.environment_variables)
 
             result: data.Report = await run_compile_stage_in_venv(
                 "Recompiling configuration model", cmd, cwd=project_dir, env=env_vars_compile
             )
             success = result.returncode == 0
             if not success:
@@ -497,44 +495,44 @@
     1. find a runnable(incomplete) job for every environment (if any) and call _queue on it
     2. find all unhandled but complete jobs and run _notify_listeners on them
     """
 
     _env_folder: str
 
     def __init__(self) -> None:
-        super().__init__(SLICE_COMPILER)
-        self._recompiles: dict[uuid.UUID, Task] = {}
+        super(CompilerService, self).__init__(SLICE_COMPILER)
+        self._recompiles: Dict[uuid.UUID, Task] = {}
         self._global_lock = asyncio.locks.Lock()
-        self.listeners: list[CompileStateListener] = []
-        self._scheduled_full_compiles: dict[uuid.UUID, tuple[TaskMethod, str]] = {}
+        self.listeners: List[CompileStateListener] = []
+        self._scheduled_full_compiles: Dict[uuid.UUID, Tuple[TaskMethod, str]] = {}
         # In-memory cache to keep track of the total length of all the compile queues on this Inmanta server.
         # This cache is used by the /serverstatus endpoint.
         self._queue_count_cache: int = 0
         self._queue_count_cache_lock = asyncio.locks.Lock()
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         return {"task_queue": self._queue_count_cache, "listeners": len(self.listeners)}
 
     def add_listener(self, listener: CompileStateListener) -> None:
         self.listeners.append(listener)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_ENVIRONMENT, SLICE_SERVER, SLICE_TRANSPORT]
 
     async def prestart(self, server: server.protocol.Server) -> None:
-        await super().prestart(server)
+        await super(CompilerService, self).prestart(server)
         state_dir: str = opt.state_dir.get()
         server_state_dir = ensure_directory_exist(state_dir, "server")
         self._env_folder = ensure_directory_exist(server_state_dir, "environments")
 
     async def start(self) -> None:
-        await super().start()
+        await super(CompilerService, self).start()
         await self._recover()
         self.schedule(self._cleanup, opt.server_cleanup_compiler_reports_interval.get(), initial_delay=0, cancel_on_stop=False)
 
     async def _cleanup(self) -> None:
         oldest_retained_date = datetime.datetime.now().astimezone() - datetime.timedelta(
             seconds=opt.server_compiler_report_retention.get()
         )
@@ -556,20 +554,20 @@
         """
         # remove old schedule if it exists
         if env.id in self._scheduled_full_compiles:
             self.remove_cron(*self._scheduled_full_compiles[env.id])
             del self._scheduled_full_compiles[env.id]
         # set up new schedule
         if schedule_cron:
-            metadata: dict[str, str] = {
+            metadata: Dict[str, str] = {
                 "type": "schedule",
                 "message": "Full recompile triggered by AUTO_FULL_COMPILE cron schedule",
             }
 
-            async def _request_recompile_task() -> tuple[Optional[uuid.UUID], Warnings]:
+            async def _request_recompile_task() -> Tuple[Optional[uuid.UUID], Warnings]:
                 """
                 Creates a new task for the full compile schedule.
                 If the environment is halted, the task does nothing.
                 Otherwise, it requests a recompile.
                 """
                 latest_env = await data.Environment.get_by_id(env.id)
                 if not latest_env or latest_env.halted:
@@ -591,36 +589,33 @@
         env: data.Environment,
         force_update: bool,
         do_export: bool,
         remote_id: uuid.UUID,
         metadata: Optional[JsonType] = None,
         env_vars: Optional[Mapping[str, str]] = None,
         partial: bool = False,
-        removed_resource_sets: Optional[list[str]] = None,
+        removed_resource_sets: Optional[List[str]] = None,
         exporter_plugin: Optional[str] = None,
         notify_failed_compile: Optional[bool] = None,
         failed_compile_message: Optional[str] = None,
         in_db_transaction: bool = False,
         connection: Optional[Connection] = None,
-        soft_delete: bool = False,
-    ) -> tuple[Optional[uuid.UUID], Warnings]:
+    ) -> Tuple[Optional[uuid.UUID], Warnings]:
         """
         Recompile an environment in a different thread and taking wait time into account.
 
         :param notify_failed_compile: if set to True, errors during compilation will be notified using the
                                       "failed_compile_message".
                                       if set to false, nothing will be notified. If not set then the default notifications are
                                       sent (failed pull stage and errors during the do_export)
         :param failed_compile_message: the message used in notifications if notify_failed_compile is set to True.
         :param connection: Perform the database changes using this database connection.
         :param in_db_transaction: If set to True, the connection must be provided and the connection must be part of an ongoing
                                   database transaction. If this parameter is set to True, is required to call
                                   `CompileService.notify_compile_request_committed()` right after the transaction commits.
-        :param soft_delete: Silently ignore deletion of resource sets in removed_resource_sets if they contain
-            resources that are being exported.
         :return: the compile id of the requested compile and any warnings produced during the request
         """
         if in_db_transaction and not connection:
             raise Exception("A connection should be provided when in_db_transaction is True.")
         if in_db_transaction and connection and not connection.is_in_transaction():
             raise Exception("in_db_transaction is True, but the given connection is not executing a transaction.")
         if removed_resource_sets is None:
@@ -646,15 +641,14 @@
             metadata=metadata,
             environment_variables=env_vars,
             partial=partial,
             removed_resource_sets=removed_resource_sets,
             exporter_plugin=exporter_plugin,
             notify_failed_compile=notify_failed_compile,
             failed_compile_message=failed_compile_message,
-            soft_delete=soft_delete,
         )
         if not in_db_transaction:
             async with self._queue_count_cache_lock:
                 await compile.insert(connection)
                 self._queue_count_cache += 1
             await self._queue(compile)
         else:
@@ -818,15 +812,15 @@
         """
         Runs a compile request. At completion, looks for similar compile requests based on _compile_merge_key and marks
         those as completed as well.
         """
         await self._auto_recompile_wait(compile)
 
         compile_merge_key: Hashable = CompilerService._compile_merge_key(compile)
-        merge_candidates: list[data.Compile] = [
+        merge_candidates: List[data.Compile] = [
             c
             for c in await data.Compile.get_next_compiles_for_environment(compile.environment)
             if not c.id == compile.id and CompilerService._compile_merge_key(c) == compile_merge_key
         ]
 
         runner = self._get_compile_runner(compile, project_dir=os.path.join(self._env_folder, str(compile.environment)))
 
@@ -915,15 +909,15 @@
     async def get_compile_data(self, compile_id: uuid.UUID) -> Optional[model.CompileData]:
         compile: Optional[data.Compile] = await data.Compile.get_by_id(compile_id)
         if compile is None:
             raise NotFound("The given compile id does not exist")
         return compile.to_dto().compile_data
 
     @protocol.handle(methods.get_compile_queue, env="tid")
-    async def get_compile_queue(self, env: data.Environment) -> list[model.CompileRun]:
+    async def get_compile_queue(self, env: data.Environment) -> List[model.CompileRun]:
         """
         Get the current compiler queue on the server
         """
         compiles = await data.Compile.get_next_compiles_for_environment(env.id)
         return [x.to_dto() for x in compiles]
 
     @protocol.handle(methods_v2.get_compile_reports, env="tid")
@@ -931,15 +925,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[uuid.UUID] = None,
         last_id: Optional[uuid.UUID] = None,
         start: Optional[datetime.datetime] = None,
         end: Optional[datetime.datetime] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "requested.desc",
     ) -> ReturnValue[Sequence[model.CompileReport]]:
         try:
             handler = CompileReportView(env, limit, filter, sort, first_id, last_id, start, end)
             return await handler.execute()
         except (InvalidFilter, InvalidSort, data.InvalidQueryParameter, data.InvalidFieldNameException) as e:
             raise BadRequest(e.message) from e
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/databaseservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/databaseservice.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
-from typing import Optional
+from typing import Dict, List, Optional
 
 import asyncpg
 from pyformance import gauge
 from pyformance.meters import CallbackGauge
 
 from inmanta import data, util
 from inmanta.server import SLICE_DATABASE
@@ -31,15 +31,15 @@
 LOGGER = logging.getLogger(__name__)
 
 
 class DatabaseService(protocol.ServerSlice):
     """Slice to initialize the database"""
 
     def __init__(self) -> None:
-        super().__init__(SLICE_DATABASE)
+        super(DatabaseService, self).__init__(SLICE_DATABASE)
         self._pool: Optional[asyncpg.pool.Pool] = None
         self._db_pool_watcher: Optional[util.ExhaustedPoolWatcher] = None
 
     async def start(self) -> None:
         await super().start()
         self.start_monitor()
         await self.connect_database()
@@ -60,15 +60,15 @@
         self.schedule(self._report_database_pool_exhaustion, interval=3_600 * 24, cancel_on_stop=True)
 
     async def stop(self) -> None:
         await super().stop()
         await self.disconnect_database()
         self._pool = None
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return []
 
     async def connect_database(self) -> None:
         """Connect to the database"""
         database_host = opt.db_host.get()
         database_port = opt.db_port.get()
 
@@ -89,15 +89,15 @@
         )
         LOGGER.info("Connected to PostgreSQL database %s on %s:%d", opt.db_name.get(), database_host, database_port)
 
     async def disconnect_database(self) -> None:
         """Disconnect the database"""
         await data.disconnect()
 
-    async def get_status(self) -> dict[str, ArgumentTypes]:
+    async def get_status(self) -> Dict[str, ArgumentTypes]:
         """Get the status of the database connection"""
         connected = await self.get_connection_status()
         status = {
             "connected": connected,
             "database": opt.db_name.get(),
             "host": opt.db_host.get(),
         }
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/dryrunservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/dryrunservice.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import asyncio
 import logging
 import uuid
-from typing import Optional, cast
+from typing import Dict, List, Optional, cast
 
 from inmanta import data
 from inmanta.data.model import DryRun, DryRunReport, ResourceDiff, ResourceDiffStatus, ResourceVersionIdStr
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.exceptions import NotFound
 from inmanta.resources import Id
 from inmanta.server import (
@@ -43,21 +43,21 @@
 class DyrunService(protocol.ServerSlice):
     """Slice for dryun support"""
 
     agent_manager: AgentManager
     autostarted_agent_manager: AutostartedAgentManager
 
     def __init__(self) -> None:
-        super().__init__(SLICE_DRYRUN)
+        super(DyrunService, self).__init__(SLICE_DRYRUN)
         self.dryrun_lock = asyncio.Lock()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_AGENT_MANAGER, SLICE_AUTOSTARTED_AGENT_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.agent_manager = cast(AgentManager, server.get_slice(SLICE_AGENT_MANAGER))
         self.autostarted_agent_manager = cast(AutostartedAgentManager, server.get_slice(SLICE_AUTOSTARTED_AGENT_MANAGER))
 
@@ -88,22 +88,22 @@
                 self.add_background_task(client.do_dryrun(env.id, dryrun.id, agent, version_id))
             else:
                 agents_down.append(agent)
                 LOGGER.warning("Agent %s from model %s in env %s is not available for a dryrun", agent, version_id, env.id)
 
         # Mark the resources in an undeployable state as done
         async with self.dryrun_lock:
-            undeployable_ids = model.get_undeployable()
+            undeployable_ids = await model.get_undeployable()
             undeployable_version_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in undeployable_ids]
             undeployable = await data.Resource.get_resources(environment=env.id, resource_version_ids=undeployable_version_ids)
             await self._save_resources_without_changes_to_dryrun(
                 dryrun_id=dryrun.id, resources=undeployable, diff_status=ResourceDiffStatus.undefined
             )
 
-            skip_undeployable_ids = model.get_skipped_for_undeployable()
+            skip_undeployable_ids = await model.get_skipped_for_undeployable()
             skip_undeployable_version_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in skip_undeployable_ids]
             skipundeployable = await data.Resource.get_resources(
                 environment=env.id, resource_version_ids=skip_undeployable_version_ids
             )
             await self._save_resources_without_changes_to_dryrun(
                 dryrun_id=dryrun.id, resources=skipundeployable, diff_status=ResourceDiffStatus.skipped_for_undefined
             )
@@ -118,15 +118,15 @@
             await self._save_resources_without_changes_to_dryrun(
                 dryrun_id=dryrun.id, resources=resources_with_agents_down, diff_status=ResourceDiffStatus.agent_down
             )
 
         return dryrun
 
     async def _save_resources_without_changes_to_dryrun(
-        self, dryrun_id: uuid.UUID, resources: list[data.Resource], diff_status: Optional[ResourceDiffStatus] = None
+        self, dryrun_id: uuid.UUID, resources: List[data.Resource], diff_status: Optional[ResourceDiffStatus] = None
     ):
         for res in resources:
             parsed_id = Id.parse_id(res.resource_id)
             parsed_id.set_version(res.model)
             payload = {
                 "changes": {},
                 "id_fields": {
@@ -168,15 +168,15 @@
 
         return (
             200,
             {"dryruns": [{"id": x.id, "version": x.model, "date": x.date, "total": x.total, "todo": x.todo} for x in dryruns]},
         )
 
     @handle(methods_v2.list_dryruns, env="tid")
-    async def list_dryruns(self, env: data.Environment, version: int) -> list[DryRun]:
+    async def list_dryruns(self, env: data.Environment, version: int) -> List[DryRun]:
         model = await data.ConfigurationModel.get_version(environment=env.id, version=version)
         if model is None:
             raise NotFound("The requested version does not exist.")
 
         dtos = await data.DryRun.list_dryruns(order_by_column="date", order="DESC", environment=env.id, model=version)
         return dtos
 
@@ -226,21 +226,21 @@
             for rvid, resource in resources_with_already_known_status.items()
         ]
         version_diff.sort(key=lambda r: r.resource_id)
         dto = DryRunReport(summary=dryrun.to_dto(), diff=version_diff)
 
         return dto
 
-    def get_attributes_from_changes(self, changes: dict[str, dict[str, object]], key: str) -> dict[str, object]:
+    def get_attributes_from_changes(self, changes: Dict[str, Dict[str, object]], key: str) -> Dict[str, object]:
         return {attr_name: values[key] for attr_name, values in changes.items() if attr_name != "requires"}
 
-    def resource_will_be_unpurged(self, from_attributes: dict[str, object], to_attributes: dict[str, object]) -> bool:
+    def resource_will_be_unpurged(self, from_attributes: Dict[str, object], to_attributes: Dict[str, object]) -> bool:
         return from_attributes.get("purged") is True and to_attributes.get("purged") is False
 
-    def resource_will_be_purged(self, from_attributes: dict[str, object], to_attributes: dict[str, object]) -> bool:
+    def resource_will_be_purged(self, from_attributes: Dict[str, object], to_attributes: Dict[str, object]) -> bool:
         return from_attributes.get("purged") is False and to_attributes.get("purged") is True
 
     @handle(methods.dryrun_update, dryrun_id="id", env="tid")
     async def dryrun_update(
         self, env: data.Environment, dryrun_id: uuid.UUID, resource: ResourceVersionIdStr, changes: JsonType
     ) -> Apireturn:
         async with self.dryrun_lock:
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/environment_metrics_service.py` & `inmanta-core-9.3.0/src/inmanta/server/services/environment_metrics_service.py`

 * *Files 4% similar despite different names*

```diff
@@ -19,15 +19,15 @@
 import logging
 import math
 import textwrap
 import uuid
 from collections.abc import Sequence
 from datetime import datetime, timedelta
 from enum import Enum
-from typing import Optional, Union
+from typing import Dict, List, Optional, Union
 
 import asyncpg
 
 from inmanta.data import (
     ENVIRONMENT_METRICS_RETENTION,
     Agent,
     Compile,
@@ -175,22 +175,22 @@
         raise NotImplementedError()
 
 
 class EnvironmentMetricsService(protocol.ServerSlice):
     """Slice for the management of metrics"""
 
     def __init__(self) -> None:
-        super().__init__(SLICE_ENVIRONMENT_METRICS)
-        self.metrics_collectors: dict[str, MetricsCollector] = {}
+        super(EnvironmentMetricsService, self).__init__(SLICE_ENVIRONMENT_METRICS)
+        self.metrics_collectors: Dict[str, MetricsCollector] = {}
         self.previous_timestamp = datetime.now().astimezone()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def start(self) -> None:
         await super().start()
         self.register_metric_collector(ResourceCountMetricsCollector())
         self.register_metric_collector(CompileWaitingTimeMetricsCollector())
         self.register_metric_collector(AgentCountMetricsCollector())
@@ -306,79 +306,47 @@
             LOGGER.warning(
                 "flush_metrics method took more than %d seconds: "
                 "new attempts to flush metrics are fired faster than they resolve. "
                 "Verify the load on the Database and the available connection pool size.",
                 COLLECTION_INTERVAL_IN_SEC,
             )
 
-    def _round_timestamp_for_interval(self, timestamp: datetime, hours_in_time_window: int, round_up: bool) -> datetime:
-        """
-        Round the given timestamp as such that it's unix timestamp is a multiple of the given hours_in_time_window.
-
-        :param round_up: If True, round the timestamp up, otherwise round it down.
-        :returns: The rounded timestamp with the same timezone as the given timestamp.
-        """
-        rounding_method = math.ceil if round_up else math.floor
-        hours_in_timestamp: float = timestamp.timestamp() / 3600
-        hours_in_time_window_rounded: float = rounding_method(hours_in_timestamp / hours_in_time_window) * hours_in_time_window
-        return datetime.fromtimestamp(hours_in_time_window_rounded * 3600, tz=timestamp.tzinfo)
-
     def _divide_time_interval_in_time_windows(
-        self, start_interval: datetime, end_interval: datetime, nb_time_windows: int, round_timestamps: bool
-    ) -> tuple[datetime, datetime, int, list[datetime]]:
+        self, start_interval: datetime, end_interval: datetime, nb_time_windows: int
+    ) -> list[datetime]:
         """
         This method divides the given time interval into the given number of time windows.
-        If round_timestamps it True, the start_interval, end_interval and nb_time_windows may be adjusted
-        to have equally sized time windows that start and end at a full hour.
+        The result is a list of timestamps that represent the end time of each window. This list of timestamps
+        is sorted in ASC order.
         """
-        if round_timestamps:
-            # First round the nb_time_windows and only then the start_interval and end_interval to
-            # make sure the rounded values stay as close as possible to their original values.
-            hour_in_time_window_rounded: int = math.floor(
-                (end_interval - start_interval).total_seconds() / nb_time_windows / 3600
-            )
-            start_interval = self._round_timestamp_for_interval(start_interval, hour_in_time_window_rounded, round_up=False)
-            end_interval = self._round_timestamp_for_interval(end_interval, hour_in_time_window_rounded, round_up=True)
-            nb_time_windows = int((end_interval - start_interval).total_seconds() / (hour_in_time_window_rounded * 3600))
-        total_seconds_in_interval: float = (end_interval - start_interval).total_seconds()
-        seconds_per_time_window = math.floor(total_seconds_in_interval / nb_time_windows)
-        result = [end_interval - timedelta(seconds=seconds_per_time_window) * i for i in range(nb_time_windows)]
+        total_seconds_in_interval = (end_interval - start_interval).total_seconds()
+        seconds_per_window = math.floor(total_seconds_in_interval / nb_time_windows)
+        result = [end_interval - timedelta(seconds=seconds_per_window) * i for i in range(nb_time_windows)]
         result.reverse()
-        return start_interval, end_interval, nb_time_windows, result
+        return result
 
     @handle(method=methods_v2.get_environment_metrics, env="tid")
     async def get_environment_metrics(
         self,
         env: Environment,
-        metrics: list[str],
+        metrics: List[str],
         start_interval: datetime,
         end_interval: datetime,
         nb_datapoints: int,
-        round_timestamps: bool = False,
     ) -> EnvironmentMetricsResult:
         if start_interval >= end_interval:
             raise BadRequest("start_interval should be strictly smaller than end_interval.")
         if start_interval + timedelta(minutes=1) * nb_datapoints >= end_interval:
             raise BadRequest(
                 "start_interval and end_interval should be at least <nb_datapoints> minutes separated from each other."
             )
         if nb_datapoints <= 0:
             raise BadRequest("nb_datapoints should be larger than 0")
         if not metrics:
             raise BadRequest("The 'metrics' argument should contain the name of at least one metric.")
-        if round_timestamps and (end_interval - start_interval).total_seconds() < 3600 * nb_datapoints:
-            raise BadRequest(
-                "When round_timestamps is set to True, the number of hours between start_interval"
-                " and end_interval should be at least the amount of hours equal to nb_datapoints."
-            )
-
-        start_interval, end_interval, nb_datapoints, timestamps = self._divide_time_interval_in_time_windows(
-            start_interval, end_interval, nb_datapoints, round_timestamps
-        )
-
         unknown_metric_names = [
             m for m in metrics if m not in self.metrics_collectors.keys() and m != "orchestrator.compile_rate"
         ]
         if unknown_metric_names:
             raise BadRequest(f"The following metrics given in the metrics parameter are unknown: {unknown_metric_names}")
 
         def _get_sub_query(metric: str, group_by: str, table_name: str, aggregation_function: str, metrics_list: str) -> str:
@@ -404,15 +372,15 @@
             """
             ).strip()
 
         query_on_gauge_table = _get_sub_query(
             metric="metric_name",
             group_by="category",
             table_name=EnvironmentMetricsGauge.table_name(),
-            aggregation_function="(avg(count)::float)",
+            aggregation_function="(sum(count)::float)/(count(*)::float)",
             metrics_list="$5",
         )
         query_on_timer_table = _get_sub_query(
             metric="metric_name",
             group_by="category",
             table_name=EnvironmentMetricsTimer.table_name(),
             aggregation_function="(sum(value)::float)/NULLIF(sum(count)::float, 0)",
@@ -431,15 +399,15 @@
             ({query_on_gauge_table})
             UNION ALL
             ({query_on_timer_table})
             {f"UNION ALL ({query_for_compiler_rate})" if "orchestrator.compile_rate" in metrics else ""}
         """.strip()
 
         # Initialize everything with default values
-        result_metrics: dict[str, list[Union[float, dict[str, float], None]]] = {
+        result_metrics: Dict[str, List[Union[float, Dict[str, float], None]]] = {
             m: [0 if m == "orchestrator.compile_rate" else None for _ in range(nb_datapoints)] for m in metrics
         }
         async with EnvironmentMetricsGauge.get_connection() as con:
             values = [env.id, start_interval, end_interval, nb_datapoints, metrics]
             records = await con.fetch(query, *values)
             for r in records:
                 if r["value"] is None:
@@ -459,15 +427,20 @@
                 else:
                     if result_metrics[metric_name][index_in_list] is None:
                         result_metrics[metric_name][index_in_list] = {category: value}
                     else:
                         result_metrics[metric_name][index_in_list][category] = value
 
         # Convert to naive timestamps
-        return EnvironmentMetricsResult(start=start_interval, end=end_interval, timestamps=timestamps, metrics=result_metrics)
+        return EnvironmentMetricsResult(
+            start=start_interval,
+            end=end_interval,
+            timestamps=self._divide_time_interval_in_time_windows(start_interval, end_interval, nb_datapoints),
+            metrics=result_metrics,
+        )
 
 
 class ResourceCountMetricsCollector(MetricsCollector):
     """
     This Metric will track the number of resources (grouped by resources state).
     """
 
@@ -489,15 +462,15 @@
             SELECT e.id as environment, s.name as status, COALESCE(r.count, 0) as count
             FROM {Environment.table_name()} AS e
             CROSS JOIN unnest(enum_range(NULL::resourcestate)) AS s(name)
             LEFT JOIN nonzero_statuses AS r
             ON r.environment = e.id AND r.status = s.name
             ORDER BY r.environment, r.status
             """
-        metric_values: list[MetricValue] = []
+        metric_values: List[MetricValue] = []
         result: Sequence[asyncpg.Record] = await connection.fetch(query)
         for record in result:
             assert isinstance(record["count"], int)
             assert isinstance(record["environment"], uuid.UUID)
             assert isinstance(record["status"], str)
             metric_values.append(MetricValue(self.get_metric_name(), record["count"], record["environment"], record["status"]))
         return metric_values
@@ -535,15 +508,15 @@
 SELECT e.id AS environment, s.status, COALESCE(a.count, 0) AS count
 FROM {Environment.table_name()} AS e
 CROSS JOIN (VALUES ('paused'), ('up'), ('down')) AS s(status)
 LEFT JOIN agent_counts AS a
     ON a.environment = e.id AND a.status = s.status
 ORDER BY environment, s.status
         """
-        metric_values: list[MetricValue] = []
+        metric_values: List[MetricValue] = []
         result: Sequence[asyncpg.Record] = await connection.fetch(query)
         for record in result:
             assert isinstance(record["count"], int)
             assert isinstance(record["environment"], uuid.UUID)
             assert isinstance(record["status"], str)
             metric_values.append(MetricValue(self.get_metric_name(), record["count"], record["environment"], record["status"]))
         return metric_values
@@ -569,15 +542,15 @@
             WHERE completed >= $1
             AND completed < $2
             GROUP BY environment
         """
         values = [start_interval, end_interval]
         result: Sequence[asyncpg.Record] = await connection.fetch(query, *values)
 
-        metric_values: list[MetricValueTimer] = []
+        metric_values: List[MetricValueTimer] = []
         for record in result:
             assert isinstance(record["count"], int)
             assert isinstance(record["environment"], uuid.UUID)
             assert isinstance(record["compile_time"], timedelta)
 
             total_compile_time = record["compile_time"].total_seconds()  # Convert compile_time to float
             assert isinstance(total_compile_time, float)
@@ -609,15 +582,15 @@
             WHERE started >= $1
             AND started < $2
             GROUP BY environment
         """
         values = [start_interval, end_interval]
         result: Sequence[asyncpg.Record] = await connection.fetch(query, *values)
 
-        metric_values: list[MetricValueTimer] = []
+        metric_values: List[MetricValueTimer] = []
         for record in result:
             assert isinstance(record["count"], int)
             assert isinstance(record["environment"], uuid.UUID)
             assert isinstance(record["compile_waiting_time"], timedelta)
 
             compile_waiting_time = record["compile_waiting_time"].total_seconds()  # Convert compile_waiting_time to float
             assert isinstance(compile_waiting_time, float)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/environmentservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/environmentservice.py`

 * *Files 8% similar despite different names*

```diff
@@ -23,18 +23,16 @@
 import re
 import shutil
 import uuid
 import warnings
 from collections import defaultdict
 from collections.abc import Set
 from enum import Enum
-from re import Pattern
-from typing import Optional, cast
+from typing import Dict, List, Optional, Pattern, cast
 
-import asyncpg
 from asyncpg import StringDataRightTruncationError
 
 from inmanta import config, data
 from inmanta.data import Setting, model
 from inmanta.protocol import encode_token, handle, methods, methods_v2
 from inmanta.protocol.common import ReturnValue, attach_warnings
 from inmanta.protocol.exceptions import BadRequest, Forbidden, NotFound, ServerError
@@ -52,15 +50,14 @@
 )
 from inmanta.server.agentmanager import AgentManager, AutostartedAgentManager
 from inmanta.server.server import Server
 from inmanta.server.services import compilerservice
 from inmanta.server.services.orchestrationservice import OrchestrationService
 from inmanta.server.services.resourceservice import ResourceService
 from inmanta.types import Apireturn, JsonType, Warnings
-from inmanta.util import get_compiler_version
 
 LOGGER = logging.getLogger(__name__)
 
 
 def rename_fields(env: model.Environment) -> JsonType:
     env_dict = env.dict()
     env_dict["project"] = env_dict["project_id"]
@@ -83,70 +80,69 @@
 
     async def environment_action_created(self, env: model.Environment) -> None:
         """
         Will be called when a new environment is created
 
         :param env: The new environment
         """
+        pass
 
     async def environment_action_cleared(self, env: model.Environment) -> None:
         """
         Will be called when the environment is cleared
 
         :param env: The environment that is cleared
         """
+        pass
 
     async def environment_action_deleted(self, env: model.Environment) -> None:
         """
         Will be called when the environment is deleted
 
         :param env: The environment that is deleted
         """
+        pass
 
     async def environment_action_updated(self, updated_env: model.Environment, original_env: model.Environment) -> None:
         """
         Will be called when an environment is updated
         :param updated_env: The updated environment
         :param original_env: The original environment
         """
+        pass
 
 
 class EnvironmentService(protocol.ServerSlice):
     """Slice with project and environment management"""
 
     server_slice: Server
     agent_manager: AgentManager
     autostarted_agent_manager: AutostartedAgentManager
     orchestration_service: OrchestrationService
     resource_service: ResourceService
-    listeners: dict[EnvironmentAction, list[EnvironmentListener]]
-    # environment_state_operation_lock is to prevent concurrent execution of
-    # operations that modify the state of an environment, such as halting, resuming, or deleting.
-    # This lock helps prevent race conditions and ensures that state changes are carried out in a safe and
-    # sequential manner. It guarantees that operations affecting the agent states and environment status
-    # do not overlap.
-    environment_state_operation_lock: asyncio.Lock
+    listeners: Dict[EnvironmentAction, List[EnvironmentListener]]
+    agent_state_lock: asyncio.Lock
     icon_regex: Pattern[str] = re.compile("^(image/png|image/jpeg|image/webp|image/svg\\+xml);(base64),(.+)$")
 
     def __init__(self) -> None:
-        super().__init__(SLICE_ENVIRONMENT)
+        super(EnvironmentService, self).__init__(SLICE_ENVIRONMENT)
         self.listeners = defaultdict(list)
-        self.environment_state_operation_lock = asyncio.Lock()
+        self.agent_state_lock = asyncio.Lock()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [
             SLICE_COMPILER,
             SLICE_SERVER,
             SLICE_DATABASE,
             SLICE_AUTOSTARTED_AGENT_MANAGER,
             SLICE_ORCHESTRATION,
             SLICE_RESOURCE,
         ]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.server_slice = cast(Server, server.get_slice(SLICE_SERVER))
         self.agent_manager = cast(AgentManager, server.get_slice(SLICE_AGENT_MANAGER))
         self.autostarted_agent_manager = cast(AutostartedAgentManager, server.get_slice(SLICE_AUTOSTARTED_AGENT_MANAGER))
@@ -253,73 +249,55 @@
 
     @handle(methods.delete_environment, environment_id="id")
     async def delete_environment(self, environment_id: uuid.UUID) -> Apireturn:
         await self.environment_delete(environment_id)
         return 200
 
     @handle(methods_v2.halt_environment, env="tid")
-    async def halt(self, env: data.Environment, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        async with self.environment_state_operation_lock:
-            await self._halt(env, connection)
-
-    async def _halt(self, env: data.Environment, connection: Optional[asyncpg.connection.Connection] = None) -> None:
-        """
-        Halts the specified environment without acquiring the environment_state_operation_lock.
-        This method is designed to be an internal helper that allows for halting an environment
-        as part of a larger operation (e.g., deletion), where the lock is managed by the caller and prevent double locking.
-        """
-        async with data.Environment.get_connection(connection=connection) as con:
-            async with con.transaction():
-                refreshed_env: Optional[data.Environment] = await data.Environment.get_by_id(env.id, connection=con)
-                if refreshed_env is None:
-                    raise NotFound("Environment %s does not exist" % env.id)
-
-                # silently ignore requests if this environment has already been halted
-                if refreshed_env.halted:
-                    return
-
-                await refreshed_env.update_fields(halted=True, connection=con)
-                await self.agent_manager.halt_agents(refreshed_env, connection=con)
-        await self.autostarted_agent_manager.stop_agents(refreshed_env)
+    async def halt(self, env: data.Environment) -> None:
+        async with self.agent_state_lock:
+            async with data.Environment.get_connection() as connection:
+                async with connection.transaction():
+                    refreshed_env: Optional[data.Environment] = await data.Environment.get_by_id(env.id, connection=connection)
+                    if refreshed_env is None:
+                        raise NotFound("Environment %s does not exist" % env.id)
+
+                    # silently ignore requests if this environment has already been halted
+                    if refreshed_env.halted:
+                        return
+
+                    await refreshed_env.update_fields(halted=True, connection=connection)
+                    await self.agent_manager.halt_agents(refreshed_env, connection=connection)
+            await self.autostarted_agent_manager.stop_agents(refreshed_env)
 
     @handle(methods_v2.resume_environment, env="tid")
     async def resume(self, env: data.Environment) -> None:
-        async with self.environment_state_operation_lock:
+        async with self.agent_state_lock:
             async with data.Environment.get_connection() as connection:
                 async with connection.transaction():
                     refreshed_env: Optional[data.Environment] = await data.Environment.get_by_id(env.id, connection=connection)
                     if refreshed_env is None:
                         raise NotFound("Environment %s does not exist" % env.id)
-                    if refreshed_env.is_marked_for_deletion:
-                        raise BadRequest("Cannot resume an environment that is marked for deletion.")
+
                     # silently ignore requests if this environment has already been resumed
                     if not refreshed_env.halted:
                         return
 
                     await refreshed_env.update_fields(halted=False, connection=connection)
                     await self.agent_manager.resume_agents(refreshed_env, connection=connection)
             await self.autostarted_agent_manager.restart_agents(refreshed_env)
         await self.server_slice.compiler.resume_environment(refreshed_env.id)
 
-    @handle(methods.decomission_environment, env="id")
-    async def decommission_environment(self, env: data.Environment, metadata: Optional[JsonType]) -> Apireturn:
-        data: Optional[model.ModelMetadata] = None
-        if metadata:
-            data = model.ModelMetadata(message=metadata.get("message", ""), type=metadata.get("type", ""))
-
-        version = await self.environment_decommission(env, data)
-        return 200, {"version": version}
-
     @handle(methods.clear_environment, env="id")
     async def clear_environment(self, env: data.Environment) -> Apireturn:
         await self.environment_clear(env)
         return 200
 
     @handle(methods.create_token, env="tid")
-    async def create_token(self, env: data.Environment, client_types: list[str], idempotent: bool) -> Apireturn:
+    async def create_token(self, env: data.Environment, client_types: List[str], idempotent: bool) -> Apireturn:
         """
         Create a new auth token for this environment
         """
         return 200, {"token": await self.environment_create_token(env, client_types, idempotent)}
 
     @handle(methods.list_settings, env="tid")
     async def list_settings(self, env: data.Environment) -> Apireturn:
@@ -363,19 +341,14 @@
         name: str,
         repository: str,
         branch: str,
         environment_id: Optional[uuid.UUID],
         description: str = "",
         icon: str = "",
     ) -> model.Environment:
-        # check if an environment with this name is already defined in this project
-        envs = await data.Environment.get_list(project=project_id, name=name)
-        if len(envs) > 0:
-            raise BadRequest(f"Project with id={project_id} already has an environment with name {name}")
-
         if environment_id is None:
             environment_id = uuid.uuid4()
 
         if (repository is None and branch is not None) or (repository is not None and branch is None):
             raise BadRequest("Repository and branch should be set together.")
         if repository is None:
             repository = ""
@@ -482,78 +455,56 @@
 
         if env is None:
             raise NotFound("The environment id does not exist.")
 
         return env.to_dto()
 
     @handle(methods_v2.environment_list)
-    async def environment_list(self, details: bool = False) -> list[model.Environment]:
+    async def environment_list(self, details: bool = False) -> List[model.Environment]:
         # data access framework does not support multi-column order by, but multi-environment projects are rare
         # (and discouraged)
         # => sort by primary column in SQL, then do full sort in Python, cheap because mostly sorted already by this point
         env_list = await data.Environment.get_list(details=details, order_by_column="project")
         return sorted((env.to_dto() for env in env_list), key=lambda e: (e.project_id, e.name, e.id))
 
     @handle(methods_v2.environment_delete, environment_id="id")
     async def environment_delete(self, environment_id: uuid.UUID) -> None:
-        async with self.environment_state_operation_lock:
-            async with data.Environment.get_connection() as connection:
-                env = await data.Environment.get_by_id(environment_id, connection=connection)
-                if env is None:
-                    raise NotFound("The environment with given id does not exist.")
-
-                is_protected_environment = await env.get(data.PROTECTED_ENVIRONMENT, connection)
-                if is_protected_environment:
-                    raise Forbidden(
-                        f"Environment {environment_id} is protected. See environment setting: {data.PROTECTED_ENVIRONMENT}"
-                    )
-
-                # Check if the environment is halted; if not, halt it
-                if not env.halted:
-                    LOGGER.info("Halting Environment %s", str(environment_id))
-                    await self._halt(env, connection=connection)
-
-                await env.mark_for_deletion(connection=connection)
-                self._disable_schedules(env)
-                await asyncio.gather(self.autostarted_agent_manager.stop_agents(env), env.delete_cascade(connection=connection))
-
-            self.resource_service.close_resource_action_logger(environment_id)
-            await self.notify_listeners(EnvironmentAction.deleted, env.to_dto())
-
-            self._delete_environment_dir(environment_id)
+        env = await data.Environment.get_by_id(environment_id)
+        if env is None:
+            raise NotFound("The environment with given id does not exist.")
 
-    @handle(methods_v2.environment_decommission, env="id")
-    async def environment_decommission(self, env: data.Environment, metadata: Optional[model.ModelMetadata]) -> int:
         is_protected_environment = await env.get(data.PROTECTED_ENVIRONMENT)
         if is_protected_environment:
-            raise Forbidden(f"Environment {env.id} is protected. See environment setting: {data.PROTECTED_ENVIRONMENT}")
-        version = await env.get_next_version()
-        if metadata is None:
-            metadata = model.ModelMetadata(message="Decommission of environment", type="api")
-        version_info = model.ModelVersionInfo(export_metadata=metadata)
-        await self.orchestration_service.put_version(env, version, [], {}, [], version_info.dict(), get_compiler_version())
-        return version
+            raise Forbidden(f"Environment {environment_id} is protected. See environment setting: {data.PROTECTED_ENVIRONMENT}")
+
+        self._disable_schedules(env)
+        await asyncio.gather(self.autostarted_agent_manager.stop_agents(env), env.delete_cascade())
+
+        self.resource_service.close_resource_action_logger(environment_id)
+        await self.notify_listeners(EnvironmentAction.deleted, env.to_dto())
+
+        self._delete_environment_dir(environment_id)
 
     @handle(methods_v2.environment_clear, env="id")
     async def environment_clear(self, env: data.Environment) -> None:
         """
         Clear the environment
         """
         is_protected_environment = await env.get(data.PROTECTED_ENVIRONMENT)
         if is_protected_environment:
             raise Forbidden(f"Environment {env.id} is protected. See environment setting: {data.PROTECTED_ENVIRONMENT}")
 
         await self.autostarted_agent_manager.stop_agents(env)
-        await env.clear()
+        await env.delete_cascade(only_content=True)
 
         await self.notify_listeners(EnvironmentAction.cleared, env.to_dto())
         self._delete_environment_dir(env.id)
 
     @handle(methods_v2.environment_create_token, env="tid")
-    async def environment_create_token(self, env: data.Environment, client_types: list[str], idempotent: bool) -> str:
+    async def environment_create_token(self, env: data.Environment, client_types: List[str], idempotent: bool) -> str:
         """
         Create a new auth token for this environment
         """
         if not config.Config.getboolean("server", "auth", False):
             raise BadRequest("Authentication is disabled, generating a token is not allowed")
         return encode_token(client_types, str(env.id), idempotent)
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/fileservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/fileservice.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,16 +15,15 @@
 
     Contact: code@inmanta.com
 """
 import base64
 import difflib
 import logging
 import os
-from collections.abc import Iterable
-from typing import cast
+from typing import Iterable, List, cast
 
 from inmanta.protocol import handle, methods
 from inmanta.protocol.exceptions import BadRequest, NotFound, ServerError
 from inmanta.server import SLICE_FILE, SLICE_SERVER, SLICE_TRANSPORT
 from inmanta.server import config as opt
 from inmanta.server import protocol
 from inmanta.server.server import Server
@@ -36,20 +35,20 @@
 
 class FileService(protocol.ServerSlice):
     """Slice serving and managing files"""
 
     server_slice: Server
 
     def __init__(self) -> None:
-        super().__init__(SLICE_FILE)
+        super(FileService, self).__init__(SLICE_FILE)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_SERVER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.server_slice = cast(Server, server.get_slice(SLICE_SERVER))
 
     @handle(methods.upload_file, file_hash="id")
@@ -118,21 +117,21 @@
             else:
                 LOGGER.error("File corrupt, expected hash %s but found %s at %s", file_hash, actualhash, file_name)
                 raise ServerError(
                     f"File corrupt, expected hash {file_hash} but found {actualhash}, please contact the server administrator"
                 )
 
     @handle(methods.stat_files)
-    async def stat_files(self, files: list[str]) -> Apireturn:
+    async def stat_files(self, files: List[str]) -> Apireturn:
         """
-        Return which files in the list don't exist on the server
+        Return which files in the list exist on the server
         """
         return 200, {"files": self.stat_file_internal(files)}
 
-    def stat_file_internal(self, files: Iterable[str]) -> list[str]:
+    def stat_file_internal(self, files: Iterable[str]) -> List[str]:
         """
         Return which files in the list don't exist on the server
         """
         # A dict is used here instead of a set to have efficient set-like behaviour while preserving insertion order. Only its
         # keys are relevant.
         response: dict[str, object] = {}
 
@@ -140,37 +139,37 @@
             f_path = os.path.join(self.server_slice._server_storage["files"], f)
             if not os.path.exists(f_path):
                 response[f] = None
 
         return list(response.keys())
 
     @handle(methods.diff)
-    async def file_diff(self, file_id_1: str, file_id_2: str) -> Apireturn:
+    async def file_diff(self, a: str, b: str) -> Apireturn:
         """
         Diff the two files identified with the two hashes
         """
-        if file_id_1 == "" or file_id_1 == "0":
-            file_1_lines: list[str] = []
+        if a == "" or a == "0":
+            a_lines: List[str] = []
         else:
-            file_1_path = os.path.join(self.server_slice._server_storage["files"], file_id_1)
-            if not os.path.exists(file_1_path):
+            a_path = os.path.join(self.server_slice._server_storage["files"], a)
+            if not os.path.exists(a_path):
                 raise NotFound()
 
-            with open(file_1_path, encoding="utf-8") as fd:
-                file_1_lines = fd.readlines()
+            with open(a_path, "r", encoding="utf-8") as fd:
+                a_lines = fd.readlines()
 
-        if file_id_2 == "" or file_id_2 == "0":
-            file_2_lines: list[str] = []
+        if b == "" or b == "0":
+            b_lines: List[str] = []
         else:
-            file_2_path = os.path.join(self.server_slice._server_storage["files"], file_id_2)
-            if not os.path.exists(file_2_path):
+            b_path = os.path.join(self.server_slice._server_storage["files"], b)
+            if not os.path.exists(b_path):
                 raise NotFound()
 
-            with open(file_2_path, encoding="utf-8") as fd:
-                file_2_lines = fd.readlines()
+            with open(b_path, "r", encoding="utf-8") as fd:
+                b_lines = fd.readlines()
 
         try:
-            diff = difflib.unified_diff(file_1_lines, file_2_lines, fromfile=file_id_1, tofile=file_id_2)
+            diff = difflib.unified_diff(a_lines, b_lines, fromfile=a, tofile=b)
         except FileNotFoundError:
             raise NotFound()
 
         return 200, {"diff": list(diff)}
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/metricservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/metricservice.py`

 * *Files 1% similar despite different names*

```diff
@@ -30,15 +30,15 @@
 LOGGER = logging.getLogger(__name__)
 
 
 class MetricsService(protocol.ServerSlice):
     """Slice managing metrics collector"""
 
     def __init__(self) -> None:
-        super().__init__(SLICE_METRICS)
+        super(MetricsService, self).__init__(SLICE_METRICS)
         self._influx_db_reporter: Optional[InfluxReporter] = None
 
     async def start(self) -> None:
         self.start_auto_benchmark()
         self.start_metric_reporters()
         await super().start()
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/notificationservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/notificationservice.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,16 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import datetime
 import logging
 import uuid
-from collections.abc import Sequence
-from typing import Optional, cast
+from typing import Dict, List, Optional, Sequence, cast
 
 from asyncpg import Connection
 
 from inmanta import const, data
 from inmanta.data import InvalidSort
 from inmanta.data.dataview import NotificationsView
 from inmanta.data.model import Notification
@@ -39,20 +38,20 @@
 
 class NotificationService(protocol.ServerSlice, CompileStateListener):
     """Slice for notification management"""
 
     _compiler_service: CompilerService
 
     def __init__(self) -> None:
-        super().__init__(SLICE_NOTIFICATION)
+        super(NotificationService, self).__init__(SLICE_NOTIFICATION)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_COMPILER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self._compiler_service = cast(CompilerService, server.get_slice(SLICE_COMPILER))
         self._compiler_service.add_listener(self)
 
@@ -139,15 +138,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[uuid.UUID] = None,
         last_id: Optional[uuid.UUID] = None,
         start: Optional[datetime.datetime] = None,
         end: Optional[datetime.datetime] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "created.desc",
     ) -> ReturnValue[Sequence[Notification]]:
         try:
             handler = NotificationsView(
                 environment=env,
                 limit=limit,
                 sort=sort,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/orchestrationservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/orchestrationservice.py`

 * *Files 9% similar despite different names*

```diff
@@ -15,44 +15,36 @@
 
     Contact: code@inmanta.com
 """
 import datetime
 import logging
 import uuid
 from collections import abc, defaultdict
-from typing import Literal, Optional, cast
+from typing import Dict, List, Literal, Optional, Set, cast
 
 import asyncpg
 import asyncpg.connection
 import asyncpg.exceptions
 import pydantic
-from asyncpg import Connection
 
 from inmanta import const, data
 from inmanta.const import ResourceState
-from inmanta.data import (
-    APILIMIT,
-    AVAILABLE_VERSIONS_TO_KEEP,
-    ENVIRONMENT_AGENT_TRIGGER_METHOD,
-    PURGE_ON_DELETE,
-    InvalidSort,
-    RowLockMode,
-)
+from inmanta.data import APILIMIT, AVAILABLE_VERSIONS_TO_KEEP, ENVIRONMENT_AGENT_TRIGGER_METHOD, InvalidSort
 from inmanta.data.dataview import DesiredStateVersionView
 from inmanta.data.model import (
     DesiredStateVersion,
     PromoteTriggerMethod,
     ResourceDiff,
     ResourceIdStr,
     ResourceMinimal,
     ResourceVersionIdStr,
 )
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.common import ReturnValue, attach_warnings
-from inmanta.protocol.exceptions import BadRequest, BaseHttpException, Conflict, NotFound, ServerError
+from inmanta.protocol.exceptions import BadRequest, BaseHttpException, NotFound, ServerError
 from inmanta.resources import Id
 from inmanta.server import (
     SLICE_AGENT_MANAGER,
     SLICE_AUTOSTARTED_AGENT_MANAGER,
     SLICE_DATABASE,
     SLICE_ORCHESTRATION,
     SLICE_RESOURCE,
@@ -60,15 +52,14 @@
 )
 from inmanta.server import config as opt
 from inmanta.server import diff, protocol
 from inmanta.server.agentmanager import AgentManager, AutostartedAgentManager
 from inmanta.server.services.resourceservice import ResourceService
 from inmanta.server.validate_filter import InvalidFilter
 from inmanta.types import Apireturn, JsonType, PrimitiveTypes
-from inmanta.util.db import ConnectionInTransaction
 
 LOGGER = logging.getLogger(__name__)
 
 PERFORM_CLEANUP: bool = True
 # Kill switch for cleanup, for use when working with historical data
 
 
@@ -202,39 +193,39 @@
         ] = await data.Resource.get_resources_in_resource_sets(
             environment=env_id,
             version=base_version,
             resource_sets=updated_resource_sets,
             include_shared_resources=True,
             connection=connection,
         )
-        rids_deleted_resource_sets: abc.Set[ResourceIdStr] = {
+        rids_deleted_resource_sets: abc.Set[ResourceIdStr] = set(
             rid
             for rid in (
                 await data.Resource.get_resources_in_resource_sets(
                     environment=env_id,
                     version=base_version,
                     resource_sets=deleted_resource_sets,
                     connection=connection,
                 )
             ).keys()
-        }
+        )
         return PartialUpdateMerger(
             env_id,
             base_version,
             version,
             rids_in_partial_compile,
             updated_resource_sets,
             deleted_resource_sets,
             updated_and_shared_resources_old,
             rids_deleted_resource_sets,
         )
 
     def merge_updated_and_shared_resources(
         self, updated_and_shared_resources: abc.Sequence[data.Resource]
-    ) -> dict[ResourceIdStr, data.Resource]:
+    ) -> Dict[ResourceIdStr, data.Resource]:
         """
          Separates named resource sets from the shared resource set and expands the shared set with the shared resources in
          the previous model version.
 
         :param updated_and_shared_resources: The resources that are part of the partial compile.
         :returns: The subset of resources in the new version of the configuration model that belong to the shared resource set
                   or a resource set that is updated by this partial compile.
@@ -269,15 +260,15 @@
 
             resource_set_validator = ResourceSetValidator(set(new_updated_and_shared_resources.values()))
             try:
                 resource_set_validator.ensure_no_cross_resource_set_dependencies()
             except CrossResourceSetDependencyError as e:
                 raise BadRequest(e.get_error_message())
 
-    def _merge_shared_resources(self, shared_resources_new: dict[ResourceIdStr, data.Resource]) -> abc.Sequence[data.Resource]:
+    def _merge_shared_resources(self, shared_resources_new: Dict[ResourceIdStr, data.Resource]) -> abc.Sequence[data.Resource]:
         """
         Merge the set of shared resources present in the old version of the model together with the set of shared resources
         present in the partial compile.
 
         :param shared_resources_new: The set of shared resources present in the partial compile.
         :returns: The set of shared resources that should be present in the new version of the model.
         """
@@ -374,20 +365,20 @@
     """Resource Manager service"""
 
     agentmanager_service: "AgentManager"
     autostarted_agent_manager: AutostartedAgentManager
     resource_service: ResourceService
 
     def __init__(self) -> None:
-        super().__init__(SLICE_ORCHESTRATION)
+        super(OrchestrationService, self).__init__(SLICE_ORCHESTRATION)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_RESOURCE, SLICE_AGENT_MANAGER, SLICE_DATABASE]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.agentmanager_service = cast("AgentManager", server.get_slice(SLICE_AGENT_MANAGER))
         self.autostarted_agent_manager = cast(AutostartedAgentManager, server.get_slice(SLICE_AUTOSTARTED_AGENT_MANAGER))
         self.resource_service = cast(ResourceService, server.get_slice(SLICE_RESOURCE))
@@ -404,25 +395,21 @@
         """
         # TODO: move to data and use queries for delete
         envs = await data.Environment.get_list(halted=False)
         for env_item in envs:
             # get available versions
             n_versions = await env_item.get(AVAILABLE_VERSIONS_TO_KEEP)
             assert isinstance(n_versions, int)
-            versions = await data.ConfigurationModel.get_list(environment=env_item.id, order_by_column="version", order="DESC")
+            versions = await data.ConfigurationModel.get_list(environment=env_item.id)
             if len(versions) > n_versions:
+                LOGGER.info("Removing %s available versions from environment %s", len(versions) - n_versions, env_item.id)
                 version_dict = {x.version: x for x in versions}
-                latest_released_version: Optional[int] = next((v.version for v in versions if v.released), None)
-                if latest_released_version is not None:
-                    # Never cleanup the latest released version
-                    del version_dict[latest_released_version]
                 delete_list = sorted(version_dict.keys())
                 delete_list = delete_list[:-n_versions]
-                if delete_list:
-                    LOGGER.info("Removing %s available versions from environment %s", len(delete_list), env_item.id)
+
                 for v in delete_list:
                     await version_dict[v].delete_cascade()
 
         # Cleanup old agents from agent table in db
         await data.Agent.clean_up()
 
     @handle(methods.list_versions, env="tid")
@@ -470,22 +457,22 @@
             limit = APILIMIT
         elif limit > APILIMIT:
             raise BadRequest(
                 f"limit parameter can not exceed {APILIMIT}, got {limit}."
                 f" To retrieve more entries, use /api/v2/resource_actions"
             )
 
-        resources_out: list[JsonType] = []
+        resources_out: List[JsonType] = []
         d = {"model": version, "resources": resources_out}
-        resource_action_lookup: dict[ResourceVersionIdStr, list[data.ResourceAction]] = {}
+        resource_action_lookup: Dict[ResourceVersionIdStr, List[data.ResourceAction]] = {}
 
         for res_dict in resources:
             resources_out.append(res_dict)
             if bool(include_logs):
-                actions: list[data.ResourceAction] = []
+                actions: List[data.ResourceAction] = []
                 res_dict["actions"] = actions
                 resource_action_lookup[res_dict["resource_version_id"]] = actions
 
         if include_logs:
             # get all logs, unsorted
             all_logs = await data.ResourceAction.get_logs_for_version(env.id, version_id, log_filter, limit)
             for log in all_logs:
@@ -494,39 +481,33 @@
 
         d["unknowns"] = await data.UnknownParameter.get_list(environment=env.id, version=version_id)
 
         return 200, d
 
     @handle(methods.delete_version, version_id="id", env="tid")
     async def delete_version(self, env: data.Environment, version_id: int) -> Apireturn:
-        async with data.ConfigurationModel.get_connection() as connection:
-            version = await data.ConfigurationModel.get_version(env.id, version_id, connection=connection)
-
-            if version is None:
-                return 404, {"message": "The given configuration model does not exist yet."}
-
-            active_version = await data.ConfigurationModel.get_latest_version(env.id, connection=connection)
-            if active_version and active_version.version == version.version:
-                raise BadRequest("Cannot delete the active version")
+        version = await data.ConfigurationModel.get_version(env.id, version_id)
+        if version is None:
+            return 404, {"message": "The given configuration model does not exist yet."}
 
-            await version.delete_cascade(connection=connection)
-            return 200
+        await version.delete_cascade()
+        return 200
 
     @handle(methods_v2.reserve_version, env="tid")
     async def reserve_version(self, env: data.Environment) -> int:
         return await env.get_next_version()
 
     def _create_dao_resources_from_api_resources(
         self,
         env_id: uuid.UUID,
-        resources: list[JsonType],
-        resource_state: dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]],
-        resource_sets: dict[ResourceIdStr, Optional[str]],
+        resources: List[JsonType],
+        resource_state: Dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]],
+        resource_sets: Dict[ResourceIdStr, Optional[str]],
         set_version: Optional[int] = None,
-    ) -> dict[ResourceIdStr, data.Resource]:
+    ) -> Dict[ResourceIdStr, data.Resource]:
         """
         This method converts the resources sent to the put_version or put_partial endpoint to dao Resource objects.
         The resulting resource objects will have their provides set up correctly for cross agent dependencies
         and the version field of these resources will be set to set_version if provided.
 
         An exception will be raised when the one of the following constraints is not satisfied:
             * A resource present in the resource_sets parameter is not present in the resources dictionary.
@@ -612,49 +593,48 @@
         Return the resources that are skipped_for_undeployable given the full set of resources and
         the resource ids of the resources that are undeployable.
 
         :param resources: All resources in the model.
         :param undeployable_ids: The ids of the resource that are undeployable.
         """
         # Build up provides tree
-        provides_tree: dict[ResourceIdStr, list[ResourceIdStr]] = defaultdict(list)
+        provides_tree: Dict[ResourceIdStr, List[ResourceIdStr]] = defaultdict(lambda: [])
         for r in resources:
             if "requires" in r.attributes:
                 for req in r.attributes["requires"]:
                     req_id = Id.parse_id(req)
                     provides_tree[req_id.resource_str()].append(r.resource_id)
         # Find skipped for undeployables
         work = list(undeployable_ids)
-        skippeable: set[ResourceIdStr] = set()
+        skippeable: Set[ResourceIdStr] = set()
         while len(work) > 0:
             current = work.pop()
             if current in skippeable:
                 continue
             skippeable.add(current)
             work.extend(provides_tree[current])
         return list(skippeable - set(undeployable_ids))
 
     async def _put_version(
         self,
         env: data.Environment,
         version: int,
-        rid_to_resource: dict[ResourceIdStr, data.Resource],
+        rid_to_resource: Dict[ResourceIdStr, data.Resource],
         unknowns: abc.Sequence[data.UnknownParameter],
         version_info: Optional[JsonType] = None,
-        resource_sets: Optional[dict[ResourceIdStr, Optional[str]]] = None,
+        resource_sets: Optional[Dict[ResourceIdStr, Optional[str]]] = None,
         partial_base_version: Optional[int] = None,
-        removed_resource_sets: Optional[list[str]] = None,
+        removed_resource_sets: Optional[List[str]] = None,
         *,
         connection: asyncpg.connection.Connection,
     ) -> None:
         """
         :param rid_to_resource: This parameter should contain all the resources when a full compile is done.
                                 When a partial compile is done, it should contain all the resources that belong to the
-                                updated resource sets or the shared resource sets. This method updates this object with
-                                purge-on-delete resources.
+                                updated resource sets or the shared resource sets.
         :param unknowns: This parameter should contain all the unknowns for all the resources in the new version of the model.
                          Also the unknowns for resources that are not present in rid_to_resource.
         :param partial_base_version: When a partial compile is done, this parameter contains the version of the
                                      configurationmodel this partial compile was based on. Otherwise this parameter should be
                                      None.
         :param removed_resource_sets: When a partial compile is done, this parameter should indicate the names of the resource
                                       sets that are removed by the partial compile. When no resource sets are removed by
@@ -664,21 +644,14 @@
             * The requires and provides relationships of the resources in rid_to_resource must be set correctly. For a
               partial compile, this means it is assumed to be valid with respect to all absolute constraints that apply to
               partial compiles. Constraints that are relative to the base version will be verified by this method.
             * When a partial compile was done, all resources in rid_to_resource must meet the constraints of a partial compile.
             * The resource sets defined in the removed_resource_sets argument must not overlap with the resource sets present
               in the resource_sets argument.
 
-        This method adds resources to the model that are no longer present in the new version of the model and had the
-        purge_on_delete flag set to true. This method makes sure that the requires and provides relationships of these
-        additional resources are set correctly. This dependency wiring is also safe for a partial compile because
-        a partial compile cannot delete shared resources and because resources that belong to a non-shared resource set cannot
-        reference resources in another non-shared resource set. That way all dependencies of the deleted resources are present
-        in the rid_to_resource parameter.
-
         When a partial compile is done, the undeployable and skipped_for_undeployable resources of a configurationmodel are
         copied from the old version to the new version. This operation is safe because the only resources missing from
         rid_to_resource are resources that belong to an unchanged, non-shared resource set. Those resources can only have
         cross resource set dependencies in a non-shared resource set and the latter resource set cannot be changed by a partial
         compile.
 
         Validations done by this method:
@@ -718,16 +691,14 @@
 
         started = datetime.datetime.now().astimezone()
 
         resource_set_validator = ResourceSetValidator(set(rid_to_resource.values()))
         undeployable_ids: abc.Sequence[ResourceIdStr] = [
             res.resource_id for res in rid_to_resource.values() if res.status in const.UNDEPLOYABLE_STATES
         ]
-        updated_resource_sets: abc.Set[str] = {sr for sr in resource_sets.values() if sr is not None}
-        deleted_resource_sets_as_set: abc.Set[str] = set(removed_resource_sets)
         async with connection.transaction():
             try:
                 if is_partial_update:
                     # Make mypy happy
                     assert partial_base_version is not None
                     cm = await data.ConfigurationModel.create_for_partial_compile(
                         env_id=env.id,
@@ -737,16 +708,15 @@
                         total=len(rid_to_resource),
                         version_info=version_info,
                         undeployable=undeployable_ids,
                         skipped_for_undeployable=sorted(
                             self._get_skipped_for_undeployable(list(rid_to_resource.values()), undeployable_ids)
                         ),
                         partial_base=partial_base_version,
-                        updated_resource_sets=updated_resource_sets,
-                        deleted_resource_sets=deleted_resource_sets_as_set,
+                        rids_in_partial_compile=set(rid_to_resource.keys()),
                         connection=connection,
                     )
                 else:
                     cm = data.ConfigurationModel(
                         environment=env.id,
                         version=version,
                         date=datetime.datetime.now().astimezone(),
@@ -758,27 +728,27 @@
                         ),
                         is_suitable_for_partial_compiles=not resource_set_validator.has_cross_resource_set_dependency(),
                     )
                     await cm.insert(connection=connection)
             except asyncpg.exceptions.UniqueViolationError:
                 raise ServerError("The given version is already defined. Versions should be unique.")
 
-            all_ids: set[Id] = {Id.parse_id(rid, version) for rid in rid_to_resource.keys()}
+            all_ids: set[Id] = set(Id.parse_id(rid, version) for rid in rid_to_resource.keys())
             if is_partial_update:
                 # Make mypy happy
                 assert partial_base_version is not None
                 # This dict maps a resource id to its resource set for unchanged resource sets.
                 rids_unchanged_resource_sets: dict[
                     ResourceIdStr, str
                 ] = await data.Resource.copy_resources_from_unchanged_resource_set(
                     environment=env.id,
                     source_version=partial_base_version,
                     destination_version=version,
-                    updated_resource_sets=updated_resource_sets,
-                    deleted_resource_sets=deleted_resource_sets_as_set,
+                    updated_resource_sets=set(sr for sr in resource_sets.values() if sr is not None),
+                    deleted_resource_sets=set(removed_resource_sets),
                     connection=connection,
                 )
                 resources_that_moved_resource_sets = rids_unchanged_resource_sets.keys() & rid_to_resource.keys()
                 if resources_that_moved_resource_sets:
                     msg = (
                         "The following Resource(s) cannot be migrated to a different resource set using a partial compile, "
                         "a full compile is necessary for this process:\n"
@@ -787,25 +757,14 @@
                         f"    {rid} moved from {rids_unchanged_resource_sets[rid]} to {resource_sets[rid]}"
                         for rid in resources_that_moved_resource_sets
                     )
 
                     raise BadRequest(msg)
                 all_ids |= {Id.parse_id(rid, version) for rid in rids_unchanged_resource_sets.keys()}
 
-            purge_on_delete_resources: dict[ResourceIdStr, data.Resource] = await self._get_resources_for_purge_on_delete(
-                env=env,
-                version=version,
-                rid_to_resource=rid_to_resource,
-                all_resource_ids=[i.resource_str() for i in all_ids],
-                version_info=version_info,
-                connection=connection,
-            )
-            rid_to_resource.update(purge_on_delete_resources)
-            all_ids |= {Id.parse_id(rid, version) for rid in purge_on_delete_resources.keys()}
-
             await data.Resource.insert_many(list(rid_to_resource.values()), connection=connection)
             await cm.recalculate_total(connection=connection)
 
             await data.UnknownParameter.insert_many(unknowns, connection=connection)
 
             all_agents: abc.Set[str] = {res.agent for res in rid_to_resource.values()}
             for agent in all_agents:
@@ -828,116 +787,35 @@
                     finished=now,
                     messages=[log_line],
                 )
                 await ra.insert(connection=connection)
 
         LOGGER.debug("Successfully stored version %d", version)
 
-    async def _get_resources_for_purge_on_delete(
-        self,
-        env: data.Environment,
-        version: int,
-        rid_to_resource: abc.Mapping[ResourceIdStr, data.Resource],
-        all_resource_ids: abc.Sequence[ResourceIdStr],
-        version_info: Optional[JsonType] = None,
-        *,
-        connection: asyncpg.connection.Connection,
-    ) -> dict[ResourceIdStr, data.Resource]:
-        """
-        Return a dictionary of resources that were present in the old version of the model but that no longer exist in this
-        version (in rid_to_resource) and had the purge_on_delete flag set to true. The returned resources will have the purged
-        attribute set to True and their requires/provides relationships inverted.
-
-        :param env: The environment we are discovering purged resources for.
-        :param version: The new version of the configuration model in which the purge_on_delete resources should be added.
-        :param rid_to_resource: When a full compile is done, this dictionary contains an entry for all resources that are
-                                part of the full compile. When a partial compile is done, this dictionary contains an entry
-                                for each resource in the new version of the model that belongs to an updated or shared
-                                resource set.
-        :param all_resource_ids: All the resource ids of all the resources present in the new version of the model. When
-                                 a partial compile is done, this sequence also includes the resource ids of resources that were
-                                 not updated by the partial compile.
-        """
-
-        def safe_get(input: object, key: str, default: object) -> object:
-            if not isinstance(input, dict):
-                return default
-            if key not in input:
-                return default
-            return input[key]
-
-        rid_to_resource = dict(rid_to_resource)
-
-        # detect failed compiles
-        metadata: object = safe_get(version_info, const.EXPORT_META_DATA, {})
-        compile_state = safe_get(metadata, const.META_DATA_COMPILE_STATE, "")
-        failed = compile_state == const.Compilestate.failed
-
-        result = {}
-        if not failed and (await env.get(PURGE_ON_DELETE)):
-            # search for deleted resources (purge_on_delete)
-            resources_to_purge: list[data.Resource] = await data.Resource.get_deleted_resources(
-                env.id, version, all_resource_ids, connection=connection
-            )
-
-            previous_requires = {}
-            for res in resources_to_purge:
-                LOGGER.warning("Purging %s, purged resource based on %s", res.resource_id, res.resource_version_id)
-
-                attributes = res.attributes.copy()
-                attributes["purged"] = True
-                attributes["requires"] = []
-                res_obj = data.Resource.new(
-                    env.id,
-                    resource_version_id=ResourceVersionIdStr(f"{res.resource_id},v={version}"),
-                    attributes=attributes,
-                )
-
-                previous_requires[res_obj.resource_id] = res.attributes["requires"]
-                rid_to_resource[res_obj.resource_id] = res_obj
-                result[res_obj.resource_id] = res_obj
-
-            # invert dependencies on purges
-            for res_id, requires in previous_requires.items():
-                res_obj = rid_to_resource[res_id]
-                for require in requires:
-                    req_id = Id.parse_id(require)
-
-                    if req_id.resource_str() in rid_to_resource:
-                        req_res = rid_to_resource[req_id.resource_str()]
-                        req_res.attributes["requires"].append(res_obj.resource_id)
-                        if res_obj.agent != req_res.agent:
-                            res_obj.provides.append(req_res.resource_id)
-        return result
-
     async def _trigger_auto_deploy(
         self,
         env: data.Environment,
         version: int,
-        *,
-        connection: Optional[Connection],
     ) -> None:
         """
         Triggers auto-deploy for stored resources. Must be called only after transaction that stores resources has been allowed
         to commit. If not respected, the auto deploy might work on stale data, likely resulting in resources hanging in the
         deploying state.
         """
         auto_deploy = await env.get(data.AUTO_DEPLOY)
         if auto_deploy:
             LOGGER.debug("Auto deploying version %d", version)
             push_on_auto_deploy = cast(bool, await env.get(data.PUSH_ON_AUTO_DEPLOY))
             agent_trigger_method_on_autodeploy = cast(str, await env.get(data.AGENT_TRIGGER_METHOD_ON_AUTO_DEPLOY))
             agent_trigger_method_on_autodeploy = const.AgentTriggerMethod[agent_trigger_method_on_autodeploy]
-            await self.release_version(
-                env, version, push_on_auto_deploy, agent_trigger_method_on_autodeploy, connection=connection
-            )
+            await self.release_version(env, version, push_on_auto_deploy, agent_trigger_method_on_autodeploy)
 
     def _create_unknown_parameter_daos_from_api_unknowns(
-        self, env_id: uuid.UUID, version: int, unknowns: Optional[list[dict[str, PrimitiveTypes]]] = None
-    ) -> list[data.UnknownParameter]:
+        self, env_id: uuid.UUID, version: int, unknowns: Optional[List[Dict[str, PrimitiveTypes]]] = None
+    ) -> List[data.UnknownParameter]:
         """
         Create UnknownParameter dao's from the unknowns dictionaries passed through the put_version() and put_partial API
         endpoint.
         """
         if not unknowns:
             return []
         result = []
@@ -953,25 +831,42 @@
                 environment=env_id,
                 version=version,
                 metadata=uk["metadata"],
             )
             result.append(unknown_parameter)
         return result
 
+    async def _put_version_lock(self, env: data.Environment, *, shared: bool = False, connection: asyncpg.Connection) -> None:
+        """
+        Acquires a transaction-level advisory lock for concurrency control between put_version and put_partial.
+
+        :param env: The environment to acquire the lock for.
+        :param shared: If true, doesn't conflict with other shared locks, only with non-shared once.
+        :param connection: The connection hosting the transaction for which to acquire a lock.
+        """
+        lock: str = "pg_advisory_xact_lock_shared" if shared else "pg_advisory_xact_lock"
+        await connection.execute(
+            # Advisory lock keys are only 32 bit (or a single 64 bit key), while a full uuid is 128 bit.
+            # Since locking slightly too strictly at extremely low odds is acceptable, we only use a 32 bit subvalue
+            # of the uuid. For uuid4, time_low is (despite the name) randomly generated. Since it is an unsigned
+            # integer while Postgres expects a signed one, we shift it by 2**31.
+            f"SELECT {lock}({const.PG_ADVISORY_KEY_PUT_VERSION}, {env.id.time_low - 2**31})"
+        )
+
     @handle(methods.put_version, env="tid")
     async def put_version(
         self,
         env: data.Environment,
         version: int,
-        resources: list[JsonType],
-        resource_state: dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]],
-        unknowns: list[dict[str, PrimitiveTypes]],
+        resources: List[JsonType],
+        resource_state: Dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]],
+        unknowns: List[Dict[str, PrimitiveTypes]],
         version_info: JsonType,
         compiler_version: Optional[str] = None,
-        resource_sets: Optional[dict[ResourceIdStr, Optional[str]]] = None,
+        resource_sets: Optional[Dict[ResourceIdStr, Optional[str]]] = None,
     ) -> Apireturn:
         """
         :param unknowns: dict with the following structure
                             {
                              "resource": ResourceIdStr,
                              "parameter": str,
                              "source": str
@@ -986,43 +881,35 @@
         unknowns_objs = self._create_unknown_parameter_daos_from_api_unknowns(env.id, version, unknowns)
         rid_to_resource = self._create_dao_resources_from_api_resources(
             env_id=env.id,
             resources=resources,
             resource_state=resource_state,
             resource_sets=resource_sets,
         )
-
         async with data.Resource.get_connection() as con:
             async with con.transaction():
                 # Acquire a lock that conflicts with the lock acquired by put_partial but not with itself
-                await env.put_version_lock(shared=True, connection=con)
+                await self._put_version_lock(env, shared=True, connection=con)
                 await self._put_version(
                     env, version, rid_to_resource, unknowns_objs, version_info, resource_sets, connection=con
                 )
-            try:
-                await self._trigger_auto_deploy(env, version, connection=con)
-            except Conflict as e:
-                # this should be an api warning, but this is not supported here
-                LOGGER.warning(
-                    "Could not perform auto deploy on version %d in environment %s, because %s", version, env.id, e.log_message
-                )
-
+        await self._trigger_auto_deploy(env, version)
         return 200
 
     @handle(methods_v2.put_partial, env="tid")
     async def put_partial(
         self,
         env: data.Environment,
         resources: object,
-        resource_state: Optional[dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]]] = None,
-        unknowns: Optional[list[dict[str, PrimitiveTypes]]] = None,
+        resource_state: Optional[Dict[ResourceIdStr, Literal[ResourceState.available, ResourceState.undefined]]] = None,
+        unknowns: Optional[List[Dict[str, PrimitiveTypes]]] = None,
         version_info: Optional[JsonType] = None,
-        resource_sets: Optional[dict[ResourceIdStr, Optional[str]]] = None,
-        removed_resource_sets: Optional[list[str]] = None,
-    ) -> ReturnValue[int]:
+        resource_sets: Optional[Dict[ResourceIdStr, Optional[str]]] = None,
+        removed_resource_sets: Optional[List[str]] = None,
+    ) -> int:
         """
         :param unknowns: dict with the following structure
                     {
                      "resource": ResourceIdStr,
                      "parameter": str,
                      "source": str
                     }
@@ -1033,23 +920,23 @@
             unknowns = []
         if resource_sets is None:
             resource_sets = {}
         if removed_resource_sets is None:
             removed_resource_sets = []
 
         try:
-            pydantic.parse_obj_as(list[ResourceMinimal], resources)
+            pydantic.parse_obj_as(List[ResourceMinimal], resources)
         except pydantic.ValidationError:
             raise BadRequest(
                 "Type validation failed for resources argument. "
                 f"Expected an argument of type List[Dict[str, Any]] but received {resources}"
             )
         else:
             # Make mypy happy
-            resources = cast(list[JsonType], resources)
+            resources = cast(List[JsonType], resources)
 
         # validate resources before any side effects take place
         for r in resources:
             rid = Id.parse_id(r["id"])
             if rid.get_version() != 0:
                 raise BadRequest("Resources for partial export should not contain version information")
 
@@ -1059,15 +946,15 @@
                 "Following resource sets are present in the removed resource sets and in the resources that are exported: "
                 f"{intersection}"
             )
 
         async with data.Resource.get_connection() as con:
             async with con.transaction():
                 # Acquire a lock that conflicts with itself and with the lock acquired by put_version
-                await env.put_version_lock(shared=False, connection=con)
+                await self._put_version_lock(env, shared=False, connection=con)
 
                 # Only request a new version once the resource lock has been acquired to ensure a monotonic version history
                 version: int = await env.get_next_version(connection=con)
 
                 current_versions: abc.Sequence[data.ConfigurationModel] = await data.ConfigurationModel.get_versions(
                     env.id, limit=1
                 )
@@ -1089,23 +976,23 @@
                         # This should never happen
                         LOGGER.warning(
                             "Base version %d was marked as not suitable for partial compiles, but no cross resource set"
                             " dependencies were found.",
                             base_version,
                         )
 
-                rid_to_resource: dict[ResourceIdStr, data.Resource] = self._create_dao_resources_from_api_resources(
+                rid_to_resource: Dict[ResourceIdStr, data.Resource] = self._create_dao_resources_from_api_resources(
                     env_id=env.id,
                     resources=resources,
                     resource_state=resource_state,
                     resource_sets=resource_sets,
                     set_version=version,
                 )
 
-                updated_resource_sets: abc.Set[str] = {sr_name for sr_name in resource_sets.values() if sr_name is not None}
+                updated_resource_sets: abc.Set[str] = set(sr_name for sr_name in resource_sets.values() if sr_name is not None)
                 partial_update_merger = await PartialUpdateMerger.create(
                     env_id=env.id,
                     base_version=base_version,
                     version=version,
                     rids_in_partial_compile=set(rid_to_resource.keys()),
                     updated_resource_sets=updated_resource_sets,
                     deleted_resource_sets=set(removed_resource_sets),
@@ -1128,165 +1015,112 @@
                     merged_unknowns,
                     version_info,
                     resource_sets,
                     partial_base_version=base_version,
                     removed_resource_sets=removed_resource_sets,
                     connection=con,
                 )
-
-            returnvalue: ReturnValue[int] = ReturnValue[int](200, response=version)
-            try:
-                await self._trigger_auto_deploy(env, version, connection=con)
-            except Conflict as e:
-                # It is unclear if this condition can ever happen
-                LOGGER.warning(
-                    "Could not perform auto deploy on version %d in environment %s, because %s", version, env.id, e.log_message
-                )
-                returnvalue.add_warnings([f"Could not perform auto deploy: {e.log_message} {e.details}"])
-
-        return returnvalue
+        await self._trigger_auto_deploy(env, version)
+        return version
 
     @handle(methods.release_version, version_id="id", env="tid")
     async def release_version(
         self,
         env: data.Environment,
         version_id: int,
         push: bool,
         agent_trigger_method: Optional[const.AgentTriggerMethod] = None,
         *,
         connection: Optional[asyncpg.connection.Connection] = None,
     ) -> Apireturn:
-        async with data.ConfigurationModel.get_connection(connection) as connection:
-            async with connection.transaction():
-                with ConnectionInTransaction(connection) as connection_holder:
-                    # explicit lock to allow patching of increments for stale failures
-                    # (locks out patching stage of deploy_done to avoid races)
-                    await env.acquire_release_version_lock(connection=connection)
-                    model = await data.ConfigurationModel.get_version_internal(
-                        env.id, version_id, connection=connection, lock=RowLockMode.FOR_NO_KEY_UPDATE
-                    )
-                    if model is None:
-                        return 404, {"message": "The request version does not exist."}
-
-                    if model.released:
-                        raise Conflict(f"The version {version_id} on environment {env.id} is already released.")
+        model = await data.ConfigurationModel.get_version(env.id, version_id, connection=connection)
+        if model is None:
+            return 404, {"message": "The request version does not exist."}
+
+        # Already mark undeployable resources as deployed to create a better UX (change the version counters)
+        undep = await model.get_undeployable()
+        now = datetime.datetime.now().astimezone()
+
+        if undep:
+            undep_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in undep]
+            # not checking error conditions
+            await self.resource_service.resource_action_update(
+                env,
+                undep_ids,
+                action_id=uuid.uuid4(),
+                started=now,
+                finished=now,
+                status=const.ResourceState.undefined,
+                action=const.ResourceAction.deploy,
+                changes={},
+                messages=[],
+                change=const.Change.nochange,
+                send_events=False,
+                connection=connection,
+            )
 
-                    latest_version = await data.ConfigurationModel.get_version_nr_latest_version(env.id, connection=connection)
+            skippable = await model.get_skipped_for_undeployable()
+            if skippable:
+                skippable_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in skippable]
+                # not checking error conditions
+                await self.resource_service.resource_action_update(
+                    env,
+                    skippable_ids,
+                    action_id=uuid.uuid4(),
+                    started=now,
+                    finished=now,
+                    status=const.ResourceState.skipped_for_undefined,
+                    action=const.ResourceAction.deploy,
+                    changes={},
+                    messages=[],
+                    change=const.Change.nochange,
+                    send_events=False,
+                    connection=connection,
+                )
 
-                    # ensure we are the latest version
-                    # this is required for the subsequent increment calculation to make sense
-                    # this does introduce a race condition, with any OTHER release running concurrently on this environment
-                    # We could lock the get_version_nr_latest_version for update to prevent this
-                    if model.version < (latest_version or -1):
-                        raise Conflict(
-                            f"The version {version_id} on environment {env.id} "
-                            f"is older then the latest released version {latest_version}."
-                        )
+        increments: tuple[abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]] = await self.resource_service.get_increment(
+            env, version_id
+        )
 
-                    # Already mark undeployable resources as deployed to create a better UX (change the version counters)
-                    undep = model.get_undeployable()
-                    now = datetime.datetime.now().astimezone()
-
-                    if undep:
-                        undep_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in undep]
-                        # not checking error conditions
-                        await self.resource_service.resource_action_update(
-                            env,
-                            undep_ids,
-                            action_id=uuid.uuid4(),
-                            started=now,
-                            finished=now,
-                            status=const.ResourceState.undefined,
-                            action=const.ResourceAction.deploy,
-                            changes={},
-                            messages=[],
-                            change=const.Change.nochange,
-                            send_events=False,
-                            connection=connection_holder,
-                        )
+        increment_ids, neg_increment = increments
+        await self.resource_service.mark_deployed(env, neg_increment, now, version_id)
 
-                        skippable = model.get_skipped_for_undeployable()
-                        if skippable:
-                            skippable_ids = [ResourceVersionIdStr(rid + ",v=%s" % version_id) for rid in skippable]
-                            # not checking error conditions
-                            await self.resource_service.resource_action_update(
-                                env,
-                                skippable_ids,
-                                action_id=uuid.uuid4(),
-                                started=now,
-                                finished=now,
-                                status=const.ResourceState.skipped_for_undefined,
-                                action=const.ResourceAction.deploy,
-                                changes={},
-                                messages=[],
-                                change=const.Change.nochange,
-                                send_events=False,
-                                connection=connection_holder,
-                            )
-
-                    if latest_version:
-                        # Set the updated field:
-                        # BE VERY CAREFUL
-                        # All state copied here has a race with stale deploy
-                        # This is handled in propagate_resource_state_if_stale
-                        await data.Resource.copy_last_success(env.id, latest_version, version_id, connection=connection)
-                        await data.Resource.copy_last_produced_events(env.id, latest_version, version_id, connection=connection)
-
-                        increments: tuple[
-                            abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]
-                        ] = await self.resource_service.get_increment(
-                            env,
-                            version_id,
-                            connection=connection,
-                        )
+        # Setting the model's released field to True is the trigger for the agents to start pulling in the resources.
+        # This has to be done after the resources outside of the increment have been marked as deployed.
+        await model.update_fields(released=True, result=const.VersionState.deploying, connection=connection)
 
-                        increment_ids, neg_increment = increments
-                        await self.resource_service.mark_deployed(
-                            env, neg_increment, now, version_id, connection=connection_holder
-                        )
+        if model.total == 0:
+            await model.mark_done(connection=connection)
+            return 200, {"model": model}
 
-                    # Setting the model's released field to True is the trigger for the agents
-                    # to start pulling in the resources.
-                    # This has to be done after the resources outside of the increment have been marked as deployed.
-                    await model.update_fields(released=True, result=const.VersionState.deploying, connection=connection)
-
-            if model.total == 0:
-                await model.mark_done(connection=connection)
-                return 200, {"model": model}
-
-            if push:
-                # We can't be in a transaction here, or the agent will not see the data that as committed
-                # This assert prevents anyone from wrapping this method in a transaction by accident
-                assert not connection.is_in_transaction()
-                # fetch all resource in this cm and create a list of distinct agents
-                agents = await data.ConfigurationModel.get_agents(env.id, version_id, connection=connection)
-                await self.autostarted_agent_manager._ensure_agents(env, agents, connection=connection)
-
-                for agent in agents:
-                    client = self.agentmanager_service.get_agent_client(env.id, agent)
-                    if client is not None:
-                        if not agent_trigger_method:
-                            env_agent_trigger_method = await env.get(ENVIRONMENT_AGENT_TRIGGER_METHOD, connection=connection)
-                            incremental_deploy = env_agent_trigger_method == const.AgentTriggerMethod.push_incremental_deploy
-                        else:
-                            incremental_deploy = agent_trigger_method is const.AgentTriggerMethod.push_incremental_deploy
-                        self.add_background_task(client.trigger(env.id, agent, incremental_deploy))
+        if push:
+            # fetch all resource in this cm and create a list of distinct agents
+            agents = await data.ConfigurationModel.get_agents(env.id, version_id, connection=connection)
+            await self.autostarted_agent_manager._ensure_agents(env, agents, connection=connection)
+
+            for agent in agents:
+                client = self.agentmanager_service.get_agent_client(env.id, agent)
+                if client is not None:
+                    if not agent_trigger_method:
+                        env_agent_trigger_method = await env.get(ENVIRONMENT_AGENT_TRIGGER_METHOD, connection=connection)
+                        incremental_deploy = env_agent_trigger_method == const.AgentTriggerMethod.push_incremental_deploy
                     else:
-                        LOGGER.warning(
-                            "Agent %s from model %s in env %s is not available for a deploy", agent, version_id, env.id
-                        )
+                        incremental_deploy = agent_trigger_method is const.AgentTriggerMethod.push_incremental_deploy
+                    self.add_background_task(client.trigger(env.id, agent, incremental_deploy))
+                else:
+                    LOGGER.warning("Agent %s from model %s in env %s is not available for a deploy", agent, version_id, env.id)
 
-            return 200, {"model": model}
+        return 200, {"model": model}
 
     @handle(methods.deploy, env="tid")
     async def deploy(
         self,
         env: data.Environment,
         agent_trigger_method: const.AgentTriggerMethod = const.AgentTriggerMethod.push_full_deploy,
-        agents: Optional[list[str]] = None,
+        agents: Optional[List[str]] = None,
     ) -> Apireturn:
         warnings = []
 
         # get latest version
         version_id = await data.ConfigurationModel.get_version_nr_latest_version(env.id)
         if version_id is None:
             return 404, {"message": "No version available"}
@@ -1331,17 +1165,17 @@
     @handle(methods_v2.list_desired_state_versions, env="tid")
     async def desired_state_version_list(
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         start: Optional[int] = None,
         end: Optional[int] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "version.desc",
-    ) -> ReturnValue[list[DesiredStateVersion]]:
+    ) -> ReturnValue[List[DesiredStateVersion]]:
         try:
             return await DesiredStateVersionView(
                 environment=env,
                 limit=limit,
                 filter=filter,
                 sort=sort,
                 start=start,
@@ -1378,28 +1212,28 @@
 
     @handle(methods_v2.get_diff_of_versions, env="tid")
     async def get_diff_of_versions(
         self,
         env: data.Environment,
         from_version: int,
         to_version: int,
-    ) -> list[ResourceDiff]:
+    ) -> List[ResourceDiff]:
         await self._validate_version_parameters(env.id, from_version, to_version)
 
         from_version_resources = await data.Resource.get_list(environment=env.id, model=from_version)
         to_version_resources = await data.Resource.get_list(environment=env.id, model=to_version)
 
         from_state = diff.Version(self.convert_resources(from_version_resources))
         to_state = diff.Version(self.convert_resources(to_version_resources))
 
         version_diff = to_state.generate_diff(from_state)
 
         return version_diff
 
-    def convert_resources(self, resources: list[data.Resource]) -> dict[ResourceIdStr, diff.Resource]:
+    def convert_resources(self, resources: List[data.Resource]) -> Dict[ResourceIdStr, diff.Resource]:
         return {res.resource_id: diff.Resource(resource_id=res.resource_id, attributes=res.attributes) for res in resources}
 
     async def _validate_version_parameters(self, env: uuid.UUID, first_version: int, other_version: int) -> None:
         if first_version >= other_version:
             raise BadRequest(
                 f"Invalid version parameters: ({first_version}, {other_version}). "
                 "The second version number should be strictly greater than the first"
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/paramservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/paramservice.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,18 +14,17 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import datetime
 import logging
 import uuid
-from collections.abc import Sequence
-from typing import Any, Optional, Union, cast
+from typing import Any, Dict, List, Optional, Sequence, Tuple, Union, cast
 
-from inmanta import data
+from inmanta import data, util
 from inmanta.const import ParameterSource
 from inmanta.data import InvalidSort
 from inmanta.data.dataview import FactsView, ParameterView
 from inmanta.data.model import Fact, Parameter, ResourceIdStr
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.common import ReturnValue, attach_warnings
 from inmanta.protocol.exceptions import BadRequest, NotFound
@@ -43,23 +42,23 @@
 class ParameterService(protocol.ServerSlice):
     """Slice for parameter management"""
 
     server_slice: Server
     agentmanager: AgentManager
 
     def __init__(self) -> None:
-        super().__init__(SLICE_PARAM)
+        super(ParameterService, self).__init__(SLICE_PARAM)
 
         self._fact_expire = opt.server_fact_expire.get()
         self._fact_renew = opt.server_fact_renew.get()
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_SERVER, SLICE_DATABASE, SLICE_AGENT_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.server_slice = cast(Server, server.get_slice(SLICE_SERVER))
         self.agentmanager = cast(AgentManager, server.get_slice(SLICE_AGENT_MANAGER))
 
@@ -221,18 +220,18 @@
             resource_id = ""
 
         params = await data.Parameter.get_list(environment=env.id, name=param_id, resource_id=resource_id)
 
         return attach_warnings(200, {"parameter": params[0]}, warnings)
 
     @handle(methods.set_parameters, env="tid")
-    async def set_parameters(self, env: data.Environment, parameters: list[dict[str, Any]]) -> Apireturn:
+    async def set_parameters(self, env: data.Environment, parameters: List[Dict[str, Any]]) -> Apireturn:
         recompile = False
 
-        params: list[tuple[str, ResourceIdStr]] = []
+        params: List[Tuple[str, ResourceIdStr]] = []
         for param in parameters:
             name: str = param["id"]
             source = param["source"]
             value = param["value"] if "value" in param else None
             resource_id: ResourceIdStr = param["resource_id"] if "resource_id" in param else None
             metadata = param["metadata"] if "metadata" in param else None
 
@@ -271,28 +270,28 @@
             "params": [(param.name, param.resource_id)],
         }
         warnings = await self.server_slice._async_recompile(env, False, metadata=metadata)
 
         return attach_warnings(200, None, warnings)
 
     @handle(methods.list_params, env="tid")
-    async def list_params(self, env: data.Environment, query: dict[str, str]) -> Apireturn:
+    async def list_params(self, env: data.Environment, query: Dict[str, str]) -> Apireturn:
         params = await data.Parameter.list_parameters(env.id, **query)
         return (
             200,
             {
                 "parameters": params,
                 "expire": self._fact_expire,
-                # Serialization happens in the RESTHandler's json encoder
-                "now": datetime.datetime.now().astimezone(),
+                # Return datetime in UTC without explicit timezone offset
+                "now": util.datetime_utc_isoformat(datetime.datetime.now()),
             },
         )
 
     @handle(methods_v2.get_facts, env="tid")
-    async def get_facts(self, env: data.Environment, rid: ResourceIdStr) -> list[Fact]:
+    async def get_facts(self, env: data.Environment, rid: ResourceIdStr) -> List[Fact]:
         params = await data.Parameter.get_list(environment=env.id, resource_id=rid, order_by_column="name")
         dtos = [param.as_fact() for param in params]
         return dtos
 
     @handle(methods_v2.get_fact, env="tid")
     async def get_fact(self, env: data.Environment, rid: ResourceIdStr, id: uuid.UUID) -> Fact:
         param = await data.Parameter.get_one(environment=env.id, resource_id=rid, id=id)
@@ -305,15 +304,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[uuid.UUID] = None,
         last_id: Optional[uuid.UUID] = None,
         start: Optional[Union[datetime.datetime, str]] = None,
         end: Optional[Union[datetime.datetime, str]] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "name.asc",
     ) -> ReturnValue[Sequence[Parameter]]:
         try:
             handler = ParameterView(
                 environment=env,
                 limit=limit,
                 sort=sort,
@@ -333,15 +332,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[uuid.UUID] = None,
         last_id: Optional[uuid.UUID] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "name.asc",
     ) -> ReturnValue[Sequence[Fact]]:
         try:
             handler = FactsView(
                 environment=env,
                 limit=limit,
                 sort=sort,
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/projectservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/projectservice.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import asyncio
 import logging
 import uuid
-from typing import Optional, cast
+from typing import List, Optional, cast
 
 import asyncpg
 
 from inmanta import data
 from inmanta.data import model
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.exceptions import NotFound, ServerError
@@ -44,20 +44,20 @@
 class ProjectService(protocol.ServerSlice):
     """Slice with project and environment management"""
 
     autostarted_agent_manager: AutostartedAgentManager
     resource_service: ResourceService
 
     def __init__(self) -> None:
-        super().__init__(SLICE_PROJECT)
+        super(ProjectService, self).__init__(SLICE_PROJECT)
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_RESOURCE, SLICE_AUTOSTARTED_AGENT_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.autostarted_agent_manager = cast(AutostartedAgentManager, server.get_slice(SLICE_AUTOSTARTED_AGENT_MANAGER))
         self.resource_service = cast(ResourceService, server.get_slice(SLICE_RESOURCE))
 
@@ -73,15 +73,15 @@
 
     @handle(methods.modify_project, project_id="id")
     async def modify_project(self, project_id: uuid.UUID, name: str) -> Apireturn:
         return 200, {"project": (await self.project_modify(project_id, name)).dict()}
 
     @handle(methods.list_projects)
     async def list_projects(self) -> Apireturn:
-        project_list: list[JsonType] = [x.dict() for x in await self.project_list()]
+        project_list: List[JsonType] = [x.dict() for x in await self.project_list()]
         for project in project_list:
             project["environments"] = [x["id"] for x in project["environments"]]
         return 200, {"projects": project_list}
 
     @handle(methods.get_project, project_id="id")
     async def get_project(self, project_id: uuid.UUID) -> Apireturn:
         project_model = (await self.project_get(project_id)).dict()
@@ -126,15 +126,15 @@
 
             return project.to_dto()
 
         except asyncpg.exceptions.UniqueViolationError:
             raise ServerError(f"A project with name {name} already exists.")
 
     @handle(methods_v2.project_list)
-    async def project_list(self, environment_details: bool = False) -> list[model.Project]:
+    async def project_list(self, environment_details: bool = False) -> List[model.Project]:
         project_list = []
 
         for project in await data.Project.get_list(order_by_column="name", order="ASC"):
             project_model = project.to_dto()
             project_model.environments = [
                 e.to_dto()
                 for e in await data.Environment.get_list(
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/resourceservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/resourceservice.py`

 * *Files 14% similar despite different names*

```diff
@@ -17,27 +17,34 @@
 """
 import asyncio
 import datetime
 import logging
 import os
 import uuid
 from collections import abc, defaultdict
-from collections.abc import Callable, Sequence
-from typing import Any, Optional, Union, cast
+from typing import Any, Callable, Dict, List, Optional, Sequence, Union, cast
 
 from asyncpg.connection import Connection
 from asyncpg.exceptions import UniqueViolationError
+from pydantic import ValidationError
 from tornado.httputil import url_concat
 
 from inmanta import const, data, util
 from inmanta.const import STATE_UPDATE, TERMINAL_STATES, TRANSIENT_STATES, VALID_STATES_ON_STATE_UPDATE, Change, ResourceState
 from inmanta.data import APILIMIT, InvalidSort
-from inmanta.data.dataview import ResourceHistoryView, ResourceLogsView, ResourcesInVersionView, ResourceView
+from inmanta.data.dataview import (
+    DiscoveredResourceView,
+    ResourceHistoryView,
+    ResourceLogsView,
+    ResourcesInVersionView,
+    ResourceView,
+)
 from inmanta.data.model import (
     AttributeStateChange,
+    DiscoveredResource,
     LatestReleasedResource,
     LogLine,
     ReleasedResourceDetails,
     Resource,
     ResourceAction,
     ResourceHistory,
     ResourceIdStr,
@@ -45,25 +52,23 @@
     ResourceType,
     ResourceVersionIdStr,
     VersionedResource,
     VersionedResourceDetails,
 )
 from inmanta.protocol import handle, methods, methods_v2
 from inmanta.protocol.common import ReturnValue
-from inmanta.protocol.exceptions import BadRequest, Conflict, NotFound, ServerError
+from inmanta.protocol.exceptions import BadRequest, Conflict, NotFound
 from inmanta.protocol.return_value_meta import ReturnValueWithMeta
 from inmanta.resources import Id
 from inmanta.server import SLICE_AGENT_MANAGER, SLICE_DATABASE, SLICE_RESOURCE, SLICE_TRANSPORT
 from inmanta.server import config as opt
 from inmanta.server import protocol
 from inmanta.server.agentmanager import AgentManager
 from inmanta.server.validate_filter import InvalidFilter
-from inmanta.types import Apireturn, PrimitiveTypes
-from inmanta.util import parse_timestamp
-from inmanta.util.db import ConnectionMaybeInTransaction, ConnectionNotInTransaction
+from inmanta.types import Apireturn, JsonType, PrimitiveTypes
 
 LOGGER = logging.getLogger(__name__)
 
 
 def error_and_log(message: str, **context: Any) -> None:
     """
     :param message: message to return both to logger and to remote caller
@@ -97,28 +102,28 @@
 
 class ResourceService(protocol.ServerSlice):
     """Resource Manager service"""
 
     agentmanager_service: "AgentManager"
 
     def __init__(self) -> None:
-        super().__init__(SLICE_RESOURCE)
+        super(ResourceService, self).__init__(SLICE_RESOURCE)
 
-        self._resource_action_loggers: dict[uuid.UUID, logging.Logger] = {}
-        self._resource_action_handlers: dict[uuid.UUID, logging.Handler] = {}
+        self._resource_action_loggers: Dict[uuid.UUID, logging.Logger] = {}
+        self._resource_action_handlers: Dict[uuid.UUID, logging.Handler] = {}
 
         # Dict: environment_id: (model_version, increment, negative_increment)
-        self._increment_cache: dict[uuid.UUID, Optional[tuple[int, abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]]] = {}
+        self._increment_cache: Dict[uuid.UUID, Optional[tuple[int, abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]]] = {}
         # lock to ensure only one inflight request
-        self._increment_cache_locks: dict[uuid.UUID, asyncio.Lock] = defaultdict(lambda: asyncio.Lock())
+        self._increment_cache_locks: Dict[uuid.UUID, asyncio.Lock] = defaultdict(lambda: asyncio.Lock())
 
-    def get_dependencies(self) -> list[str]:
+    def get_dependencies(self) -> List[str]:
         return [SLICE_DATABASE, SLICE_AGENT_MANAGER]
 
-    def get_depended_by(self) -> list[str]:
+    def get_depended_by(self) -> List[str]:
         return [SLICE_TRANSPORT]
 
     async def prestart(self, server: protocol.Server) -> None:
         await super().prestart(server)
         self.agentmanager_service = cast("AgentManager", server.get_slice(SLICE_AGENT_MANAGER))
 
     async def start(self) -> None:
@@ -211,62 +216,57 @@
         self,
         env: data.Environment,
         resource_id: ResourceVersionIdStr,
         logs: bool,
         status: bool,
         log_action: const.ResourceAction,
         log_limit: int,
-        connection: Optional[Connection] = None,
     ) -> Apireturn:
         # Validate resource version id
         try:
             Id.parse_resource_version_id(resource_id)
         except ValueError:
             return 400, {"message": f"{resource_id} is not a valid resource version id"}
 
-        async with data.ResourceAction.get_connection(connection) as con:
-            resv = await data.Resource.get(env.id, resource_id, con)
-            if resv is None:
-                return 404, {"message": "The resource with the given id does not exist in the given environment"}
-
-            if status is not None and status:
-                return 200, {"status": resv.status}
-
-            actions: list[data.ResourceAction] = []
-            if bool(logs):
-                action_name = None
-                if log_action is not None:
-                    action_name = log_action.name
+        resv = await data.Resource.get(env.id, resource_id)
+        if resv is None:
+            return 404, {"message": "The resource with the given id does not exist in the given environment"}
+
+        if status is not None and status:
+            return 200, {"status": resv.status}
+
+        actions: List[data.ResourceAction] = []
+        if bool(logs):
+            action_name = None
+            if log_action is not None:
+                action_name = log_action.name
 
-                actions = await data.ResourceAction.get_log(
-                    environment=env.id, resource_version_id=resource_id, action=action_name, limit=log_limit, connection=con
-                )
+            actions = await data.ResourceAction.get_log(
+                environment=env.id, resource_version_id=resource_id, action=action_name, limit=log_limit
+            )
 
-            return 200, {"resource": resv, "logs": actions}
+        return 200, {"resource": resv, "logs": actions}
 
     # This endpoint doesn't have a method associated yet.
     # Intended for use by other slices
     async def get_resources_in_latest_version(
         self,
         environment: data.Environment,
         resource_type: Optional[ResourceType] = None,
-        attributes: dict[PrimitiveTypes, PrimitiveTypes] = {},
-        connection: Optional[Connection] = None,
-    ) -> list[Resource]:
-        result = await data.Resource.get_resources_in_latest_version(
-            environment.id, resource_type, attributes, connection=connection
-        )
+        attributes: Dict[PrimitiveTypes, PrimitiveTypes] = {},
+    ) -> List[Resource]:
+        result = await data.Resource.get_resources_in_latest_version(environment.id, resource_type, attributes)
         return [r.to_dto() for r in result]
 
     @handle(methods.get_resources_for_agent, env="tid")
     async def get_resources_for_agent(
         self, env: data.Environment, agent: str, version: int, sid: uuid.UUID, incremental_deploy: bool
     ) -> Apireturn:
         if not self.agentmanager_service.is_primary(env, sid, agent):
-            return 409, {"message": f"This agent is not currently the primary for the endpoint {agent} (sid: {sid})"}
+            return 409, {"message": "This agent is not currently the primary for the endpoint %s (sid: %s)" % (agent, sid)}
         if incremental_deploy:
             if version is not None:
                 return 500, {"message": "Cannot request increment for a specific version"}
             result = await self.get_resource_increment_for_agent(env, agent)
         else:
             result = await self.get_all_resources_for_agent(env, agent, version)
         return result
@@ -326,36 +326,21 @@
 
         now = datetime.datetime.now().astimezone()
 
         def on_agent(res: ResourceIdStr) -> bool:
             idr = Id.parse_id(res)
             return idr.get_agent_name() == agent
 
-        # This is a bit subtle.
-        # Any resource we consider deployed has to be marked as such.
-        # Otherwise the agent will fail the deployment.
-        # Stale successful deployments can cause resource that were available to be now considered deployed.
-        # We don't do this back propagation on deploy,
-        #   because it is about a lot of resource that need to grab a lock to check if they are stale
-        # We do it here, as we always have.
-        # This method only updates the state for resources that are currently in the available or deploying state.
-        # As such, it should not race with backpropagation on failure.
-        await self.mark_deployed(
-            env,
-            neg_increment,
-            now,
-            version,
-            filter=on_agent,
-            only_update_from_states={const.ResourceState.available, const.ResourceState.deploying},
-        )
+        # set already done to deployed
+        await self.mark_deployed(env, neg_increment, now, version, filter=on_agent)
 
         resources = await data.Resource.get_resources_for_version(env.id, version, agent)
 
-        deploy_model: list[dict[str, Any]] = []
-        resource_ids: list[str] = []
+        deploy_model: List[Dict[str, Any]] = []
+        resource_ids: List[str] = []
 
         for rv in resources:
             if rv.resource_id not in increment_ids:
                 continue
 
             # TODO double parsing of ID
             def in_requires(req: ResourceIdStr) -> bool:
@@ -390,171 +375,56 @@
     async def mark_deployed(
         self,
         env: data.Environment,
         resources_id: abc.Set[ResourceIdStr],
         timestamp: datetime.datetime,
         version: int,
         filter: Callable[[ResourceIdStr], bool] = lambda x: True,
-        connection: ConnectionMaybeInTransaction = ConnectionNotInTransaction(),
-        only_update_from_states: Optional[set[const.ResourceState]] = None,
     ) -> None:
         """
         Set the status of the provided resources as deployed
         :param env: Environment to consider.
         :param resources_id: Set of resources to mark as deployed.
         :param timestamp: Timestamp for the log message and the resource action entry.
         :param version: Version of the resources to consider.
         :param filter: Filter function that takes a resource id as an argument and returns True if it should be kept.
         """
         resources_version_ids: list[ResourceVersionIdStr] = [
             ResourceVersionIdStr(f"{res_id},v={version}") for res_id in resources_id if filter(res_id)
         ]
-        if not resources_version_ids:
-            return
         logline = {
             "level": "INFO",
             "msg": "Setting deployed due to known good status",
-            "timestamp": util.datetime_iso_format(timestamp),
+            "timestamp": util.datetime_utc_isoformat(timestamp),
             "args": [],
         }
-
         await self.resource_action_update(
             env,
             resources_version_ids,
             action_id=uuid.uuid4(),
             started=timestamp,
             finished=timestamp,
             status=const.ResourceState.deployed,
             # does this require a different ResourceAction?
             action=const.ResourceAction.deploy,
             changes={},
             messages=[logline],
             change=const.Change.nochange,
             send_events=False,
             keep_increment_cache=True,
-            is_increment_notification=True,
-            only_update_from_states=only_update_from_states,
-            connection=connection,
         )
 
-    async def _update_deploy_state(
-        self,
-        env: data.Environment,
-        resource_id: ResourceIdStr,
-        timestamp: datetime.datetime,
-        version: int,
-        status: ResourceState,
-        message: str,
-        fail_on_error: bool,
-        connection: Optional[Connection] = None,
-        can_overwrite_available: bool = True,
-    ) -> None:
-        """
-        Set the status of the provided resources as to skipped or failed
-
-        Performs all required bookkeeping for this.
-
-        Factored out the code to set a status on a resource
-
-
-        :param env: Environment to consider.
-        :param resource_id: resource to mark.
-        :param timestamp: Timestamp for the log message and the resource action entry.
-        :param version: Version of the resources to consider.
-        :param status: status to set
-        :param message: reason to log on the transfer
-        :param fail_on_error: When encountering an undeployable state: fail or do nothing?.
-        :param can_overwrite_available: can we overwrite available.
-            If set to false, we return without changes if the current state is available
-        """
-        resource_version_id = resource_id + ",v=" + str(version)
-        logline = LogLine(
-            level=const.LogLevel.INFO,
-            msg=f"Setting {status.value} because of {message}",
-            timestamp=timestamp,
-        )
-
-        assert status in [ResourceState.failed, ResourceState.skipped]
-        # this method is purpose specific for now.
-
-        async with data.Resource.get_connection(connection) as connection:
-            async with connection.transaction():
-                # validate resources
-                resource = await data.Resource.get_one(
-                    environment=env.id,
-                    resource_id=resource_id,
-                    model=version,
-                    # acquire lock on Resource before read and before lock on ResourceAction to prevent conflicts with
-                    # cascading deletes
-                    lock=data.RowLockMode.FOR_NO_KEY_UPDATE,
-                    connection=connection,
-                )
-                if not resource:
-                    raise NotFound("The resource with the given ids do not exist in the given environment.")
-
-                # no escape from terminal
-                if resource.status != status and resource.status in TERMINAL_STATES:
-                    if not fail_on_error:
-                        return
-                    else:
-                        LOGGER.error("Attempting to set undeployable resource to deployable state")
-                        raise AssertionError("Attempting to set undeployable resource to deployable state")
-
-                if resource.status == ResourceState.available and not can_overwrite_available:
-                    return
-
-                resource_action = data.ResourceAction(
-                    environment=env.id,
-                    version=version,
-                    resource_version_ids=[resource_version_id],
-                    action_id=uuid.uuid4(),
-                    action=const.ResourceAction.deploy,
-                    started=timestamp,
-                    messages=[
-                        {
-                            **logline.dict(),
-                            "timestamp": logline.timestamp.astimezone().isoformat(timespec="microseconds"),
-                        }
-                    ],
-                    changes={},
-                    status=status,
-                    change=const.Change.nochange,
-                    finished=timestamp,
-                )
-                await resource_action.insert(connection=connection)
-
-                self.log_resource_action(
-                    env.id,
-                    [resource_version_id],
-                    logline.level.to_int,
-                    logline.timestamp,
-                    logline.msg,
-                )
-
-                self.clear_env_cache(env)
-
-                await resource.update_fields(
-                    last_deploy=timestamp,
-                    status=status,
-                    last_non_deploying_status=const.NonDeployingResourceState(status),
-                    connection=connection,
-                )
-
-    async def get_increment(
-        self, env: data.Environment, version: int, connection: Optional[Connection] = None
-    ) -> tuple[abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]:
+    async def get_increment(self, env: data.Environment, version: int) -> tuple[abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]:
         """
         Get the increment for a given environment and a given version of the model from the _increment_cache if possible.
         In case of cache miss, the increment calculation is performed behind a lock to make sure it is only done once per
         version, per environment.
 
         :param env: The environment to consider.
-        :param version: The version of the model to consider.
-        :param connection: connection to use towards the DB.
-            When the connection is in a transaction, we will always invalidate the cache
+        :parma version: The version of the model to consider.
         """
 
         def _get_cache_entry() -> Optional[tuple[abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]]:
             """
             Returns a tuple (increment, negative_increment) if a cache entry exists for the given environment and version
             or None if no such cache entry exists.
             """
@@ -565,32 +435,32 @@
             (version_cache_entry, incr, neg_incr) = cache_entry
             if version_cache_entry != version:
                 # Cache entry exists for another version
                 return None
             return incr, neg_incr
 
         increment: Optional[tuple[abc.Set[ResourceIdStr], abc.Set[ResourceIdStr]]] = _get_cache_entry()
-        if increment is None or (connection is not None and connection.is_in_transaction()):
+        if increment is None:
             lock = self._increment_cache_locks[env.id]
             async with lock:
                 increment = _get_cache_entry()
                 if increment is None:
-                    increment = await data.ConfigurationModel.get_increment(env.id, version, connection=connection)
+                    increment = await data.ConfigurationModel.get_increment(env.id, version)
                     self._increment_cache[env.id] = (version, *increment)
         return increment
 
     @handle(methods_v2.resource_deploy_done, env="tid", resource_id="rvid")
     async def resource_deploy_done(
         self,
         env: data.Environment,
         resource_id: Id,
         action_id: uuid.UUID,
         status: ResourceState,
-        messages: list[LogLine] = [],
-        changes: dict[str, AttributeStateChange] = {},
+        messages: List[LogLine] = [],
+        changes: Dict[str, AttributeStateChange] = {},
         change: Optional[Change] = None,
         keep_increment_cache: bool = False,
     ) -> None:
         resource_id_str = resource_id.resource_version_str()
         finished = datetime.datetime.now().astimezone()
         changes_with_rvid = {resource_id_str: {attr_name: attr_change.dict()} for attr_name, attr_change in changes.items()}
 
@@ -661,56 +531,31 @@
                     changes=changes_with_rvid,
                     status=status,
                     change=change,
                     finished=finished,
                     connection=connection,
                 )
 
-                extra_fields = {}
-                if status == ResourceState.deployed:
-                    extra_fields["last_success"] = resource_action.started
-
-                propagate_event_timers = False
-                # keep track IF we need to propagate if we are stale
-                # but only do it at the end of the transaction
-                if change != Change.nochange:
-                    # We are producing an event
-                    extra_fields["last_produced_events"] = finished
-                    propagate_event_timers = True
+                # final resource update
+                if not keep_increment_cache:
+                    self.clear_env_cache(env)
 
                 await resource.update_fields(
                     last_deploy=finished,
                     status=status,
                     last_non_deploying_status=const.NonDeployingResourceState(status),
-                    **extra_fields,
                     connection=connection,
                 )
 
-                # final resource update
-                if not keep_increment_cache:
-                    self.clear_env_cache(env)
-
                 if "purged" in resource.attributes and resource.attributes["purged"] and status == const.ResourceState.deployed:
                     await data.Parameter.delete_all(environment=env.id, resource_id=resource.resource_id, connection=connection)
 
-                propagate_deploy_state = status == ResourceState.failed or status == ResourceState.skipped
-                await self.propagate_resource_state_if_stale(
-                    connection,
-                    env,
-                    [resource_id],
-                    resource_action.started,
-                    finished,
-                    status,
-                    propagate_event_timers,
-                    propagate_deploy_state,
-                )
-
         self.add_background_task(data.ConfigurationModel.mark_done_if_done(env.id, resource.model))
 
-        waiting_agents = {(Id.parse_id(prov).get_agent_name(), resource.resource_version_id) for prov in resource.provides}
+        waiting_agents = set([(Id.parse_id(prov).get_agent_name(), resource.resource_version_id) for prov in resource.provides])
         for agent, resource_id in waiting_agents:
             aclient = self.agentmanager_service.get_agent_client(env.id, agent)
             if aclient is not None:
                 if change is None:
                     change = const.Change.nochange
                 await aclient.resource_event(
                     tid=env.id,
@@ -718,86 +563,32 @@
                     resource=resource_id,
                     send_events=False,
                     state=status,
                     change=change,
                     changes=changes_with_rvid,
                 )
 
-    async def propagate_resource_state_if_stale(
-        self,
-        connection: Connection,
-        env: data.Environment,
-        resource_ids: list[Id],
-        started: datetime.datetime,
-        finished: datetime.datetime,
-        deploy_state: ResourceState,
-        propagate_event_timers: bool,
-        propagate_deploy_state: bool,
-    ) -> None:
-        if propagate_deploy_state or propagate_event_timers:
-            # lock out release version
-            await env.acquire_release_version_lock(connection=connection)
-            latest_version = await data.ConfigurationModel.get_version_nr_latest_version(env.id, connection=connection)
-
-            for resource_id in resource_ids:
-                if latest_version is not None and latest_version > resource_id.version:
-                    # we are stale, forward propagate our status
-                    # this is required because:
-                    # upon release of the newer version our old status may have been copied over into the new version
-                    # (by the increment calculation)
-                    # the new version may thus hide this failure
-                    # issue #6475
-                    # the release_version_lock above ensure we can not race with release itself
-                    # this is at the end of the transaction to not block release too long
-                    # and vice versa
-                    if propagate_deploy_state:
-                        await self._update_deploy_state(
-                            env,
-                            resource_id.resource_str(),
-                            finished,
-                            latest_version,
-                            deploy_state,
-                            f"update on stale version {resource_id.version}",
-                            fail_on_error=False,
-                            connection=connection,
-                            can_overwrite_available=False,
-                        )
-                    if propagate_event_timers:
-                        # We only update last_succes IF we are a success
-                        last_success = started if deploy_state == const.ResourceState.deployed else None
-                        await data.Resource.update_event_timers_if_newer(
-                            env.id, resource_id.resource_str(), latest_version, last_success, finished, connection=connection
-                        )
-
     @handle(methods.resource_action_update, env="tid")
     async def resource_action_update(
         self,
         env: data.Environment,
-        resource_ids: list[ResourceVersionIdStr],
+        resource_ids: List[ResourceVersionIdStr],
         action_id: uuid.UUID,
         action: const.ResourceAction,
         started: datetime.datetime,
         finished: datetime.datetime,
         status: Optional[Union[const.ResourceState, const.DeprecatedResourceState]],
-        messages: list[dict[str, Any]],
-        changes: dict[str, Any],
+        messages: List[Dict[str, Any]],
+        changes: Dict[str, Any],
         change: const.Change,
         send_events: bool,
         keep_increment_cache: bool = False,
-        is_increment_notification: bool = False,
-        only_update_from_states: Optional[set[const.ResourceState]] = None,
         *,
-        connection: ConnectionMaybeInTransaction = ConnectionNotInTransaction(),
+        connection: Optional[Connection] = None,
     ) -> Apireturn:
-        """
-        :param is_increment_notification: is this the increment calucation setting the deployed status,
-            instead of an actual deploy? Used to keep track of the last_success field on the resources,
-            which should not be updated for increments.
-        """
-
         def convert_legacy_state(
             status: Optional[Union[const.ResourceState, const.DeprecatedResourceState]]
         ) -> Optional[const.ResourceState]:
             if status is None or isinstance(status, const.ResourceState):
                 return status
             if status == const.DeprecatedResourceState.processing_events:
                 return const.ResourceState.deploying
@@ -819,15 +610,15 @@
                     resource_ids=resource_ids,
                     action=action,
                     action_id=action_id,
                 )
             # and needs to be valid
             if status not in VALID_STATES_ON_STATE_UPDATE:
                 error_and_log(
-                    f"Status {status} is not valid on action {action}",
+                    "Status %s is not valid on action %s" % (status, action),
                     resource_ids=resource_ids,
                     action=action,
                     action_id=action_id,
                 )
             if status in TRANSIENT_STATES:
                 if not is_resource_action_finished:
                     pass
@@ -849,69 +640,79 @@
                         resource_ids=resource_ids,
                         action=action,
                         action_id=action_id,
                     )
 
         assert all(Id.is_resource_version_id(rvid) for rvid in resource_ids)
 
-        resources: list[data.Resource]
-        async with data.Resource.get_connection(connection.connection) as inner_connection:
-            async with inner_connection.transaction():
+        resources: List[data.Resource]
+        async with data.Resource.get_connection(connection) as connection:
+            async with connection.transaction():
                 # validate resources
                 resources = await data.Resource.get_resources(
                     env.id,
                     resource_ids,
                     # acquire lock on Resource before read and before lock on ResourceAction to prevent conflicts with
                     # cascading deletes
-                    lock=data.RowLockMode.FOR_NO_KEY_UPDATE,
-                    connection=inner_connection,
+                    lock=data.RowLockMode.FOR_UPDATE,
+                    connection=connection,
                 )
                 if len(resources) == 0 or (len(resources) != len(resource_ids)):
-                    raise NotFound(
-                        message="The resources with the given ids do not exist in the given environment. "
-                        f"Only {len(resources)} of {len(resource_ids)} resources found."
+                    return (
+                        404,
+                        {
+                            "message": "The resources with the given ids do not exist in the given environment. "
+                            "Only %s of %s resources found." % (len(resources), len(resource_ids))
+                        },
                     )
 
-                if only_update_from_states is not None:
-                    resources = [resource for resource in resources if resource.status in only_update_from_states]
-                    if not resources:
-                        return 200, {"message": "no resources with the given state found"}
-                    resource_ids = [resource.resource_version_id for resource in resources]
-
                 # validate transitions
                 if is_resource_state_update:
                     # no escape from terminal
                     if any(resource.status != status and resource.status in TERMINAL_STATES for resource in resources):
                         LOGGER.error("Attempting to set undeployable resource to deployable state")
                         raise AssertionError("Attempting to set undeployable resource to deployable state")
 
                 # get instance
-                resource_action = await data.ResourceAction.get(action_id=action_id, connection=inner_connection)
+                resource_action = await data.ResourceAction.get(action_id=action_id, connection=connection)
                 if resource_action is None:
                     # new
                     if started is None:
-                        raise ServerError(message="A resource action can only be created with a start datetime.")
+                        return 500, {"message": "A resource action can only be created with a start datetime."}
 
                     version = Id.parse_id(resource_ids[0]).version
                     resource_action = data.ResourceAction(
                         environment=env.id,
                         version=version,
                         resource_version_ids=resource_ids,
                         action_id=action_id,
                         action=action,
                         started=started,
                     )
-                    await resource_action.insert(connection=inner_connection)
+                    await resource_action.insert(connection=connection)
                 else:
                     # existing
                     if resource_action.finished is not None:
-                        raise ServerError(
-                            message="An resource action can only be updated when it has not been finished yet. This action "
-                            f"finished at {resource_action.finished}"
+                        return (
+                            500,
+                            {
+                                "message": (
+                                    "An resource action can only be updated when it has not been finished yet. This action "
+                                    "finished at %s" % resource_action.finished
+                                )
+                            },
                         )
+
+                def parse_timestamp(timestamp: str) -> datetime.datetime:
+                    try:
+                        return datetime.datetime.strptime(timestamp, const.TIME_ISOFMT + "%z")
+                    except ValueError:
+                        # interpret naive datetimes as UTC
+                        return datetime.datetime.strptime(timestamp, const.TIME_ISOFMT).replace(tzinfo=datetime.timezone.utc)
+
                 for msg in messages:
                     # All other data is stored in the database. The msg was already formatted at the client side.
                     self.log_resource_action(
                         env.id,
                         resource_ids,
                         const.LogLevel(msg["level"]).to_int,
                         parse_timestamp(msg["timestamp"]),
@@ -925,15 +726,15 @@
                         }
                         for msg in messages
                     ],
                     changes=changes,
                     status=status,
                     change=change,
                     finished=finished,
-                    connection=inner_connection,
+                    connection=connection,
                 )
 
                 async def update_fields_resource(
                     resource: data.Resource, connection: Optional[Connection] = None, **kwargs: object
                 ) -> None:
                     """
                     This method ensures that the `last_non_deploying_status` field in the database
@@ -943,93 +744,62 @@
                         kwargs["last_non_deploying_status"] = const.NonDeployingResourceState(kwargs["status"])
                     await resource.update_fields(**kwargs, connection=connection)
 
                 if is_resource_state_update:
                     # transient resource update
                     if not is_resource_action_finished:
                         for res in resources:
-                            await update_fields_resource(res, status=status, connection=inner_connection)
+                            await update_fields_resource(res, status=status, connection=connection)
                         if not keep_increment_cache:
                             self.clear_env_cache(env)
                         return 200
 
                     else:
                         # final resource update
                         if not keep_increment_cache:
                             self.clear_env_cache(env)
 
-                        propagate_event_timers = change != Change.nochange
-
-                        await self.propagate_resource_state_if_stale(
-                            inner_connection,
-                            env,
-                            [Id.parse_id(res) for res in resource_ids],
-                            started,
-                            finished,
-                            status,  # mypy can't figure out this is never None here
-                            propagate_event_timers,
-                            status == ResourceState.failed or status == ResourceState.skipped,
-                        )
-
-                        model_version: Optional[int] = None
+                        model_version = None
                         for res in resources:
-                            extra_fields = {}
-                            if status == ResourceState.deployed and not is_increment_notification:
-                                extra_fields["last_success"] = resource_action.started
-                            if propagate_event_timers:
-                                extra_fields["last_produced_events"] = finished
-                            await update_fields_resource(
-                                res, last_deploy=finished, status=status, **extra_fields, connection=inner_connection
-                            )
+                            await update_fields_resource(res, last_deploy=finished, status=status, connection=connection)
                             model_version = res.model
 
                             if (
                                 "purged" in res.attributes
                                 and res.attributes["purged"]
                                 and status == const.ResourceState.deployed
                             ):
                                 await data.Parameter.delete_all(
-                                    environment=env.id, resource_id=res.resource_id, connection=inner_connection
+                                    environment=env.id, resource_id=res.resource_id, connection=connection
                                 )
 
         if is_resource_state_update and is_resource_action_finished:
+            self.add_background_task(data.ConfigurationModel.mark_done_if_done(env.id, model_version))
+            waiting_agents = set(
+                [(Id.parse_id(prov).get_agent_name(), res.resource_version_id) for res in resources for prov in res.provides]
+            )
 
-            def post_deploy_update() -> None:
-                assert model_version is not None  # mypy can't figure this out
-                # Make sure tasks are scheduled AFTER the tx is done.
-                # This method is only called if the transaction commits successfully.
-                self.add_background_task(data.ConfigurationModel.mark_done_if_done(env.id, model_version))
-
-                waiting_agents = {
-                    (Id.parse_id(prov).get_agent_name(), res.resource_version_id) for res in resources for prov in res.provides
-                }
-
-                for agent, resource_id in waiting_agents:
-                    aclient = self.agentmanager_service.get_agent_client(env.id, agent)
-                    if aclient is not None:
-                        if change is None:
-                            my_change = const.Change.nochange
-                        else:
-                            my_change = change
-
-                        self.add_background_task(
-                            aclient.resource_event(env.id, agent, resource_id, send_events, status, my_change, changes)
-                        )
-
-            connection.call_after_tx(post_deploy_update)
+            for agent, resource_id in waiting_agents:
+                aclient = self.agentmanager_service.get_agent_client(env.id, agent)
+                if aclient is not None:
+                    if change is None:
+                        change = const.Change.nochange
+                    self.add_background_task(
+                        aclient.resource_event(env.id, agent, resource_id, send_events, status, change, changes)
+                    )
 
         return 200
 
     @handle(methods_v2.resource_deploy_start, env="tid", resource_id="rvid")
     async def resource_deploy_start(
         self,
         env: data.Environment,
         resource_id: Id,
         action_id: uuid.UUID,
-    ) -> dict[ResourceVersionIdStr, const.ResourceState]:
+    ) -> Dict[ResourceVersionIdStr, const.ResourceState]:
         resource_id_str = resource_id.resource_version_str()
         async with data.Resource.get_connection() as connection:
             async with connection.transaction():
                 resource = await data.Resource.get_one(
                     connection=connection,
                     environment=env.id,
                     resource_id=resource_id.resource_str(),
@@ -1076,19 +846,15 @@
         attribute: Optional[str] = None,
         attribute_value: Optional[str] = None,
         log_severity: Optional[str] = None,
         limit: Optional[int] = 0,
         action_id: Optional[uuid.UUID] = None,
         first_timestamp: Optional[datetime.datetime] = None,
         last_timestamp: Optional[datetime.datetime] = None,
-        exclude_changes: Optional[list[Change]] = None,
-    ) -> ReturnValue[list[ResourceAction]]:
-        if exclude_changes is None:
-            exclude_changes = []
-
+    ) -> ReturnValue[List[ResourceAction]]:
         if (attribute and not attribute_value) or (not attribute and attribute_value):
             raise BadRequest(
                 f"Attribute and attribute_value should both be supplied to use them filtering. "
                 f"Received attribute: {attribute}, attribute_value: {attribute_value}"
             )
         if first_timestamp and last_timestamp:
             raise BadRequest(
@@ -1113,15 +879,14 @@
             attribute=attribute,
             attribute_value=attribute_value,
             log_severity=log_severity,
             limit=limit,
             action_id=action_id,
             first_timestamp=first_timestamp,
             last_timestamp=last_timestamp,
-            exclude_changes=exclude_changes,
         )
         resource_action_dtos = [resource_action.to_dto() for resource_action in resource_actions]
         links = {}
 
         def _get_query_params(
             resource_type: Optional[str] = None,
             agent: Optional[str] = None,
@@ -1154,19 +919,20 @@
             previous_params["action_id"] = resource_action_dtos[0].action_id
             links["prev"] = url_concat(base_url, previous_params)
         return_value = ReturnValue(response=resource_action_dtos, links=links if links else None)
         return return_value
 
     @handle(methods_v2.get_resource_events, env="tid", resource_id="rvid")
     async def get_resource_events(
-        self, env: data.Environment, resource_id: Id, exclude_change: Optional[const.Change] = None
-    ) -> dict[ResourceIdStr, list[ResourceAction]]:
+        self,
+        env: data.Environment,
+        resource_id: Id,
+    ) -> Dict[ResourceIdStr, List[ResourceAction]]:
         return {
-            k: [ra.to_dto() for ra in v]
-            for k, v in (await data.ResourceAction.get_resource_events(env, resource_id, exclude_change)).items()
+            k: [ra.to_dto() for ra in v] for k, v in (await data.ResourceAction.get_resource_events(env, resource_id)).items()
         }
 
     @handle(methods_v2.resource_did_dependency_change, env="tid", resource_id="rvid")
     async def resource_did_dependency_change(
         self,
         env: data.Environment,
         resource_id: Id,
@@ -1185,15 +951,15 @@
         self,
         env: data.Environment,
         limit: Optional[int] = None,
         first_id: Optional[ResourceVersionIdStr] = None,
         last_id: Optional[ResourceVersionIdStr] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
         deploy_summary: bool = False,
     ) -> ReturnValueWithMeta[Sequence[LatestReleasedResource]]:
         try:
             handler = ResourceView(env, limit, first_id, last_id, start, end, filter, sort, deploy_summary)
 
             out = await handler.execute()
@@ -1245,15 +1011,15 @@
     async def resource_logs(
         self,
         env: data.Environment,
         rid: ResourceIdStr,
         limit: Optional[int] = None,
         start: Optional[datetime.datetime] = None,
         end: Optional[datetime.datetime] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "timestamp.desc",
     ) -> ReturnValue[Sequence[ResourceLog]]:
         try:
             handler = ResourceLogsView(environment=env, rid=rid, limit=limit, sort=sort, start=start, end=end, filter=filter)
             out = await handler.execute()
             return out
         except (InvalidFilter, InvalidSort, data.InvalidQueryParameter, data.InvalidFieldNameException) as e:
@@ -1265,15 +1031,15 @@
         env: data.Environment,
         version: int,
         limit: Optional[int] = None,
         first_id: Optional[ResourceVersionIdStr] = None,
         last_id: Optional[ResourceVersionIdStr] = None,
         start: Optional[str] = None,
         end: Optional[str] = None,
-        filter: Optional[dict[str, list[str]]] = None,
+        filter: Optional[Dict[str, List[str]]] = None,
         sort: str = "resource_type.desc",
     ) -> ReturnValueWithMeta[Sequence[VersionedResource]]:
         try:
             handler = ResourcesInVersionView(env, version, limit, filter, sort, first_id, last_id, start, end)
             return await handler.execute()
         except (InvalidFilter, InvalidSort, data.InvalidQueryParameter, data.InvalidFieldNameException) as e:
             raise BadRequest(e.message) from e
@@ -1282,7 +1048,59 @@
     async def versioned_resource_details(
         self, env: data.Environment, version: int, rid: ResourceIdStr
     ) -> VersionedResourceDetails:
         resource = await data.Resource.get_versioned_resource_details(environment=env.id, version=version, resource_id=rid)
         if not resource:
             raise NotFound("The resource with the given id does not exist")
         return resource
+
+    @handle(methods_v2.discovered_resource_create, env="tid")
+    async def discovered_resource_create(self, env: data.Environment, discovered_resource_id: str, values: JsonType) -> None:
+        try:
+            discovered_resource = DiscoveredResource(discovered_resource_id=discovered_resource_id, values=values)
+        except ValidationError as e:
+            # this part was copy/pasted from protocol.common.MethodProperties.validate_arguments.
+            error_msg = f"Failed to validate argument\n{str(e)}"
+            LOGGER.exception(error_msg)
+            raise BadRequest(error_msg, {"validation_errors": e.errors()})
+
+        dao = discovered_resource.to_dao(env.id)
+        await dao.insert_with_overwrite()
+
+    @handle(methods_v2.discovered_resource_create_batch, env="tid")
+    async def discovered_resources_create_batch(
+        self, env: data.Environment, discovered_resources: List[DiscoveredResource]
+    ) -> None:
+        dao_list = [res.to_dao(env.id) for res in discovered_resources]
+        await data.DiscoveredResource.insert_many_with_overwrite(dao_list)
+
+    @handle(methods_v2.discovered_resources_get, env="tid")
+    async def discovered_resources_get(
+        self, env: data.Environment, discovered_resource_id: ResourceIdStr
+    ) -> DiscoveredResource:
+        result = await data.DiscoveredResource.get_one(environment=env.id, discovered_resource_id=discovered_resource_id)
+        if not result:
+            raise NotFound(f"discovered_resource with name {discovered_resource_id} not found in env {env.id}")
+        dto = result.to_dto()
+        return dto
+
+    @protocol.handle(methods_v2.discovered_resources_get_batch, env="tid")
+    async def discovered_resources_get_batch(
+        self,
+        env: data.Environment,
+        limit: Optional[int] = None,
+        start: Optional[str] = None,
+        end: Optional[str] = None,
+        sort: str = "discovered_resource_id.asc",
+    ) -> ReturnValue[Sequence[DiscoveredResource]]:
+        try:
+            handler = DiscoveredResourceView(
+                environment=env,
+                limit=limit,
+                sort=sort,
+                start=start,
+                end=end,
+            )
+            out = await handler.execute()
+            return out
+        except (InvalidFilter, InvalidSort, data.InvalidQueryParameter, data.InvalidFieldNameException) as e:
+            raise BadRequest(e.message) from e
```

### Comparing `inmanta-core-8.7.4/src/inmanta/server/services/userservice.py` & `inmanta-core-9.3.0/src/inmanta/server/services/userservice.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/server/validate_filter.py` & `inmanta-core-9.3.0/src/inmanta/server/validate_filter.py`

 * *Files 3% similar despite different names*

```diff
@@ -13,16 +13,15 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import datetime
 from abc import ABC, abstractmethod
-from collections.abc import Callable
-from typing import Optional, TypeVar
+from typing import Callable, Dict, List, Optional, Tuple, Type, TypeVar
 
 import dateutil
 import more_itertools
 from pydantic import BaseModel, ValidationError, validator
 
 from inmanta import const
 from inmanta.data import DateRangeConstraint, QueryFilter, QueryType, RangeConstraint, RangeOperator
@@ -49,46 +48,48 @@
     return v
 
 
 def parse_range_value_to_date(single_constraint: str, value: str) -> datetime.datetime:
     try:
         datetime_obj: datetime.datetime = dateutil.parser.isoparse(value)
     except ValueError:
-        raise ValueError(f"Invalid range constraint {single_constraint}: '{value}' is not a valid datetime")
+        raise ValueError("Invalid range constraint %s: '%s' is not a valid datetime" % (single_constraint, value))
     else:
         return datetime_obj if datetime_obj.tzinfo is not None else datetime_obj.replace(tzinfo=datetime.timezone.utc)
 
 
 def parse_range_value_to_int(single_constraint: str, value: str) -> int:
     try:
         return int(value)
     except ValueError:
-        raise ValueError(f"Invalid range constraint {single_constraint}: '{value}' is not an integer")
+        raise ValueError("Invalid range constraint %s: '%s' is not an integer" % (single_constraint, value))
 
 
 S = TypeVar("S", int, datetime.datetime)
 
 
 def get_range_operator_parser(
     parse_value_to_type: Callable[[str, str], S]
-) -> Callable[[object, object], Optional[list[tuple[RangeOperator, S]]]]:
-    def parse_range_operator(v: object) -> Optional[list[tuple[RangeOperator, S]]]:
+) -> Callable[[object, object], Optional[List[Tuple[RangeOperator, S]]]]:
+    def parse_range_operator(v: object) -> Optional[List[Tuple[RangeOperator, S]]]:
         """
         Transform list of "<lt|le|gt|ge>:<x>" constraint specifiers to typed objects.
         """
 
-        def transform_single(single: str, parse_value_to_type: Callable[[str, str], S]) -> tuple[RangeOperator, S]:
-            split: list[str] = single.split(":", maxsplit=1)
+        def transform_single(single: str, parse_value_to_type: Callable[[str, str], S]) -> Tuple[RangeOperator, S]:
+            split: List[str] = single.split(":", maxsplit=1)
             if len(split) != 2:
                 raise ValueError("Invalid range constraint %s, expected '<lt|le|gt|ge>:<x>`" % single)
             operator: RangeOperator
             try:
                 operator = RangeOperator.parse(split[0])
             except ValueError:
-                raise ValueError(f"Invalid range operator {split[0]} in constraint {single}, expected one of lt, le, gt, ge")
+                raise ValueError(
+                    "Invalid range operator %s in constraint %s, expected one of lt, le, gt, ge" % (split[0], single)
+                )
             bound = parse_value_to_type(single, split[1])
             return (operator, bound)
 
         if v is None:
             return None
 
         if isinstance(v, str):
@@ -108,100 +109,101 @@
     The `to_query_type` method describes how to interpret this as filter in for a database query by providing the correct
     `QueryType`
     """
 
     # Pydantic doesn't support Generic BaseModels on python 3.6
 
     @abstractmethod
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         """Get the value of the filter with the correct query type"""
+        pass
 
 
 class BooleanEqualityFilter(Filter):
     """Represents a valid boolean which should be handled as an equality filter"""
 
     field: Optional[bool]
     validate_field: classmethod = validator("field", pre=True, allow_reuse=True)(parse_single_value)
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field is not None:
             return (QueryType.EQUALS, self.field)
         return None
 
 
 class BooleanIsNotNullFilter(BooleanEqualityFilter, Filter):
     """Represents a valid boolean which should be handled as an IS_NOT_NULL filter"""
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field is not None:
             return (QueryType.IS_NOT_NULL, None) if self.field else (QueryType.EQUALS, None)
         return None
 
 
 class DateRangeFilter(Filter):
     """Represents a valid date range constraint which should be handled as a range filter"""
 
     field: Optional[DateRangeConstraint]
 
     @validator("field", pre=True)
     @classmethod
-    def parse_requested(cls, v: object) -> Optional[list[tuple[RangeOperator, datetime.datetime]]]:
+    def parse_requested(cls, v: object) -> Optional[List[Tuple[RangeOperator, datetime.datetime]]]:
         return get_range_operator_parser(parse_range_value_to_date)(v)
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.RANGE, self.field)
         return None
 
 
 class IntRangeFilter(Filter):
     field: Optional[RangeConstraint]
 
     @validator("field", pre=True)
     @classmethod
-    def parse_field(cls, v: object) -> Optional[list[tuple[RangeOperator, int]]]:
+    def parse_field(cls, v: object) -> Optional[List[Tuple[RangeOperator, int]]]:
         return get_range_operator_parser(parse_range_value_to_int)(v)
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.RANGE, self.field)
         return None
 
 
 class ContainsPartialFilter(Filter):
     """Represents a valid string list constraint which should be handled as a partial containment filter"""
 
-    field: Optional[list[str]]
+    field: Optional[List[str]]
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.CONTAINS_PARTIAL, self.field)
         return None
 
 
 class ContainsFilter(Filter):
     """Represents a valid string list constraint which should be handled as a containment filter"""
 
-    field: Optional[list[str]]
+    field: Optional[List[str]]
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.CONTAINS, self.field)
         return None
 
 
 class CombinedContainsFilterResourceState(Filter):
     """Represents a valid ReleasedResourceState constraint,
     which handles the filters as contains or not contains filters based on their values"""
 
-    field: Optional[dict[QueryType, list[ReleasedResourceState]]]
+    field: Optional[Dict[QueryType, List[ReleasedResourceState]]]
 
     @validator("field", pre=True)
     @classmethod
-    def parse_field(cls, v: object) -> Optional[dict[QueryType, ReleasedResourceState]]:
+    def parse_field(cls, v: object) -> Optional[Dict[QueryType, ReleasedResourceState]]:
         if v is None:
             return None
         if isinstance(v, list) and all(isinstance(x, str) for x in v):
             status_contains_filters = [status_filter for status_filter in v if not status_filter.startswith("!")]
             status_not_contains_filters = [status_filter[1:] for status_filter in v if status_filter.startswith("!")]
 
             intersection = set(status_contains_filters).intersection(status_not_contains_filters)
@@ -214,27 +216,27 @@
             if status_not_contains_filters:
                 filters[QueryType.NOT_CONTAINS] = status_not_contains_filters
 
             return filters if filters else None
 
         raise ValueError(f"value is not a valid list of resource state constraints: {str(v)}")
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.COMBINED, self.field)
         return None
 
 
 class ContainsFilterResourceAction(Filter):
     """Represents a valid ResourceAction list constraint which should be handled as a containment filter"""
 
     # Pydantic doesn't support Generic models on python 3.6
-    field: Optional[list[const.ResourceAction]]
+    field: Optional[List[const.ResourceAction]]
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field:
             return (QueryType.CONTAINS, self.field)
         return None
 
 
 class LogLevelFilter(Filter):
     """Represents a valid LogLevel constraint which is considered to be the minimal log level"""
@@ -256,43 +258,43 @@
                         too_long=ValueError(f"Multiple values provided for 'minimal_log_level' filter: {v}"),
                     ).upper()
                 ]
             except KeyError:
                 raise ValueError(f"{v} is not a valid log level")
         return v
 
-    def to_query_type(self) -> Optional[tuple[QueryType, object]]:
+    def to_query_type(self) -> Optional[Tuple[QueryType, object]]:
         if self.field is not None:
             return (QueryType.CONTAINS, self._get_log_levels_for_filter(self.field))
         return None
 
-    def _get_log_levels_for_filter(self, minimal_log_level: const.LogLevel) -> list[str]:
+    def _get_log_levels_for_filter(self, minimal_log_level: const.LogLevel) -> List[str]:
         return [level.value for level in const.LogLevel if level.to_int >= minimal_log_level.to_int]
 
 
 class FilterValidator(ABC):
     """
     This class provides methods to validate and process filters as received via the API.
     """
 
     @property
     @abstractmethod
-    def allowed_filters(self) -> dict[str, type[Filter]]:
+    def allowed_filters(self) -> Dict[str, Type[Filter]]:
         """A dictionary that determines the mapping between the allowed filters and how they should be parsed and validated"""
         raise NotImplementedError()
 
-    def process_filters(self, filter: Optional[dict[str, list[str]]]) -> dict[str, QueryFilter]:
+    def process_filters(self, filter: Optional[Dict[str, List[str]]]) -> Dict[str, QueryFilter]:
         """
         Processes filters and returns a structured query filter object.
 
         :raises InvalidFilter: The supplied filter is invalid.
         """
         if filter is None:
             return {}
-        query: dict[str, QueryFilter] = {}
+        query: Dict[str, QueryFilter] = {}
         for filter_name, filter_class in self.allowed_filters.items():
             try:
                 # Validate the provided filter value with pydantic,
                 # then determine how it should be handled according to its QueryType
                 validated_query_type = filter_class(field=filter.get(filter_name)).to_query_type()
                 if validated_query_type is not None:
                     query[filter_name] = validated_query_type
```

### Comparing `inmanta-core-8.7.4/src/inmanta/types.py` & `inmanta-core-9.3.0/src/inmanta/types.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,28 +15,27 @@
 
     Contact: code@inmanta.com
 """
 # This file defines named type definition for the Inmanta code base
 
 import builtins
 import uuid
-from collections.abc import Callable, Coroutine, Mapping, Sequence
 from datetime import datetime
-from typing import TYPE_CHECKING, Any, Optional, Union
+from typing import TYPE_CHECKING, Any, Callable, Coroutine, Dict, List, Mapping, Optional, Sequence, Tuple, Type, Union
 
 import typing_inspect
 from pydantic import errors, types
 
 if TYPE_CHECKING:
     # Include imports from other modules here and use the quoted annotation in the definition to prevent import loops
     from inmanta.data.model import BaseModel  # noqa: F401
     from inmanta.protocol.common import ReturnValue  # noqa: F401
 
 
-class StrictNonIntBool:
+class StrictNonIntBool(object):
     """
     StrictNonIntBool to allow for bools which are not type-coerced and that are not a subclass of int
     Based on StrictBool from pydantic
     """
 
     @classmethod
     def __get_validators__(cls) -> "types.CallableGenerator":
@@ -49,39 +48,39 @@
         """
         if isinstance(value, bool):
             return value
 
         raise errors.StrictBoolError()
 
     @classmethod
-    def __modify_schema__(cls, f_schema: dict[str, Any]) -> dict[str, Any]:
+    def __modify_schema__(cls, f_schema: Dict[str, Any]) -> Dict[str, Any]:
         """
         Should be handled as a boolean in OpenAPI schemas
         """
         f_schema["type"] = "boolean"
         return f_schema
 
 
-def issubclass(sub: type, super: Union[type, tuple[type, ...]]) -> bool:
+def issubclass(sub: Type, super: Union[Type, Tuple[Type, ...]]) -> bool:
     """
     Alternative issubclass implementation that interpretes instances of NewType for the first argument as their super type.
     """
     if typing_inspect.is_new_type(sub):
         return issubclass(sub.__supertype__, super)
     return builtins.issubclass(sub, super)
 
 
 PrimitiveTypes = Union[uuid.UUID, StrictNonIntBool, int, float, datetime, str]
 SimpleTypes = Union["BaseModel", PrimitiveTypes]
 
-JsonType = dict[str, Any]
-ReturnTupple = tuple[int, Optional[JsonType]]
+JsonType = Dict[str, Any]
+ReturnTupple = Tuple[int, Optional[JsonType]]
 
 ArgumentTypes = Union[SimpleTypes, Sequence[SimpleTypes], Mapping[str, SimpleTypes]]
 
 ReturnTypes = Optional[ArgumentTypes]
 MethodReturn = Union[ReturnTypes, "ReturnValue[ReturnTypes]"]
 MethodType = Callable[..., MethodReturn]
 
 Apireturn = Union[int, ReturnTupple, "ReturnValue[ReturnTypes]", "ReturnValue[None]", ReturnTypes]
-Warnings = Optional[list[str]]
+Warnings = Optional[List[str]]
 HandlerType = Callable[..., Coroutine[Any, Any, Apireturn]]
```

### Comparing `inmanta-core-8.7.4/src/inmanta/user_setup.py` & `inmanta-core-9.3.0/src/inmanta/user_setup.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/src/inmanta/util/__init__.py` & `inmanta-core-9.3.0/src/inmanta/util.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2023 Inmanta
+    Copyright 2022 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
 
@@ -30,26 +30,25 @@
 import threading
 import time
 import uuid
 import warnings
 from abc import ABC, abstractmethod
 from asyncio import CancelledError, Future, Lock, Task, ensure_future, gather
 from collections import abc, defaultdict
-from collections.abc import Awaitable, Callable, Coroutine, Iterator
 from concurrent.futures import ThreadPoolExecutor
 from dataclasses import dataclass
 from logging import Logger
 from types import TracebackType
-from typing import BinaryIO, Optional, TypeVar, Union
+from typing import Awaitable, BinaryIO, Callable, Coroutine, Dict, Iterator, List, Optional, Set, Tuple, Type, TypeVar, Union
 
 import asyncpg
 from tornado import gen
 
 from crontab import CronTab
-from inmanta import COMPILER_VERSION, const
+from inmanta import COMPILER_VERSION
 from inmanta.stable_api import stable_api
 from inmanta.types import JsonType, PrimitiveTypes, ReturnTypes
 
 LOGGER = logging.getLogger(__name__)
 SALT_SIZE = 16
 HASH_ROUNDS = 100000
 
@@ -57,66 +56,29 @@
 S = TypeVar("S")
 
 
 def get_compiler_version() -> str:
     return COMPILER_VERSION
 
 
-def groupby(mylist: list[T], f: Callable[[T], S]) -> Iterator[tuple[S, Iterator[T]]]:
+def groupby(mylist: List[T], f: Callable[[T], S]) -> Iterator[Tuple[S, Iterator[T]]]:
     return itertools.groupby(sorted(mylist, key=f), f)
 
 
 def ensure_directory_exist(directory: str, *subdirs: str) -> str:
     directory = os.path.join(directory, *subdirs)
     if not os.path.exists(directory):
         os.mkdir(directory)
     return directory
 
 
-def is_sub_dict(subdct: dict[PrimitiveTypes, PrimitiveTypes], dct: dict[PrimitiveTypes, PrimitiveTypes]) -> bool:
+def is_sub_dict(subdct: Dict[PrimitiveTypes, PrimitiveTypes], dct: Dict[PrimitiveTypes, PrimitiveTypes]) -> bool:
     return not any(True for k, v in subdct.items() if k not in dct or dct[k] != v)
 
 
-def strtobool(val: str) -> bool:
-    """Convert a string representation of truth to True or False.
-
-    True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
-    are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
-    'val' is anything else.
-
-    This function is based on a function in the Python distutils package. Is is subject
-    to the following license:
-
-    Permission is hereby granted, free of charge, to any person obtaining a copy
-    of this software and associated documentation files (the "Software"), to
-    deal in the Software without restriction, including without limitation the
-    rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
-    sell copies of the Software, and to permit persons to whom the Software is
-    furnished to do so, subject to the following conditions:
-
-    The above copyright notice and this permission notice shall be included in
-    all copies or substantial portions of the Software.
-
-    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
-    IN THE SOFTWARE.
-    """
-    val = val.lower()
-    if val in ("y", "yes", "t", "true", "on", "1"):
-        return True
-    elif val in ("n", "no", "f", "false", "off", "0"):
-        return False
-    else:
-        raise ValueError("invalid truth value %r" % (val,))
-
-
 def hash_file(content: bytes) -> str:
     """
     Create a hash from the given content
     """
     sha1sum = hashlib.new("sha1")
     sha1sum.update(content)
 
@@ -131,15 +93,15 @@
         if not chunk:
             break
         h.update(chunk)
 
     return h.hexdigest()
 
 
-def is_call_ok(result: Union[int, tuple[int, JsonType]]) -> bool:
+def is_call_ok(result: Union[int, Tuple[int, JsonType]]) -> bool:
     if isinstance(result, tuple):
         if len(result) == 2:
             code, reply = result
         else:
             raise Exception("Handlers for method call can only return a status code and a reply")
 
     else:
@@ -243,15 +205,15 @@
     _crontab: CronTab = dataclasses.field(init=False, compare=False)
 
     def __post_init__(self) -> None:
         crontab: CronTab
         try:
             crontab = CronTab(self.cron)
         except ValueError as e:
-            raise ValueError(f"'{self.cron}' is not a valid cron expression: {e}")
+            raise ValueError("'%s' is not a valid cron expression: %s" % (self.cron, e))
         # can not assign directly on frozen dataclass, see dataclass docs
         object.__setattr__(self, "_crontab", crontab)
 
     def get_initial_delay(self) -> float:
         # no special treatment for first execution
         return self.get_next_delay()
 
@@ -270,31 +232,31 @@
         or gen.is_coroutine_function(function)
         or isinstance(function, functools.partial)
         and is_coroutine(function.func)
     )
 
 
 @stable_api
-class Scheduler:
+class Scheduler(object):
     """
     An event scheduler class. Identifies tasks based on an action and a schedule. Considers tasks with the same action and the
     same schedule to be the same. Callers that wish to be able to delete the tasks they add should make sure to use unique
     `call` functions.
     Assumes an event loop is already running on this thread.
     """
 
     def __init__(self, name: str) -> None:
         self.name = name
-        self._scheduled: dict[ScheduledTask, asyncio.TimerHandle] = {}
+        self._scheduled: Dict[ScheduledTask, asyncio.TimerHandle] = {}
         self._stopped = False
         # Keep track of all tasks that are currently executing to be
         # able to cancel them when the scheduler is stopped.
-        self._executing_tasks: dict[TaskMethod, list[asyncio.Task[object]]] = defaultdict(list)
+        self._executing_tasks: Dict[TaskMethod, List[asyncio.Task[object]]] = defaultdict(list)
         # Keep track of tasks that should be awaited before the scheduler is stopped
-        self._await_tasks: dict[TaskMethod, list[asyncio.Task[object]]] = defaultdict(list)
+        self._await_tasks: Dict[TaskMethod, List[asyncio.Task[object]]] = defaultdict(list)
 
     def _add_to_executing_tasks(self, action: TaskMethod, task: asyncio.Task[object], cancel_on_stop: bool = True) -> None:
         """
         Add task that is currently executing to `self._executing_tasks`.
         """
         if action in self._executing_tasks and self._executing_tasks[action]:
             LOGGER.warning("Multiple instances of background task %s are executing simultaneously", action.__name__)
@@ -303,15 +265,15 @@
             self._await_tasks[action].append(task)
 
     def _notify_done(self, action: TaskMethod, task: asyncio.Task[object]) -> None:
         """
         Called by the callback function of executing task when the task has finished executing.
         """
 
-        def remove_action_from_task_dict(task_dict: dict[TaskMethod, list[asyncio.Task[object]]]) -> None:
+        def remove_action_from_task_dict(task_dict: Dict[TaskMethod, List[asyncio.Task[object]]]) -> None:
             if action in task_dict:
                 try:
                     task_dict[action].remove(task)
                 except ValueError:
                     pass
 
         for task_dict in [self._executing_tasks, self._await_tasks]:
@@ -428,44 +390,27 @@
     """
     with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as tcp:
         tcp.bind(("", 0))
         _addr, port = tcp.getsockname()
         return str(port)
 
 
-def datetime_iso_format(timestamp: datetime.datetime, *, tz_aware: bool = False) -> str:
+def datetime_utc_isoformat(timestamp: datetime.datetime, *, naive_utc: bool = False) -> str:
     """
-    Returns a timestamp ISO string. Naive timestamps are assumed to be UTC.
+    Returns a timestamp ISO string in implicit UTC.
 
     :param timestamp: The timestamp to get the ISO string for.
-    :param tz_aware: Whether to return timezone aware timestamps or naive, implicit UTC timestamp.
-    """
-
-    def convert_timestamp() -> datetime.datetime:
-        if tz_aware:
-            if timestamp.tzinfo:
-                return timestamp
-            return timestamp.replace(tzinfo=datetime.timezone.utc)
-
-        if timestamp.tzinfo:
-            return timestamp.astimezone(datetime.timezone.utc).replace(tzinfo=None)
-        return timestamp
-
-    return convert_timestamp().isoformat(timespec="microseconds")
-
-
-def parse_timestamp(timestamp: str) -> datetime.datetime:
-    """
-    Parse a timestamp into a timezone aware object. Naive timestamps are assumed to be UTC.
+    :param naive_utc: Whether to interpret naive timestamps as UTC. By default naive timestamps are assumed to be in local time.
     """
-    try:
-        return datetime.datetime.strptime(timestamp, const.TIME_ISOFMT + "%z")
-    except ValueError:
-        # interpret naive datetimes as UTC
-        return datetime.datetime.strptime(timestamp, const.TIME_ISOFMT).replace(tzinfo=datetime.timezone.utc)
+    naive_utc_timestamp: datetime.datetime = (
+        timestamp
+        if timestamp.tzinfo is None and naive_utc
+        else timestamp.astimezone(datetime.timezone.utc).replace(tzinfo=None)
+    )
+    return naive_utc_timestamp.isoformat(timespec="microseconds")
 
 
 class JSONSerializable(ABC):
     """
     Instances of this class are JSON serializable. Concrete subclasses should implement json_serialization_step.
     """
 
@@ -489,23 +434,22 @@
         # Internally, all naive datetime instances are assumed local. Returns ISO timestamp with explicit timezone offset.
         return _custom_json_encoder(o if o.tzinfo is not None else o.astimezone())
 
     return _custom_json_encoder(o)
 
 
 @stable_api
-def api_boundary_json_encoder(o: object, tz_aware: bool = False) -> Union[ReturnTypes, "JSONSerializable"]:
+def api_boundary_json_encoder(o: object) -> Union[ReturnTypes, "JSONSerializable"]:
     """
     A custom json encoder that knows how to encode other types commonly used by Inmanta from standard python libraries. This
     encoder is meant to be used for API boundaries.
-    :param tz_aware: Whether to serialize timestamps as timezone aware objects or as naive implicit UTC.
     """
     if isinstance(o, datetime.datetime):
-        # Accross API boundaries, all naive datetime instances are assumed UTC.
-        return datetime_iso_format(o, tz_aware=tz_aware)
+        # Accross API boundaries, all naive datetime instances are assumed UTC. Returns ISO timestamp implicitly in UTC.
+        return datetime_utc_isoformat(o, naive_utc=True)
 
     return _custom_json_encoder(o)
 
 
 def _custom_json_encoder(o: object) -> Union[ReturnTypes, "JSONSerializable"]:
     """
     A custom json encoder that knows how to encode other types commonly used by Inmanta from standard python libraries
@@ -593,24 +537,24 @@
         )
 
 
 class StoppedException(Exception):
     """This exception is raised when a background task is added to the taskhandler when it is shutting down."""
 
 
-class TaskHandler:
+class TaskHandler(object):
     """
     This class provides a method to add a background task based on a coroutine. When the coroutine ends, any exceptions
     are reported. If stop is invoked, all background tasks are cancelled.
     """
 
     def __init__(self) -> None:
         super().__init__()
-        self._background_tasks: set[Task] = set()
-        self._await_tasks: set[Task] = set()
+        self._background_tasks: Set[Task] = set()
+        self._await_tasks: Set[Task] = set()
         self._stopped = False
 
     def is_stopped(self) -> bool:
         return self._stopped
 
     def is_running(self) -> bool:
         return not self._stopped
@@ -674,22 +618,22 @@
         if not self.done:
             if node not in self.nodes:
                 self.nodes.insert(0, node)
             else:
                 self.done = True
 
 
-def stable_depth_first(nodes: list[str], edges: dict[str, list[str]]) -> list[str]:
+def stable_depth_first(nodes: List[str], edges: Dict[str, List[str]]) -> List[str]:
     """Creates a linear sequence based on a set of "comes after" edges, same graph yields the same solution,
     independent of order given to this function"""
     nodes = sorted(nodes)
     edges = {k: sorted(v) for k, v in edges.items()}
     out = []
 
-    def dfs(node: str, seen: set[str] = set()) -> None:
+    def dfs(node: str, seen: Set[str] = set()) -> None:
         if node in out:
             return
         if node in seen:
             raise CycleException(node)
         try:
             if node in edges:
                 for edge in edges[node]:
@@ -710,26 +654,26 @@
         self.parent = parent
         self.name = name
 
     async def __aenter__(self) -> None:
         await self.parent.acquire(self.name)
 
     async def __aexit__(
-        self, exc_type: Optional[type[BaseException]], exc_value: Optional[BaseException], traceback: Optional[TracebackType]
+        self, exc_type: Optional[Type[BaseException]], exc_value: Optional[BaseException], traceback: Optional[TracebackType]
     ) -> None:
         await self.parent.release(self.name)
 
 
 class NamedLock:
     """Create fine grained locks"""
 
     def __init__(self) -> None:
         self._master_lock: Lock = Lock()
-        self._named_locks: dict[str, Lock] = {}
-        self._named_locks_counters: dict[str, int] = {}
+        self._named_locks: Dict[str, Lock] = {}
+        self._named_locks_counters: Dict[str, int] = {}
 
     def get(self, name: str) -> NamedSubLock:
         return NamedSubLock(self, name)
 
     async def acquire(self, name: str) -> None:
         async with self._master_lock:
             if name in self._named_locks:
@@ -760,15 +704,15 @@
     async def __aenter__(self) -> T:
         return self.enter_result
 
     async def __aexit__(self, *excinfo: object) -> None:
         pass
 
 
-async def join_threadpools(threadpools: list[ThreadPoolExecutor]) -> None:
+async def join_threadpools(threadpools: List[ThreadPoolExecutor]) -> None:
     """
     Asynchronously join a set of threadpools
 
     idea borrowed from BaseEventLoop.shutdown_default_executor
 
     We implemented this method because:
     1. ThreadPoolExecutor.shutdown(wait=True)` is a blocking call, blocking the ioloop.
```

### Comparing `inmanta-core-8.7.4/src/inmanta/warnings.py` & `inmanta-core-9.3.0/src/inmanta/warnings.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,17 +14,16 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import logging
 import warnings
-from collections.abc import Mapping
 from enum import Enum
-from typing import Literal, Optional, TextIO, Union
+from typing import Dict, List, Literal, Mapping, Optional, TextIO, Type, Union
 
 
 class InmantaWarning(Warning):
     """
     Base class for Inmanta Warnings.
     Those warnings won't contain the python trace and are intended to be shown to end users.
     """
@@ -67,36 +66,36 @@
     WarningOption(
         "disable-inmanta-warnings",
         {True: WarningRule(WarningBehaviour.IGNORE, module=REGEX_INMANTA_MODULE)}
     )
     would add a rule to ignore Inmanta warnings but leave other warning's behaviour as is.
     """
 
-    def __init__(self, name: str, options: dict[Union[str, bool], WarningRule]) -> None:
+    def __init__(self, name: str, options: Dict[Union[str, bool], WarningRule]) -> None:
         self.name: str = name
-        self.options: dict[Union[str, bool], WarningRule] = options
+        self.options: Dict[Union[str, bool], WarningRule] = options
 
     def apply(self, option: Union[str, bool]) -> None:
         """
         Apply the warning rule tied to the given option.
         """
         if option not in self.options:
-            raise Exception(f"Illegal option {option} for {self.name}")
+            raise Exception("Illegal option %s for %s" % (option, self.name))
         rule: WarningRule = self.options[option]
         rule.apply()
 
 
 class WarningsManager:
     """
     Manages warning behaviour guided by a config file.
     """
 
     # List of warning options with a rule tied to each possible option value.
     # Options are applied left to right so general options should come before specific ones.
-    options: list[WarningOption] = [
+    options: List[WarningOption] = [
         WarningOption(
             "default",
             {
                 "warn": WarningRule(WarningBehaviour.WARN, module=REGEX_INMANTA_MODULE),
                 "ignore": WarningRule(WarningBehaviour.IGNORE, module=REGEX_INMANTA_MODULE),
                 "error": WarningRule(WarningBehaviour.ERROR, module=REGEX_INMANTA_MODULE),
             },
@@ -131,15 +130,15 @@
         # Warn all Inmanta-related warnings by default. Behaviour can be controlled using the --warnings argument on the CLI.
         warnings.filterwarnings(WarningBehaviour.WARN.value, module=REGEX_INMANTA_MODULE)
 
     @classmethod
     def _showwarning(
         cls,
         message: Union[str, Warning],
-        category: type[Warning],
+        category: Type[Warning],
         filename: str,
         lineno: int,
         file: Optional[TextIO] = None,
         line: Optional[str] = None,
     ) -> None:
         """
         Shows a warning.
@@ -149,15 +148,15 @@
         :param filename: Required for compatibility but will be ignored.
         :param lineno: Required for compatibility but will be ignored.
         :param file: The file to write the warning to. Defaults to stderr.
         :param line: Required for compatibility but will be ignored.
         """
         # implementation based on warnings._showwarnmsg_impl and logging._showwarning
         if issubclass(category, InmantaWarning):
-            text = f"{category.__name__}: {message}"
+            text = "%s: %s" % (category.__name__, message)
             logger = logging.getLogger("inmanta.warnings")
         else:
             text: str = warnings.formatwarning(
                 # ignore type check because warnings.formatwarning accepts Warning instance but it's type definition doesn't
                 message,  # type: ignore
                 category,
                 filename,
```

### Comparing `inmanta-core-8.7.4/src/inmanta_core.egg-info/SOURCES.txt` & `inmanta-core-9.3.0/src/inmanta_core.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -34,15 +34,15 @@
 src/inmanta/profile_mem.py
 src/inmanta/py.typed
 src/inmanta/reporter.py
 src/inmanta/resources.py
 src/inmanta/stable_api.py
 src/inmanta/types.py
 src/inmanta/user_setup.py
-src/inmanta/validation_type.py
+src/inmanta/util.py
 src/inmanta/warnings.py
 src/inmanta/agent/__init__.py
 src/inmanta/agent/agent.py
 src/inmanta/agent/cache.py
 src/inmanta/agent/config.py
 src/inmanta/agent/handler.py
 src/inmanta/agent/reporting.py
@@ -103,26 +103,17 @@
 src/inmanta/db/versions/v202301160.py
 src/inmanta/db/versions/v202301170.py
 src/inmanta/db/versions/v202301190.py
 src/inmanta/db/versions/v202302200.py
 src/inmanta/db/versions/v202302270.py
 src/inmanta/db/versions/v202303070.py
 src/inmanta/db/versions/v202303071.py
+src/inmanta/db/versions/v202304060.py
 src/inmanta/db/versions/v202304070.py
 src/inmanta/db/versions/v202306060.py
-src/inmanta/db/versions/v202308010.py
-src/inmanta/db/versions/v202308020.py
-src/inmanta/db/versions/v202308100.py
-src/inmanta/db/versions/v202309130.py
-src/inmanta/db/versions/v202310040.py
-src/inmanta/db/versions/v202310090.py
-src/inmanta/db/versions/v202310180.py
-src/inmanta/db/versions/v202402130.py
-src/inmanta/db/versions/v202403120.py
-src/inmanta/db/versions/v202403220.py
 src/inmanta/db/versions/v3.py
 src/inmanta/db/versions/v4.py
 src/inmanta/db/versions/v5.py
 src/inmanta/db/versions/v6.py
 src/inmanta/db/versions/v7.py
 src/inmanta/execute/__init__.py
 src/inmanta/execute/proxy.py
@@ -176,17 +167,14 @@
 src/inmanta/server/services/metricservice.py
 src/inmanta/server/services/notificationservice.py
 src/inmanta/server/services/orchestrationservice.py
 src/inmanta/server/services/paramservice.py
 src/inmanta/server/services/projectservice.py
 src/inmanta/server/services/resourceservice.py
 src/inmanta/server/services/userservice.py
-src/inmanta/util/__init__.py
-src/inmanta/util/db.py
-src/inmanta/util/dict_path.py
 src/inmanta_core.egg-info/PKG-INFO
 src/inmanta_core.egg-info/SOURCES.txt
 src/inmanta_core.egg-info/dependency_links.txt
 src/inmanta_core.egg-info/entry_points.txt
 src/inmanta_core.egg-info/not-zip-safe
 src/inmanta_core.egg-info/requires.txt
 src/inmanta_core.egg-info/top_level.txt
@@ -204,14 +192,15 @@
 tests/test_compiler_entrypoints.py
 tests/test_config.py
 tests/test_const.py
 tests/test_data.py
 tests/test_data_concurrency.py
 tests/test_data_model.py
 tests/test_deploy.py
+tests/test_discovered_resources.py
 tests/test_docs_snippets.py
 tests/test_docstring_parser.py
 tests/test_env.py
 tests/test_export.py
 tests/test_extension_loading.py
 tests/test_file_parser.py
 tests/test_handler.py
@@ -232,8 +221,8 @@
 tests/test_projectmetadata.py
 tests/test_protocol.py
 tests/test_proxy.py
 tests/test_resource.py
 tests/test_server.py
 tests/test_type.py
 tests/test_usersetup.py
-tests/test_validation_type.py
+tests/test_util.py
```

### Comparing `inmanta-core-8.7.4/src/inmanta_core.egg-info/requires.txt` & `inmanta-core-9.3.0/src/inmanta_core.egg-info/requires.txt`

 * *Files 12% similar despite different names*

```diff
@@ -1,40 +1,38 @@
-asyncpg~=0.25
-build~=1.0
+asyncpg<0.28,~=0.25
 click-plugins~=1.0
 click<8.2,>=8.0
 colorlog~=6.4
 cookiecutter<3,>=1
 crontab<2.0,>=0.23
 cryptography<42,>=36
 docstring-parser<0.16,>=0.10
 email-validator<3,>=1
-execnet<2,>=1
-importlib_metadata<8,>=4
+execnet~=1.0
+importlib_metadata<7,>=4
 jinja2~=3.0
-more-itertools<11,>=8
+more-itertools<10,>=8
 netifaces~=0.11
 packaging>=21.3
 pip>=21.3
 ply~=3.0
 pydantic<2,>=1.10.8
 pyformance~=0.4
 PyJWT~=2.0
 pynacl~=1.5
 python-dateutil~=2.0
 pyyaml~=6.0
-setuptools
 texttable~=1.0
 tornado~=6.0
-typing-extensions<4.10,>=4.8
 typing_inspect~=0.9
+build~=0.7
 ruamel.yaml~=0.17
 toml~=0.10
 
 [datatrace]
 graphviz
 
 [debug]
 rpdb
 
 [pytest-inmanta-extensions]
-pytest-inmanta-extensions~=8.7.4.0.dev
+pytest-inmanta-extensions~=9.3.0.0.dev
```

### Comparing `inmanta-core-8.7.4/src/inmanta_ext/core/__init__.py` & `inmanta-core-9.3.0/src/inmanta_plugins/1/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """
-    Copyright 2019 Inmanta
+    Copyright 2021 Inmanta
 
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
 
         http://www.apache.org/licenses/LICENSE-2.0
```

### Comparing `inmanta-core-8.7.4/src/inmanta_ext/core/extension.py` & `inmanta-core-9.3.0/src/inmanta_ext/core/extension.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_2way_protocol.py` & `inmanta-core-9.3.0/tests/test_2way_protocol.py`

 * *Files 8% similar despite different names*

```diff
@@ -11,18 +11,18 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-import asyncio
+
 import logging
-import time
 import uuid
+from typing import Set
 
 import pytest
 from pytest import fixture
 from tornado.gen import sleep
 
 # Methods need to be defined before the Client class is loaded by Python
 from inmanta import protocol  # NOQA
@@ -42,65 +42,53 @@
 
 
 @method(path="/status/<id>", operation="GET", server_agent=True, timeout=10)
 def get_agent_status_x(id: str):
     pass
 
 
-@method(path="/notify/<id>", operation="GET", server_agent=True, timeout=10, reply=False)
-def get_agent_push(id: str):
-    pass
-
-
 class SessionSpy(SessionListener, ServerSlice):
     def __init__(self):
         ServerSlice.__init__(self, "sessionspy")
         self.expires = 0
-        self._sessions = []
+        self.__sessions = []
 
-    async def new_session(self, session, endpoint_names_snapshot: set[str]):
-        self._sessions.append(session)
+    async def new_session(self, session, endpoint_names_snapshot: Set[str]):
+        self.__sessions.append(session)
 
     @protocol.handle(get_status_x)
     async def get_status_x(self, tid):
         status_list = []
-        for session in self._sessions:
+        for session in self.__sessions:
             client = session.get_client()
             status = await client.get_agent_status_x("x")
             if status is not None and status.code == 200:
                 status_list.append(status.result)
 
         return 200, {"agents": status_list}
 
-    async def expire(self, session, endpoint_names_snapshot: set[str]):
-        self._sessions.remove(session)
+    async def expire(self, session, endpoint_names_snapshot: Set[str]):
+        self.__sessions.remove(session)
         print(session._sid)
         self.expires += 1
 
     def get_sessions(self):
-        return self._sessions
+        return self.__sessions
 
 
 class Agent(protocol.SessionEndpoint):
     def __init__(self, name: str, timeout: int = 120, reconnect_delay: int = 5):
-        super().__init__(name, timeout, reconnect_delay)
+        super(Agent, self).__init__(name, timeout, reconnect_delay)
         self.reconnect = 0
         self.disconnect = 0
-        self.pushes = 0
 
     @protocol.handle(get_agent_status_x)
     async def get_agent_status_x(self, id):
         return 200, {"status": "ok", "agents": list(self.end_point_names)}
 
-    @protocol.handle(get_agent_push)
-    async def get_agent_push(self, id):
-        self.pushes += 1
-        LOGGER.debug("PUSH!")
-        await asyncio.sleep(1)
-
     async def on_reconnect(self) -> None:
         self.reconnect += 1
 
     async def on_disconnect(self) -> None:
         self.disconnect += 1
 
 
@@ -146,23 +134,14 @@
     status = await client.get_status_x(str(agent.environment))
     assert status.code == 200
     assert "agents" in status.result
     assert len(status.result["agents"]) == 1
     assert status.result["agents"][0]["status"], "ok"
     await server.stop()
 
-    # test no reply
-    for session in server._sessions:
-        client = session.get_client()
-        now = time.monotonic()
-        status = await client.get_agent_push("x")
-        duration = time.monotonic() - now
-        assert duration < 0.9  # less then built-in wait time
-        assert status.result is None
-
     await rs.stop()
     await agent.stop()
     await assert_agent_counter(agent, 1, 0)
 
 
 async def check_sessions(sessions):
     for s in sessions:
```

### Comparing `inmanta-core-8.7.4/tests/test_agent.py` & `inmanta-core-9.3.0/tests/test_agent.py`

 * *Files 5% similar despite different names*

```diff
@@ -196,7 +196,24 @@
     config.Config.set("config", "agent-names", "test123,test456")
     agent2 = await agent_factory(environment=env_id)
     assert sorted(list(agent2.get_end_point_names())) == sorted(["test123", "test456"])
 
     # When both are set, the constructor takes precedence
     agent3 = await agent_factory(hostname="node3", environment=env_id)
     assert list(agent3.get_end_point_names()) == ["node3"]
+
+
+async def test_update_agent_map(server, environment, agent_factory):
+    """
+    If the URI of an enabled agent changes, it should still be enabled after the change
+    """
+    env_id = uuid.UUID(environment)
+    agent_map = {"node1": "localhost"}
+
+    agent1 = await agent_factory(hostname="node1", environment=env_id, agent_map=agent_map)
+    assert agent1.agent_map == agent_map
+
+    agent1.unpause("node1")
+
+    await agent1._update_agent_map({"node1": "localhost2"})
+
+    assert agent1._instances["node1"].is_enabled()
```

### Comparing `inmanta-core-8.7.4/tests/test_agent_manager.py` & `inmanta-core-9.3.0/tests/test_agent_manager.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,38 +17,35 @@
 """
 import asyncio
 import datetime
 import logging
 import typing
 import uuid
 from asyncio import subprocess
-from typing import Optional
+from typing import Dict, List, Optional, Set, Tuple
 from unittest.mock import Mock
 from uuid import UUID, uuid4
 
 import pytest
-from tornado.httpclient import AsyncHTTPClient
 
 from inmanta import config, data
 from inmanta.agent import Agent, agent
 from inmanta.agent import config as agent_config
 from inmanta.config import Config
 from inmanta.const import AgentAction, AgentStatus
-from inmanta.protocol import Result, handle, typedmethod
-from inmanta.protocol.common import ReturnValue
-from inmanta.server import SLICE_AGENT_MANAGER, SLICE_AUTOSTARTED_AGENT_MANAGER, protocol
+from inmanta.protocol import Result
+from inmanta.server import SLICE_AGENT_MANAGER, SLICE_AUTOSTARTED_AGENT_MANAGER
 from inmanta.server.agentmanager import AgentManager, AutostartedAgentManager, SessionAction, SessionManager
-from inmanta.server.bootloader import InmantaBootloader
-from inmanta.server.protocol import ServerSlice, Session
+from inmanta.server.protocol import Session
 from utils import UNKWN, assert_equal_ish, retry_limited
 
 LOGGER = logging.getLogger(__name__)
 
 
-class Collector:
+class Collector(object):
     def __init__(self):
         self.values = []
 
     def __call__(self, arg):
         self.values.append(arg)
 
     async def proccess(self):
@@ -65,20 +62,20 @@
 async def api_call_future(*args, **kwargs) -> Result:
     """
     Mock implementation of Client methods
     """
     return Result(200, "X")
 
 
-class MockSession:
+class MockSession(object):
     """
     An environment that segments agents connected to the server
     """
 
-    def __init__(self, sid, tid, endpoint_names: set[str], nodename):
+    def __init__(self, sid, tid, endpoint_names: Set[str], nodename):
         self._sid = sid
         self.tid = tid
         self.endpoint_names = endpoint_names
         self.nodename = nodename
         self.client = Mock()
         self.client.set_state.side_effect = empty_future
         self.client.get_status = api_call_future
@@ -789,17 +786,17 @@
     project_id = result.result["project"]["id"]
 
     result = await client.create_environment(project_id=project_id, name="test1")
     env1_id = UUID(result.result["environment"]["id"])
     result = await client.create_environment(project_id=project_id, name="test2")
     env2_id = UUID(result.result["environment"]["id"])
 
-    env_to_agent_map: dict[UUID, agent.Agent] = {}
+    env_to_agent_map: Dict[UUID, agent.Agent] = {}
 
-    async def start_agent(env_id: UUID, agent_names: list[str]) -> None:
+    async def start_agent(env_id: UUID, agent_names: List[str]) -> None:
         for agent_name in agent_names:
             await data.Agent(environment=env_id, name=agent_name, paused=False).insert()
 
         agent_map = {agent_name: "localhost" for agent_name in agent_names}
         a = agent.Agent(hostname="node1", environment=env_id, agent_map=agent_map, code_loader=False)
         for agent_name in agent_names:
             await a.add_end_point_name(agent_name)
@@ -811,15 +808,15 @@
             agent: data.Agent = await data.Agent.get_one(environment=env_id, name=agent_name)
             return agent.primary is not None
 
         await asyncio.gather(*(retry_limited(has_primary, timeout=10, agent_name=agent_name) for agent_name in agent_names))
 
     await asyncio.gather(start_agent(env1_id, ["agent1", "agent2"]), start_agent(env2_id, ["agent1"]))
 
-    async def assert_agents_paused(expected_statuses: dict[tuple[UUID, str], bool]) -> None:
+    async def assert_agents_paused(expected_statuses: Dict[Tuple[UUID, str], bool]) -> None:
         async def _does_expected_status_match_actual_status() -> bool:
             for (env_id, agent_name), paused in expected_statuses.items():
                 # Check in-memory session state
                 live_session_found = (env_id, agent_name) in agent_manager.tid_endpoint_to_session
                 if live_session_found == paused:
                     LOGGER.info(
                         "live_session_found=%s for agent %s in environment %s, while expected paused state is %s",
@@ -911,15 +908,15 @@
         result = await client.all_agents_action(tid=env1_id, action=AgentAction.unpause.value)
         assert result.code == 200
         await assert_agents_paused(
             expected_statuses={(env1_id, "agent1"): False, (env1_id, "agent2"): False, (env2_id, "agent1"): False}
         )
 
     # set up for halt test
-    async def assert_agents_halt_state(env_id: UUID, agents_running: dict[str, bool], halted: bool) -> None:
+    async def assert_agents_halt_state(env_id: UUID, agents_running: Dict[str, bool], halted: bool) -> None:
         """
         :param agents_running: dictionary of agents that were running before environment halting.
         """
         for agent_name, running in agents_running.items():
             db_agent: data.Agent = await data.Agent.get_one(environment=env_id, name=agent_name)
             assert db_agent.unpause_on_resume is (running if halted else None)
 
@@ -986,20 +983,20 @@
 
     result = await client.agent_action(environment, name="agent1", action="unknown_action")
     assert result.code == 400
 
     result = await client.agent_action(environment, name="agent2", action=AgentAction.pause.value)
     assert result.code == 200
 
-    async def assert_agents_on_resume_state(agent_states: dict[str, Optional[bool]]) -> None:
+    async def assert_agents_on_resume_state(agent_states: Dict[str, Optional[bool]]) -> None:
         for agent_name, on_resume in agent_states.items():
             agent_from_db = await data.Agent.get_one(environment=env_id, name=agent_name)
             assert agent_from_db.unpause_on_resume is on_resume
 
-    async def assert_agents_paused_state(agent_states: dict[str, bool]) -> None:
+    async def assert_agents_paused_state(agent_states: Dict[str, bool]) -> None:
         for agent_name, paused in agent_states.items():
             agent_from_db = await data.Agent.get_one(environment=env_id, name=agent_name)
             assert agent_from_db.paused is paused
 
     await assert_agents_on_resume_state({"agent1": None, "agent2": None, "agent3": None})
     await assert_agents_paused_state({"agent1": False, "agent2": True, "agent3": False})
 
@@ -1187,15 +1184,15 @@
 async def test_error_handling_agent_fork(server, environment, monkeypatch):
     """
     Verifies resolution of issue: inmanta/inmanta-core#2777
     """
     exception_message = "The start of the agent failed"
 
     async def _dummy_fork_inmanta(
-        self, args: list[str], outfile: Optional[str], errfile: Optional[str], cwd: Optional[str] = None
+        self, args: List[str], outfile: Optional[str], errfile: Optional[str], cwd: Optional[str] = None
     ) -> subprocess.Process:
         raise Exception(exception_message)
 
     # Make the _fork_inmanta method raise an Exception
     monkeypatch.setattr(AutostartedAgentManager, "_fork_inmanta", _dummy_fork_inmanta)
 
     env = await data.Environment.get_by_id(UUID(environment))
@@ -1290,112 +1287,12 @@
     await agentmanager.ensure_agent_registered(env, "test1")
     await autostarted_agentmanager._ensure_agents(env, ["test1"])
 
     logdir = Config.get("config", "log-dir")
     log_file_path = f"{logdir}/agent-{environment}.log"  # Path to the log file
 
     def log_contains_debug_line():
-        with open(log_file_path) as f:
+        with open(log_file_path, mode="r") as f:
             log_content = f.read()
         return "DEBUG    inmanta.protocol.endpoints Start transport for client agent" in log_content
 
     await retry_limited(log_contains_debug_line, 10)
-
-
-async def test_heartbeat_different_session(server_pre_start, async_finalizer, caplog):
-    """
-    Verify that:
-      - if the max_clients is reached, the heartbeat will still work as it is in a different pool
-      - the max_clients option in the config changes the number of max_clients in a pool
-      - debug logs concerning 'max_clients limit reached' logged by Tornado, are logged as inmanta warnings.
-    """
-    caplog.set_level(logging.WARNING)
-    hanglock = asyncio.Event()
-
-    @typedmethod(
-        path="/test",
-        operation="GET",
-        client_types=["agent"],
-        agent_server=True,
-    )
-    def test_method(number: int) -> ReturnValue[int]:  # NOQA
-        """
-        api endpoint that never returns
-        """
-
-    class TestSlice(ServerSlice):
-        @handle(test_method)
-        async def test_method_implementation(self, number: int) -> ReturnValue[int]:  # NOQA
-            LOGGER.warning(f"HANG {number}")
-            await hanglock.wait()
-            return ReturnValue(response=number)
-
-    Config.set("agent_rest_transport", "max_clients", "1")
-
-    # This part is copied from the app.start_agent function. It needs to be called before the server starts.
-    # We need to be able to create an environment before we can create an agent which we can't do using the start_agent function
-    max_clients: int = Config.get("agent_rest_transport", "max_clients", "10")
-    AsyncHTTPClient.configure(None, max_clients=max_clients)
-
-    server = TestSlice(name="test_slice")
-
-    ibl = InmantaBootloader()
-    ctx = ibl.load_slices()
-
-    for mypart in ctx.get_slices():
-        ibl.restserver.add_slice(mypart)
-
-    ibl.restserver.add_slice(server)
-
-    await ibl.start()
-    async_finalizer.add(server.stop)
-    async_finalizer.add(ibl.stop)
-
-    client = protocol.Client("client")
-
-    result = await client.create_project("project-test")
-    assert result.code == 200
-    proj_id = result.result["project"]["id"]
-
-    result = await client.create_environment(proj_id, "test", None, None)
-    assert result.code == 200
-    env_id = result.result["environment"]["id"]
-    environment = await data.Environment.get_by_id(uuid.UUID(env_id))
-
-    agent_manager = ibl.restserver.get_slice(SLICE_AGENT_MANAGER)
-
-    a = Agent(hostname="node1", environment=environment.id, agent_map={"agent1": "localhost"}, code_loader=False)
-    await a.add_end_point_name("agent1")
-    await a.add_end_point_name("agent1")
-
-    async_finalizer.add(a.stop)
-    await a.start()
-
-    # Wait until session is created
-    await retry_limited(lambda: len(agent_manager.sessions) == 1, 10)
-
-    # Have many connections in flight
-    hangers = asyncio.gather(*(a._client.test_method(i) for i in range(5)))
-    logging.warning("WAITING!")
-    assert not hangers.done()
-
-    def did_exceed_capacity():
-        msg = "max_clients limit reached, request queued. 1 active, 2 queued requests."
-        for record in caplog.records:
-            if msg in record.message:
-                if record.name == "inmanta.protocol.endpoints" and record.levelno == logging.WARNING:
-                    return True
-        return False
-
-    await retry_limited(did_exceed_capacity, 10)
-
-    caplog.set_level(logging.NOTSET)
-    caplog.clear()
-
-    def still_sending_heartbeats():
-        count = caplog.text.count("Level 3 sending heartbeat for")
-        return count > 2
-
-    await retry_limited(still_sending_heartbeats, 10)
-
-    hanglock.set()
-    await hangers
```

### Comparing `inmanta-core-8.7.4/tests/test_app.py` & `inmanta-core-9.3.0/tests/test_app.py`

 * *Files 22% similar despite different names*

```diff
@@ -24,15 +24,14 @@
 from subprocess import TimeoutExpired
 from threading import Timer
 
 import pytest
 
 import inmanta.util
 from inmanta import const
-from inmanta.app import CompileSummaryReporter
 
 
 def get_command(
     tmp_dir,
     stdout_log_level=None,
     log_file=None,
     log_level_log_file=None,
@@ -309,15 +308,15 @@
     (args, log_dir) = get_command(tmpdir, log_file=log_file, log_level_log_file=log_level)
     if with_tty:
         (stdout, _, _) = run_with_tty(args)
     else:
         (stdout, _, _) = run_without_tty(args)
     assert log_file in os.listdir(log_dir)
     log_file = os.path.join(log_dir, log_file)
-    with open(log_file) as f:
+    with open(log_file, "r") as f:
         log_lines = f.readlines()
     check_logs(log_lines, regexes_required_lines, regexes_forbidden_lines, timed=True)
     check_logs(stdout, [], regexes_required_lines, timed=True)
     check_logs(stdout, [], regexes_required_lines, timed=False)
 
 
 @pytest.mark.parametrize_any(
@@ -372,18 +371,18 @@
 def check_logs(log_lines, regexes_required_lines, regexes_forbidden_lines, timed):
     compiled_regexes_requires_lines = get_compiled_regexes(regexes_required_lines, timed)
     compiled_regexes_forbidden_lines = get_compiled_regexes(regexes_forbidden_lines, timed)
     for line in log_lines:
         print(line)
     for regex in compiled_regexes_requires_lines:
         if not any(regex.match(line) for line in log_lines):
-            pytest.fail(f"Required pattern was not found in log lines: {regex.pattern}")
+            pytest.fail("Required pattern was not found in log lines: %s" % (regex.pattern,))
     for regex in compiled_regexes_forbidden_lines:
         if any(regex.match(line) for line in log_lines):
-            pytest.fail(f"Forbidden pattern found in log lines: {regex.pattern}")
+            pytest.fail("Forbidden pattern found in log lines: %s" % (regex.pattern,))
 
 
 def test_check_shutdown():
     process = do_run([sys.executable, os.path.join(os.path.dirname(__file__), "miniapp.py")])
     # wait for handler to be in place
     try:
         process.communicate(timeout=2)
@@ -437,29 +436,29 @@
     This test case is also used to test the caching (issue 3838)
     Since this is a basic smoke test for argument parsing, no assertion
     about the caching is done here.
     """
     snippetcompiler.setup_for_snippet(
         """
 entity Test:
-    int attr
+    number attr
 end
 
 implement Test using std::none
 
 o = Test(attr="1234")
         """
     )
     cwd = snippetcompiler.project_dir if cache_cf_files else "."
 
     output = (
         f"""Could not set attribute `attr` on instance `__config__::Test (instantiated at {cwd}/main.cf:8)` """
         f"""(reported in Construct(Test) ({cwd}/main.cf:8))
 caused by:
-  Invalid value '1234', expected int (reported in Construct(Test) ({cwd}/main.cf:8))
+  Invalid value '1234', expected Number (reported in Construct(Test) ({cwd}/main.cf:8))
 """
     )
 
     def exec(*cmd):
         process = do_run([sys.executable, "-m", "inmanta.app"] + list(cmd), cwd=snippetcompiler.project_dir)
         _, err = process.communicate(timeout=30)
         assert output in err.decode()
@@ -507,15 +506,15 @@
 
 @pytest.mark.timeout(20)
 def test_warning_min_c_option_file_doesnt_exist(snippetcompiler, tmpdir):
     non_existing_config_file = os.path.join(tmpdir, "non_existing_config_file")
     snippetcompiler.setup_for_snippet(
         """
 entity Test:
-    int attr
+    number attr
 end
 """
     )
     config_options = ["-c", non_existing_config_file, "-vvv"]
     args = [sys.executable, "-m", "inmanta.app"] + config_options + ["compile"]
     process = do_run(args, cwd=snippetcompiler.project_dir)
     out, err = process.communicate(timeout=30)
@@ -555,62 +554,7 @@
     (stdout, stderr, return_code) = run_without_tty(args, killtime=15, termtime=10)
     test_project_path = os.path.join(tmpdir, "test-project")
     assert return_code == 0
     assert os.path.exists(test_project_path)
     (stdout, stderr, return_code) = run_without_tty(args, killtime=15, termtime=10)
     assert return_code != 0
     assert any("already exists" in error for error in stderr)
-
-
-def test_compiler_summary_reporter(capsys) -> None:
-    """
-    Test whether the CompileSummaryReporter class produces correct output.
-    """
-    # Success
-    summary_reporter = CompileSummaryReporter()
-    with summary_reporter.compiler_exception.capture():
-        pass
-    assert not summary_reporter.is_failure()
-    summary_reporter.print_summary(show_stack_traces=True)
-    assert re.match(r"\n=+ SUCCESS =+\n", capsys.readouterr().err)
-
-    # Compile failure
-    summary_reporter = CompileSummaryReporter()
-    with summary_reporter.compiler_exception.capture():
-        raise Exception("This is a compilation failure")
-    assert summary_reporter.is_failure()
-    summary_reporter.print_summary(show_stack_traces=False)
-    output = capsys.readouterr().err
-    assert re.match(r"\n=+ COMPILATION FAILURE =+\nError: This is a compilation failure\n", output)
-    assert "= EXCEPTION TRACE =" not in output
-    summary_reporter.print_summary(show_stack_traces=True)
-    output = capsys.readouterr().err
-    assert re.match(
-        r"\n=+ EXCEPTION TRACE =+\n(.|\n)*\n=+ COMPILATION FAILURE =+\nError: This is a compilation failure\n", output
-    )
-
-    # Compile failure and export failure
-    summary_reporter = CompileSummaryReporter()
-    with summary_reporter.compiler_exception.capture():
-        raise Exception("This is a compilation failure")
-    with summary_reporter.exporter_exception.capture():
-        raise Exception("This is an export failure")
-    assert summary_reporter.is_failure()
-    summary_reporter.print_summary(show_stack_traces=False)
-    output = capsys.readouterr().err
-    assert re.match(r"\n=+ COMPILATION FAILURE =+\nError: This is a compilation failure\n", output)
-    assert "= EXCEPTION TRACE =" not in output
-
-    # Export failure
-    summary_reporter = CompileSummaryReporter()
-    with summary_reporter.compiler_exception.capture():
-        pass
-    with summary_reporter.exporter_exception.capture():
-        raise Exception("This is an export failure")
-    assert summary_reporter.is_failure()
-    summary_reporter.print_summary(show_stack_traces=False)
-    output = capsys.readouterr().err
-    assert re.match(r"\n=+ EXPORT FAILURE =+\nError: This is an export failure\n", output)
-    assert "= EXCEPTION TRACE =" not in output
-    summary_reporter.print_summary(show_stack_traces=True)
-    output = capsys.readouterr().err
-    assert re.match(r"\n=+ EXCEPTION TRACE =+\n(.|\n)*\n=+ EXPORT FAILURE =+\nError: This is an export failure\n", output)
```

### Comparing `inmanta-core-8.7.4/tests/test_app_cli.py` & `inmanta-core-9.3.0/tests/test_app_cli.py`

 * *Files 19% similar despite different names*

```diff
@@ -14,30 +14,27 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import asyncio
 import os
-import re
 import shutil
 import sys
-import textwrap
 from asyncio import subprocess
 
 import py
 import pytest
 
 from inmanta import env
 from inmanta.app import cmd_parser
 from inmanta.command import ShowUsageException
 from inmanta.compiler.config import feature_compiler_cache
 from inmanta.config import Config
 from inmanta.const import VersionState
-from utils import v1_module_from_template
 
 
 def app(args):
     parser = cmd_parser()
 
     options, other = parser.parse_known_args(args=args)
     options.other = other
@@ -65,24 +62,22 @@
         "project",
         "install",
     ]
     process = await subprocess.create_subprocess_exec(
         *args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=str(project_dir)
     )
     try:
-        (stdout, stderr) = await asyncio.wait_for(process.communicate(), timeout=30)
+        await asyncio.wait_for(process.communicate(), timeout=30)
     except asyncio.TimeoutError as e:
         process.kill()
         (stdout, stderr) = await process.communicate()
         print(stdout.decode())
         print(stderr.decode())
         raise e
 
-    assert process.returncode == 0, f"{stdout}\n\n{stderr}"
-
 
 def test_help(inmanta_config, capsys):
     with pytest.raises(SystemExit):
         app(["-h"])
     out, _ = capsys.readouterr()
 
     assert out.startswith("usage:")
@@ -442,135 +437,7 @@
     except asyncio.TimeoutError as e:
         process.kill()
         await process.communicate()
         raise e
 
     assert process.returncode == 1
     assert "The --delete-resource-set option should always be used together with the --partial option" in stderr.decode("utf-8")
-
-
-@pytest.mark.parametrize("set_keep_logger_names_option", [True, False])
-async def test_logger_name_in_compiler_exporter_output(
-    server,
-    environment: str,
-    tmpvenv_active_inherit: env.VirtualEnv,
-    modules_dir: str,
-    tmpdir,
-    monkeypatch,
-    set_keep_logger_names_option: bool,
-) -> None:
-    """
-    This test case verifies that the logger name mentioned in the log of the compile/export command is correct. Namely:
-
-    * compiler: For log lines produced by the compiler.
-    * exporter: For log lines produced by the exporter.
-    * <name-of-module>: For log lines produced by a specific module and the name of the logger was set to __name__.
-    """
-    v1_template_path: str = os.path.join(modules_dir, "minimalv1module")
-    mod_name = "mymod"
-    libs_dir = os.path.join(tmpdir, "libs")
-    v1_module_from_template(
-        source_dir=v1_template_path,
-        dest_dir=os.path.join(libs_dir, mod_name),
-        new_name=mod_name,
-        new_content_init_cf="",
-        new_content_init_py=textwrap.dedent(
-            """
-                from inmanta.plugins import plugin
-                import logging
-
-                LOGGER = logging.getLogger(__name__)
-
-                @plugin
-                def test_plugin():
-                    LOGGER.info("test")
-            """,
-        ),
-    )
-
-    path_project_yml_file = tmpdir.join("project.yml")
-    path_project_yml_file.write(
-        textwrap.dedent(
-            f"""
-                name: testproject
-                modulepath: {libs_dir}
-                downloadpath: {libs_dir}
-                repo: https://github.com/inmanta/
-            """
-        )
-    )
-
-    path_main_cf = tmpdir.join("main.cf")
-    path_main_cf.write(
-        textwrap.dedent(
-            """
-                import mymod
-                mymod::test_plugin()
-            """
-        )
-    )
-
-    await install_project(python_env=tmpvenv_active_inherit, project_dir=tmpdir)
-
-    # Compile command
-    args = [
-        tmpvenv_active_inherit.python_path,
-        "-m",
-        "inmanta.app",
-        "-vvv",
-        *(["--keep-logger-names"] if set_keep_logger_names_option else []),
-        "compile",
-    ]
-    process = await subprocess.create_subprocess_exec(
-        *args, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.STDOUT, cwd=tmpdir
-    )
-    try:
-        (stdout, _) = await asyncio.wait_for(process.communicate(), timeout=30)
-    except asyncio.TimeoutError as e:
-        process.kill()
-        await process.communicate()
-        raise e
-
-    stdout = stdout.decode("utf-8")
-    assert process.returncode == 0, f"Process ended with bad return code, got {process.returncode} (expected 0): {stdout}"
-    if set_keep_logger_names_option:
-        assert "inmanta.compiler         DEBUG   Starting compile" in stdout
-        assert "inmanta_plugins.mymod    INFO    test" in stdout
-    else:
-        assert "compiler       DEBUG   Starting compile" in stdout
-        assert "mymod          INFO    test" in stdout
-
-    # Export command
-    server_port = Config.get("client_rest_transport", "port")
-    server_host = Config.get("client_rest_transport", "host", "localhost")
-    args = [
-        tmpvenv_active_inherit.python_path,
-        "-m",
-        "inmanta.app",
-        "-vvv",
-        *(["--keep-logger-names"] if set_keep_logger_names_option else []),
-        "export",
-    ]
-    args.extend(["--server_port", str(server_port)])
-    args.extend(["--server_address", str(server_host)])
-    args.extend(["-e", environment])
-
-    process = await subprocess.create_subprocess_exec(
-        *args, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.STDOUT, cwd=tmpdir
-    )
-    try:
-        (stdout, _) = await asyncio.wait_for(process.communicate(), timeout=30)
-    except asyncio.TimeoutError as e:
-        process.kill()
-        await process.communicate()
-        raise e
-
-    stdout = stdout.decode("utf-8")
-    assert process.returncode == 0, f"Process ended with bad return code, got {process.returncode} (expected 0): {stdout}"
-    if set_keep_logger_names_option:
-        assert "inmanta.compiler         DEBUG   Starting compile" in stdout
-        assert "inmanta_plugins.mymod    INFO    test" in stdout
-        assert re.search("inmanta.export[ ]+INFO[ ]+Committed resources with version 1", stdout)
-    else:
-        assert re.search("^compiler[ ]*DEBUG[ ]+Starting compile", stdout)
-        assert "mymod          INFO    test" in stdout
-        assert re.search("\nexporter[ ]+INFO[ ]+Committed resources with version 1", stdout)
```

### Comparing `inmanta-core-8.7.4/tests/test_cache.py` & `inmanta-core-9.3.0/tests/test_cache.py`

 * *Files 1% similar despite different names*

```diff
@@ -138,15 +138,15 @@
 
     assert value, cache.find("testx", resource=resource)
     with pytest.raises(KeyError):
         assert value == cache.find("test", version=version)
 
 
 def test_multi_threaded():
-    class Spy:
+    class Spy(object):
         def __init__(self):
             self.created = 0
             self.deleted = 0
             self.lock = Lock()
 
         def create(self):
             with self.lock:
@@ -287,15 +287,15 @@
 def test_get_or_else_none():
     called = []
 
     def creator(param, resource, version):
         called.append("x")
         return param
 
-    class Sequencer:
+    class Sequencer(object):
         def __init__(self, sequence):
             self.seq = sequence
             self.count = 0
 
         def __call__(self, **kwargs):
             out = self.seq[self.count]
             self.count += 1
@@ -336,15 +336,15 @@
             self.closed = True
 
     my_closable = Closeable()
     my_closable_2 = Closeable()
 
     xcache = AgentCache()
 
-    class DT:
+    class DT(object):
         def __init__(self, cache):
             self.cache = cache
             self.count = 0
             self.c2 = 0
             self.c3 = 0
 
         @cache()
```

### Comparing `inmanta-core-8.7.4/tests/test_cli.py` & `inmanta-core-9.3.0/tests/test_cli.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,14 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import datetime
 import os
 import uuid
+from typing import Dict
 
 import pytest
 
 from inmanta import data
 from inmanta.const import Change, ResourceAction, ResourceState
 from inmanta.util import get_compiler_version
 from utils import get_resource
@@ -112,15 +113,15 @@
 
     os.chdir(tmpdir)
     result = await cli.run("environment", "save", env_name)
     assert result.exit_code == 0
 
     path_dot_inmanta_file = os.path.join(tmpdir, ".inmanta")
     assert os.path.isfile(path_dot_inmanta_file)
-    with open(path_dot_inmanta_file, encoding="utf-8") as f:
+    with open(path_dot_inmanta_file, "r", encoding="utf-8") as f:
         file_content = f.read()
         assert f"environment={env_id}" in file_content
 
 
 async def test_environment_recompile(server, environment, client, cli):
     result = await client.get_compile_reports(environment)
     assert result.code == 200
@@ -255,33 +256,33 @@
     result = await client.create_project("test")
     assert result.code == 200
 
     result = await cli.run("environment", "create", "-n", "test-env-0", "-p", "test", "--save")
     assert result.exit_code == 0
     assert os.path.exists(file_path)
 
-    with open(file_path) as inmanta_file:
+    with open(file_path, "r") as inmanta_file:
         file_content_0 = inmanta_file.read()
     ctime_0 = os.path.getctime(file_path)
 
     result = await cli.run("environment", "create", "-n", "test-env-1", "-p", "test", "--save", input="n")
     assert result.exit_code == 0
 
-    with open(file_path) as inmanta_file:
+    with open(file_path, "r") as inmanta_file:
         file_content_1 = inmanta_file.read()
 
     ctime_1 = os.path.getctime(file_path)
 
     assert file_content_0 == file_content_1
     assert ctime_0 == ctime_1
 
     result = await cli.run("environment", "create", "-n", "test-env-2", "-p", "test", "--save", input="y")
     assert result.exit_code == 0
 
-    with open(file_path) as inmanta_file:
+    with open(file_path, "r") as inmanta_file:
         file_content_2 = inmanta_file.read()
 
     ctime_2 = os.path.getctime(file_path)
 
     assert file_content_0 != file_content_2
     assert ctime_0 != ctime_2
 
@@ -299,15 +300,15 @@
     env2 = data.Environment(name="env2", project=project.id)
     await env2.insert()
 
     await data.Agent(environment=env1.id, name="agent1", paused=False).insert()
     await data.Agent(environment=env1.id, name="agent2", paused=False).insert()
     await data.Agent(environment=env2.id, name="agent3", paused=False).insert()
 
-    async def assert_agent_paused(env_id: uuid.UUID, expected_records: dict[str, bool]) -> None:
+    async def assert_agent_paused(env_id: uuid.UUID, expected_records: Dict[str, bool]) -> None:
         result = await cli.run("agent", "list", "-e", str(env_id))
         assert result.exit_code == 0
         output = result.stdout.replace(" ", "")
         assert "Agent|Environment|Paused" in output
         for agent_name, paused in expected_records.items():
             assert f"{agent_name}|{env_id}|{paused}" in output
```

### Comparing `inmanta-core-8.7.4/tests/test_compilation.py` & `inmanta-core-9.3.0/tests/test_compilation.py`

 * *Files 2% similar despite different names*

```diff
@@ -76,15 +76,15 @@
         firsts.append(first)
         for other in v[1:]:
             assert first[2] == other[2]
 
     for i in range(len(firsts)):
         for j in range(len(firsts)):
             if not i == j:
-                assert firsts[i][2] != firsts[j][2], "Variable {}{} should not be equal to {}{}".format(
+                assert firsts[i][2] != firsts[j][2], "Variable %s%s should not be equal to %s%s" % (
                     firsts[i][0],
                     firsts[i][1],
                     firsts[j][0],
                     firsts[j][1],
                 )
```

### Comparing `inmanta-core-8.7.4/tests/test_compiler_entrypoints.py` & `inmanta-core-9.3.0/tests/test_compiler_entrypoints.py`

 * *Files 14% similar despite different names*

```diff
@@ -189,15 +189,15 @@
         if location.file == os.path.join(snippetcompiler.project_dir, "main.cf")
     )
     assert location.lnr == 4
     assert location.start_char == 5
     assert location.end_lnr == 4
     assert location.end_char == 18
     assert resolves_to.location.file == os.path.join(snippetcompiler.modules_dir, "tests", "plugins", "__init__.py")
-    assert resolves_to.location.lnr == 14
+    assert resolves_to.location.lnr == 13
 
 
 def test_get_types_and_scopes(snippetcompiler):
     """
     Test the get_types_and_scopes() entrypoint of the compiler.
     """
     snippetcompiler.setup_for_snippet(
@@ -305,78 +305,7 @@
     verify_anchor(15, 5, 16, None)
     verify_anchor(17, 22, 26, "this is a test entity")
     verify_anchor(20, 22, 33, None)
     verify_anchor(23, 22, 23, None)
     verify_anchor(23, 11, 15, "this is a test entity")
     verify_anchor(24, 29, 30, None)
     verify_anchor(24, 11, 22, None)
-
-
-def test_constructor_with_inferred_namespace(snippetcompiler):
-    """
-    Test that the anchor for a constructor for an entity with an inferred namespace is correctly added to the anchormap
-    The test checks if the anchormap correctly reflects the relationship between the
-    source range (where the entity is instantiated: line 9 in main.cf) and the target range (where the
-    entity is defined: line 1 in the _init.cf file of the tests module)
-    """
-
-    module: str = "tests"
-    target_path = os.path.join(os.path.dirname(__file__), "data", "modules", module, "model", "_init.cf")
-
-    snippetcompiler.setup_for_snippet(
-        """
-    import mod1
-    import tests
-    entity A:
-    end
-
-    A.mytest [1] -- tests::Test [1]
-
-    A(mytest = Test())
-    """,
-        autostd=False,
-    )
-
-    compiler = Compiler()
-    (statements, blocks) = compiler.compile()
-    sched = scheduler.Scheduler()
-
-    anchormap = sched.anchormap(compiler, statements, blocks)
-    assert len(anchormap) == 5
-    range_source = Range(os.path.join(snippetcompiler.project_dir, "main.cf"), 9, 16, 9, 20)
-    range_target = Range(target_path, 1, 8, 1, 12)
-
-    assert (range_source, range_target) in anchormap
-
-
-def test_constructor_renamed_namespace(snippetcompiler):
-    """
-    Test that the anchor for a constructor with `import a as b` works
-    """
-
-    module: str = "tests"
-    target_path = os.path.join(os.path.dirname(__file__), "data", "modules", module, "model", "subpack", "submod.cf")
-
-    snippetcompiler.setup_for_snippet(
-        """
-    import mod1
-    import tests::subpack::submod as t
-    entity A:
-    end
-
-    A.mytest [1] -- t::Test [1]
-
-    A(mytest = t::Test())
-    """,
-        autostd=False,
-    )
-
-    compiler = Compiler()
-    (statements, blocks) = compiler.compile()
-    sched = scheduler.Scheduler()
-
-    anchormap = sched.anchormap(compiler, statements, blocks)
-    assert len(anchormap) == 5
-    range_source = Range(os.path.join(snippetcompiler.project_dir, "main.cf"), 9, 16, 9, 23)
-    range_target = Range(target_path, 1, 8, 1, 12)
-
-    assert (range_source, range_target) in anchormap
```

### Comparing `inmanta-core-8.7.4/tests/test_config.py` & `inmanta-core-9.3.0/tests/test_config.py`

 * *Files 2% similar despite different names*

```diff
@@ -35,28 +35,28 @@
     for deprecated_option, new_option in [
         (cfg.agent_interval, cfg.agent_deploy_interval),
         (cfg.agent_splay, cfg.agent_deploy_splay_time),
     ]:
         Config.set(deprecated_option.section, deprecated_option.name, "22")
         caplog.clear()
         assert new_option.get() == 22
-        assert f"Config option {deprecated_option.name} is deprecated. Use {new_option.name} instead." in caplog.text
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option.name, new_option.name) in caplog.text
 
         Config.set(new_option.section, new_option.name, "23")
         caplog.clear()
         assert new_option.get() == 23
-        assert f"Config option {deprecated_option.name} is deprecated. Use {new_option.name} instead." not in caplog.text
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option.name, new_option.name) not in caplog.text
 
         Config.load_config()  # Reset config options to default values
         assert new_option.get() != 23
         assert deprecated_option.get() != 23
         Config.set(new_option.section, new_option.name, "24")
         caplog.clear()
         assert new_option.get() == 24
-        assert f"Config option {deprecated_option.name} is deprecated. Use {new_option.name} instead." not in caplog.text
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option.name, new_option.name) not in caplog.text
 
 
 def test_options():
     configa = Option("test", "a", "markerA", "test a docs")
     configb = Option("test", "B", option_as_default(configa), "test b docs")
 
     assert "test.a" in configb.get_default_desc()
```

### Comparing `inmanta-core-8.7.4/tests/test_const.py` & `inmanta-core-9.3.0/tests/test_const.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_data.py` & `inmanta-core-9.3.0/tests/test_data.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,16 +19,15 @@
 import datetime
 import enum
 import json
 import logging
 import time
 import uuid
 from collections import abc
-from datetime import timezone
-from typing import Optional, cast
+from typing import Dict, List, Optional, Type, cast
 
 import asyncpg
 import pytest
 from asyncpg import Connection, ForeignKeyViolationError
 from asyncpg.pool import Pool
 
 import utils
@@ -106,15 +105,15 @@
     assert len(records) == 0
 
 
 async def test_db_schema_enum_consistency(init_dataclasses_and_load_schema) -> None:
     """
     Verify that enumeration fields defined in data document objects match values defined in the db schema.
     """
-    all_db_document_classes: abc.Set[type[data.BaseDocument]] = utils.get_all_subclasses(data.BaseDocument) - {
+    all_db_document_classes: abc.Set[Type[data.BaseDocument]] = utils.get_all_subclasses(data.BaseDocument) - {
         data.BaseDocument
     }
     for cls in all_db_document_classes:
         enums: abc.Mapping[str, data.Field] = {
             name: field for name, field in cls.get_field_metadata().items() if issubclass(field.field_type, enum.Enum)
         }
         for enum_column, field in enums.items():
@@ -344,15 +343,15 @@
             await data.Resource.get_one(environment=environment, resource_id=id.resource_str(), model=id.version)
         ) is not None
     assert await data.ResourceAction.get_by_id(resource_action.action_id) is not None
     assert (await data.Code.get_one(environment=code.environment, resource=code.resource, version=code.version)) is not None
     assert (await data.UnknownParameter.get_by_id(unknown_parameter.id)) is not None
     assert (await env.get(data.AUTO_DEPLOY)) is True
 
-    await env.clear()
+    await env.delete_cascade(only_content=True)
 
     assert (await data.Project.get_by_id(project.id)) is not None
     assert (await data.Environment.get_by_id(env.id)) is not None
     assert (await data.AgentProcess.get_one(sid=agent_proc.sid)) is None
     assert (await data.AgentInstance.get_by_id(agi1.id)) is None
     assert (await data.AgentInstance.get_by_id(agi2.id)) is None
     assert (await data.Agent.get_one(environment=agent.environment, name=agent.name)) is None
@@ -394,15 +393,15 @@
     """
     # Create project and environment
     project = data.Project(name="proj")
     await project.insert()
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
     await env.insert()
 
-    async def assert_setting_in_db(expected_autostart_agent_map: dict[str, object]) -> None:
+    async def assert_setting_in_db(expected_autostart_agent_map: Dict[str, object]) -> None:
         """
         Verify that the state of the setting.autostart_agent_map setting in the database matches the given
         expected_autostart_agent_map dictionary.
         """
         async with data.Environment.get_connection() as connection:
             query = f"SELECT setting->'{data.AUTOSTART_AGENT_MAP}' FROM {data.Environment.table_name()} WHERE id=$1"
             result = await connection.fetchval(query, env.id)
@@ -425,32 +424,32 @@
 async def test_environment_deprecated_setting(init_dataclasses_and_load_schema, caplog):
     project = data.Project(name="proj")
     await project.insert()
 
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
     await env.insert()
 
-    for deprecated_option, new_option, old_value, new_value in [
-        (data.AUTOSTART_AGENT_INTERVAL, data.AUTOSTART_AGENT_DEPLOY_INTERVAL, 22, "23"),
-        (data.AUTOSTART_SPLAY, data.AUTOSTART_AGENT_DEPLOY_SPLAY_TIME, 22, 23),
+    for deprecated_option, new_option in [
+        (data.AUTOSTART_AGENT_INTERVAL, data.AUTOSTART_AGENT_DEPLOY_INTERVAL),
+        (data.AUTOSTART_SPLAY, data.AUTOSTART_AGENT_DEPLOY_SPLAY_TIME),
     ]:
-        await env.set(deprecated_option, old_value)
+        await env.set(deprecated_option, 22)
         caplog.clear()
-        assert (await env.get(new_option)) == old_value
-        assert f"Config option {deprecated_option} is deprecated. Use {new_option} instead." in caplog.text
+        assert (await env.get(new_option)) == 22
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option, new_option) in caplog.text
 
-        await env.set(new_option, new_value)
+        await env.set(new_option, 23)
         caplog.clear()
-        assert (await env.get(new_option)) == new_value
-        assert f"Config option {deprecated_option} is deprecated. Use {new_option} instead." not in caplog.text
+        assert (await env.get(new_option)) == 23
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option, new_option) not in caplog.text
 
         await env.unset(deprecated_option)
         caplog.clear()
-        assert (await env.get(new_option)) == new_value
-        assert f"Config option {deprecated_option} is deprecated. Use {new_option} instead." not in caplog.text
+        assert (await env.get(new_option)) == 23
+        assert "Config option %s is deprecated. Use %s instead." % (deprecated_option, new_option) not in caplog.text
 
 
 async def test_agent_process(init_dataclasses_and_load_schema):
     project = data.Project(name="test")
     await project.insert()
 
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
@@ -513,15 +512,15 @@
     await env1.insert()
     env2 = data.Environment(name="env2", project=project.id, repo_url="", repo_branch="")
     await env2.insert()
 
     now = datetime.datetime.now()
 
     async def insert_agent_proc_and_instances(
-        env_id: uuid.UUID, hostname: str, expired_proc: Optional[datetime.datetime], expired_instances: list[datetime.datetime]
+        env_id: uuid.UUID, hostname: str, expired_proc: Optional[datetime.datetime], expired_instances: List[datetime.datetime]
     ) -> None:
         agent_proc = data.AgentProcess(hostname=hostname, environment=env_id, expired=expired_proc, sid=uuid.uuid4())
         await agent_proc.insert()
         for i in range(len(expired_instances)):
             agent_instance = data.AgentInstance(
                 id=uuid.uuid4(), process=agent_proc.sid, name=f"agent_instance{i}", expired=expired_instances[i], tid=env_id
             )
@@ -747,15 +746,15 @@
     await env2.insert()
 
     await data.Agent(environment=env1.id, name="agent1", last_failover=datetime.datetime.now(), paused=False).insert()
     await data.Agent(environment=env1.id, name="agent2", last_failover=datetime.datetime.now(), paused=False).insert()
     await data.Agent(environment=env2.id, name="agent3", last_failover=datetime.datetime.now(), paused=False).insert()
     agents_in_env1 = ["agent1", "agent2"]
 
-    async def assert_paused(env_paused_map: dict[uuid.UUID, bool]) -> None:
+    async def assert_paused(env_paused_map: Dict[uuid.UUID, bool]) -> None:
         for env_id, paused in env_paused_map.items():
             agents = await data.Agent.get_list(environment=env_id)
             assert all([a.paused == paused for a in agents])
 
     # Test initial state
     await assert_paused(env_paused_map={env1.id: False, env2.id: False})
     # Pause env1 and pause again
@@ -1199,163 +1198,14 @@
     res4 = get_resource(4, [3])
     await res4.insert()
 
     res5 = get_resource(5, [4])
     await res5.insert()
 
 
-async def test_resource_purge_on_delete(init_dataclasses_and_load_schema):
-    project = data.Project(name="test")
-    await project.insert()
-
-    env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
-    await env.insert()
-
-    # model 1
-    version = 1
-    cm1 = data.ConfigurationModel(
-        environment=env.id,
-        version=version,
-        date=datetime.datetime.now(),
-        total=2,
-        version_info={},
-        released=True,
-        deployed=True,
-        is_suitable_for_partial_compiles=False,
-    )
-    await cm1.insert()
-
-    res11 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/motd],v=%s" % version,
-        status=const.ResourceState.deployed,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-    )
-    await res11.insert()
-
-    res12 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent2,path=/etc/motd],v=%s" % version,
-        status=const.ResourceState.deployed,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": True},
-    )
-    await res12.insert()
-
-    # model 2 (multiple undeployed versions)
-    while version < 10:
-        version += 1
-        cm2 = data.ConfigurationModel(
-            environment=env.id,
-            version=version,
-            date=datetime.datetime.now(),
-            total=1,
-            version_info={},
-            released=False,
-            deployed=False,
-            is_suitable_for_partial_compiles=False,
-        )
-        await cm2.insert()
-
-        res21 = data.Resource.new(
-            environment=env.id,
-            resource_version_id="std::File[agent5,path=/etc/motd],v=%s" % version,
-            status=const.ResourceState.available,
-            attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-        )
-        await res21.insert()
-
-    # model 3
-    version += 1
-    cm3 = data.ConfigurationModel(
-        environment=env.id,
-        version=version,
-        date=datetime.datetime.now(),
-        total=0,
-        version_info={},
-        is_suitable_for_partial_compiles=False,
-    )
-    await cm3.insert()
-
-    to_purge = await data.Resource.get_deleted_resources(env.id, version, set())
-
-    assert len(to_purge) == 1
-    assert to_purge[0].model == 1
-    assert to_purge[0].resource_id == "std::File[agent1,path=/etc/motd]"
-
-
-async def test_issue_422(init_dataclasses_and_load_schema):
-    project = data.Project(name="test")
-    await project.insert()
-
-    env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
-    await env.insert()
-
-    # model 1
-    version = 1
-    cm1 = data.ConfigurationModel(
-        environment=env.id,
-        version=version,
-        date=datetime.datetime.now(),
-        total=1,
-        version_info={},
-        released=True,
-        deployed=True,
-        is_suitable_for_partial_compiles=False,
-    )
-    await cm1.insert()
-
-    res11 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/motd],v=%s" % version,
-        status=const.ResourceState.deployed,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-    )
-    await res11.insert()
-
-    # model 2 (multiple undeployed versions)
-    version += 1
-    cm2 = data.ConfigurationModel(
-        environment=env.id,
-        version=version,
-        date=datetime.datetime.now(),
-        total=1,
-        version_info={},
-        released=False,
-        deployed=False,
-        is_suitable_for_partial_compiles=False,
-    )
-    await cm2.insert()
-
-    res21 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/motd],v=%s" % version,
-        status=const.ResourceState.available,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-    )
-    await res21.insert()
-
-    # model 3
-    version += 1
-    cm3 = data.ConfigurationModel(
-        environment=env.id,
-        version=version,
-        date=datetime.datetime.now(),
-        total=0,
-        version_info={},
-        is_suitable_for_partial_compiles=False,
-    )
-    await cm3.insert()
-
-    to_purge = await data.Resource.get_deleted_resources(env.id, version, set())
-
-    assert len(to_purge) == 1
-    assert to_purge[0].model == 1
-    assert to_purge[0].resource_id == "std::File[agent1,path=/etc/motd]"
-
-
 async def test_get_latest_resource(init_dataclasses_and_load_schema, postgresql_client):
     project = data.Project(name="test")
     await project.insert()
 
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
     await env.insert()
 
@@ -1807,98 +1657,25 @@
 
     assert res1.attribute_hash is not None
     assert res1.attribute_hash == res2.attribute_hash
     assert res3.attribute_hash is not None
     assert res1.attribute_hash != res3.attribute_hash
 
 
-async def test_resource_copy_last_success(init_dataclasses_and_load_schema):
-    project = data.Project(name="test")
-    await project.insert()
-
-    env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
-    await env.insert()
-
-    marker_date = datetime.datetime(1987, 12, 3, 15, 23, 36, 0, tzinfo=timezone.utc)
-
-    for version in range(1, 5):
-        cm1 = data.ConfigurationModel(
-            environment=env.id,
-            version=version,
-            date=datetime.datetime.now(),
-            total=1,
-            version_info={},
-            released=(version == 2),
-            deployed=True,
-            is_suitable_for_partial_compiles=False,
-        )
-        await cm1.insert()
-
-    res1 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/file1],v=1",
-        status=const.ResourceState.deployed,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-    )
-    res2 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/file1],v=2",
-        status=const.ResourceState.deployed,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": False},
-        last_success=marker_date,
-    )
-    res3 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/file1],v=3",
-        status=const.ResourceState.available,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": True},
-    )
-    res4 = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/file1],v=4",
-        status=const.ResourceState.available,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": True},
-    )
-
-    side_res = data.Resource.new(
-        environment=env.id,
-        resource_version_id="std::File[agent1,path=/etc/file2],v=3",
-        status=const.ResourceState.available,
-        attributes={"path": "/etc/motd", "purge_on_delete": True, "purged": True},
-    )
-
-    await res1.insert()
-    await res2.insert()
-    await res3.insert()
-    await res4.insert()
-    await side_res.insert()
-
-    await data.Resource.copy_last_success(env.id, 2, 3)
-
-    readres = await data.Resource.get(env.id, res3.resource_version_id)
-    assert readres.last_success == marker_date
-
-    readres = await data.Resource.get(env.id, res4.resource_version_id)
-    assert readres.last_success is None
-
-    readres = await data.Resource.get(env.id, side_res.resource_version_id)
-    assert readres.last_success is None
-
-
 async def test_get_resource_type_count_for_latest_version(init_dataclasses_and_load_schema):
     """
     Test for the get_resource_type_count_for_latest_version query
     """
     project = data.Project(name="test")
     await project.insert()
 
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
     await env.insert()
 
-    async def assert_expected_count(expected_report: dict[str, int]):
+    async def assert_expected_count(expected_report: Dict[str, int]):
         # Checks the expected_report against the actual one
         report = await data.Resource.get_resource_type_count_for_latest_version(env.id)
         assert report == expected_report
 
     # model 1
     version = 1
     cm1 = data.ConfigurationModel(
@@ -3219,15 +2996,15 @@
 
     env = data.Environment(name="dev", project=project.id, repo_url="", repo_branch="")
     await env.insert()
 
     async def assert_last_non_deploying_state(
         environment: uuid.UUID,
         resource_version_id: ResourceVersionIdStr,
-        expected_states: dict[ResourceVersionIdStr, const.ResourceState],
+        expected_states: Dict[ResourceVersionIdStr, const.ResourceState],
     ) -> None:
         rvid_to_resource_state = await data.Resource.get_last_non_deploying_state_for_dependencies(
             environment=environment, resource_version_id=Id.parse_id(resource_version_id)
         )
         assert expected_states == rvid_to_resource_state
 
     # V1
```

### Comparing `inmanta-core-8.7.4/tests/test_data_concurrency.py` & `inmanta-core-9.3.0/tests/test_data_concurrency.py`

 * *Files 6% similar despite different names*

```diff
@@ -11,39 +11,38 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from utils import get_resource
 
 """
 This module contains tests related to database concurrency issues. Whenever we fix a concurrency issue, be it performance
 or deadlock related, a test should be added to ensure this occurence can not accidentally be introduced again.
 """
 
 import asyncio
 import datetime
 import uuid
 from collections import abc
-from typing import Optional, TypeVar
+from typing import Optional, Type, TypeVar
 
 import asyncpg
 import pytest
 
 from inmanta import const, data
 from inmanta.data import model
 from inmanta.protocol.common import Result
 
 
 def slowdown_queries(
     monkeypatch,
     *,
-    cls: type[data.BaseDocument] = data.BaseDocument,
+    cls: Type[data.BaseDocument] = data.BaseDocument,
     query_funcs: Optional[abc.Collection[str]] = None,
     delay: float = 1,
 ) -> None:
     """
     Introduces an artificial delay after each query execution through data.Document in order to increase the likelyhood of
     concurrent transactions.
 
@@ -224,34 +223,7 @@
 
     # Verify that this does not raise a deadlock exception. A failure on the insert is expected and acceptable if the delete
     # wins the race.
     try:
         await asyncio.gather(insert, delete())
     except asyncpg.ForeignKeyViolationError:
         pass
-
-
-@pytest.mark.slowtest
-async def test_release_version_concurrently(monkeypatch, server, client, environment: str, clienthelper) -> None:
-    version1 = await clienthelper.get_version()
-    resource1 = get_resource(version1, key="test1")
-    await clienthelper.put_version_simple(resources=[resource1], version=version1)
-
-    version2 = await clienthelper.get_version()
-    resource1 = get_resource(version2, key="test1")
-    await clienthelper.put_version_simple(resources=[resource1], version=version2)
-
-    slowdown_queries(monkeypatch)
-
-    f1 = asyncio.create_task(client.release_version(environment, version2))
-    f2 = asyncio.create_task(client.release_version(environment, version2))
-
-    # get results
-    r1 = await f1
-    r2 = await f2
-
-    # One should have made it, the other was too late
-    assert {r1.code, r2.code} == {200, 409}
-
-    # releasing an older version is always too late
-    r3 = await client.release_version(environment, version1)
-    assert r3.code == 409
```

### Comparing `inmanta-core-8.7.4/tests/test_data_model.py` & `inmanta-core-9.3.0/tests/test_data_model.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_deploy.py` & `inmanta-core-9.3.0/tests/test_deploy.py`

 * *Files 12% similar despite different names*

```diff
@@ -22,49 +22,42 @@
 
 import pytest
 from tornado import process
 
 from inmanta import deploy
 
 
-@pytest.mark.parametrize("default_main_file", [True, False])
-def test_deploy(snippetcompiler, tmpdir, postgres_db, default_main_file: bool):
-    """
-    Test the deploy command. The default_main_file parameter checks that the deploy command accepts
-    files other than `main.cf` through its `-f` cli option.
-    """
+def test_deploy(snippetcompiler, tmpdir, postgres_db):
     file_name = tmpdir.join("test_file")
     # TODO: when agentconfig deploys no longer require an agent restart, define a new agent. Currently this makes the
     # test to slow.
-    code = f"""
-        host = std::Host(name="internal", os=std::linux)
-        file = std::Symlink(host=host, source="/dev/null", target="{file_name}")
+    snippetcompiler.setup_for_snippet(
+        """
+    host = std::Host(name="internal", os=std::linux)
+    file = std::Symlink(host=host, source="/dev/null", target="%s")
     """
-
-    main_file = "main.cf" if default_main_file else "other.cf"
-    project = snippetcompiler.setup_for_snippet(code, main_file=main_file)
+        % file_name
+    )
 
     os.chdir(snippetcompiler.project_dir)
-    Options = collections.namedtuple("Options", ["dryrun", "dashboard", "main_file"])
-    options = Options(dryrun=False, dashboard=False, main_file=main_file)
+    Options = collections.namedtuple("Options", ["dryrun", "dashboard"])
+    options = Options(dryrun=False, dashboard=False)
 
     assert not file_name.exists()
 
     run = deploy.Deploy(options, postgresport=postgres_db.port)
     try:
         if not run.setup():
             raise Exception("Failed to setup server")
         run.run()
     finally:
         run.stop()
 
     assert file_name.exists()
 
-    assert project.main_file == main_file
-
 
 @pytest.mark.slowtest
 def test_deploy_with_non_default_config(snippetcompiler, tmpdir) -> None:
     """
     Ensure that configuration options set in one of the inmanta configuration
     files cannot make the `inmanta deploy` fail.
     """
```

### Comparing `inmanta-core-8.7.4/tests/test_docs_snippets.py` & `inmanta-core-9.3.0/tests/test_docs_snippets.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_docstring_parser.py` & `inmanta-core-9.3.0/tests/test_docstring_parser.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_env.py` & `inmanta-core-9.3.0/tests/test_env.py`

 * *Files 12% similar despite different names*

```diff
@@ -13,24 +13,24 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: bart@inmanta.com
 """
 import glob
 import importlib
+import json
 import logging
 import os
 import re
 import subprocess
 import sys
 import tempfile
 from importlib.abc import Loader
-from re import Pattern
 from subprocess import CalledProcessError
-from typing import Callable, Optional
+from typing import Dict, List, Optional, Pattern, Tuple
 from unittest.mock import patch
 
 import py
 import pytest
 from pkg_resources import Requirement
 
 from inmanta import env, loader, module
@@ -72,52 +72,56 @@
     with pytest.raises(ValueError) as e:
         env.PythonEnvironment(env_path="")
     assert e.value.args[0] == "The env_path cannot be an empty string."
 
 
 @pytest.mark.slowtest
 def test_basic_install(tmpdir):
+    """If this test fails, try running "pip uninstall lorem dummy-yummy iplib" before running it."""
     env_dir1 = tmpdir.mkdir("env1").strpath
+
+    with pytest.raises(ImportError):
+        import lorem  # NOQA
+
     venv1 = env.VirtualEnv(env_dir1)
-    assert not venv1.are_installed(["lorem"])
 
     venv1.use_virtual_env()
     venv1.install_from_list(["lorem"])
-    assert venv1.are_installed(["lorem"])
+    import lorem  # NOQA
+
+    lorem.sentence()
 
-    assert not venv1.are_installed(["dummy-yummy"])
+    with pytest.raises(ImportError):
+        import yummy  # NOQA
 
     venv1 = env.VirtualEnv(env_dir1)
+
     venv1.use_virtual_env()
     venv1.install_from_list(["dummy-yummy"])
-    assert venv1.are_installed(["dummy-yummy"])
-
+    import yummy  # NOQA
 
-def test_git_based_install(tmpdir: py.path.local) -> None:
-    """
-    Verify that the install methods can handle git-based installs over https.
-    """
-    venv = env.VirtualEnv(tmpdir.mkdir("env").strpath)
-    venv.use_virtual_env()
+    with pytest.raises(ImportError):
+        import iplib  # NOQA
 
-    pkg_name: str = "pytest-inmanta"
-    assert not venv.are_installed([pkg_name])
+    venv1 = env.VirtualEnv(env_dir1)
 
+    venv1.use_virtual_env()
     try:
-        venv.install_from_list([f"{pkg_name}@git+https://github.com/inmanta/{pkg_name}"])
+        venv1.install_from_list(
+            ["lorem == 0.1.1", "dummy-yummy", "iplib@git+https://github.com/bartv/python3-iplib", "lorem", "iplib >=0.0.1"]
+        )
     except CalledProcessError as ep:
         print(ep.stdout)
         raise
-
-    assert venv.are_installed([pkg_name])
+    import iplib  # NOQA
 
 
 @pytest.mark.slowtest
 def test_install_fails(tmpdir, caplog, monkeypatch):
-    venv = env.VirtualEnv(str(tmpdir))
+    venv = env.VirtualEnv(tmpdir)
     venv.use_virtual_env()
     caplog.clear()
     caplog.set_level(logging.INFO)
     package_name = "non-existing-pkg-inmanta"
 
     # monkeypatch pip install to set --no-index for security reasons (anyone could publish this package to PyPi)
     compose = env.PipCommandBuilder.compose_install_command
@@ -140,29 +144,29 @@
 @pytest.mark.slowtest
 def test_install_package_already_installed_in_parent_env(tmpdir):
     """Test using and installing a package that is already present in the parent virtual environment."""
     # get all packages in the parent
     parent_installed = list(env.process_env.get_installed_packages().keys())
 
     # create a venv and list all packages available in the venv
-    venv = env.VirtualEnv(str(tmpdir))
+    venv = env.VirtualEnv(tmpdir)
     venv.use_virtual_env()
 
     installed_packages = list(env.PythonEnvironment(python_path=venv._parent_python).get_installed_packages().keys())
 
     # verify that the venv sees all parent packages
     assert not set(parent_installed) - set(installed_packages)
 
     # site dir should be empty
     site_dir = os.path.join(venv.env_path, "lib/python*/site-packages")
     dirs = glob.glob(site_dir)
     assert len(dirs) == 1
     site_dir = dirs[0]
 
-    def _list_dir(path: str, ignore: list[str]) -> list[str]:
+    def _list_dir(path: str, ignore: List[str]) -> List[str]:
         return [d for d in os.listdir(site_dir) if d not in ignore]
 
     # site_dir should only contain a sitecustomize.py file that sets up inheritance from the parent venv
     assert not _list_dir(site_dir, ignore=["inmanta-inherit-from-parent-venv.pth", "__pycache__"])
 
     # test installing a package that is already present in the parent venv
     assert "more-itertools" in parent_installed
@@ -176,72 +180,47 @@
 
 
 def test_req_parser(tmpdir):
     url = "git+https://github.com/bartv/python3-iplib"
     at_url = "iplib@" + url
     egg_url = url + "#egg=iplib"
 
-    e = env.VirtualEnv(os.path.abspath(tmpdir))
+    e = env.VirtualEnv(tmpdir)
     name, u = e._parse_line(url)
     assert name is None
     assert u == url
 
     name, u = e._parse_line(at_url)
     assert name == "iplib"
     assert u == egg_url
 
     e._parse_line(egg_url)
     assert name == "iplib"
     assert u == egg_url
 
 
 def test_gen_req_file(tmpdir):
-    e = env.VirtualEnv(os.path.abspath(tmpdir))
+    e = env.VirtualEnv(tmpdir)
     req = [
         "lorem == 0.1.1",
         "lorem > 0.1",
         "dummy-yummy",
         "iplib@git+https://github.com/bartv/python3-iplib",
         "lorem",
         # verify support for environment markers as described in PEP 508
         "lorem;python_version<'3.7'",
         "lorem;platform_machine == 'x86_64' and platform_system == 'Linux'",
     ]
 
     req_lines = [x for x in e._gen_content_requirements_file(req).split("\n") if len(x) > 0]
-    assert len(req_lines) == 5
-    assert "lorem == 0.1.1, > 0.1" in req_lines
-    assert "dummy-yummy" in req_lines
-    assert "git+https://github.com/bartv/python3-iplib#egg=iplib" in req_lines
-    assert 'lorem ; python_version < "3.7"' in req_lines
-    assert 'lorem ; platform_machine == "x86_64" and platform_system == "Linux"' in req_lines
-
-
-def test_gen_req_file_multiple_python_versions(tmpdir):
-    e = env.VirtualEnv(os.path.abspath(tmpdir))
-    req = [
-        "lorem",
-        "lorem == 0.1;python_version=='3.7'",
-        "lorem == 0.2;python_version=='3.9'",
-    ]
-
-    req_lines = [x for x in e._gen_content_requirements_file(req).split("\n") if len(x) > 0]
     assert len(req_lines) == 3
-    assert "lorem" in req_lines
-    assert 'lorem == 0.1 ; python_version == "3.7"' in req_lines
-    assert 'lorem == 0.2 ; python_version == "3.9"' in req_lines
-
-
-def test_gen_req_file_multiple_extras(tmpdir):
-    e = env.VirtualEnv(os.path.abspath(tmpdir))
-    req = ["dep[opt]", "dep[otheropt]"]
-
-    req_lines = [x for x in e._gen_content_requirements_file(req).split("\n") if len(x) > 0]
-    assert len(req_lines) == 1
-    assert "dep[opt,otheropt]" in req_lines
+    assert (
+        'lorem == 0.1.1, > 0.1 ; python_version < "3.7" and platform_machine == "x86_64" and platform_system == "Linux"'
+        in req_lines
+    )
 
 
 def test_environment_python_version_multi_digit(tmpdir: py.path.local) -> None:
     """
     Make sure the constructor for env.Environment can handle multi-digit minor versions of Python to ensure compatibility with
     Python 3.10+.
     """
@@ -253,102 +232,42 @@
             )
 
 
 @pytest.mark.slowtest
 @pytest.mark.parametrize_any("version", [None, version.Version("8.6.0")])
 def test_process_env_install_from_index(
     tmpdir: str,
-    tmpvenv_active: tuple[py.path.local, py.path.local],
+    tmpvenv_active: Tuple[py.path.local, py.path.local],
     version: Optional[version.Version],
 ) -> None:
     """
     Install a package from a pip index into the process_env. Assert any version specs are respected.
     """
     package_name: str = "more-itertools"
     assert package_name not in env.process_env.get_installed_packages()
     env.process_env.install_from_index([Requirement.parse(package_name + (f"=={version}" if version is not None else ""))])
-    installed: dict[str, version.Version] = env.process_env.get_installed_packages()
+    installed: Dict[str, version.Version] = env.process_env.get_installed_packages()
     assert package_name in installed
     if version is not None:
         assert installed[package_name] == version
 
 
 @pytest.mark.slowtest
-@pytest.mark.parametrize_any("use_env_url", [False, True])
-@pytest.mark.parametrize_any("use_extra_indexes", [False, True])
-def test_process_env_install_from_index_not_found(
-    create_empty_local_package_index_factory: Callable[[str], str],
-    monkeypatch,
-    use_env_url: bool,
-    use_extra_indexes: bool,
-) -> None:
+def test_process_env_install_from_index_not_found(tmpvenv_active: Tuple[py.path.local, py.path.local]) -> None:
     """
     Attempt to install a package that does not exist from a pip index. Assert the appropriate error is raised.
     """
-    index_urls = []
-    if not use_env_url:
-        index_urls.extend([create_empty_local_package_index_factory()])
-        if use_extra_indexes:
-            index_urls.extend(
-                [
-                    create_empty_local_package_index_factory("extra1"),
-                    create_empty_local_package_index_factory("extra2"),
-                ]
-            )
-    else:
-        env_url = create_empty_local_package_index_factory("env1")
-        monkeypatch.setenv("PIP_INDEX_URL", env_url)
-        index_urls.extend([env_url])
-        if use_extra_indexes:
-            extra_env_indexes = [
-                create_empty_local_package_index_factory("extra_env1"),
-                create_empty_local_package_index_factory("extra_env2"),
-            ]
-            monkeypatch.setenv("PIP_EXTRA_INDEX_URL", " ".join(extra_env_indexes))
-            index_urls.extend(extra_env_indexes)
-
-    expected = (
-        "Packages this-package-does-not-exist were not "
-        "found in the given indexes. (Looking in indexes: %s)" % ", ".join(index_urls)
-    )
-
-    with pytest.raises(env.PackageNotFound, match=re.escape(expected)):
-        env.process_env.install_from_index(
-            [Requirement.parse("this-package-does-not-exist")], index_urls=None if use_env_url else index_urls
-        )
-
-
-@pytest.mark.parametrize_any("has_index_url", [True, False])
-def test_process_env_install_no_index(
-    tmpdir: py.path.local, create_empty_local_package_index_factory: Callable[[str], str], monkeypatch, has_index_url: bool
-) -> None:
-    """
-    Attempt to install a package that does not exist with --no-index.
-    To have --no-index set in the pip cmd, index_urls needs to be an empty list
-    it can also be set in the env_vars:
-    If index_urls is set to none, the env vars are used and if PIP_NO_INDEX is true
-    --no-index is used.
-    """
-    index_urls: Optional[list[str]] = []  # explicitly set to [] to have --no-index in the pip command
-    if not has_index_url:
-        # If index_urls is set to none, the env vars are used.
-        index_urls = None
-        monkeypatch.setenv("PIP_NO_INDEX", "true")
-
-    expected = "Packages this-package-does-not-exist were not found. No indexes were used."
-
-    with pytest.raises(env.PackageNotFound, match=re.escape(expected)):
-        env.process_env.install_from_index(
-            requirements=[Requirement.parse("this-package-does-not-exist")], index_urls=index_urls
-        )
+    with pytest.raises(env.PackageNotFound):
+        # pass empty index list for security reasons (anyone could publish this package to PyPi)
+        env.process_env.install_from_index([Requirement.parse("this-package-does-not-exist")], index_urls=[])
 
 
 @pytest.mark.slowtest
 def test_process_env_install_from_index_conflicting_reqs(
-    tmpdir: str, tmpvenv_active: tuple[py.path.local, py.path.local]
+    tmpdir: str, tmpvenv_active: Tuple[py.path.local, py.path.local]
 ) -> None:
     """
     Attempt to install a package with conflicting version requirements from a pip index. Make sure this fails and the
     package remains uninstalled.
     """
     package_name: str = "more-itertools"
     with pytest.raises(env.ConflictingRequirements) as e:
@@ -356,15 +275,15 @@
     assert "conflicting dependencies" in e.value.msg
     assert package_name not in env.process_env.get_installed_packages()
 
 
 @pytest.mark.slowtest
 @pytest.mark.parametrize("editable", [True, False])
 def test_process_env_install_from_source(
-    tmpvenv_active: tuple[py.path.local, py.path.local],
+    tmpvenv_active: Tuple[py.path.local, py.path.local],
     modules_v2_dir: str,
     editable: bool,
 ) -> None:
     """
     Install a package from source into the process_env. Make sure the editable option actually results in an editable install.
     """
     package_name: str = "inmanta-module-minimalv2module"
@@ -379,15 +298,15 @@
 # v1 plugin loader overrides loader paths so verify that it doesn't interfere with env.process_env installs
 @pytest.mark.parametrize("v1_plugin_loader", [True, False])
 @pytest.mark.parametrize("package_name", ["lorem", "more-itertools", "inmanta-module-minimalv2module"])
 @pytest.mark.slowtest
 def test_active_env_get_module_file(
     local_module_package_index: str,
     tmpdir: py.path.local,
-    tmpvenv_active: tuple[py.path.local, py.path.local],
+    tmpvenv_active: Tuple[py.path.local, py.path.local],
     v1_plugin_loader: bool,
     package_name: str,
 ) -> None:
     """
     Test the env.ActiveEnv.get_module_file() command on a newly installed package. Make sure it works regardless of whether we
     install a dependency of inmanta-core (which is already installed in the encapsulating development venv), a new package or an
     inmanta module (namespace package).
@@ -410,15 +329,15 @@
 
     if v1_plugin_loader:
         loader.PluginModuleFinder.configure_module_finder([os.path.join(str(tmpdir), "libs")])
 
     assert env.ActiveEnv.get_module_file(module_name) is None
     env.process_env.install_from_index([Requirement.parse(package_name)], index_urls=[index] if index is not None else None)
     assert package_name in env.process_env.get_installed_packages()
-    module_info: Optional[tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(module_name)
+    module_info: Optional[Tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(module_name)
     assert module_info is not None
     module_file, mod_loader = module_info
     assert module_file is not None
     assert not isinstance(mod_loader, loader.PluginModuleLoader)
     assert module_file == os.path.join(env.process_env.site_packages_dir, *module_name.split("."), "__init__.py")
     # verify that the package was installed in the development venv
     assert str(venv_dir) in module_file
@@ -426,39 +345,39 @@
     assert module_name in sys.modules
     assert sys.modules[module_name].__file__ == module_file
 
 
 @pytest.mark.slowtest
 def test_active_env_get_module_file_editable_namespace_package(
     tmpdir: str,
-    tmpvenv_active: tuple[py.path.local, py.path.local],
+    tmpvenv_active: Tuple[py.path.local, py.path.local],
     modules_v2_dir: str,
 ) -> None:
     """
     Verify that get_module_file works after installing an editable namespace package in an active environment.
     """
     package_name: str = "inmanta-module-minimalv2module"
     module_name: str = "inmanta_plugins.minimalv2module"
 
     assert env.ActiveEnv.get_module_file(module_name) is None
     project_dir: str = os.path.join(modules_v2_dir, "minimalv2module")
     env.process_env.install_from_source([env.LocalPackagePath(path=project_dir, editable=True)])
     assert package_name in env.process_env.get_installed_packages()
-    module_info: Optional[tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(module_name)
+    module_info: Optional[Tuple[Optional[str], Loader]] = env.ActiveEnv.get_module_file(module_name)
     assert module_info is not None
     module_file, mod_loader = module_info
     assert module_file is not None
     assert not isinstance(mod_loader, loader.PluginModuleLoader)
     assert module_file == os.path.join(modules_v2_dir, "minimalv2module", *module_name.split("."), "__init__.py")
     importlib.import_module(module_name)
     assert module_name in sys.modules
     assert sys.modules[module_name].__file__ == module_file
 
 
-def create_install_package(name: str, version: version.Version, requirements: list[Requirement]) -> None:
+def create_install_package(name: str, version: version.Version, requirements: List[Requirement]) -> None:
     """
     Creates and installs a simple package with specified requirements. Creates package in a temporary directory and
     cleans it up after install.
 
     :param name: Package name.
     :param version: Version for this package.
     :param requirements: Requirements on other packages. Required packages must already be installed when calling this function.
@@ -500,15 +419,15 @@
     caplog.set_level(logging.WARNING)
 
     in_scope_test: Pattern[str] = re.compile("test-package-.*")
     in_scope_nonext: Pattern[str] = re.compile("nonexistant-package")
 
     error_msg: str = "Incompatibility between constraint"
 
-    def assert_all_checks(expect_test: tuple[bool, str] = (True, ""), expect_nonext: tuple[bool, str] = (True, "")) -> None:
+    def assert_all_checks(expect_test: Tuple[bool, str] = (True, ""), expect_nonext: Tuple[bool, str] = (True, "")) -> None:
         """
         verify what the check method for 2 different scopes: for an existing package and a non existing one.
 
         param: expect_test: Tuple with as first value a bool and as second value a string. The bool is true if the execution
         will not raise an error, false if it will raise an error. The second argument is the warning message that can be find
         in the logs.
         param: expect_nonext: Tuple with as first value a bool and as second value a string. The bool is true if the execution
@@ -546,15 +465,15 @@
 @pytest.mark.slowtest
 def test_active_env_check_constraints(caplog, tmpvenv_active_inherit: str) -> None:
     """
     Verify that the env.ActiveEnv.check() method's constraints parameter is taken into account as expected.
     """
     caplog.set_level(logging.WARNING)
     in_scope: Pattern[str] = re.compile("test-package-.*")
-    constraints: list[Requirement] = [Requirement.parse("test-package-one~=1.0")]
+    constraints: List[Requirement] = [Requirement.parse("test-package-one~=1.0")]
 
     env.ActiveEnv.check(in_scope)
 
     caplog.clear()
     with pytest.raises(env.ConflictingRequirements):
         env.ActiveEnv.check(in_scope, constraints)
 
@@ -603,28 +522,34 @@
         r"package versions have conflicting dependencies",
         excinfo.value.msg,
     )
     assert match is not None
 
 
 @pytest.mark.slowtest
-@pytest.mark.parametrize("invalid_char", ['"', "$", "`"])
-def test_invalid_chars_in_venv_path(tmpdir, invalid_char: str) -> None:
+def test_pip_binary_when_venv_path_contains_double_quote(tmpdir) -> None:
     """
-    Test that an error is raised when attempting to create a venv with invalid chars in its path.
+    Test whether the pip binary generated by the VirtualEnv class works correctly when the
+    pip binary contains a double quote.
     """
-    venv_name = f"test{invalid_char}test"
-    venv_dir = os.path.join(tmpdir, venv_name)
+    venv_dir = os.path.join(tmpdir, 'tes t"test')
+    venv = env.VirtualEnv(venv_dir)
+    venv.use_virtual_env()
+    assert any('"' in path and " " in path for path in sys.path)
 
-    with pytest.raises(ValueError) as excinfo:
-        env.VirtualEnv(venv_dir)
-    assert (
-        f"Cannot create virtual environment because the provided path `{venv_dir}` contains an"
-        f" invalid character (`{invalid_char}`)."
-    ) in str(excinfo.value)
+    pip_binary = os.path.join(os.path.dirname(venv.python_path), "pip")
+    # Ensure that the pip command doesn't raise an exception
+    result = subprocess.check_output(
+        [pip_binary, "list", "--format", "json", "--disable-pip-version-check", "--no-python-version-warning"],
+        timeout=10,
+        encoding="utf-8",
+    )
+    parsed_output = json.loads(result)
+    # Ensure inheritance works correctly
+    assert "inmanta-core" in [elem["name"] for elem in parsed_output]
 
 
 @pytest.mark.slowtest
 def test_cache_on_active_env(tmpvenv_active_inherit: env.ActiveEnv, local_module_package_index: str) -> None:
     """
     Test whether the cache on an active env works correctly.
     """
```

### Comparing `inmanta-core-8.7.4/tests/test_export.py` & `inmanta-core-9.3.0/tests/test_export.py`

 * *Files 2% similar despite different names*

```diff
@@ -15,30 +15,30 @@
 
     Contact: code@inmanta.com
 """
 import json
 import logging
 import os
 import shutil
-from typing import Optional
+from typing import Dict, List, Optional
 
 import pytest
 
 import inmanta.resources
 from inmanta import config, const
 from inmanta.ast import CompilerException, ExternalException
 from inmanta.const import ResourceState
 from inmanta.data import Environment, Resource
 from inmanta.export import DependencyCycleException
 from inmanta.server import SLICE_RESOURCE
 from inmanta.server.server import Server
 from utils import LogSequence, v1_module_from_template
 
 
-async def assert_resource_set_assignment(environment, assignment: dict[str, Optional[str]]) -> None:
+async def assert_resource_set_assignment(environment, assignment: Dict[str, Optional[str]]) -> None:
     """
     Verify whether the resources on the server are assignment to the resource sets given via the assignment argument.
 
     :param environment
     :param assignment: Map the value of name attribute of resource Res to the resource set that resource is expected to
                        belong to.
     """
@@ -385,15 +385,15 @@
         "dct": dct,
     }
 )
         """,
     )
     snippetcompiler.do_export()
     tmp_file: str = os.path.join(snippetcompiler.project_dir, "dump.json")
-    with open(tmp_file) as f:
+    with open(tmp_file, "r") as f:
         export: dict = json.loads(f.read())
         my_dict: dict = {"dct": {"a": 1, "b": 2}}
         assert len(export) == 1
         print(export[0])
         assert export[0]["wrapped_proxies"] == {
             "my_list": [1, 2, 3],
             "my_dict": my_dict,
@@ -447,24 +447,23 @@
         snippetcompiler.do_export()
     assert (
         e.value.format_trace()
         == "Failed to get attribute 'real_name' for export on 'exp::Test3'\ncaused by:\nKeyError: 'tom'\n"
     )
 
 
-@pytest.mark.parametrize("soft_delete", [True, False])
-async def test_resource_set(snippetcompiler, modules_dir: str, tmpdir, environment, client, soft_delete: bool) -> None:
+async def test_resource_set(snippetcompiler, modules_dir: str, tmpdir, environment) -> None:
     """
     Test that resource sets are exported correctly, when a full compile or an incremental compile is done.
     """
 
     async def export_model(
         model: str,
         partial_compile: bool,
-        resource_sets_to_remove: Optional[list[str]] = None,
+        resource_sets_to_remove: Optional[List[str]] = None,
     ) -> None:
         init_py = """
 from inmanta.resources import (
     Resource,
     resource,
 )
 @resource("modulev1::Res", agent="name", id_attribute="name")
@@ -489,15 +488,14 @@
     import modulev1
             """,
             add_to_module_path=[str(tmpdir)],
         )
         await snippetcompiler.do_export_and_deploy(
             partial_compile=partial_compile,
             resource_sets_to_remove=resource_sets_to_remove,
-            soft_delete=soft_delete,
         )
 
     # Full compile
     await export_model(
         model="""
 entity Res extends std::Resource:
     string name
@@ -557,63 +555,14 @@
             "the_resource_e": "resource_set_3",
             "the_resource_f": "resource_set_4",
             "the_resource_y": None,
             "the_resource_z": None,
         },
     )
 
-    model = """
-        entity Res extends std::Resource:
-            string name
-        end
-        implement Res using std::none
-
-        g = Res(name="the_resource_g")
-        std::ResourceSet(name="resource_set_5", resources=[g])
-    """
-    if not soft_delete:
-        with pytest.raises(
-            Exception,
-            match=(
-                "Invalid request: Following resource sets are present in the removed resource"
-                " sets and in the resources that are exported: {'resource_set_5'}"
-            ),
-        ):
-            await export_model(
-                model=model,
-                partial_compile=True,
-                resource_sets_to_remove=["resource_set_5"],
-            )
-
-    else:
-        await export_model(
-            model=model,
-            partial_compile=True,
-            resource_sets_to_remove=["resource_set_5"],
-        )
-        await assert_resource_set_assignment(
-            environment,
-            assignment={
-                "the_resource_a": "resource_set_1",
-                "the_resource_c2": "resource_set_1",
-                "the_resource_d": "resource_set_3",
-                "the_resource_e": "resource_set_3",
-                "the_resource_f": "resource_set_4",
-                "the_resource_g": "resource_set_5",  # Check it didn't get removed
-                "the_resource_y": None,
-                "the_resource_z": None,
-            },
-        )
-
-    response = await client.list_versions(tid=environment)
-    assert response.code == 200
-
-    # One of the 3 partial compiles is expected to fail when soft_delete is true:
-    assert len(response.result["versions"]) == 2 + soft_delete
-
 
 async def test_resource_in_multiple_resource_sets(snippetcompiler, modules_dir: str, tmpdir, environment) -> None:
     """
     test that an error is raised if a resource is in multiple
     resource_sets
     """
     init_cf = """
@@ -687,15 +636,15 @@
     When a partial compile is ran, the exporter should trigger a deletion of each ResourceSet, defined in the partial model,
     that doesn't have any resources associated
     """
 
     async def export_model(
         model: str,
         partial_compile: bool,
-        resource_sets_to_remove: Optional[list[str]] = None,
+        resource_sets_to_remove: Optional[List[str]] = None,
     ) -> None:
         init_py = """
 from inmanta.resources import (
     Resource,
     resource,
 )
 @resource("modulev1::Res", agent="name", id_attribute="name")
@@ -783,30 +732,7 @@
         assignment={
             "the_resource_a": "resource_set_1",
             "the_resource_c2": "resource_set_1",
             "the_resource_f": "resource_set_4",
             "the_resource_z": None,
         },
     )
-
-
-def test_attribute_value_of_id_has_str_type(snippetcompiler):
-    """
-    Verify that the id.attribute_value field of resources emitted by the exporter have the type str.
-    Even if the type in the model is different.
-    """
-    snippetcompiler.setup_for_snippet(
-        """
-        import testmodule_integer_id
-
-        testmodule_integer_id::Test(
-            id_attr=123,
-            agent="internal",
-        )
-        """
-    )
-    version, resource_dct = snippetcompiler.do_export()
-    resources = list(resource_dct.values())
-    assert len(resources) == 1
-    id_attribute_value = resources[0].id.attribute_value
-    assert isinstance(id_attribute_value, str)
-    assert id_attribute_value == "123"
```

### Comparing `inmanta-core-8.7.4/tests/test_extension_loading.py` & `inmanta-core-9.3.0/tests/test_extension_loading.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,18 +15,17 @@
 
     Contact: code@inmanta.com
 """
 import importlib
 import logging
 import os
 import sys
-from collections.abc import Generator
 from contextlib import contextmanager
 from functools import partial
-from typing import Any
+from typing import Any, Generator
 
 import pytest
 import yaml
 
 import inmanta.server
 import inmanta_ext
 from inmanta import data
@@ -44,15 +43,15 @@
 from inmanta.server.extensions import BoolFeature, FeatureManager, InvalidFeature, InvalidSliceNameException, StringListFeature
 from inmanta.server.protocol import Server, ServerSlice
 from utils import log_contains
 
 
 @contextmanager
 def splice_extension_in(name: str) -> Generator[Any, Any, None]:
-    """Context manager to load all extensions in tests/data/{name}/inmanta_ext/ to the interpreter and unload them again"""
+    """Context manager to all extensions in tests/data/{name}/inmanta_ext/ to the interpreter and unload them again"""
     oldpath = sys.path
     try:
         sys.path = sys.path + [os.path.join(os.path.dirname(__file__), "data", name)]
         importlib.reload(inmanta_ext)
         yield
     finally:
         sys.path = oldpath
```

### Comparing `inmanta-core-8.7.4/tests/test_file_parser.py` & `inmanta-core-9.3.0/tests/test_file_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import os
+from typing import List
 
 from pkg_resources import Requirement
 
 from inmanta.file_parser import RequirementsTxtParser
 
 
 def test_requirements_txt_parser(tmpdir) -> None:
@@ -35,15 +36,15 @@
     """
 
     requirements_txt_file = os.path.join(tmpdir, "requirements.txt")
     with open(requirements_txt_file, "w", encoding="utf-8") as fd:
         fd.write(content)
 
     expected_requirements = ["test==1.2.3", "other-dep~=2.0.0", "third-dep<5.0.0", "splitteddep", "Capital"]
-    requirements: list[Requirement] = RequirementsTxtParser().parse(requirements_txt_file)
+    requirements: List[Requirement] = RequirementsTxtParser().parse(requirements_txt_file)
     assert requirements == [Requirement.parse(r) for r in expected_requirements]
     requirements_as_str = RequirementsTxtParser.parse_requirements_as_strs(requirements_txt_file)
     assert requirements_as_str == expected_requirements
 
     new_content = RequirementsTxtParser.get_content_with_dep_removed(requirements_txt_file, remove_dep_on_pkg="test")
     assert (
         new_content
```

### Comparing `inmanta-core-8.7.4/tests/test_handler.py` & `inmanta-core-9.3.0/tests/test_handler.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
-from typing import Any
+from typing import Any, Dict
 
 import pytest
 
 from inmanta.agent.handler import CRUDHandlerGeneric as CRUDHandler
 from inmanta.agent.handler import HandlerContext, ResourcePurged
 from inmanta.const import ResourceState
 from inmanta.resources import Id, PurgeableResource, resource
@@ -110,15 +110,15 @@
     class DummyCrud(CRUDHandler[TestResource]):
         def __init__(self):
             self.updated = False
 
         def read_resource(self, ctx: HandlerContext, resource: TestResource) -> None:
             resource.value = "b"
 
-        def update_resource(self, ctx: HandlerContext, changes: dict[str, dict[str, Any]], resource: TestResource) -> None:
+        def update_resource(self, ctx: HandlerContext, changes: Dict[str, Dict[str, Any]], resource: TestResource) -> None:
             self.updated = True
 
     res = TestResource(Id(entity_type="aa::Aa", agent_name="aa", attribute="aa", attribute_value="aa", version=1))
 
     # Sets are not JSON serializable
     res.value = {"a"}
     res.purged = False
@@ -163,15 +163,15 @@
             self.updated = False
 
         def read_resource(self, ctx: HandlerContext, resource: TestResource) -> None:
             resource.value = "b"
             unserializable_set = {"b"}
             ctx.debug(msg="Unserializable kwargs: ", kwargs={"unserializable": unserializable_set})
 
-        def update_resource(self, ctx: HandlerContext, changes: dict[str, dict[str, Any]], resource: TestResource) -> None:
+        def update_resource(self, ctx: HandlerContext, changes: Dict[str, Dict[str, Any]], resource: TestResource) -> None:
             self.updated = True
 
     res = TestResource(Id(entity_type="aa::Aa", agent_name="aa", attribute="aa", attribute_value="aa", version=1))
 
     res.value = "a"
     res.purged = False
```

### Comparing `inmanta-core-8.7.4/tests/test_import_entry_points.py` & `inmanta-core-9.3.0/tests/test_import_entry_points.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,16 +18,15 @@
 """
     These tests make sure that for each module mentioned in the compiler API docs, using it as an entry point for importing
     does not result in an import loop (see #2341 and #2342).
 """
 
 import importlib
 import multiprocessing
-from collections.abc import Callable, Iterator
-from typing import Optional
+from typing import Callable, Iterator, Optional
 
 import pytest
 
 
 @pytest.fixture(scope="session")
 def import_entry_point() -> Iterator[Callable[[str], Optional[int]]]:
     """
@@ -121,11 +120,7 @@
 def test_import_compiler(import_entry_point: Callable[[str], Optional[int]]) -> None:
     assert import_entry_point("inmanta.compiler") == 0
 
 
 def test_import_server(import_entry_point: Callable[[str], Optional[int]]) -> None:
     assert import_entry_point("inmanta.server.extensions") == 0
     assert import_entry_point("inmanta.server.bootloader") == 0
-
-
-def test_import_validation_type(import_entry_point: Callable[[str], Optional[int]]) -> None:
-    assert import_entry_point("inmanta.validation_type") == 0
```

### Comparing `inmanta-core-8.7.4/tests/test_influxdbreporting.py` & `inmanta-core-9.3.0/tests/test_influxdbreporting.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,14 +13,15 @@
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import asyncio
 import re
+from typing import Type
 
 import pytest
 import tornado
 from pyformance import gauge, global_registry, timer
 from tornado.httpserver import HTTPServer
 from tornado.web import url
 
@@ -56,15 +57,15 @@
                 assert influxlineprotocol.match(line)
                 self.parent.lines.append(line)
         except Exception as e:
             # carry over  failures
             self.parent.failure = e
 
 
-class InfluxdbMock:
+class InfluxdbMock(object):
     def __init__(self, socket):
         self.querycount = 0
         self.writecount = 0
         self.failure = None
         self.lines = []
 
         self.app = tornado.web.Application(
@@ -160,15 +161,15 @@
     assert mr.count == base + 1
     mr.stop()
 
 
 async def test_available_metrics(server):
     metrics = global_registry().dump_metrics()
 
-    types: dict[str, list[type]] = {}
+    types: dict[str, list[Type]] = {}
     # Ensure type consistency
     for metric in metrics.values():
         for key, value in metric.items():
             if key in types:
                 # don't use isinstance, because bool is int in python, but not for influxdb
                 assert type(value) in types[key], f"inconsistent types for {key}: {type(value)} and {types[key]}"
             else:
```

### Comparing `inmanta-core-8.7.4/tests/test_io.py` & `inmanta-core-9.3.0/tests/test_io.py`

 * *Files 0% similar despite different names*

```diff
@@ -287,15 +287,15 @@
 
 
 @pytest.mark.parametrize("io", io_list)
 def test_run_pythonpath(io, tmpdir):
     """Test to see if the python path of the venv is removed for the subprocess
     See issue #2676
     """
-    venv = env.VirtualEnv(os.path.abspath(tmpdir))
+    venv = env.VirtualEnv(tmpdir)
     venv.use_virtual_env()
 
     result = io.run("env")
     assert "PYTHONPATH" not in result[0]
 
     if not hasattr(io, "run_as") or not io.run_as:
         # This does not work as expected when using the run_as root feature with bash and sudo because by default
```

### Comparing `inmanta-core-8.7.4/tests/test_jwt.py` & `inmanta-core-9.3.0/tests/test_jwt.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_loader.py` & `inmanta-core-9.3.0/tests/test_loader.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 import importlib.util
 import inspect
 import os
 import shutil
 import sys
 from logging import INFO
 from types import ModuleType
-from typing import Optional
+from typing import List, Optional, Set
 
 import py
 import pytest
 from pytest import fixture
 
 import utils
 from inmanta import const, env, loader, moduletool
@@ -75,27 +75,27 @@
             return content
 
     # get types
     types = dict(mgr.get_types())
     assert "std::File" in types
     assert "std::Directory" in types
 
-    single_type_list: list[SourceInfo] = types["std::File"]
-    multi_type_list: list[SourceInfo] = types["std::Directory"]
+    single_type_list: List[SourceInfo] = types["std::File"]
+    multi_type_list: List[SourceInfo] = types["std::Directory"]
 
     assert len(single_type_list) == 1
     single_content: str = assert_content(single_type_list[0], single.MyHandler)
 
     assert len(multi_type_list) == 3
     multi_content: str = assert_content(
         next(s for s in multi_type_list if s.module_name == "inmanta_plugins.multiple_plugin_files.handlers"), multi.MyHandler
     )
 
     # get_file_hashes
-    mgr_contents: set[bytes] = {mgr.get_file_content(hash) for hash in mgr.get_file_hashes()}
+    mgr_contents: Set[bytes] = {mgr.get_file_content(hash) for hash in mgr.get_file_hashes()}
     assert single_content in mgr_contents
     assert multi_content in mgr_contents
 
     with pytest.raises(KeyError):
         mgr.get_file_content("test")
 
     # register type without source
```

### Comparing `inmanta-core-8.7.4/tests/test_logging.py` & `inmanta-core-9.3.0/tests/test_logging.py`

 * *Files 1% similar despite different names*

```diff
@@ -124,15 +124,15 @@
     assert handler.baseFilename == str(log_file)
 
     # Log a message
     logger = logging.getLogger("test_logger")
     logger.info("This is a test message")
 
     # Verify the message was written to the log file
-    with open(str(log_file)) as f:
+    with open(str(log_file), "r") as f:
         contents = f.read()
         assert "This is a test message" in contents
 
 
 @pytest.mark.parametrize_any(
     "log_file, log_file_level, verbose",
     [(None, "INFO", 1), (None, "ERROR", 4), ("test.log", "WARNING", 4), ("test.log", "DEBUG", 4)],
@@ -159,15 +159,15 @@
         error_in_output = "test_logger              ERROR   error: This is the fourth test" in log_output
         assert debug_in_output if int(verbose) >= 3 else not debug_in_output
         assert info_in_output if int(verbose) >= 2 else not info_in_output
         assert warning_in_output if int(verbose) >= 1 else not warning_in_output
         assert error_in_output
 
     else:
-        with open(str(log_file)) as f:
+        with open(str(log_file), "r") as f:
             log_output = f.read().strip()
             debug_in_output = "DEBUG    test_logger debug: This is the first test" in log_output
             info_in_output = "INFO     test_logger info: This is the second test" in log_output
             warning_in_output = "WARNING  test_logger warning: This is the third test" in log_output
             error_in_output = "ERROR    test_logger error: This is the fourth test" in log_output
             assert debug_in_output if log_file_level in ["DEBUG"] else not debug_in_output
             assert info_in_output if log_file_level in ["DEBUG", "INFO"] else not info_in_output
@@ -200,14 +200,14 @@
     assert log_output == expected_output
 
     log_file = tmpdir.join("test.log")
 
     options3 = Options(log_file=log_file, log_file_level="WARNING", verbose="4")
     inmanta_logger.apply_options(options3)
     logger.warning("warning: This is the second test")
-    with open(str(log_file)) as f:
+    with open(str(log_file), "r") as f:
         contents = f.read()
         assert "WARNING  test_logger warning: This is the second test" in contents
 
     log_output = stream.getvalue().strip()
     expected_output = "test_logger              INFO    This is a test message"
     assert log_output == expected_output
```

### Comparing `inmanta-core-8.7.4/tests/test_module_loader.py` & `inmanta-core-9.3.0/tests/test_module_loader.py`

 * *Files 0% similar despite different names*

```diff
@@ -17,16 +17,15 @@
 """
 import logging
 import os
 import py_compile
 import shutil
 import sys
 from collections import abc
-from collections.abc import Sequence
-from typing import Optional
+from typing import Dict, List, Optional, Sequence, Set
 
 import py
 import pytest
 from pkg_resources import Requirement
 
 from inmanta import compiler, const, loader, plugins, resources
 from inmanta.ast import CompilerException
@@ -85,15 +84,15 @@
        * A warning is logged
        * The V2 module is loaded and not the V1 module.
     """
 
     module_name = "v1_print_plugin"
 
     def compile_and_verify(
-        expected_message: str, expect_warning: bool, install_v2_modules: list[LocalPackagePath] = []
+        expected_message: str, expect_warning: bool, install_v2_modules: List[LocalPackagePath] = []
     ) -> None:
         caplog.clear()
         snippetcompiler_clean.setup_for_snippet(f"import {module_name}", install_v2_modules=install_v2_modules, autostd=False)
         snippetcompiler_clean.do_export()
         assert expected_message in capsys.readouterr().out
         got_warning = f"Module {module_name} is installed as a V1 module and a V2 module" in caplog.text
         assert got_warning == expect_warning
@@ -171,17 +170,22 @@
             snippet=f"import {module_name}",
             install_project=True,
             python_package_sources=[],
             python_requires=[
                 InmantaModuleRequirement.parse(module_name).get_python_package_requirement(),
             ],
         )
+
     message: str = (
-        "Attempting to install a v2 module non_existing_module but no v2 module source is configured. Add at least one repo of "
-        'type "package" to the project config file.'
+        "Attempting to install a v2 module non_existing_module but no v2 module source is configured. Add the relevant pip "
+        "indexes to the project config file. e.g. to add PyPi as a module source, add the following to "
+        "the `pip` section of the project's `project.yml`:"
+        "\n\t  index_urls:"
+        "\n\t\t  - https://pypi.org/simple"
+        "\nAnother option is to set the use_config_file project option to true to use the system's pip config file."
     )
     assert message in e.value.format_trace()
 
 
 @pytest.mark.parametrize("allow_v1", [True, False])
 def test_load_module_v1_already_installed(snippetcompiler, modules_dir: str, allow_v1: bool) -> None:
     """
@@ -359,15 +363,15 @@
         autostd=False,
         python_package_sources=[local_module_package_index],
         python_requires=[Requirement.parse("inmanta-module-complex-module-dependencies-mod1")],
         install_project=False,
     )
     assert "complex_module_dependencies_mod1" not in project.modules
     assert "complex_module_dependencies_mod2" not in project.modules
-    loaded_namespaces: set[str] = {ns for ns, _, _ in project.load_module_recursive(install=True)}
+    loaded_namespaces: Set[str] = set(ns for ns, _, _ in project.load_module_recursive(install=True))
     assert "complex_module_dependencies_mod1" in project.modules
     assert "complex_module_dependencies_mod2" in project.modules
     expected_namespaces = {
         "complex_module_dependencies_mod1",
         "complex_module_dependencies_mod1::submod",
         "complex_module_dependencies_mod2",
         "complex_module_dependencies_mod2::submod",
@@ -378,15 +382,15 @@
 def test_load_import_based_v2_project(local_module_package_index: str, snippetcompiler_clean) -> None:
     """
     A project needs to explicitly list its v2 dependencies in order to be able to load them. Import-based loading is not
     allowed.
     """
     module_name: str = "minimalv2module"
 
-    def load(requires: Optional[list[Requirement]] = None) -> None:
+    def load(requires: Optional[List[Requirement]] = None) -> None:
         project: Project = snippetcompiler_clean.setup_for_snippet(
             f"import {module_name}",
             autostd=False,
             install_project=False,
             python_package_sources=[local_module_package_index],
             # make sure that even listing the requirement in project.yml does not suffice
             project_requires=[InmantaModuleRequirement.parse(module_name)],
@@ -418,15 +422,15 @@
     main_module_name: str = "mymodule"
     dependency_module_name: str = "minimalv2module"
     index: PipIndex = PipIndex(os.path.join(str(tmpdir), ".my-index"))
     libs_dir: str = os.path.join(str(tmpdir), "libs")
     os.makedirs(libs_dir)
 
     model: str = f"import {dependency_module_name}"
-    requirements: list[InmantaModuleRequirement] = (
+    requirements: List[InmantaModuleRequirement] = (
         [InmantaModuleRequirement.parse(dependency_module_name)] if explicit_dependency else []
     )
 
     if v1:
         v1_module_from_template(
             os.path.join(modules_dir, "minimalv1module"),
             os.path.join(libs_dir, main_module_name),
@@ -1368,15 +1372,15 @@
 
 def test_cross_module_dependency(local_module_package_index: str, snippetcompiler, capsys) -> None:
     """
     This test checks that the python code living in the inmanta_plugins dir of a module ('anothermod' in this test case)
     that is not loaded, can be used from the plugins of another module. ('cross_module_dependency' in this test case)
     """
 
-    def check_name_space(name_space: dict[str, object], includes: Sequence[str], excludes: Sequence[str]) -> None:
+    def check_name_space(name_space: Dict[str, object], includes: Sequence[str], excludes: Sequence[str]) -> None:
         """
         Check that all the items in `includes` are present in `name_space`
         and that no item in `excludes` is present in `name_space`
         """
         for x in includes:
             assert x in name_space
         for x in excludes:
@@ -1408,15 +1412,15 @@
     )
 
     types, _ = compiler.do_compile()
 
     out, _ = capsys.readouterr()
     output = out.strip()
 
-    expected_output: list[str] = [
+    expected_output: List[str] = [
         "message from project model",
         "triple this string" * 3,
         "message from cross_module_dependency model",
     ]
     for line in expected_output:
         assert line in output
```

### Comparing `inmanta-core-8.7.4/tests/test_modules.py` & `inmanta-core-9.3.0/tests/test_modules.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,17 +17,16 @@
 """
 
 import logging
 import os
 import shutil
 import tempfile
 import unittest
-from collections.abc import Mapping
 from importlib.abc import Loader
-from typing import Optional
+from typing import List, Mapping, Optional, Tuple, Type
 from unittest import mock
 
 import py
 import pytest
 
 from _io import StringIO
 from inmanta import const, env, module
@@ -121,15 +120,15 @@
     """
     Test whether the warning regarding non-versioned modules is given correctly.
     """
     # Disable modules_dir
     snippetcompiler_clean.modules_dir = None
 
     def compile_and_assert_warning(
-        module_name: str, needs_versioning_warning: bool, install_v2_modules: list[LocalPackagePath] = []
+        module_name: str, needs_versioning_warning: bool, install_v2_modules: List[LocalPackagePath] = []
     ) -> None:
         caplog.clear()
         snippetcompiler_clean.setup_for_snippet(f"import {module_name}", autostd=False, install_v2_modules=install_v2_modules)
         snippetcompiler_clean.do_export()
         warning_message = f"Module {module_name} is not version controlled, we recommend you do this as soon as possible."
         assert (warning_message in caplog.text) is needs_versioning_warning
 
@@ -195,18 +194,18 @@
         ),
     ],
 )
 def test_get_requirements(
     modules_dir: str,
     modules_v2_dir: str,
     v1_module: bool,
-    all_python_requirements: list[str],
-    strict_python_requirements: list[str],
-    module_requirements: list[str],
-    module_v2_requirements: list[str],
+    all_python_requirements: List[str],
+    strict_python_requirements: List[str],
+    module_requirements: List[str],
+    module_v2_requirements: List[str],
 ) -> None:
     """
     Test the different methods to get the requirements of a module.
     """
     module_name = "many_dependencies"
 
     if v1_module:
@@ -216,15 +215,15 @@
         module_dir = os.path.join(modules_v2_dir, module_name)
         mod = module.ModuleV2(module.DummyProject(autostd=False), module_dir)
 
     assert set(mod.get_all_python_requirements_as_list()) == set(all_python_requirements)
     assert set(mod.get_strict_python_requirements_as_list()) == set(strict_python_requirements)
     assert set(mod.get_module_requirements()) == set(module_requirements)
     assert set(mod.get_module_v2_requirements()) == set(module_v2_requirements)
-    assert set(mod.requires()) == {module.InmantaModuleRequirement.parse(req) for req in module_requirements}
+    assert set(mod.requires()) == set(module.InmantaModuleRequirement.parse(req) for req in module_requirements)
 
 
 @pytest.mark.parametrize("editable", [True, False])
 def test_module_v2_source_get_installed_module_editable(
     # Use clean snippetcompiler (separate venv) because this test installs test packages into the snippetcompiler venv.
     snippetcompiler_clean,
     modules_v2_dir: str,
@@ -257,15 +256,15 @@
     """
     # install and load std as v1
     snippetcompiler.setup_for_snippet("import std")
     module.Project.get().load_plugins()
 
     # make sure the v1 module finder is configured and discovered by env.process_env
     assert PluginModuleFinder.MODULE_FINDER is not None
-    module_info: Optional[tuple[Optional[str], Loader]] = env.process_env.get_module_file("inmanta_plugins.std")
+    module_info: Optional[Tuple[Optional[str], Loader]] = env.process_env.get_module_file("inmanta_plugins.std")
     assert module_info is not None
     path, loader = module_info
     assert path is not None
     assert isinstance(loader, PluginModuleLoader)
 
     source: module.ModuleV2Source = module.ModuleV2Source(urls=[])
     assert source.path_for("std") is None
@@ -392,15 +391,15 @@
     Verify that ModuleLike.from_path() and subclass overrides work as expected.
     """
 
     def check(
         path: str,
         *,
         subdir: Optional[str] = None,
-        expected: Mapping[type[module.ModuleLike], Optional[type[module.ModuleLike]]],
+        expected: Mapping[Type[module.ModuleLike], Optional[Type[module.ModuleLike]]],
     ) -> None:
         """
         Check the functionality for the given path and expected outcomes.
 
         :param path: The path to the root of the module like directory.
         :param subdir: The subpath to pass to `from_path`, relative to `path`.
         :param expected: Key-value pairs where keys represent the classes to call the method on and values the expected type
```

### Comparing `inmanta-core-8.7.4/tests/test_openapi.py` & `inmanta-core-9.3.0/tests/test_openapi.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
     Contact: code@inmanta.com
 """
 import enum
 import inspect
 import json
 from datetime import datetime
-from typing import Optional, Union
+from typing import Dict, List, Optional, Union
 from uuid import UUID
 
 import pytest
 from openapi_spec_validator import openapi_v30_spec_validator
 from pydantic.networks import AnyHttpUrl, AnyUrl, PostgresDsn
 
 from inmanta.const import ClientType, ResourceAction
@@ -35,22 +35,22 @@
     ArgOptionHandler,
     FunctionParameterHandler,
     OpenApiConverter,
     OpenApiTypeConverter,
     OperationHandler,
 )
 from inmanta.protocol.openapi.model import MediaType, OpenApiDataTypes, ParameterType, Schema
-from inmanta.server import SLICE_SERVER, config
+from inmanta.server import SLICE_SERVER
 from inmanta.server.extensions import FeatureManager
 from inmanta.server.protocol import Server
 
 
 class DummyException(BaseHttpException):
     def __init__(self):
-        super().__init__(status_code=405)
+        super(DummyException, self).__init__(status_code=405)
 
 
 @pytest.fixture
 def feature_manager(server: Server) -> FeatureManager:
     return server.get_slice(SLICE_SERVER).feature_manager
 
 
@@ -175,30 +175,21 @@
     )
     def dummy_get_with_default_values(
         no_def: int, id: int = 5, param: str = "test", fl: float = 0.1, opt: Optional[str] = None
     ) -> str:
         return ""
 
 
-async def test_generate_openapi_definition(server: Server):
-    feature_manager = server.get_slice(SLICE_SERVER).feature_manager
+async def test_generate_openapi_definition(server: Server, feature_manager: FeatureManager):
     global_url_map = server._transport.get_global_url_map(server.get_slices().values())
     openapi = OpenApiConverter(global_url_map, feature_manager)
     openapi_json = openapi.generate_openapi_json()
     assert openapi_json
     openapi_parsed = json.loads(openapi_json)
     openapi_v30_spec_validator.validate(openapi_parsed)
-    assert "https" not in openapi_parsed["servers"][0]["url"]
-    # enable https
-    config.server_ssl_key.set("ssl_key")
-    config.server_ssl_cert.set("ssl_cert")
-    openapi_json = openapi.generate_openapi_json()
-    assert openapi_json
-    openapi_parsed = json.loads(openapi_json)
-    assert "https" in openapi_parsed["servers"][0]["url"]
 
 
 def test_filter_api_methods(server, api_methods_fixture, feature_manager):
     post = UrlMethod(properties=MethodProperties.methods["post_method"][0], slice=None, method_name="post_method", handler=None)
     methods = {
         "POST": post,
         "GET": UrlMethod(
@@ -269,56 +260,56 @@
     type_converter = OpenApiTypeConverter()
     openapi_type = type_converter.get_openapi_type(Optional[str])
     assert openapi_type == Schema(type="string", nullable=True)
 
 
 def test_openapi_types_list():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(list[Union[int, UUID]])
+    openapi_type = type_converter.get_openapi_type(List[Union[int, UUID]])
     assert openapi_type == Schema(
         type="array", items=Schema(anyOf=[Schema(type="integer"), Schema(type="string", format="uuid")])
     )
 
 
 def test_openapi_types_enum():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(list[ResourceAction])
+    openapi_type = type_converter.get_openapi_type(List[ResourceAction])
     assert openapi_type.type == "array"
     assert openapi_type.items.ref == type_converter.ref_prefix + "ResourceAction"
 
     resource_action_type = type_converter.components.schemas["ResourceAction"]
     assert resource_action_type.type == "string"
     assert resource_action_type.enum == ["store", "push", "pull", "deploy", "dryrun", "getfact", "other"]
 
 
 def test_openapi_types_dict():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(dict[str, UUID])
+    openapi_type = type_converter.get_openapi_type(Dict[str, UUID])
     assert openapi_type == Schema(type="object", additionalProperties=Schema(type="string", format="uuid"))
 
 
 def test_openapi_types_list_of_model():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(list[model.Project])
+    openapi_type = type_converter.get_openapi_type(List[model.Project])
     assert openapi_type.type == "array"
     assert openapi_type.items.ref == type_converter.ref_prefix + "Project"
 
 
 def test_openapi_types_list_of_list_of_optional_model():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(list[list[Optional[model.Project]]])
+    openapi_type = type_converter.get_openapi_type(List[List[Optional[model.Project]]])
     assert openapi_type.type == "array"
     assert openapi_type.items.type == "array"
     assert openapi_type.items.items.ref == type_converter.ref_prefix + "Project"
     assert openapi_type.items.items.nullable
 
 
 def test_openapi_types_dict_of_union():
     type_converter = OpenApiTypeConverter()
-    openapi_type = type_converter.get_openapi_type(dict[str, Union[model.Project, model.Environment]])
+    openapi_type = type_converter.get_openapi_type(Dict[str, Union[model.Project, model.Environment]])
     assert openapi_type.type == "object"
     assert len(openapi_type.additionalProperties.anyOf) == 2
     assert openapi_type.additionalProperties.anyOf[0].ref == type_converter.ref_prefix + "Project"
     assert openapi_type.additionalProperties.anyOf[1].ref == type_converter.ref_prefix + "Environment"
 
 
 def test_openapi_types_optional_union():
```

### Comparing `inmanta-core-8.7.4/tests/test_parser.py` & `inmanta-core-9.3.0/tests/test_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,14 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
 import re
 import warnings
+from typing import List
 
 import pytest
 
 from inmanta import compiler
 from inmanta.ast import LocatableString, Namespace, Range
 from inmanta.ast.blocks import BasicBlock
 from inmanta.ast.constraint.expression import And, Equals, GreaterThan, In, IsDefined, Not, Or, Regex
@@ -31,15 +32,14 @@
     CreateDict,
     CreateList,
     IndexLookup,
     MapLookup,
     SetAttribute,
     ShortIndexLookup,
     StringFormat,
-    StringFormatV2,
 )
 from inmanta.ast.statements.call import FunctionCall
 from inmanta.ast.statements.define import DefineEntity, DefineImplement, DefineIndex, DefineTypeConstraint, TypeDeclaration
 from inmanta.ast.statements.generator import ConditionalExpression, Constructor, If
 from inmanta.ast.variables import AttributeReference, Reference
 from inmanta.execute.util import NoneValue
 from inmanta.parser import InvalidNamespaceAccess, ParserException, SyntaxDeprecationWarning
@@ -137,15 +137,15 @@
     statements = parse_code(
         """
 entity Test extends Foo, foo::sub::Bar:
     \"\"\" %s
     \"\"\"
     string hello
     bool bar = true
-    int? ten=5
+    number? ten=5
 end
 """
         % documentation
     )
 
     assert len(statements) == 1
 
@@ -423,15 +423,15 @@
     assert stmt.inherit is True
 
 
 @pytest.mark.parametrize(
     "implementations",
     [["parents", "std::none"], ["std::none", "parents"], ["i1", "parents", "i2"], ["std::none"], ["i1", "i2"]],
 )
-def test_implements_parent_in_list(implementations: list[str]):
+def test_implements_parent_in_list(implementations: List[str]):
     statements = parse_code(
         """
 implement Test using %s
         """
         % ", ".join(implementations)
     )
 
@@ -600,15 +600,15 @@
 """
     )
 
     assert len(statements) == 1
     stmt = statements[0]
     assert isinstance(stmt, DefineIndex)
     assert str(stmt.type) == "File"
-    assert [str(a) for a in stmt.attributes] == ["host", "path"]
+    assert stmt.attributes == ["host", "path"]
 
 
 def test_ctr():
     statements = parse_code(
         """
 File(host = 5, path = "Jos")
 """
@@ -1016,38 +1016,14 @@
     assert isinstance(stmt.value._variables[0][0], AttributeReference)
     assert str(stmt.value._variables[0][0].instance.name) == "c"
     assert str(stmt.value._variables[0][0].attribute) == "d"
     assert stmt.value._variables[0][0].instance.locatable_name.location == Range("test", 2, 7, 2, 8)
     assert stmt.value._variables[0][0].attribute.location == Range("test", 2, 9, 2, 10)
 
 
-def test_string_format_v2():
-    statements = parse_code('f"hello { world }"')
-    assert len(statements) == 1
-    stmt = statements[0]
-    assert isinstance(stmt, StringFormatV2)
-    assert len(stmt._variables) == 1
-    ref: Reference
-    full_name: str
-    ref, full_name = list(stmt._variables.items())[0]
-    assert ref.name == "world"
-    assert full_name == " world "
-
-    statements = parse_code('f"hello { world:>{width }}"')
-    assert len(statements) == 1
-    stmt = statements[0]
-    assert isinstance(stmt, StringFormatV2)
-    assert len(stmt._variables) == 2
-    assert {ref.name: full_name for ref, full_name in stmt._variables.items()} == {"world": " world", "width": "width "}
-    assert stmt._format_string == "hello { world:>{width }}"
-
-    with pytest.raises(ParserException, match=r"Syntax error: Invalid f-string:.*\(test:1:1\)"):
-        statements = parse_code('f"hello {"')
-
-
 def test_attribute_reference():
     statements = parse_code(
         """
 a=a::b::c.d
 """
     )
```

### Comparing `inmanta-core-8.7.4/tests/test_postgres.py` & `inmanta-core-9.3.0/tests/test_postgres.py`

 * *Files 14% similar despite different names*

```diff
@@ -11,15 +11,14 @@
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
-from asyncio import Event
 
 """
 This module contains tests related to PostgreSQL and how we interact with it. Its purpose is to verify PostgreSQL internals,
 especially those that are not explicitly documented anywhere. These tests act both as a confidence check for compatibility with
 future PostgreSQL versions and as a knowledge collector to refer back to when we need it.
 """
 import asyncio
@@ -166,67 +165,7 @@
 
     await insert()
     with pytest.raises(asyncpg.DeadlockDetectedError):
         await asyncio.gather(
             deadlock,
             delete(),
         )
-
-
-@pytest.mark.slowtest
-async def test_postgres_transaction_re_entry(postgresql_pool) -> None:
-    """
-    When do transaction lock each other out?
-
-    More specifically, how to make the release_version method lock itself out.
-    """
-
-    # Make a table
-    async with postgresql_pool.acquire() as connection:
-        await connection.execute("CREATE TABLE IF NOT EXISTS root (name varchar PRIMARY KEY, released BOOL);")
-        await connection.execute(
-            """
-            INSERT INTO root VALUES
-                ('root1', False),
-                ('root2', False);
-            """
-        )
-
-    async def update_root(name: str, lock: Event):
-        # Main routine: lock table and update if required
-        # there is lock given as an argument to make sure we can make one wait for the other
-        async with postgresql_pool.acquire() as connection:
-            async with connection.transaction():
-                print(f"{name}: ENTER")
-                # for update is the key here!!!
-                record = await connection.fetchrow("select released from root where name=$1 for update", "root1")
-                print(f"{name}: WAIT")
-                await lock.wait()
-                assert len(record) == 1
-                if record[0] is True:
-                    return False
-                print(f"{name}: UPDATE")
-                await connection.execute("UPDATE root SET released=true where name=$1", "root1")
-                return True
-        print(f"{name}: COMMITTED")
-
-    # Two locks
-    l1 = Event()
-    l2 = Event()
-
-    # Two task running
-    f1 = asyncio.create_task(update_root("1", l1))
-    f2 = asyncio.create_task(update_root("2", l2))
-
-    # Sleep a bit to get them to lock up
-    await asyncio.sleep(0.1)
-    # Unlock
-    l2.set()
-    l1.set()
-
-    # get results
-    r1 = await f1
-    r2 = await f2
-
-    # One should return true, the other false
-    print(r1, r2)
-    assert r1 + r2 == 1
```

### Comparing `inmanta-core-8.7.4/tests/test_postgres_proc.py` & `inmanta-core-9.3.0/tests/test_postgres_proc.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_project.py` & `inmanta-core-9.3.0/tests/test_project.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 """
 import base64
 import logging
 import os
 import uuid
 from collections import defaultdict
 from pathlib import Path
-from typing import cast
+from typing import Dict, List, cast
 
 import pytest
 
 from inmanta.data import model
 from inmanta.module import ModuleLoadingException, Project
 from inmanta.server import SLICE_ENVIRONMENT
 from inmanta.server.services.environmentservice import EnvironmentAction, EnvironmentListener, EnvironmentService
@@ -83,15 +83,15 @@
 
 async def test_project_api_v2_project_list_ordering(client_v2):
     """
     Creates a few projects with several environments each.
     Check that they are ordered by ascending (project_name, environment_name)
     """
 
-    project_environments_map: dict[str, list[str]] = defaultdict(list)
+    project_environments_map: Dict[str, List[str]] = defaultdict(lambda: [])
 
     for project_n in range(3):
         project_name: str = f"test-project-{project_n}"
         result = await client_v2.project_create(project_name)
         assert result.code == 200
         assert "data" in result.result
         assert "id" in result.result["data"]
@@ -182,15 +182,15 @@
 
     # Create env in non existing project
     result = await client_v2.environment_create(project_id=uuid.uuid4(), name="dev")
     assert result.code == 404
 
     # Create a duplicate environment
     result = await client_v2.environment_create(project_id=project_id, name="dev")
-    assert result.code == 400
+    assert result.code == 500
 
     # Modify a non existing environment
     result = await client_v2.environment_modify(id=uuid.uuid4(), name="dev")
     assert result.code == 404
 
     # Create a duplicate environment
     result = await client_v2.environment_create(project_id=project_id, name="dev", repository="")
@@ -208,18 +208,14 @@
     # Operation on non existing
     result = await client_v2.environment_get(id=uuid.uuid4())
     assert result.code == 404
 
     result = await client_v2.environment_delete(id=uuid.uuid4())
     assert result.code == 404
 
-    # Decommission
-    result = await client_v2.environment_decommission(id=env1_id)
-    assert result.code == 200
-
 
 async def test_modify_environment_project(client_v2):
     """Test modifying the project of an environment"""
 
     # Create two projects and two environments
     result = await client_v2.project_create("dev-project")
     assert result.code == 200
@@ -306,39 +302,14 @@
 
     result = await client.list_environments()
     assert result.code == 200
     assert "environments" in result.result
     assert len(result.result["environments"]) == 0
 
 
-async def test_create_env_same_name(client):
-    result = await client.create_project("env-test")
-    assert result.code == 200
-    assert "project" in result.result
-    assert "id" in result.result["project"]
-    project_id = result.result["project"]["id"]
-
-    result = await client.create_environment(project_id=project_id, name="dev1")
-    assert result.code == 200
-
-    result = await client.create_environment(project_id=project_id, name="dev2")
-    assert result.code == 200
-    env_id = result.result["environment"]["id"]
-
-    # try to create a new env with the same name as an existing one
-    result = await client.create_environment(project_id=project_id, name="dev1")
-    assert result.code == 400
-    assert f"Project with id={project_id} already has an environment with name dev1" in result.result["message"]
-
-    # try to rename an existing env using a name that is already used.
-    result = await client.modify_environment(id=env_id, name="dev1")
-    assert result.code == 400
-    assert f"Project with id={project_id} already has an environment with name dev1" in result.result["message"]
-
-
 async def test_project_cascade(client):
     result = await client.create_project("env-test")
     project_id = result.result["project"]["id"]
 
     result = await client.create_environment(project_id=project_id, name="dev")
     result = await client.create_environment(project_id=project_id, name="prod")
 
@@ -419,18 +390,14 @@
     result = await client_v2.environment_get(id=env1_id)
     assert result.code == 200
     assert result.result["data"]["name"] == "dev"
 
     result = await client_v2.environment_delete(id=uuid.uuid4())
     assert result.code == 404
 
-    # Decommission
-    result = await client_v2.environment_decommission(id=env1_id)
-    assert result.code == 200
-
     # Clear
     result = await client_v2.environment_clear(id=env1_id)
     assert result.code == 200
 
     # Delete
     result = await client_v2.environment_delete(id=env1_id)
     assert result.code == 200
@@ -464,24 +431,24 @@
             project.load()
         # make sure project load works after installing modules
         project.install_modules()
         project.load()
 
 
 @pytest.fixture
-def environment_icons() -> dict[str, str]:
+def environment_icons() -> Dict[str, str]:
     icon_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "icon")
     icon_names = ["logo.jpeg", "logo.png", "logo.svg", "logo.webp"]
     icon_dict = {}
     for name in icon_names:
         icon_dict[name.split(".")[1]] = base64.b64encode(Path(os.path.join(icon_dir, name)).read_bytes()).decode("utf-8")
     return icon_dict
 
 
-async def test_environment_icon_description(client_v2, environment_icons: dict[str, str]):
+async def test_environment_icon_description(client_v2, environment_icons: Dict[str, str]):
     """Test creating an environment with an icon and description"""
 
     result = await client_v2.project_create("dev-project")
     assert result.code == 200
     project_id_a = result.result["data"]["id"]
     desc = "This is an environment"
     result = await client_v2.environment_create(project_id=project_id_a, name="env", description=desc)
@@ -587,15 +554,15 @@
     assert result.code == 200
     assert result.result["data"]["icon"] == ""
 
     result = await client_v2.environment_modify(id_of_env_to_modify, name_of_env_to_modify, description="b" * 256)
     assert result.code == 400
 
 
-async def test_environment_icon_with_details_only(client_v2, environment_icons: dict[str, str]):
+async def test_environment_icon_with_details_only(client_v2, environment_icons: Dict[str, str]):
     """Test that the icon for an environment is only returned when explicitly requested"""
     result = await client_v2.project_create("dev-project")
     assert result.code == 200
     project_id_a = result.result["data"]["id"]
     # Create environment with description and icon
     icon_data_string = f"image/png;base64,{environment_icons['png']}"
     description = "desc"
```

### Comparing `inmanta-core-8.7.4/tests/test_projectmetadata.py` & `inmanta-core-9.3.0/tests/test_projectmetadata.py`

 * *Files 26% similar despite different names*

```diff
@@ -12,20 +12,20 @@
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 import logging
-from typing import Optional
+from typing import List, Optional
 
 import pytest
 
 from inmanta.module import ModuleRepoType, Project, ProjectMetadata, RelationPrecedenceRule
-from utils import assert_no_warning
+from utils import assert_no_warning, log_contains
 
 
 @pytest.mark.parametrize(
     "repo",
     [
         ("https://github.com/inmanta/{}.git"),
         ("git@github.com:inmanta/{}.git"),
@@ -71,30 +71,91 @@
 )
 def test_relation_precedence_policy_parsing(
     precedence_rule: str, valid: bool, expected_precedence_rule: Optional[RelationPrecedenceRule]
 ) -> None:
     if valid:
         assert expected_precedence_rule is not None
         project_metadata = ProjectMetadata(name="test", relation_precedence_policy=[precedence_rule])
-        relation_precedence_rules: list[RelationPrecedenceRule] = project_metadata.get_relation_precedence_rules()
+        relation_precedence_rules: List[RelationPrecedenceRule] = project_metadata.get_relation_precedence_rules()
         assert len(relation_precedence_rules) == 1
         assert relation_precedence_rules[0] == expected_precedence_rule
     else:
         with pytest.raises(ValueError):
             ProjectMetadata(name="test", relation_precedence_policy=[precedence_rule])
 
 
 def test_no_module_path(tmp_path, caplog):
     with caplog.at_level(logging.WARNING):
         with (tmp_path / "project.yml").open("w") as fh:
             fh.write(
                 """
     name: testproject
     downloadpath: libs
+    pip:
+        index_urls:
+            - https://pypi.org/simple
+    """
+            )
+
+        Project(tmp_path, autostd=False)
+    assert_no_warning(caplog)
+
+
+def test_deprecation_warning_repo_of_type_package(tmp_path, caplog):
+    with caplog.at_level(logging.WARNING):
+        with (tmp_path / "project.yml").open("w") as fh:
+            fh.write(
+                """
+    name: testproject
+    downloadpath: libs
     repo:
-        - url: https://pypi.org/simple
-          type: package
+       - url: https://pypi.org/simple
+         type: package
+    pip:
+        index_urls:
+            - https://pypi.org/simple
     """
             )
 
         Project(tmp_path, autostd=False)
+    log_contains(
+        caplog,
+        "inmanta.module",
+        logging.WARNING,
+        (
+            "Setting a pip index through the `repo -> url` option with type `package` in the project.yml file is deprecated. "
+            "Please set the pip index url through the `pip -> index_urls` option instead."
+        ),
+    )
+
+
+@pytest.mark.parametrize("use_pip_config_file, value", [(True, True), (True, False), (False, False)])
+def test_pip_config(tmp_path, caplog, use_pip_config_file, value):
+    """
+    Verify that "use_config_file" can be specified in a project.yml file but that it isn't mandatory
+    If it is not specified, verify that the default value "False" is used in the project.
+    """
+    pip_config_file = """
+    pip:
+        index_urls:
+            - https://pypi.org/simple
+
+    """
+    pip_config_file += (
+        f"""
+        use_config_file: {value}
+        """
+        if use_pip_config_file
+        else ""
+    )
+    with caplog.at_level(logging.WARNING):
+        with (tmp_path / "project.yml").open("w") as fh:
+            fh.write(
+                f"""
+    name: testproject
+    downloadpath: libs
+    {pip_config_file}
+    """
+            )
+    project = Project(tmp_path, autostd=False)
     assert_no_warning(caplog)
+    assert project.metadata.pip.use_config_file == value
```

### Comparing `inmanta-core-8.7.4/tests/test_protocol.py` & `inmanta-core-9.3.0/tests/test_protocol.py`

 * *Files 5% similar despite different names*

```diff
@@ -20,18 +20,17 @@
 import datetime
 import json
 import os
 import random
 import time
 import urllib.parse
 import uuid
-from collections.abc import Iterator
 from enum import Enum
 from itertools import chain
-from typing import Any, Optional, Union
+from typing import Any, Dict, Iterator, List, Optional, Union
 
 import pydantic
 import pytest
 import tornado
 from pydantic.types import StrictBool
 from tornado import web
 from tornado.httpclient import AsyncHTTPClient, HTTPRequest
@@ -153,20 +152,20 @@
 
     other_files = ["testtest"]
     result = await client.stat_files(files=file_names + other_files)
     assert len(result.result["files"]) == len(other_files)
 
 
 async def test_diff(client):
-    ca = b"Hello world\n"
+    ca = "Hello world\n".encode()
     ha = hash_file(ca)
     result = await client.upload_file(id=ha, content=base64.b64encode(ca).decode("ascii"))
     assert result.code == 200
 
-    cb = b"Bye bye world\n"
+    cb = "Bye bye world\n".encode()
     hb = hash_file(cb)
     result = await client.upload_file(id=hb, content=base64.b64encode(cb).decode("ascii"))
     assert result.code == 200
 
     diff = await client.diff(ha, hb)
     assert diff.code == 200
     assert len(diff.result["diff"]) == 5
@@ -196,15 +195,15 @@
     state_dir = opt.state_dir.get()
 
     file_dir = os.path.join(state_dir, "server", "files")
 
     file_name = os.path.join(file_dir, hash)
 
     with open(file_name, "wb+") as fd:
-        fd.write(b"Haha!")
+        fd.write("Haha!".encode())
 
     opt.server_delete_currupt_files.set("false")
     result = await client.get_file(id=hash)
     assert result.code == 500
 
     result = await client.upload_file(id=hash, content=body)
     assert result.code == 500
@@ -220,15 +219,15 @@
 async def test_gzip_encoding(server):
     """
     Test if the server accepts gzipped encoding and returns gzipped encoding.
     """
     (hash, content, body) = make_random_file(size=1024)
 
     port = opt.get_bind_port()
-    url = f"http://localhost:{port}/api/v1/file/{hash}"
+    url = "http://localhost:%s/api/v1/file/%s" % (port, hash)
 
     zipped, body = protocol.gzipped_json({"content": body})
     assert zipped
 
     request = HTTPRequest(
         url=url,
         method="PUT",
@@ -425,27 +424,27 @@
         @protocol.typedmethod(path="/test", operation="POST", client_types=["api"])
         def test_method(project: Project) -> ReturnValue[Project]:  # NOQA
             """
             Create a new project
             """
 
         @protocol.typedmethod(path="/test2", operation="POST", client_types=["api"])
-        def test_method2(project: list[Project]) -> ReturnValue[list[Project]]:  # NOQA
+        def test_method2(project: List[Project]) -> ReturnValue[List[Project]]:  # NOQA
             """
             Create a new project
             """
 
         @protocol.handle(test_method)
         async def test_methodi(self, project: Project) -> ReturnValue[Project]:
             new_project = project.copy()
 
             return ReturnValue(response=new_project)
 
         @protocol.handle(test_method2)
-        async def test_method2i(self, project: list[Project]) -> ReturnValue[list[Project]]:
+        async def test_method2i(self, project: List[Project]) -> ReturnValue[List[Project]]:
             return ReturnValue(response=project)
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -778,19 +777,19 @@
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class Project(BaseModel):
         name: str
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=["api"])
-        def test_method(data: list[Project], data2: list[int]) -> Project:  # NOQA
+        def test_method(data: List[Project], data2: List[int]) -> Project:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, data: list[Project], data2: list[int]) -> Project:
+        async def test_method(self, data: List[Project], data2: List[int]) -> Project:
             assert len(data) == 1
             assert data[0].name == "test"
             assert len(data2) == 3
 
             return Project(name="test_method")
 
     rs = Server()
@@ -811,19 +810,19 @@
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class Project(BaseModel):
         name: str
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=["api"])
-        def test_method(data: dict[str, Project], data2: dict[str, int]) -> Project:  # NOQA
+        def test_method(data: Dict[str, Project], data2: Dict[str, int]) -> Project:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, data: dict[str, Project], data2: dict[str, int]) -> Project:
+        async def test_method(self, data: Dict[str, Project], data2: Dict[str, int]) -> Project:
             assert len(data) == 1
             assert data["projectA"].name == "test"
             assert len(data2) == 3
 
             return Project(name="test_method")
 
     rs = Server()
@@ -846,19 +845,19 @@
     types = Union[pydantic.StrictInt, pydantic.StrictStr]
 
     class Result(BaseModel):
         val: Optional[types]
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=["api"])
-        def test_method(data: dict[str, Optional[types]]) -> Result:  # NOQA
+        def test_method(data: Dict[str, Optional[types]]) -> Result:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, data: dict[str, Optional[types]]) -> Result:
+        async def test_method(self, data: Dict[str, Optional[types]]) -> Result:
             assert len(data) == 1
             assert "test" in data
             return Result(val=data["test"])
 
         @protocol.typedmethod(path="/test", operation="GET", client_types=["api"])
         def test_method2(data: Optional[str] = None) -> None:  # NOQA
             pass
@@ -899,27 +898,27 @@
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class Project(BaseModel):
         name: str
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=["api"])
-        def test_method(data: Project) -> list[Project]:  # NOQA
+        def test_method(data: Project) -> List[Project]:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, data: Project) -> list[Project]:  # NOQA
+        async def test_method(self, data: Project) -> List[Project]:  # NOQA
             return [Project(name="test_method")]
 
         @protocol.typedmethod(path="/test2", operation="POST", client_types=["api"])
-        def test_method2(data: Project) -> list[str]:  # NOQA
+        def test_method2(data: Project) -> List[str]:  # NOQA
             pass
 
         @protocol.handle(test_method2)
-        async def test_method2(self, data: Project) -> list[str]:  # NOQA
+        async def test_method2(self, data: Project) -> List[str]:  # NOQA
             return ["test_method"]
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -955,43 +954,43 @@
 
         @protocol.typedmethod(path="/test", operation="PUT", client_types=["api"])
         def test_method2(name: Iterator[str]) -> None:
             """
             Create a new project
             """
 
-    assert "Type collections.abc.Iterator[str] of argument name can only be generic List, Dict or Literal" in str(e.value)
+    assert "Type typing.Iterator[str] of argument name can only be generic List, Dict or Literal" in str(e.value)
 
     with pytest.raises(InvalidMethodDefinition) as e:
 
         @protocol.typedmethod(path="/test", operation="PUT", client_types=["api"])
-        def test_method3(name: list[object]) -> None:
+        def test_method3(name: List[object]) -> None:
             """
             Create a new project
             """
 
     assert (
         "Type object of argument name must be a either BaseModel, Enum, UUID, str, float, int, StrictNonIntBool, datetime, "
         "bytes or a List of these types or a Dict with str keys and values of these types."
     ) in str(e.value)
 
     with pytest.raises(InvalidMethodDefinition) as e:
 
         @protocol.typedmethod(path="/test", operation="PUT", client_types=["api"])
-        def test_method4(name: dict[int, str]) -> None:
+        def test_method4(name: Dict[int, str]) -> None:
             """
             Create a new project
             """
 
-    assert "Type dict[int, str] of argument name must be a Dict with str keys and not int" in str(e.value)
+    assert "Type typing.Dict[int, str] of argument name must be a Dict with str keys and not int" in str(e.value)
 
     with pytest.raises(InvalidMethodDefinition) as e:
 
         @protocol.typedmethod(path="/test", operation="PUT", client_types=["api"])
-        def test_method5(name: dict[str, object]) -> None:
+        def test_method5(name: Dict[str, object]) -> None:
             """
             Create a new project
             """
 
     assert (
         "Type object of argument name must be a either BaseModel, Enum, UUID, str, float, int, StrictNonIntBool, datetime, "
         "bytes or a List of these types or a Dict with str keys and values of these types."
@@ -1009,33 +1008,33 @@
 
 
 async def test_union_types(unused_tcp_port, postgres_db, database_name, async_finalizer):
     """Test use of union types"""
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     SimpleTypes = Union[float, int, StrictBool, str]  # NOQA
-    AttributeTypes = Union[SimpleTypes, list[SimpleTypes], dict[str, SimpleTypes]]  # NOQA
+    AttributeTypes = Union[SimpleTypes, List[SimpleTypes], Dict[str, SimpleTypes]]  # NOQA
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="GET", client_types=["api"])
-        def test_method(data: SimpleTypes, version: Optional[int] = None) -> list[SimpleTypes]:  # NOQA
+        def test_method(data: SimpleTypes, version: Optional[int] = None) -> List[SimpleTypes]:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, data: SimpleTypes, version: Optional[int] = None) -> list[SimpleTypes]:  # NOQA
+        async def test_method(self, data: SimpleTypes, version: Optional[int] = None) -> List[SimpleTypes]:  # NOQA
             if isinstance(data, list):
                 return data
             return [data]
 
         @protocol.typedmethod(path="/testp", operation="POST", client_types=["api"])
-        def test_methodp(data: AttributeTypes, version: Optional[int] = None) -> list[SimpleTypes]:  # NOQA
+        def test_methodp(data: AttributeTypes, version: Optional[int] = None) -> List[SimpleTypes]:  # NOQA
             pass
 
         @protocol.handle(test_methodp)
-        async def test_methodp(self, data: AttributeTypes, version: Optional[int] = None) -> list[SimpleTypes]:  # NOQA
+        async def test_methodp(self, data: AttributeTypes, version: Optional[int] = None) -> List[SimpleTypes]:  # NOQA
             if isinstance(data, list):
                 return data
             return [data]
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
@@ -1476,21 +1475,21 @@
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(
             api_prefix="test", path="/project/<project>", operation="GET", arg_options=ENV_OPTS, client_types=["api"]
         )
         def test_method(
             tid: uuid.UUID, project: str, include_deleted: bool = False
-        ) -> list[Union[uuid.UUID, Project, bool]]:  # NOQA
+        ) -> List[Union[uuid.UUID, Project, bool]]:  # NOQA
             pass
 
         @protocol.handle(test_method)
         async def test_method(
             tid: uuid.UUID, project: Project, include_deleted: bool = False
-        ) -> list[Union[uuid.UUID, Project, bool]]:  # NOQA
+        ) -> List[Union[uuid.UUID, Project, bool]]:  # NOQA
             return [tid, project, include_deleted]
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -1526,15 +1525,15 @@
     async_finalizer.add(rs.stop)
 
     request = MethodProperties.methods["test_method"][0].build_call(args=[], kwargs={"id": "1", "name": "monty", "age": 42})
     assert request.url == "/api/v1/test/1/monty?age=42"
 
 
 async def test_2151_method_header_parameter_in_body(async_finalizer, unused_tcp_port) -> None:
-    async def _id(x: object, dct: dict[str, str]) -> object:
+    async def _id(x: object, dct: Dict[str, str]) -> object:
         return x
 
     @protocol.method(
         path="/testmethod",
         operation="POST",
         arg_options={"header_param": ArgOption(header="X-Inmanta-Header-Param", getter=_id)},
         client_types=[const.ClientType.api],
@@ -1648,75 +1647,75 @@
         @protocol.typedmethod(path="/testmethod", operation="POST", client_types=[const.ClientType.api])
         def test_method(arg: Any) -> None:
             pass
 
 
 async def test_method_nonstrict_allowed(async_finalizer, unused_tcp_port) -> None:
     @protocol.typedmethod(path="/zipsingle", operation="POST", client_types=[const.ClientType.api], strict_typing=False)
-    def merge_dicts(one: dict[str, Any], other: dict[str, int], any_arg: Any) -> dict[str, Any]:
+    def merge_dicts(one: Dict[str, Any], other: Dict[str, int], any_arg: Any) -> Dict[str, Any]:
         """
         Merge two dicts.
         """
 
     class TestSlice(ServerSlice):
         @protocol.handle(merge_dicts)
-        async def merge_dicts_impl(self, one: dict[str, Any], other: dict[str, int], any_arg: Any) -> dict[str, Any]:
+        async def merge_dicts_impl(self, one: Dict[str, Any], other: Dict[str, int], any_arg: Any) -> Dict[str, Any]:
             return {**one, **other}
 
     configure(unused_tcp_port, "", "")
     server: Server = Server()
     server_slice: ServerSlice = TestSlice("my_test_slice")
     server.add_slice(server_slice)
     await server.start()
     async_finalizer.add(server_slice.stop)
     async_finalizer.add(server.stop)
 
     client: protocol.Client = protocol.Client("client")
 
-    one: dict[str, Any] = {"my": {"nested": {"keys": 42}}}
-    other: dict[str, int] = {"single_level": 42}
+    one: Dict[str, Any] = {"my": {"nested": {"keys": 42}}}
+    other: Dict[str, int] = {"single_level": 42}
     response: Result = await client.merge_dicts(one, other, None)
     assert response.code == 200
     assert response.result == {"data": {**one, **other}}
 
 
 @pytest.mark.parametrize(
     "param_type,param_value,expected_url",
     [
         (
-            dict[str, str],
+            Dict[str, str],
             {"a": "b", "c": "d", ",&?=%": ",&?=%."},
             "/api/v1/test/1/monty?filter.a=b&filter.c=d&filter.%2C%26%3F%3D%25=%2C%26%3F%3D%25.",
         ),
         (
-            dict[str, list[str]],
+            Dict[str, List[str]],
             {"a": ["b"], "c": ["d", "e"], "g": ["h"]},
             "/api/v1/test/1/monty?filter.a=b&filter.c=d&filter.c=e&filter.g=h",
         ),
         (
-            dict[str, list[str]],
+            Dict[str, List[str]],
             {"a": ["b"], "c": ["d", "e"], ",&?=%": [",&?=%", "f"], ".g.h": ["i"]},
             "/api/v1/test/1/monty?filter.a=b&filter.c=d&filter.c=e"
             "&filter.%2C%26%3F%3D%25=%2C%26%3F%3D%25&filter.%2C%26%3F%3D%25=f&filter..g.h=i",
         ),
         (
-            list[str],
+            List[str],
             [
                 "a ",
                 "b,",
                 "c",
             ],
             "/api/v1/test/1/monty?filter=a+&filter=b%2C&filter=c",
         ),
         (
-            list[str],
+            List[str],
             ["a", "b", ",&?=%", "c", "."],
             "/api/v1/test/1/monty?filter=a&filter=b&filter=%2C%26%3F%3D%25&filter=c&filter=.",
         ),
-        (list[str], ["a ", "b", "c", ","], "/api/v1/test/1/monty?filter=a+&filter=b&filter=c&filter=%2C"),
+        (List[str], ["a ", "b", "c", ","], "/api/v1/test/1/monty?filter=a+&filter=b&filter=c&filter=%2C"),
     ],
 )
 async def test_dict_list_get_roundtrip(
     unused_tcp_port, postgres_db, database_name, async_finalizer, param_type, param_value, expected_url
 ):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
@@ -1748,19 +1747,19 @@
 
 
 async def test_dict_get_optional(unused_tcp_port, postgres_db, database_name, async_finalizer):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test/<id>/<name>", operation="GET", client_types=["api"])
-        def test_method(id: str, name: str, filter: Optional[dict[str, str]] = None) -> str:  # NOQA
+        def test_method(id: str, name: str, filter: Optional[Dict[str, str]] = None) -> str:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str, name: str, filter: Optional[dict[str, str]] = None) -> str:  # NOQA
+        async def test_method(self, id: str, name: str, filter: Optional[Dict[str, str]] = None) -> str:  # NOQA
             return ",".join(filter.keys()) if filter is not None else ""
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -1782,19 +1781,19 @@
 
 
 async def test_dict_list_nested_get_optional(unused_tcp_port, postgres_db, database_name, async_finalizer):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test/<id>/<name>", operation="GET", client_types=["api"])
-        def test_method(id: str, name: str, filter: Optional[dict[str, list[str]]] = None) -> str:  # NOQA
+        def test_method(id: str, name: str, filter: Optional[Dict[str, List[str]]] = None) -> str:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str, name: str, filter: Optional[dict[str, list[str]]] = None) -> str:  # NOQA
+        async def test_method(self, id: str, name: str, filter: Optional[Dict[str, List[str]]] = None) -> str:  # NOQA
             return ",".join(filter.keys()) if filter is not None else ""
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -1815,23 +1814,23 @@
     assert response.result["data"] == ""
 
 
 @pytest.mark.parametrize(
     "param_type,expected_error_message",
     [
         (
-            dict[str, dict[str, str]],
+            Dict[str, Dict[str, str]],
             "nested dictionaries and union types for dictionary values are not supported for GET requests",
         ),
         (
-            dict[str, Union[str, list[str]]],
+            Dict[str, Union[str, List[str]]],
             "nested dictionaries and union types for dictionary values are not supported for GET requests",
         ),
-        (list[dict[str, str]], "lists of dictionaries and lists of lists are not supported for GET requests"),
-        (list[list[str]], "lists of dictionaries and lists of lists are not supported for GET requests"),
+        (List[Dict[str, str]], "lists of dictionaries and lists of lists are not supported for GET requests"),
+        (List[List[str]], "lists of dictionaries and lists of lists are not supported for GET requests"),
     ],
 )
 async def test_dict_list_get_invalid(
     unused_tcp_port, postgres_db, database_name, async_finalizer, param_type, expected_error_message
 ):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
@@ -1850,27 +1849,27 @@
 
 
 async def test_list_get_optional(unused_tcp_port, postgres_db, database_name, async_finalizer):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test/<id>/<name>", operation="GET", client_types=["api"])
-        def test_method(id: str, name: str, sort: Optional[list[int]] = None) -> str:  # NOQA
+        def test_method(id: str, name: str, sort: Optional[List[int]] = None) -> str:  # NOQA
             pass
 
         @protocol.typedmethod(path="/test_uuid/<id>", operation="GET", client_types=["api"])
-        def test_method_uuid(id: str, sort: Optional[list[uuid.UUID]] = None) -> str:  # NOQA
+        def test_method_uuid(id: str, sort: Optional[List[uuid.UUID]] = None) -> str:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str, name: str, sort: Optional[list[int]] = None) -> str:  # NOQA
+        async def test_method(self, id: str, name: str, sort: Optional[List[int]] = None) -> str:  # NOQA
             return str(sort) if sort else ""
 
         @protocol.handle(test_method_uuid)
-        async def test_method_uuid(self, id: str, sort: Optional[list[uuid.UUID]] = None) -> str:  # NOQA
+        async def test_method_uuid(self, id: str, sort: Optional[List[uuid.UUID]] = None) -> str:  # NOQA
             return str(sort) if sort else ""
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -1895,20 +1894,20 @@
 
 
 async def test_dicts_multiple_get(unused_tcp_port, postgres_db, database_name, async_finalizer):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test/<id>/<name>", operation="GET", client_types=["api"])
-        def test_method(id: str, name: str, filter: dict[str, list[str]], another_filter: dict[str, str]) -> str:  # NOQA
+        def test_method(id: str, name: str, filter: Dict[str, List[str]], another_filter: Dict[str, str]) -> str:  # NOQA
             pass
 
         @protocol.handle(test_method)
         async def test_method(
-            self, id: str, name: str, filter: dict[str, list[str]], another_filter: dict[str, str]
+            self, id: str, name: str, filter: Dict[str, List[str]], another_filter: Dict[str, str]
         ) -> str:  # NOQA
             return ",".join(chain(filter.keys(), another_filter.keys()))
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
@@ -1928,35 +1927,35 @@
 
 
 async def test_dict_list_get_by_url(unused_tcp_port, postgres_db, database_name, async_finalizer):
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test/<id>/<name>", operation="GET", client_types=["api"])
-        def test_method(id: str, name: str, filter: dict[str, str]) -> str:  # NOQA
+        def test_method(id: str, name: str, filter: Dict[str, str]) -> str:  # NOQA
             pass
 
         @protocol.typedmethod(path="/test_list/<id>", operation="GET", client_types=["api"])
-        def test_method_list(id: str, filter: list[int]) -> str:  # NOQA
+        def test_method_list(id: str, filter: List[int]) -> str:  # NOQA
             pass
 
         @protocol.typedmethod(path="/test_dict_of_lists/<id>", operation="GET", client_types=["api"])
-        def test_method_dict_of_lists(id: str, filter: dict[str, list[str]]) -> str:  # NOQA
+        def test_method_dict_of_lists(id: str, filter: Dict[str, List[str]]) -> str:  # NOQA
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str, name: str, filter: dict[str, str]) -> str:  # NOQA
+        async def test_method(self, id: str, name: str, filter: Dict[str, str]) -> str:  # NOQA
             return ",".join(filter.keys())
 
         @protocol.handle(test_method_list)
-        async def test_method_list(self, id: str, filter: list[int]) -> str:  # NOQA
+        async def test_method_list(self, id: str, filter: List[int]) -> str:  # NOQA
             return str(filter)
 
         @protocol.handle(test_method_dict_of_lists)
-        async def test_method_dict_of_lists(self, id: str, filter: dict[str, list[str]]) -> str:  # NOQA
+        async def test_method_dict_of_lists(self, id: str, filter: Dict[str, List[str]]) -> str:  # NOQA
             return ",".join(filter.keys())
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -2020,19 +2019,19 @@
 
     timezone: datetime.timezone = datetime.timezone(datetime.timedelta(hours=2))
     now: datetime.datetime = datetime.datetime.now().astimezone(timezone)
     naive_utc: datetime.datetime = now.astimezone(datetime.timezone.utc).replace(tzinfo=None)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="GET", client_types=["api"])
-        def test_method(timestamp: datetime.datetime) -> list[datetime.datetime]:
+        def test_method(timestamp: datetime.datetime) -> List[datetime.datetime]:
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, timestamp: datetime.datetime) -> list[datetime.datetime]:
+        async def test_method(self, timestamp: datetime.datetime) -> List[datetime.datetime]:
             assert timestamp.tzinfo is not None
             assert timestamp == now
             return [
                 now,
                 now.astimezone(datetime.timezone.utc),
                 now.astimezone(datetime.timezone.utc).replace(tzinfo=None),
             ]
@@ -2044,25 +2043,16 @@
     async_finalizer.add(server.stop)
     async_finalizer.add(rs.stop)
 
     client: protocol.Client = protocol.Client("client")
 
     response: Result = await client.test_method(timestamp=now)
     assert response.code == 200
+    assert all(pydantic.parse_obj_as(datetime.datetime, timestamp) == naive_utc for timestamp in response.result["data"])
 
-    def convert_to_naive_utc(timestamp: str) -> datetime.datetime:
-        datetime_obj = pydantic.parse_obj_as(datetime.datetime, timestamp)
-        if datetime_obj.tzinfo:
-            datetime_obj = datetime_obj.astimezone(datetime.timezone.utc).replace(tzinfo=None)
-
-        return datetime_obj
-
-    timestamps = [convert_to_naive_utc(timestamp) for timestamp in response.result["data"]]
-
-    assert all(timestamp == naive_utc for timestamp in timestamps)
     response: Result = await client.test_method(timestamp=now.astimezone(datetime.timezone.utc))
     assert response.code == 200
 
     response: Result = await client.test_method(timestamp=now.astimezone(datetime.timezone.utc).replace(tzinfo=None))
     assert response.code == 200
 
     response: Result = await client.test_method(timestamp=now.replace(tzinfo=None))
@@ -2099,19 +2089,19 @@
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class APydanticType(BaseModel):
         attr: int
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="GET", client_types=[const.ClientType.api])
-        def test_method(id: str) -> dict[str, list[APydanticType]]:
+        def test_method(id: str) -> Dict[str, List[APydanticType]]:
             pass
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str) -> dict[str, list[APydanticType]]:
+        async def test_method(self, id: str) -> Dict[str, List[APydanticType]]:
             return {id: [APydanticType(attr=1), APydanticType(attr=5)]}
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -2165,21 +2155,21 @@
     """
     Test the use and validation of methods that use common.ReturnValue
     """
     configure(unused_tcp_port, database_name, postgres_db.port)
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=[ClientType.api], varkw=True)
-        def test_method(id: str, **kwargs: object) -> dict[str, str]:  # NOQA
+        def test_method(id: str, **kwargs: object) -> Dict[str, str]:  # NOQA
             """
             Create a new project
             """
 
         @protocol.handle(test_method)
-        async def test_method(self, id: str, **kwargs: object) -> dict[str, str]:
+        async def test_method(self, id: str, **kwargs: object) -> Dict[str, str]:
             return {"name": str(kwargs["name"]), "value": str(kwargs["value"])}
 
     rs = Server()
     server = ProjectServer(name="projectserver")
     rs.add_slice(server)
     await rs.start()
     async_finalizer.add(server.stop)
@@ -2195,39 +2185,39 @@
 async def test_get_description_foreach_http_status_code() -> None:
     """
     Test whether the `MethodProperties.get_description_foreach_http_status_code()` method works as expected.
     """
 
     class ProjectServer(ServerSlice):
         @protocol.typedmethod(path="/test", operation="POST", client_types=[ClientType.api], varkw=True)
-        def test_method1(id: str, **kwargs: object) -> dict[str, str]:  # NOQA
+        def test_method1(id: str, **kwargs: object) -> Dict[str, str]:  # NOQA
             """
             Create a new project
 
             :returns: A new project
             :raises NotFound: The id was not found.
             :raises 500: A server error.
             """
 
         @protocol.typedmethod(path="/test", operation="POST", client_types=[ClientType.api], varkw=True)
-        def test_method2(id: str, **kwargs: object) -> dict[str, str]:  # NOQA
+        def test_method2(id: str, **kwargs: object) -> Dict[str, str]:  # NOQA
             """
             Create a new project
 
             :returns:
             :raises NotFound:
             :raises 500:
             """
 
     method_properties = protocol.common.MethodProperties.methods["test_method1"][0]
-    response_code_to_description: dict[int, str] = method_properties.get_description_foreach_http_status_code()
+    response_code_to_description: Dict[int, str] = method_properties.get_description_foreach_http_status_code()
     assert len(response_code_to_description) == 3
     assert response_code_to_description[200] == "A new project"
     assert response_code_to_description[404] == "The id was not found."
     assert response_code_to_description[500] == "A server error."
 
     method_properties = protocol.common.MethodProperties.methods["test_method2"][0]
-    response_code_to_description: dict[int, str] = method_properties.get_description_foreach_http_status_code()
+    response_code_to_description: Dict[int, str] = method_properties.get_description_foreach_http_status_code()
     assert len(response_code_to_description) == 3
     assert response_code_to_description[200] == ""
     assert response_code_to_description[404] == ""
     assert response_code_to_description[500] == ""
```

### Comparing `inmanta-core-8.7.4/tests/test_proxy.py` & `inmanta-core-9.3.0/tests/test_proxy.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_resource.py` & `inmanta-core-9.3.0/tests/test_resource.py`

 * *Files identical despite different names*

### Comparing `inmanta-core-8.7.4/tests/test_server.py` & `inmanta-core-9.3.0/tests/test_server.py`

 * *Files 3% similar despite different names*

```diff
@@ -18,26 +18,25 @@
 
 import asyncio
 import base64
 import json
 import logging
 import os
 import uuid
-from datetime import datetime, timedelta, timezone
+from datetime import datetime, timedelta
 from functools import partial
 
 import pytest
 from dateutil import parser
 from tornado.httpclient import AsyncHTTPClient, HTTPRequest
 
-from inmanta import config, const, data, loader, resources
+from inmanta import const, data, loader, resources
 from inmanta.agent import handler
 from inmanta.agent.agent import Agent
 from inmanta.const import ParameterSource
-from inmanta.data import AUTO_DEPLOY
 from inmanta.data.model import AttributeStateChange, LogLine, ResourceVersionIdStr
 from inmanta.export import upload_code
 from inmanta.protocol import Client
 from inmanta.server import (
     SLICE_AGENT_MANAGER,
     SLICE_AUTOSTARTED_AGENT_MANAGER,
     SLICE_ORCHESTRATION,
@@ -204,17 +203,14 @@
     project_id = result.result["project"]["id"]
 
     # Create environment
     result = await client.create_environment(project_id=project_id, name="env_1")
     env_1_id = result.result["environment"]["id"]
     result = await client.set_setting(tid=env_1_id, id=data.AVAILABLE_VERSIONS_TO_KEEP, value=n_versions_to_keep)
     assert result.code == 200
-    # Make sure we don't have a released version. _purge_versions() always keeps the latest released version.
-    result = await client.set_setting(env_1_id, AUTO_DEPLOY, False)
-    assert result.code == 200
 
     # Check value was set
     result = await client.get_setting(tid=env_1_id, id=data.AVAILABLE_VERSIONS_TO_KEEP)
     assert result.code == 200
     assert result.result["value"] == n_versions_to_keep
 
     for _ in range(n_versions_to_create):
@@ -230,76 +226,14 @@
 
     await server.get_slice(SLICE_ORCHESTRATION)._purge_versions()
 
     versions = await client.list_versions(tid=env_1_id)
     assert versions.result["count"] == min(n_versions_to_keep, n_versions_to_create)
 
 
-@pytest.mark.parametrize("has_released_versions", [True, False])
-async def test_purge_versions(server, client, environment, has_released_versions: bool) -> None:
-    """
-    Verify that the `OrchestrationService._purge_versions()` method works correctly and that it doesn't cleanup
-    the latest released version.
-    """
-    result = await client.set_setting(tid=environment, id=data.AUTO_DEPLOY, value="false")
-    assert result.code == 200
-
-    versions = []
-    for _ in range(5):
-        version = (await client.reserve_version(environment)).result["data"]
-        versions.append(version)
-        res = await client.put_version(
-            tid=environment,
-            version=version,
-            resources=[
-                {
-                    "id": f"unittest::Resource[internal,name=ok],v={version}",
-                    "name": "root",
-                    "desired_value": "ok",
-                    "send_event": "false",
-                    "purged": False,
-                    "requires": [],
-                }
-            ],
-            unknowns=[],
-            version_info={},
-            compiler_version=get_compiler_version(),
-        )
-        assert res.code == 200
-
-    if has_released_versions:
-        for v in versions[0:2]:
-            result = await client.release_version(environment, id=v)
-            assert result.code == 200
-
-    result = await client.set_setting(tid=environment, id=data.AVAILABLE_VERSIONS_TO_KEEP, value=3)
-    assert result.code == 200
-    await server.get_slice(SLICE_ORCHESTRATION)._purge_versions()
-
-    result = await client.list_versions(environment)
-    assert result.code == 200
-    assert result.result["count"] == (4 if has_released_versions else 3)
-    if has_released_versions:
-        assert {v["version"] for v in result.result["versions"]} == {versions[1], *versions[2:]}
-    else:
-        assert {v["version"] for v in result.result["versions"]} == {*versions[2:]}
-
-    result = await client.set_setting(tid=environment, id=data.AVAILABLE_VERSIONS_TO_KEEP, value=1)
-    assert result.code == 200
-    await server.get_slice(SLICE_ORCHESTRATION)._purge_versions()
-
-    result = await client.list_versions(environment)
-    assert result.code == 200
-    assert result.result["count"] == (2 if has_released_versions else 1)
-    if has_released_versions:
-        assert {v["version"] for v in result.result["versions"]} == {versions[1], *versions[4:]}
-    else:
-        assert {v["version"] for v in result.result["versions"]} == {*versions[4:]}
-
-
 async def test_n_versions_env_setting_scope(client, server):
     """
     The AVAILABLE_VERSIONS_TO_KEEP environment setting used to be a global config option.
     This test checks that a specific environment setting can be set for each environment
     """
 
     n_versions_to_keep_env1 = 5
@@ -313,25 +247,19 @@
     project_id = result.result["project"]["id"]
 
     # Create environments
     result = await client.create_environment(project_id=project_id, name="env_1")
     env_1_id = result.result["environment"]["id"]
     result = await client.set_setting(tid=env_1_id, id=data.AVAILABLE_VERSIONS_TO_KEEP, value=n_versions_to_keep_env1)
     assert result.code == 200
-    # Make sure we don't have a released version. _purge_versions() always keeps the latest released version.
-    result = await client.set_setting(env_1_id, AUTO_DEPLOY, False)
-    assert result.code == 200
 
     result = await client.create_environment(project_id=project_id, name="env_2")
     env_2_id = result.result["environment"]["id"]
     result = await client.set_setting(tid=env_2_id, id=data.AVAILABLE_VERSIONS_TO_KEEP, value=n_versions_to_keep_env2)
     assert result.code == 200
-    # Make sure we don't have a released version. _purge_versions() always keeps the latest released version.
-    result = await client.set_setting(env_2_id, AUTO_DEPLOY, False)
-    assert result.code == 200
 
     # Create a lot of versions in both environments
     for _ in range(n_many_versions):
         env1_version = (await client.reserve_version(env_1_id)).result["data"]
         env2_version = (await client.reserve_version(env_2_id)).result["data"]
 
         res = await client.put_version(
@@ -380,17 +308,14 @@
     agent = Agent("localhost", {"nvblah": "localhost"}, environment=environment_multi, code_loader=False)
     await agent.add_end_point_name("vm1.dev.inmanta.com")
     await agent.add_end_point_name("vm2.dev.inmanta.com")
     async_finalizer(agent.stop)
     await agent.start()
     aclient = agent._client
 
-    agentmanager = server_multi.get_slice(SLICE_AGENT_MANAGER)
-    await retry_limited(lambda: len(agentmanager.sessions) == 1, 10)
-
     version = (await client_multi.reserve_version(environment_multi)).result["data"]
 
     resources = [
         {
             "group": "root",
             "hash": "89bf880a0dc5ffc1156c8d958b4960971370ee6a",
             "id": "std::File[vm1.dev.inmanta.com,path=/etc/sysconfig/network],v=%d" % version,
@@ -552,17 +477,14 @@
     Test updating resources and logging
     """
     agent = Agent("localhost", {"blah": "localhost"}, environment=environment, code_loader=False)
     async_finalizer(agent.stop)
     await agent.start()
     aclient = agent._client
 
-    agentmanager = server.get_slice(SLICE_AGENT_MANAGER)
-    await retry_limited(lambda: len(agentmanager.sessions) == 1, 10)
-
     version = await clienthelper.get_version()
 
     resources = []
     for j in range(10):
         resources.append(
             {
                 "group": "root",
@@ -719,25 +641,25 @@
 
     assert jot != test_token
 
     client_multi._transport_instance.token = jot
 
     # try to access a non environment call (global)
     result = await client_multi.list_environments()
-    assert result.code == 403
+    assert result.code == 401
 
     result = await client_multi.list_versions(environment_multi)
     assert result.code == 200
 
     token = await client_multi.create_token(environment_multi, ["agent"], idempotent=True)
     agent_jot = token.result["token"]
 
     client_multi._transport_instance.token = agent_jot
     result = await client_multi.list_versions(environment_multi)
-    assert result.code == 403
+    assert result.code == 401
 
 
 async def test_token_without_auth(server, client, environment):
     """Generating a token when auth is not enabled is not allowed"""
     token = await client.create_token(environment, ["api"], idempotent=True)
     assert token.code == 400
 
@@ -765,15 +687,15 @@
     await asyncio.get_event_loop().run_in_executor(
         None, lambda: upload_code(sync_client_multi, environment_multi, version, code_manager)
     )
 
     for name, source_info in code_manager.get_types():
         res = await agent_multi._client.get_code(tid=environment_multi, id=version, resource=name)
         assert res.code == 200
-        assert len(source_info) >= 2
+        assert len(source_info) == 2
         for info in source_info:
             assert info.hash in res.result["sources"]
             code = res.result["sources"][info.hash]
 
             # fetch the code from the server
             response = await agent_multi._client.get_file(info.hash)
             assert response.code == 200
@@ -808,15 +730,15 @@
         compiler_version=get_compiler_version(),
     )
     assert res.code == 200
 
     resource_action_log = server.get_slice(SLICE_RESOURCE).get_resource_action_log_file(environment)
     assert os.path.isfile(resource_action_log)
     assert os.stat(resource_action_log).st_size != 0
-    with open(resource_action_log) as f:
+    with open(resource_action_log, "r") as f:
         contents = f.read()
         parts = contents.split(" ")
         # Date and time
         parser.parse(f"{parts[0]} {parts[1]}")
 
 
 async def test_invalid_sid(server, client, environment):
@@ -825,43 +747,23 @@
     """
     # request get_code with a compiler client that does not have a sid
     res = await client.get_code(tid=environment, id=1, resource="std::File")
     assert res.code == 400
     assert res.result["message"] == "Invalid request: this is an agent to server call, it should contain an agent session id"
 
 
-@pytest.mark.parametrize("tz_aware_timestamp", [True, False])
-async def test_get_param(server, client, environment, tz_aware_timestamp: bool):
-    config.Config.set("server", "tz-aware-timestamps", str(tz_aware_timestamp).lower())
-
-    result = await client.set_setting(environment, data.AUTOSTART_AGENT_DEPLOY_SPLAY_TIME, 0)
-    assert result.code == 200
-
+async def test_get_param(server, client, environment):
     metadata = {"key1": "val1", "key2": "val2"}
     await client.set_param(environment, "param", ParameterSource.user, "val", "", metadata, False)
     await client.set_param(environment, "param2", ParameterSource.user, "val2", "", {"a": "b"}, False)
 
     res = await client.list_params(tid=environment, query={"key1": "val1"})
     assert res.code == 200
-
-    def check_datetime_serialization(timestamp: str, tz_aware_timestamp):
-        """
-        Check that the given timestamp was serialized appropriately according to the server.tz-aware-timestamps option.
-        """
-        expected_format: str = const.TIME_ISOFMT
-        if tz_aware_timestamp:
-            expected_format += "%z"
-        is_aware = datetime.strptime(timestamp, expected_format).tzinfo is not None
-        assert is_aware == tz_aware_timestamp
-
-    check_datetime_serialization(res.result["now"], tz_aware_timestamp)
-
     parameters = res.result["parameters"]
     assert len(parameters) == 1
-
     metadata_received = parameters[0]["metadata"]
     assert len(metadata_received) == 2
     for k, v in metadata.items():
         assert k in metadata_received
         assert metadata_received[k] == v
 
     res = await client.list_params(tid=environment, query={})
@@ -886,17 +788,14 @@
 
 async def test_get_resource_actions(postgresql_client, client, clienthelper, server, environment, agent):
     """
     Test querying resource actions via the API
     """
     aclient = agent._client
 
-    agentmanager = server.get_slice(SLICE_AGENT_MANAGER)
-    await retry_limited(lambda: len(agentmanager.sessions) == 1, 10)
-
     version = await clienthelper.get_version()
 
     resources = []
     for j in range(10):
         resources.append(
             {
                 "group": "root",
@@ -908,73 +807,40 @@
                 "purged": False,
                 "reload": False,
                 "requires": [],
                 "version": version,
             }
         )
 
-    #  adding a resource action with its change field set to "created" to test the get_resource_actions
-    #  filtering on resources with changes
-
-    rvid_r1_v1 = f"std::File[agent1,path=/etc/file200],v={version}"
-    resources.append(
-        {
-            "group": "root",
-            "hash": "89bf880a0dc5ffc1156c8d958b4960971370ee6a",
-            "id": rvid_r1_v1,
-            "owner": "root",
-            "path": "/tmp/file200",
-            "permissions": 644,
-            "purged": False,
-            "reload": False,
-            "requires": [],
-            "version": version,
-        }
-    )
-
     res = await client.put_version(
         tid=environment,
         version=version,
         resources=resources,
         unknowns=[],
         version_info={},
         compiler_version=get_compiler_version(),
     )
     assert res.code == 200
 
     result = await client.release_version(environment, version, False)
     assert result.code == 200
 
-    resource_ids_nochange = [x["id"] for x in resources[0:-1]]
-    resource_ids_created = [resources[-1]["id"]]
+    resource_ids = [x["id"] for x in resources]
 
     # Start the deploy
     action_id = uuid.uuid4()
     now = datetime.now().astimezone()
     result = await aclient.resource_action_update(
-        environment,
-        resource_ids_created,
-        action_id,
-        "deploy",
-        now,
-        status=const.ResourceState.deploying,
-        change=const.Change.created,
-    )
-    assert result.code == 200
-
-    action_id = uuid.uuid4()
-    result = await aclient.resource_action_update(
-        environment, resource_ids_nochange, action_id, "deploy", now, status=const.ResourceState.deploying
+        environment, resource_ids, action_id, "deploy", now, status=const.ResourceState.deploying
     )
     assert result.code == 200
 
     # Get the status from a resource
     result = await client.get_resource_actions(tid=environment)
     assert result.code == 200
-    assert len(result.result["data"]) == 3
 
     result = await client.get_resource_actions(tid=environment, attribute="path")
     assert result.code == 400
     result = await client.get_resource_actions(tid=environment, attribute_value="/tmp/file")
     assert result.code == 400
     result = await client.get_resource_actions(tid=environment, attribute="path", attribute_value="/tmp/file1")
     assert result.code == 200
@@ -983,42 +849,22 @@
     result = await client.get_resource_actions(tid=environment, last_timestamp=now)
     assert result.code == 200
     assert len(result.result["data"]) == 1
     assert result.result["data"][0]["action"] == "store"
     # Query actions happening later than the start of the test case
     result = await client.get_resource_actions(tid=environment, first_timestamp=now - timedelta(minutes=1))
     assert result.code == 200
-    assert len(result.result["data"]) == 3
+    assert len(result.result["data"]) == 2
     result = await client.get_resource_actions(tid=environment, first_timestamp=now - timedelta(minutes=1), last_timestamp=now)
     assert result.code == 400
     result = await client.get_resource_actions(tid=environment, action_id=action_id)
     assert result.code == 400
     result = await client.get_resource_actions(tid=environment, first_timestamp=now - timedelta(minutes=1), action_id=action_id)
     assert result.code == 200
-    assert len(result.result["data"]) == 3
-
-    exclude_changes = [const.Change.nochange.value, const.Change.created.value]
-    result = await client.get_resource_actions(tid=environment, exclude_changes=exclude_changes)
-    assert result.code == 200
-    assert len(result.result["data"]) == 0
-
-    exclude_changes = []
-    result = await client.get_resource_actions(tid=environment, exclude_changes=exclude_changes)
-    assert result.code == 200
-    assert len(result.result["data"]) == 3
-
-    exclude_changes = [const.Change.nochange.value]
-    result = await client.get_resource_actions(tid=environment, exclude_changes=exclude_changes)
-    assert result.code == 200
-    assert len(result.result["data"]) == 1  # only one of the 3 resource_actions has change != nochange
-
-    exclude_changes = ["error"]
-    result = await client.get_resource_actions(tid=environment, exclude_changes=exclude_changes)
-    assert result.code == 400
-    assert "Failed to validate argument" in result.result["message"]
+    assert len(result.result["data"]) == 2
 
 
 async def test_resource_action_pagination(postgresql_client, client, clienthelper, server, agent):
     """Test querying resource actions via the API, including the pagination links."""
     project = data.Project(name="test")
     await project.insert()
 
@@ -1101,15 +947,15 @@
     resource_actions = result.result["data"]
     expected_action_ids = [later_action_id] + action_ids_with_the_same_timestamp[:1]
     assert [uuid.UUID(resource_action["action_id"]) for resource_action in resource_actions] == expected_action_ids
 
     # Use the next link for pagination
     next_page = result.result["links"]["next"]
     port = opt.get_bind_port()
-    base_url = f"http://localhost:{port}"
+    base_url = "http://localhost:%s" % (port,)
     url = f"{base_url}{next_page}"
     client = AsyncHTTPClient()
     request = HTTPRequest(
         url=url,
         headers={"X-Inmanta-tid": str(env.id)},
     )
     response = await client.fetch(request, raise_error=False)
@@ -1287,18 +1133,15 @@
         assert result.code == 200
         assert len(result.result["data"]) == resulting_nr_resource_actions
 
     await execute_resource_deploy_start(expected_return_code=200, resulting_nr_resource_actions=1)
     await execute_resource_deploy_start(expected_return_code=409, resulting_nr_resource_actions=1)
 
 
-@pytest.mark.parametrize(
-    "endpoint_to_use",
-    ["resource_deploy_done", "resource_action_update"],
-)
+@pytest.mark.parametrize("endpoint_to_use", ["resource_deploy_done", "resource_action_update"])
 async def test_resource_deploy_done(server, client, environment, agent, caplog, endpoint_to_use):
     """
     Ensure that the `resource_deploy_done` endpoint behaves in the same way as the `resource_action_update` endpoint
     when the finished field is not None.
     """
     env_id = uuid.UUID(environment)
 
@@ -1360,15 +1203,15 @@
     result = await client.get_version(tid=env_id, id=1)
     assert result.code == 200, result.result
     assert not result.result["model"]["deployed"]
 
     caplog.clear()
     with caplog.at_level(logging.DEBUG):
         # Mark deployment as done
-        now = datetime.now().astimezone()
+        now = datetime.now()
         if endpoint_to_use == "resource_deploy_done":
             result = await agent._client.resource_deploy_done(
                 tid=env_id,
                 rvid=rvid_r1_v1,
                 action_id=action_id,
                 status=const.ResourceState.deployed,
                 messages=[
@@ -1409,38 +1252,30 @@
     assert resource_action["environment"] == str(env_id)
     assert resource_action["version"] == model_version
     assert resource_action["resource_version_ids"] == [rvid_r1_v1]
     assert resource_action["action_id"] == str(action_id)
     assert resource_action["action"] == const.ResourceAction.deploy
     assert resource_action["started"] is not None
     assert resource_action["finished"] is not None
-
-    expected_timestamp: str
-    if opt.server_tz_aware_timestamps.get():
-        expected_timestamp = now.astimezone().isoformat(timespec="microseconds")
-    else:
-        expected_timestamp = now.astimezone(timezone.utc).replace(tzinfo=None).isoformat()
-
-    expected_resource_action_messages = [
+    assert resource_action["messages"] == [
         {
             "level": const.LogLevel.DEBUG.name,
             "msg": "message",
             "args": [],
             "kwargs": {"keyword": 123, "none": None},
-            "timestamp": expected_timestamp,
+            "timestamp": now.isoformat(timespec="microseconds"),
         },
         {
             "level": const.LogLevel.INFO.name,
             "msg": "test",
             "args": [],
             "kwargs": {},
-            "timestamp": expected_timestamp,
+            "timestamp": now.isoformat(timespec="microseconds"),
         },
     ]
-    assert resource_action["messages"] == expected_resource_action_messages
     assert resource_action["status"] == const.ResourceState.deployed
     assert resource_action["changes"] == {rvid_r1_v1: {"attr1": AttributeStateChange(current=None, desired="test").dict()}}
     assert resource_action["change"] == const.Change.purged.value
 
     result = await client.get_resource(tid=env_id, id=rvid_r1_v1)
     assert result.code == 200, result.result
     assert result.result["resource"]["last_deploy"] is not None
@@ -1560,31 +1395,31 @@
 
 
 async def test_start_location_no_redirect(server):
     """
     Ensure that there is no redirection for the "start" location. (issue #3497)
     """
     port = opt.get_bind_port()
-    base_url = f"http://localhost:{port}/"
+    base_url = "http://localhost:%s/" % (port,)
     http_client = AsyncHTTPClient()
     request = HTTPRequest(
         url=base_url,
     )
     response = await http_client.fetch(request, raise_error=False)
     assert base_url == response.effective_url
 
 
 @pytest.mark.parametrize("path", ["", "/", "/test"])
 async def test_redirect_dashboard_to_console(server, path):
     """
     Ensure that there is a redirection from the dashboard to the webconsole
     """
     port = opt.get_bind_port()
-    base_url = f"http://localhost:{port}/dashboard{path}"
-    result_url = f"http://localhost:{port}/console{path}"
+    base_url = "http://localhost:%s/dashboard%s" % (port, path)
+    result_url = "http://localhost:%s/console%s" % (port, path)
     http_client = AsyncHTTPClient()
     request = HTTPRequest(
         url=base_url,
     )
     response = await http_client.fetch(request, raise_error=False)
     assert result_url == response.effective_url
 
@@ -1607,14 +1442,21 @@
     await env1.insert()
     env2 = data.Environment(name="env2", project=project.id)
     await env2.insert()
 
     await env1.set(data.AUTOSTART_AGENT_MAP, {"agent3": "", "internal": ""})
     await env2.set(data.AUTOSTART_AGENT_MAP, {"agent1": "", "internal": ""})
 
+    # these checks are here to investigate the fact that the test case is flaky and that we have a suspicion
+    # that it is an issue with the agent map
+    agentmap_env1 = await client.get_setting(tid=env1.id, id=data.AUTOSTART_AGENT_MAP)
+    agentmap_env2 = await client.get_setting(tid=env2.id, id=data.AUTOSTART_AGENT_MAP)
+    assert agentmap_env1.result["value"] == {"agent3": "", "internal": ""}
+    assert agentmap_env2.result["value"] == {"agent1": "", "internal": ""}
+
     if env1_halted:
         result = await client.halt_environment(env1.id)
         assert result.code == 200
     if env2_halted:
         result = await client.halt_environment(env2.id)
         assert result.code == 200
 
@@ -1679,15 +1521,30 @@
         paused=False,
         id_primary=None,
     ).insert()
 
     agents_before_purge = await data.Agent.get_list()
     assert len(agents_before_purge) == 6
 
+    # these checks are here to investigate the fact that the test case is flaky and that we have a suspicion
+    # that it is an issue with the agent map
+    agentmap_env1 = await client.get_setting(tid=env1.id, id=data.AUTOSTART_AGENT_MAP)
+    agentmap_env2 = await client.get_setting(tid=env2.id, id=data.AUTOSTART_AGENT_MAP)
+    assert agentmap_env1.result["value"] == {"agent3": "", "internal": ""}
+    assert agentmap_env2.result["value"] == {"agent1": "", "internal": ""}
+
     await server.get_slice(SLICE_ORCHESTRATION)._purge_versions()
+
+    # these checks are here to investigate the fact that the test case is flaky and that we have a suspicion
+    # that it is an issue with the agent map
+    agentmap_env1 = await client.get_setting(tid=env1.id, id=data.AUTOSTART_AGENT_MAP)
+    agentmap_env2 = await client.get_setting(tid=env2.id, id=data.AUTOSTART_AGENT_MAP)
+    assert agentmap_env1.result["value"] == {"agent3": "", "internal": ""}
+    assert agentmap_env2.result["value"] == {"agent1": "", "internal": ""}
+
     agents_after_purge = [(agent.environment, agent.name) for agent in await data.Agent.get_list()]
     number_agents_env1_after_purge = 4 if env1_halted else 3
     number_agents_env2_after_purge = 2 if env2_halted else 1
     assert len(agents_after_purge) == number_agents_env1_after_purge + number_agents_env2_after_purge
     if not (env1_halted or env2_halted):
         expected_agents_after_purge = [
             (env1.id, "agent2"),
@@ -1751,97 +1608,7 @@
     result = await client.versioned_resource_details(tid=environment, version=version, rid=resource_id)
     assert result.code == 200
     assert result.result["data"]["attributes"] == attributes_on_api
 
     result = await client.resource_details(tid=environment, rid=resource_id)
     assert result.code == 200
     assert result.result["data"]["attributes"] == attributes_on_api
-
-
-@pytest.mark.parametrize("v1_partial,v2_partial", [(False, False), (False, True)])
-# the other two cases require a race condition to trigger
-# as put_partial determines its own version number
-async def test_put_stale_version(client, server, environment, clienthelper, caplog, v1_partial, v2_partial):
-    """Put a version in with auto deploy on that is already stale"""
-    await client.set_setting(environment, AUTO_DEPLOY, True)
-
-    v0 = await clienthelper.get_version()
-    v1 = await clienthelper.get_version()
-    v2 = await clienthelper.get_version()
-
-    async def put_version(version):
-        partial = (version == v1 and v1_partial) or (version == v2 and v2_partial)
-
-        if partial:
-            version = 0
-
-        resource_id = "test::Resource[agent1,key=key1]"
-        resources = [
-            {
-                "id": f"{resource_id},v={version}",
-                "att": "val",
-                "version": version,
-                "send_event": False,
-                "purged": False,
-                "requires": [],
-            }
-        ]
-
-        if partial:
-            result = await client.put_partial(
-                tid=environment,
-                resources=resources,
-                unknowns=[],
-                version_info={},
-            )
-            assert result.code == 200
-
-        else:
-            result = await client.put_version(
-                tid=environment,
-                version=version,
-                resources=resources,
-                unknowns=[],
-                version_info={},
-                compiler_version=get_compiler_version(),
-            )
-            assert result.code == 200
-
-    await put_version(v0)
-
-    with caplog.at_level(logging.WARNING):
-        await put_version(v2)
-        await put_version(v1)
-    log_contains(
-        caplog,
-        "inmanta",
-        logging.WARNING,
-        f"Could not perform auto deploy on version 2 in environment {environment}, "
-        f"because Request conflicts with the current state of the resource: "
-        f"The version 2 on environment {environment} is older then the latest released version",
-    )
-
-
-async def test_delete_active_version(client, clienthelper, server, environment):
-    """
-    Test that the active version cannot be deleted
-    """
-    version = await clienthelper.get_version()
-    assert version == 1
-    res1 = "test::Resource[agent1,key=key1]"
-    res2 = "test::Resource[agent1,key=key2]"
-    resources = [
-        {"key": "key1", "value": "value", "id": f"{res1},v={version}", "requires": [], "purged": False, "send_event": False},
-        {"key": "key2", "value": "value", "id": f"{res2},v={version}", "requires": [], "purged": False, "send_event": False},
-    ]
-
-    await clienthelper.put_version_simple(resources, version)
-
-    result = await client.release_version(
-        environment, version, push=False, agent_trigger_method=const.AgentTriggerMethod.push_full_deploy
-    )
-    assert result.code == 200
-
-    # Remove version 1
-    result = await client.delete_version(tid=environment, id=version)
-    assert result.code == 400
-    assert result.result["message"] == "Invalid request: Cannot delete the active version"
```

### Comparing `inmanta-core-8.7.4/tests/test_type.py` & `inmanta-core-9.3.0/tests/test_type.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,14 +14,15 @@
     limitations under the License.
 
     Contact: code@inmanta.com
 """
 
 import typing
 from functools import reduce
+from typing import Tuple
 
 import pytest
 from more_itertools import pairwise
 
 from inmanta.ast import Location, Namespace, RuntimeException
 from inmanta.ast.attribute import Attribute
 from inmanta.ast.entity import Entity
@@ -29,18 +30,18 @@
 from inmanta.execute.util import NoneValue
 
 
 @pytest.mark.parametrize("base_type_string", TYPES.keys())
 @pytest.mark.parametrize("multi", [True, False])
 @pytest.mark.parametrize("nullable", [True, False])
 def test_dsl_types_type_string(base_type_string: str, multi: bool, nullable: bool):
-    def apply_multi_if(tp: Type, type_string: str) -> tuple[Type, str]:
+    def apply_multi_if(tp: Type, type_string: str) -> Tuple[Type, str]:
         return (TypedList(tp), "%s[]" % type_string) if multi else (tp, type_string)
 
-    def apply_nullable_if(tp: Type, type_string: str) -> tuple[Type, str]:
+    def apply_nullable_if(tp: Type, type_string: str) -> Tuple[Type, str]:
         return (NullableType(tp), "%s?" % type_string) if nullable else (tp, type_string)
 
     assert base_type_string in TYPES
     tp, type_string = apply_nullable_if(*apply_multi_if(TYPES[base_type_string], base_type_string))
 
     assert tp.type_string() == type_string
     assert str(tp) == type_string
@@ -61,36 +62,36 @@
 
     validate(42, not multi)
     validate(NoneValue(), nullable)
     validate([0, 1, 2], multi)
     validate([0, 1, NoneValue()], False)
 
 
-def create_type(base_type: type[Type], multi: bool = False, nullable: bool = False) -> Type:
+def create_type(base_type: typing.Type[Type], multi: bool = False, nullable: bool = False) -> Type:
     base: Type = base_type()
-    transformations: list[typing.Callable[[Type], Type]] = [
+    transformations: typing.List[typing.Callable[[Type], Type]] = [
         lambda t: TypedList(t) if multi else t,
         lambda t: NullableType(t) if nullable else t,
     ]
     return reduce(lambda acc, t: t(acc), transformations, base)
 
 
 @pytest.mark.parametrize("base_type", [Bool, Integer, LiteralDict, LiteralList, Number, String])
-def test_type_equals_simple(base_type: type[Type]) -> None:
+def test_type_equals_simple(base_type: typing.Type[Type]) -> None:
     assert create_type(base_type) == create_type(base_type)
 
 
 def test_type_equals_transformations() -> None:
-    def all_transformations() -> list[Type]:
+    def all_transformations() -> typing.List[Type]:
         return [
             create_type(base_type, multi, nullable)
             for multi in [True, False]
             for nullable in [True, False]
             for base_type in [Integer, Number]
         ]
 
-    l1: list[Type] = all_transformations()
-    l2: list[Type] = all_transformations()
+    l1: typing.List[Type] = all_transformations()
+    l2: typing.List[Type] = all_transformations()
     assert l1 == l2
     for t1, t2 in pairwise(l1):
         assert t1 != t2
         assert t2 != t1
```

### Comparing `inmanta-core-8.7.4/tests/test_usersetup.py` & `inmanta-core-9.3.0/tests/test_usersetup.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 from inmanta.db.util import PGRestore
 from inmanta.server.bootloader import InmantaBootloader
 from inmanta.user_setup import cmd, get_connection_pool
 
 logger = logging.getLogger(__name__)
 
 
-class CLI_user_setup:
+class CLI_user_setup(object):
     async def run(self, run_locally, username, password, *args, **kwargs):
         # set column width very wide so lines are not wrapped
         os.environ["COLUMNS"] = "1000"
         runner = testing.CliRunner(mix_stderr=False)
 
         def invoke():
             return runner.invoke(cli=cmd, input=f"{run_locally}\n{username}\n{password}")
@@ -139,15 +139,15 @@
 
 async def test_user_setup_schema_outdated(
     tmpdir, postgres_db, database_name, postgresql_client, hard_clean_db, hard_clean_db_post
 ):
     setup_config(tmpdir, postgres_db, database_name)
 
     dump_path = os.path.join(os.path.dirname(__file__), "db/migration_tests/dumps/v202211230.sql")
-    with open(dump_path) as fh:
+    with open(dump_path, "r") as fh:
         await PGRestore(fh.readlines(), postgresql_client).run()
 
     cli = CLI_user_setup()
     result = await cli.run("yes", "new_user", "password")
     assert result.exit_code == 1
     assert (
         result.stderr == "Error: The version of the database is out of date: start the server"
```

### Comparing `inmanta-core-8.7.4/tox.ini` & `inmanta-core-9.3.0/tox.ini`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,26 @@
 [tox]
-envlist = pep8,tests,mypy,docs
+envlist = pep8,py39,mypy,docs
 skip_missing_interpreters=True
 requires = pip
            virtualenv >= 20.2.2
 
 [testenv]
 deps=
     -rrequirements.dev.txt
     -rrequirements.txt
-    -c {env:INMANTA_REQUIREMENTS_COMPONENTS_TXT:/dev/null}
 extras=
     dataflow_graphic
 # Set the environment variable INMANTA_EXTRA_PYTEST_ARGS='--fast' to run in fast mode
-commands=py.test --log-level DEBUG --cov=inmanta --cov-report term --cov-report xml --cov-config=pyproject.toml --junitxml=junit-{envname}.xml -vvv {env:INMANTA_EXTRA_PYTEST_ARGS:} --durations=50 tests
+commands=py.test --log-level DEBUG --cov=inmanta --cov-report term --cov-report xml --junitxml=junit-{envname}.xml -vvv {env:INMANTA_EXTRA_PYTEST_ARGS:} --durations=50 tests
 # The HOME environment variable is required for Git to discover the user.email and
 # user.name config options (required by test case: tests/test_app.py::test_init_project)
 # The INMANTA_RETRY_LIMITED_MULTIPLIER is used to set a multiplier in the retry_limited function
 passenv=SSH_AUTH_SOCK,ASYNC_TEST_TIMEOUT,HOME,INMANTA_RETRY_LIMITED_MULTIPLIER
-basepython={env:TOX_PYTHON:python3}
+basepython = python3.9
 
 [testenv:pep8]
 deps=
     -rrequirements.dev.txt
 commands = flake8 --output-file flake8-report.txt --tee src tests tests_common
 commands_post = flake8_junit flake8-report.txt junit-pep8.xml
```

